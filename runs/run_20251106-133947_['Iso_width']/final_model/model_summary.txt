NeuralNetwork(
  (layers): ModuleList(
    (0): Linear(in_features=9, out_features=112, bias=True)
    (1): GELU(approximate='none')
    (2): Dropout(p=0.00014697292771531992, inplace=False)
    (3): Linear(in_features=112, out_features=112, bias=True)
    (4): GELU(approximate='none')
    (5): Dropout(p=0.00014697292771531992, inplace=False)
    (6): Linear(in_features=112, out_features=1, bias=True)
  )
  (dropout): Dropout(p=0.00014697292771531992, inplace=False)
)


--- Torchinfo Summary ---
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [64, 1]                   --
├─ModuleList: 1-5                        --                        (recursive)
│    └─Linear: 2-1                       [64, 112]                 1,120
│    └─GELU: 2-2                         [64, 112]                 --
├─Dropout: 1-2                           [64, 112]                 --
├─ModuleList: 1-5                        --                        (recursive)
│    └─Linear: 2-3                       [64, 112]                 12,656
│    └─GELU: 2-4                         [64, 112]                 --
├─Dropout: 1-4                           [64, 112]                 --
├─ModuleList: 1-5                        --                        (recursive)
│    └─Linear: 2-5                       [64, 1]                   113
==========================================================================================
Total params: 13,889
Trainable params: 13,889
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 0.89
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.12
Params size (MB): 0.06
Estimated Total Size (MB): 0.17
==========================================================================================
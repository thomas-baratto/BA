Job started on argon-gtx
Job ID: 544
Working directory: /home/barattts/lavoltabuona/BA
---
Starting Python script...
Unable to determine the device handle for GPU0000:61:00.0: Unknown Error
Running: python run_optuna.py --target all --skip-optuna
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
2025-11-07 18:35:35,368 - INFO - Using device: cuda
2025-11-07 18:35:35,369 - INFO - Target labels for this run: ['Area', 'Iso_distance', 'Iso_width']
2025-11-07 18:35:35,369 - INFO - Skip Optuna: True
2025-11-07 18:35:35,370 - INFO - Skipping Optuna. Loading best parameters from study: nn_study_Area_Iso_distance_Iso_width...
2025-11-07 18:35:36,074 - ERROR - Study 'nn_study_Area_Iso_distance_Iso_width' not found in database. Available studies:
2025-11-07 18:36:04,048 - ERROR -   - nn_study_['Iso_distance']
2025-11-07 18:36:04,049 - ERROR -   - nn_study_['Area']
2025-11-07 18:36:04,049 - ERROR -   - nn_study_['Iso_width']
2025-11-07 18:36:04,049 - ERROR -   - nn_study_['Area', 'Iso_distance', 'Iso_width']
2025-11-07 18:36:04,049 - INFO - Falling back to default parameters...
2025-11-07 18:36:04,049 - INFO - Training final model with parameters...
2025-11-07 18:36:04,049 - INFO - Starting main training for labels ['Area', 'Iso_distance', 'Iso_width']...
2025-11-07 18:36:06,257 - INFO - Final training: 47896 train samples, 11975 val samples, 25660 test samples.
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
2025-11-07 18:36:06,636 - INFO - Using SmoothL1Loss (Huber Loss)
2025-11-07 18:36:08,285 - INFO - Using CosineAnnealingLR with T_max=1000
2025-11-07 18:36:08,285 - INFO - Added warmup for 10 epochs
2025-11-07 18:36:08,340 - INFO - Starting final training loop for max 1000 epochs (Patience=100)...
2025-11-07 18:36:10,521 - INFO - Epoch [1/1000], Train Loss: 0.026519, Val Loss: 0.004909, LR: 0.000190
2025-11-07 18:36:10,523 - INFO - New best model found at epoch 1 with val_loss: 0.004909
2025-11-07 18:36:12,618 - INFO - New best model found at epoch 2 with val_loss: 0.004368
2025-11-07 18:36:14,612 - INFO - New best model found at epoch 3 with val_loss: 0.004265
2025-11-07 18:36:16,612 - INFO - New best model found at epoch 4 with val_loss: 0.004124
2025-11-07 18:36:18,595 - INFO - New best model found at epoch 5 with val_loss: 0.004042
2025-11-07 18:36:20,548 - INFO - New best model found at epoch 6 with val_loss: 0.003825
2025-11-07 18:36:22,524 - INFO - New best model found at epoch 7 with val_loss: 0.002915
2025-11-07 18:36:24,483 - INFO - New best model found at epoch 8 with val_loss: 0.002420
2025-11-07 18:36:26,434 - INFO - New best model found at epoch 9 with val_loss: 0.002097
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
2025-11-07 18:36:28,393 - INFO - New best model found at epoch 10 with val_loss: 0.001943
2025-11-07 18:36:30,352 - INFO - New best model found at epoch 11 with val_loss: 0.001283
2025-11-07 18:36:32,309 - INFO - New best model found at epoch 12 with val_loss: 0.001255
2025-11-07 18:36:34,268 - INFO - New best model found at epoch 13 with val_loss: 0.000852
2025-11-07 18:36:36,227 - INFO - New best model found at epoch 14 with val_loss: 0.000666
2025-11-07 18:36:38,180 - INFO - New best model found at epoch 15 with val_loss: 0.000488
2025-11-07 18:36:40,139 - INFO - New best model found at epoch 16 with val_loss: 0.000325
2025-11-07 18:36:42,251 - INFO - New best model found at epoch 17 with val_loss: 0.000305
2025-11-07 18:36:44,207 - INFO - New best model found at epoch 18 with val_loss: 0.000277
2025-11-07 18:36:46,165 - INFO - New best model found at epoch 19 with val_loss: 0.000254
2025-11-07 18:36:48,116 - INFO - New best model found at epoch 20 with val_loss: 0.000197
2025-11-07 18:36:53,963 - INFO - New best model found at epoch 23 with val_loss: 0.000151
2025-11-07 18:37:01,769 - INFO - New best model found at epoch 27 with val_loss: 0.000119
2025-11-07 18:37:15,467 - INFO - New best model found at epoch 34 with val_loss: 0.000111
2025-11-07 18:37:19,369 - INFO - New best model found at epoch 36 with val_loss: 0.000091
2025-11-07 18:37:27,186 - INFO - New best model found at epoch 40 with val_loss: 0.000084
2025-11-07 18:37:31,084 - INFO - New best model found at epoch 42 with val_loss: 0.000082
2025-11-07 18:37:44,728 - INFO - New best model found at epoch 49 with val_loss: 0.000076
2025-11-07 18:37:46,682 - INFO - Epoch [50/1000], Train Loss: 0.000301, Val Loss: 0.000116, LR: 0.000996
2025-11-07 18:37:54,488 - INFO - New best model found at epoch 54 with val_loss: 0.000055
2025-11-07 18:38:00,365 - INFO - New best model found at epoch 57 with val_loss: 0.000055
2025-11-07 18:38:08,208 - INFO - New best model found at epoch 61 with val_loss: 0.000044
2025-11-07 18:38:27,629 - INFO - New best model found at epoch 70 with val_loss: 0.000037
2025-11-07 18:39:26,233 - INFO - Epoch [100/1000], Train Loss: 0.000218, Val Loss: 0.000106, LR: 0.000980
2025-11-07 18:39:47,750 - INFO - New best model found at epoch 111 with val_loss: 0.000034
2025-11-07 18:39:59,457 - INFO - New best model found at epoch 117 with val_loss: 0.000032
2025-11-07 18:41:02,899 - INFO - New best model found at epoch 149 with val_loss: 0.000030
2025-11-07 18:41:04,865 - INFO - Epoch [150/1000], Train Loss: 0.000198, Val Loss: 0.000056, LR: 0.000952
slurmstepd-argon-gtx: error: *** JOB 544 ON argon-gtx CANCELLED AT 2025-11-07T18:41:55 ***

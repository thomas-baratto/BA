Job started on argon-gtx
Job ID: 494
Working directory: /home/barattts/lavoltabuona/BA
---
Starting Python script...
Running: python run_optuna.py --target Iso_distance
2025-11-04 00:09:53,720 - INFO - Using device: cuda
2025-11-04 00:09:53,721 - INFO - Target labels for this run: ['Iso_distance']
2025-11-04 00:09:53,722 - INFO - Loading data for Optuna study (Labels: ['Iso_distance'])...
2025-11-04 00:09:53,889 - INFO - Starting Optuna study: nn_study_['Iso_distance']...
[I 2025-11-04 00:09:54,574] A new study created in RDB with name: nn_study_['Iso_distance']
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
2025-11-04 00:10:21,931 - INFO - Trial 0: Early stopping at epoch 36.
[I 2025-11-04 00:10:22,005] Trial 0 finished with value: 0.10577362641624002 and parameters: {'batch_size': 512, 'learning_rate': 0.001464124310101362, 'nr_hidden_layers': 4, 'nr_neurons': 23, 'dropout_rate': 0.21742096578306513, 'weight_decay': 0.0004321195558221104, 'activation_name': 'ELU', 'loss_criterion': 'L1'}. Best is trial 0 with value: 0.10577362641624002.
2025-11-04 00:12:32,103 - INFO - Trial 1: Early stopping at epoch 262.
[I 2025-11-04 00:12:32,176] Trial 1 finished with value: 0.0430841981159748 and parameters: {'batch_size': 1024, 'learning_rate': 0.0018150644503945029, 'nr_hidden_layers': 2, 'nr_neurons': 29, 'dropout_rate': 0.2832851485749906, 'weight_decay': 0.0011328836889006536, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1 with value: 0.0430841981159748.
2025-11-04 00:16:03,401 - INFO - Trial 2: Early stopping at epoch 181.
[I 2025-11-04 00:16:03,476] Trial 2 finished with value: 0.006632452666792627 and parameters: {'batch_size': 128, 'learning_rate': 0.0005237646735142144, 'nr_hidden_layers': 3, 'nr_neurons': 56, 'dropout_rate': 0.003404193828735913, 'weight_decay': 0.004017672937151894, 'activation_name': 'ELU', 'loss_criterion': 'SmoothL1'}. Best is trial 2 with value: 0.006632452666792627.
2025-11-04 00:17:19,263 - INFO - Trial 3: Early stopping at epoch 40.
[I 2025-11-04 00:17:19,325] Trial 3 finished with value: 0.03331770830274678 and parameters: {'batch_size': 64, 'learning_rate': 0.0018174614493323702, 'nr_hidden_layers': 3, 'nr_neurons': 157, 'dropout_rate': 0.26437323973163046, 'weight_decay': 0.0002507920099453685, 'activation_name': 'LeakyReLU', 'loss_criterion': 'L1'}. Best is trial 2 with value: 0.006632452666792627.
2025-11-04 00:18:51,148 - INFO - Trial 4: Early stopping at epoch 74.
[I 2025-11-04 00:18:51,222] Trial 4 finished with value: 0.11323591673517193 and parameters: {'batch_size': 128, 'learning_rate': 0.00016062457820091678, 'nr_hidden_layers': 5, 'nr_neurons': 25, 'dropout_rate': 0.40445794588030415, 'weight_decay': 2.2749068746057516e-06, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 2 with value: 0.006632452666792627.
[I 2025-11-04 00:19:00,786] Trial 5 pruned. 
[I 2025-11-04 00:19:07,900] Trial 6 pruned. 
[I 2025-11-04 00:19:14,962] Trial 7 pruned. 
2025-11-04 00:21:37,079 - INFO - Trial 8: Early stopping at epoch 83.
[I 2025-11-04 00:21:37,143] Trial 8 finished with value: 0.031822730466804665 and parameters: {'batch_size': 64, 'learning_rate': 0.006763128868474857, 'nr_hidden_layers': 2, 'nr_neurons': 16, 'dropout_rate': 0.09694263867358921, 'weight_decay': 0.00022299601179073892, 'activation_name': 'ELU', 'loss_criterion': 'SmoothL1'}. Best is trial 2 with value: 0.006632452666792627.
[I 2025-11-04 00:21:53,839] Trial 9 pruned. 
2025-11-04 00:25:22,611 - INFO - Trial 10: Early stopping at epoch 194.
[I 2025-11-04 00:25:22,675] Trial 10 finished with value: 0.004347477482690176 and parameters: {'batch_size': 128, 'learning_rate': 0.0004103660293884363, 'nr_hidden_layers': 3, 'nr_neurons': 75, 'dropout_rate': 0.001786205129865578, 'weight_decay': 0.0066002419095396924, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004347477482690176.
2025-11-04 00:26:51,872 - INFO - Trial 11: Early stopping at epoch 78.
[I 2025-11-04 00:26:51,935] Trial 11 finished with value: 0.01612908949768679 and parameters: {'batch_size': 128, 'learning_rate': 0.0004102684911822293, 'nr_hidden_layers': 3, 'nr_neurons': 70, 'dropout_rate': 0.032172720890426124, 'weight_decay': 0.007496811524309368, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004347477482690176.
[I 2025-11-04 00:26:58,737] Trial 12 pruned. 
[I 2025-11-04 00:27:07,664] Trial 13 pruned. 
[I 2025-11-04 00:27:17,846] Trial 14 pruned. 
[I 2025-11-04 00:28:41,446] Trial 15 pruned. 
[I 2025-11-04 00:28:53,396] Trial 16 pruned. 
[I 2025-11-04 00:29:02,419] Trial 17 pruned. 
[I 2025-11-04 00:29:09,148] Trial 18 pruned. 
[I 2025-11-04 00:30:41,884] Trial 19 pruned. 
[I 2025-11-04 00:32:56,096] Trial 20 pruned. 
2025-11-04 00:34:31,961 - INFO - Trial 21: Early stopping at epoch 83.
[I 2025-11-04 00:34:32,035] Trial 21 finished with value: 0.01734720820400451 and parameters: {'batch_size': 128, 'learning_rate': 0.00037604070196680685, 'nr_hidden_layers': 3, 'nr_neurons': 66, 'dropout_rate': 0.028674027138635816, 'weight_decay': 0.008387700496925816, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004347477482690176.
[I 2025-11-04 00:36:26,032] Trial 22 pruned. 
[I 2025-11-04 00:37:29,117] Trial 23 pruned. 
[I 2025-11-04 00:38:11,998] Trial 24 pruned. 
[I 2025-11-04 00:38:23,025] Trial 25 pruned. 
[I 2025-11-04 00:38:28,991] Trial 26 pruned. 
[I 2025-11-04 00:38:37,076] Trial 27 pruned. 
[I 2025-11-04 00:38:43,638] Trial 28 pruned. 
[I 2025-11-04 00:38:50,620] Trial 29 pruned. 
[I 2025-11-04 00:39:05,595] Trial 30 pruned. 
[I 2025-11-04 00:40:47,494] Trial 31 pruned. 
[I 2025-11-04 00:40:59,391] Trial 32 pruned. 
2025-11-04 00:41:48,940 - INFO - Trial 33: Early stopping at epoch 45.
[I 2025-11-04 00:41:49,004] Trial 33 finished with value: 0.017254846879953104 and parameters: {'batch_size': 128, 'learning_rate': 0.0008360162660419982, 'nr_hidden_layers': 3, 'nr_neurons': 112, 'dropout_rate': 0.07055239962469467, 'weight_decay': 0.001269278471688075, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004347477482690176.
2025-11-04 00:42:32,075 - INFO - Trial 34: Early stopping at epoch 39.
[I 2025-11-04 00:42:32,139] Trial 34 finished with value: 0.017563775119412716 and parameters: {'batch_size': 128, 'learning_rate': 0.002662098568359999, 'nr_hidden_layers': 3, 'nr_neurons': 119, 'dropout_rate': 0.07994445637209771, 'weight_decay': 0.0014929077303863566, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004347477482690176.
[I 2025-11-04 00:42:44,069] Trial 35 pruned. 
[I 2025-11-04 00:42:55,108] Trial 36 pruned. 
[I 2025-11-04 00:43:31,791] Trial 37 pruned. 
[I 2025-11-04 00:43:38,815] Trial 38 pruned. 
[I 2025-11-04 00:43:44,313] Trial 39 pruned. 
[I 2025-11-04 00:43:57,332] Trial 40 pruned. 
[I 2025-11-04 00:45:50,899] Trial 41 pruned. 
[I 2025-11-04 00:46:02,862] Trial 42 pruned. 
2025-11-04 00:47:14,744 - INFO - Trial 43: Early stopping at epoch 66.
[I 2025-11-04 00:47:14,810] Trial 43 finished with value: 0.009784632305196581 and parameters: {'batch_size': 128, 'learning_rate': 0.0005093237537397269, 'nr_hidden_layers': 3, 'nr_neurons': 121, 'dropout_rate': 0.025197516561268774, 'weight_decay': 0.003209790088648428, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004347477482690176.
2025-11-04 00:53:48,033 - INFO - Trial 44: Early stopping at epoch 213.
[I 2025-11-04 00:53:48,114] Trial 44 finished with value: 0.0027419648336115703 and parameters: {'batch_size': 64, 'learning_rate': 0.000502681104300028, 'nr_hidden_layers': 3, 'nr_neurons': 123, 'dropout_rate': 0.0007104012739901529, 'weight_decay': 0.0028318043427496627, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 44 with value: 0.0027419648336115703.
2025-11-04 00:58:17,855 - INFO - Trial 45: Early stopping at epoch 148.
[I 2025-11-04 00:58:17,925] Trial 45 finished with value: 0.00356880615293325 and parameters: {'batch_size': 64, 'learning_rate': 0.0005035819075519207, 'nr_hidden_layers': 3, 'nr_neurons': 162, 'dropout_rate': 0.0009713221254046963, 'weight_decay': 0.0026456743204461997, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 44 with value: 0.0027419648336115703.
2025-11-04 01:02:00,484 - INFO - Trial 46: Early stopping at epoch 129.
[I 2025-11-04 01:02:00,563] Trial 46 finished with value: 0.0037084005630292137 and parameters: {'batch_size': 64, 'learning_rate': 0.0005456447457397402, 'nr_hidden_layers': 2, 'nr_neurons': 173, 'dropout_rate': 0.002480861665108219, 'weight_decay': 0.0026030593731986335, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 44 with value: 0.0027419648336115703.
[I 2025-11-04 01:04:49,801] Trial 47 pruned. 
[I 2025-11-04 01:06:55,449] Trial 48 pruned. 
[I 2025-11-04 01:07:13,571] Trial 49 pruned. 
2025-11-04 01:08:43,104 - INFO - Trial 50: Early stopping at epoch 49.
[I 2025-11-04 01:08:43,171] Trial 50 finished with value: 0.007060704515983902 and parameters: {'batch_size': 64, 'learning_rate': 0.00462974874745702, 'nr_hidden_layers': 2, 'nr_neurons': 236, 'dropout_rate': 0.0017718618261557933, 'weight_decay': 0.000548438313421064, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 44 with value: 0.0027419648336115703.
2025-11-04 01:10:31,344 - INFO - Trial 51: Early stopping at epoch 64.
[I 2025-11-04 01:10:31,412] Trial 51 finished with value: 0.007700892882402331 and parameters: {'batch_size': 64, 'learning_rate': 0.003921122583767387, 'nr_hidden_layers': 2, 'nr_neurons': 213, 'dropout_rate': 0.0013234424762200217, 'weight_decay': 0.00014185849348337726, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 44 with value: 0.0027419648336115703.
2025-11-04 01:11:35,420 - INFO - Trial 52: Early stopping at epoch 37.
[I 2025-11-04 01:11:35,486] Trial 52 finished with value: 0.012271587616147547 and parameters: {'batch_size': 64, 'learning_rate': 0.004090357329825023, 'nr_hidden_layers': 2, 'nr_neurons': 251, 'dropout_rate': 0.018065824213006926, 'weight_decay': 0.0005524467284482731, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 44 with value: 0.0027419648336115703.
2025-11-04 01:12:51,633 - INFO - Trial 53: Early stopping at epoch 50.
[I 2025-11-04 01:12:51,700] Trial 53 finished with value: 0.00974652053320453 and parameters: {'batch_size': 64, 'learning_rate': 0.001117004783153428, 'nr_hidden_layers': 1, 'nr_neurons': 208, 'dropout_rate': 0.04379546945306812, 'weight_decay': 0.003007848899990575, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 44 with value: 0.0027419648336115703.
[I 2025-11-04 01:13:09,876] Trial 54 pruned. 
[I 2025-11-04 01:13:44,492] Trial 55 pruned. 
[I 2025-11-04 01:14:40,578] Trial 56 pruned. 
[I 2025-11-04 01:15:54,142] Trial 57 pruned. 
[I 2025-11-04 01:16:10,430] Trial 58 pruned. 
[I 2025-11-04 01:16:21,505] Trial 59 pruned. 
[I 2025-11-04 01:16:28,248] Trial 60 pruned. 
[I 2025-11-04 01:18:52,394] Trial 61 pruned. 
[I 2025-11-04 01:20:06,226] Trial 62 pruned. 
2025-11-04 01:21:49,578 - INFO - Trial 63: Early stopping at epoch 62.
[I 2025-11-04 01:21:49,646] Trial 63 finished with value: 0.007104721323722819 and parameters: {'batch_size': 64, 'learning_rate': 0.0031103321156164005, 'nr_hidden_layers': 2, 'nr_neurons': 223, 'dropout_rate': 0.0026537893037496133, 'weight_decay': 0.0004234683963122765, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 44 with value: 0.0027419648336115703.
2025-11-04 01:23:53,045 - INFO - Trial 64: Early stopping at epoch 66.
[I 2025-11-04 01:23:53,112] Trial 64 finished with value: 0.01028975467450908 and parameters: {'batch_size': 64, 'learning_rate': 0.003225907776130749, 'nr_hidden_layers': 3, 'nr_neurons': 234, 'dropout_rate': 0.01557199651396964, 'weight_decay': 0.0016632075467264116, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 44 with value: 0.0027419648336115703.
[I 2025-11-04 01:24:16,721] Trial 65 pruned. 
[I 2025-11-04 01:24:23,426] Trial 66 pruned. 
[I 2025-11-04 01:24:52,351] Trial 67 pruned. 
[I 2025-11-04 01:24:58,861] Trial 68 pruned. 
[I 2025-11-04 01:25:06,676] Trial 69 pruned. 
[I 2025-11-04 01:25:47,089] Trial 70 pruned. 
2025-11-04 01:28:45,758 - INFO - Trial 71: Early stopping at epoch 108.
[I 2025-11-04 01:28:45,827] Trial 71 finished with value: 0.004260428762878103 and parameters: {'batch_size': 64, 'learning_rate': 0.004017691952261499, 'nr_hidden_layers': 2, 'nr_neurons': 222, 'dropout_rate': 2.179087166467701e-05, 'weight_decay': 0.0004453453185797179, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 44 with value: 0.0027419648336115703.
2025-11-04 01:29:59,719 - INFO - Trial 72: Early stopping at epoch 40.
[I 2025-11-04 01:29:59,789] Trial 72 finished with value: 0.00951058844842985 and parameters: {'batch_size': 64, 'learning_rate': 0.008721739615594342, 'nr_hidden_layers': 2, 'nr_neurons': 223, 'dropout_rate': 0.001258237807770536, 'weight_decay': 0.0005002791376248146, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 44 with value: 0.0027419648336115703.
2025-11-04 01:31:49,218 - INFO - Trial 73: Early stopping at epoch 60.
[I 2025-11-04 01:31:49,286] Trial 73 finished with value: 0.011848041947441665 and parameters: {'batch_size': 64, 'learning_rate': 0.0049982422045713746, 'nr_hidden_layers': 2, 'nr_neurons': 187, 'dropout_rate': 0.01597155783138656, 'weight_decay': 0.0001953166778997075, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 44 with value: 0.0027419648336115703.
[I 2025-11-04 01:31:54,875] Trial 74 pruned. 
[I 2025-11-04 01:32:32,834] Trial 75 pruned. 
[I 2025-11-04 01:32:50,929] Trial 76 pruned. 
[I 2025-11-04 01:32:57,796] Trial 77 pruned. 
[I 2025-11-04 01:33:29,313] Trial 78 pruned. 
[I 2025-11-04 01:33:47,393] Trial 79 pruned. 
[I 2025-11-04 01:34:21,804] Trial 80 pruned. 
2025-11-04 01:36:19,669 - INFO - Trial 81: Early stopping at epoch 71.
[I 2025-11-04 01:36:19,737] Trial 81 finished with value: 0.007150936197296884 and parameters: {'batch_size': 64, 'learning_rate': 0.0037508174908923216, 'nr_hidden_layers': 2, 'nr_neurons': 219, 'dropout_rate': 0.002611520781718822, 'weight_decay': 0.00025537715409686785, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 44 with value: 0.0027419648336115703.
[I 2025-11-04 01:38:42,591] Trial 82 pruned. 
2025-11-04 01:39:48,380 - INFO - Trial 83: Early stopping at epoch 39.
[I 2025-11-04 01:39:48,449] Trial 83 finished with value: 0.011724706467158631 and parameters: {'batch_size': 64, 'learning_rate': 0.004982415918792495, 'nr_hidden_layers': 2, 'nr_neurons': 187, 'dropout_rate': 0.014977154105161957, 'weight_decay': 0.000425684460381223, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 44 with value: 0.0027419648336115703.
[I 2025-11-04 01:42:33,773] Trial 84 pruned. 
[I 2025-11-04 01:42:39,234] Trial 85 pruned. 
[I 2025-11-04 01:42:59,620] Trial 86 pruned. 
[I 2025-11-04 01:43:06,512] Trial 87 pruned. 
[I 2025-11-04 01:44:05,434] Trial 88 pruned. 
[I 2025-11-04 01:44:18,270] Trial 89 pruned. 
[I 2025-11-04 01:44:38,060] Trial 90 pruned. 
[I 2025-11-04 01:47:23,237] Trial 91 pruned. 
2025-11-04 01:49:39,578 - INFO - Trial 92: Early stopping at epoch 78.
[I 2025-11-04 01:49:39,650] Trial 92 finished with value: 0.005984729964623303 and parameters: {'batch_size': 64, 'learning_rate': 0.0007899073552396785, 'nr_hidden_layers': 2, 'nr_neurons': 221, 'dropout_rate': 0.010526501221107244, 'weight_decay': 8.36248314892921e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 44 with value: 0.0027419648336115703.
[I 2025-11-04 01:52:01,028] Trial 93 pruned. 
[I 2025-11-04 01:52:19,063] Trial 94 pruned. 
[I 2025-11-04 01:52:37,256] Trial 95 pruned. 
[I 2025-11-04 01:52:49,324] Trial 96 pruned. 
[I 2025-11-04 01:52:55,839] Trial 97 pruned. 
[I 2025-11-04 01:53:15,851] Trial 98 pruned. 
[I 2025-11-04 01:53:37,845] Trial 99 pruned. 
[I 2025-11-04 01:53:52,406] Trial 100 pruned. 
[I 2025-11-04 01:55:59,311] Trial 101 pruned. 
2025-11-04 02:02:45,605 - INFO - Trial 102: Early stopping at epoch 236.
[I 2025-11-04 02:02:45,676] Trial 102 finished with value: 0.002736527031669631 and parameters: {'batch_size': 64, 'learning_rate': 0.0004050463783961723, 'nr_hidden_layers': 2, 'nr_neurons': 230, 'dropout_rate': 0.0012284988892881693, 'weight_decay': 0.00016742133064808154, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 102 with value: 0.002736527031669631.
[I 2025-11-04 02:03:03,801] Trial 103 pruned. 
2025-11-04 02:06:59,505 - INFO - Trial 104: Early stopping at epoch 118.
[I 2025-11-04 02:06:59,575] Trial 104 finished with value: 0.004698027544462263 and parameters: {'batch_size': 64, 'learning_rate': 0.0003798304372630141, 'nr_hidden_layers': 2, 'nr_neurons': 233, 'dropout_rate': 0.008502837467829824, 'weight_decay': 0.0006244793454617315, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 102 with value: 0.002736527031669631.
[I 2025-11-04 02:07:17,764] Trial 105 pruned. 
[I 2025-11-04 02:07:38,259] Trial 106 pruned. 
[I 2025-11-04 02:07:43,842] Trial 107 pruned. 
[I 2025-11-04 02:07:52,390] Trial 108 pruned. 
[I 2025-11-04 02:07:59,085] Trial 109 pruned. 
[I 2025-11-04 02:08:19,142] Trial 110 pruned. 
[I 2025-11-04 02:13:54,349] Trial 111 pruned. 
2025-11-04 02:15:03,381 - INFO - Trial 112: Early stopping at epoch 40.
[I 2025-11-04 02:15:03,462] Trial 112 finished with value: 0.01146352199310455 and parameters: {'batch_size': 64, 'learning_rate': 0.004643402869265936, 'nr_hidden_layers': 2, 'nr_neurons': 254, 'dropout_rate': 0.010771857085300107, 'weight_decay': 0.004900727421855273, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 102 with value: 0.002736527031669631.
[I 2025-11-04 02:15:22,969] Trial 113 pruned. 
[I 2025-11-04 02:15:41,346] Trial 114 pruned. 
[I 2025-11-04 02:15:52,534] Trial 115 pruned. 
2025-11-04 02:21:32,848 - INFO - Trial 116: Early stopping at epoch 201.
[I 2025-11-04 02:21:32,919] Trial 116 finished with value: 0.002600859137495801 and parameters: {'batch_size': 64, 'learning_rate': 0.0010011734384461387, 'nr_hidden_layers': 2, 'nr_neurons': 236, 'dropout_rate': 0.0004281630846809164, 'weight_decay': 0.00016396578327553286, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 116 with value: 0.002600859137495801.
[I 2025-11-04 02:21:52,851] Trial 117 pruned. 
[I 2025-11-04 02:22:11,130] Trial 118 pruned. 
[I 2025-11-04 02:22:23,550] Trial 119 pruned. 
[I 2025-11-04 02:22:39,857] Trial 120 pruned. 
2025-11-04 02:26:54,736 - INFO - Trial 121: Early stopping at epoch 153.
[I 2025-11-04 02:26:54,807] Trial 121 finished with value: 0.00326906952898818 and parameters: {'batch_size': 64, 'learning_rate': 0.0003708381714998441, 'nr_hidden_layers': 2, 'nr_neurons': 227, 'dropout_rate': 9.795935778046053e-05, 'weight_decay': 0.0001553811108383373, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 116 with value: 0.002600859137495801.
[I 2025-11-04 02:27:14,580] Trial 122 pruned. 
[I 2025-11-04 02:27:32,826] Trial 123 pruned. 
2025-11-04 02:42:10,488 - INFO - Trial 124: Early stopping at epoch 495.
[I 2025-11-04 02:42:10,566] Trial 124 finished with value: 0.0014025710088954345 and parameters: {'batch_size': 64, 'learning_rate': 0.0004941338722825084, 'nr_hidden_layers': 2, 'nr_neurons': 211, 'dropout_rate': 0.000634511537600873, 'weight_decay': 0.001615577890788605, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 02:42:28,714] Trial 125 pruned. 
[I 2025-11-04 02:42:35,183] Trial 126 pruned. 
2025-11-04 02:48:19,317 - INFO - Trial 127: Early stopping at epoch 188.
[I 2025-11-04 02:48:19,393] Trial 127 finished with value: 0.0024707233492679403 and parameters: {'batch_size': 64, 'learning_rate': 0.00036262689752666134, 'nr_hidden_layers': 3, 'nr_neurons': 153, 'dropout_rate': 1.4085690882474709e-06, 'weight_decay': 0.002806148438883635, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 02:48:39,900] Trial 128 pruned. 
[I 2025-11-04 02:48:59,974] Trial 129 pruned. 
[I 2025-11-04 02:49:12,110] Trial 130 pruned. 
[I 2025-11-04 02:49:32,218] Trial 131 pruned. 
[I 2025-11-04 02:49:50,456] Trial 132 pruned. 
[I 2025-11-04 02:50:10,361] Trial 133 pruned. 
2025-11-04 02:54:07,226 - INFO - Trial 134: Early stopping at epoch 137.
[I 2025-11-04 02:54:07,302] Trial 134 finished with value: 0.0037359924473688777 and parameters: {'batch_size': 64, 'learning_rate': 0.0011283361163225369, 'nr_hidden_layers': 2, 'nr_neurons': 194, 'dropout_rate': 0.0010611369286360603, 'weight_decay': 0.003363600982165219, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 02:55:40,932] Trial 135 pruned. 
[I 2025-11-04 02:56:07,092] Trial 136 pruned. 
[I 2025-11-04 02:56:15,331] Trial 137 pruned. 
[I 2025-11-04 02:56:33,412] Trial 138 pruned. 
[I 2025-11-04 02:56:39,276] Trial 139 pruned. 
[I 2025-11-04 02:56:46,027] Trial 140 pruned. 
[I 2025-11-04 02:57:07,531] Trial 141 pruned. 
[I 2025-11-04 02:57:25,713] Trial 142 pruned. 
[I 2025-11-04 03:06:38,782] Trial 143 pruned. 
[I 2025-11-04 03:07:06,420] Trial 144 pruned. 
2025-11-04 03:09:15,473 - INFO - Trial 145: Early stopping at epoch 56.
[I 2025-11-04 03:09:15,547] Trial 145 finished with value: 0.00767368525996858 and parameters: {'batch_size': 64, 'learning_rate': 0.000981254434369635, 'nr_hidden_layers': 2, 'nr_neurons': 203, 'dropout_rate': 0.013186747268603, 'weight_decay': 0.00016560293202499453, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 03:09:27,692] Trial 146 pruned. 
2025-11-04 03:15:44,069 - INFO - Trial 147: Early stopping at epoch 216.
[I 2025-11-04 03:15:44,145] Trial 147 finished with value: 0.0019898815114433254 and parameters: {'batch_size': 64, 'learning_rate': 0.0008450634792141459, 'nr_hidden_layers': 2, 'nr_neurons': 169, 'dropout_rate': 2.3446622188030798e-05, 'weight_decay': 0.00013157448175000588, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 03:17:26,026] Trial 148 pruned. 
[I 2025-11-04 03:19:34,890] Trial 149 pruned. 
[I 2025-11-04 03:23:10,310] Trial 150 pruned. 
2025-11-04 03:26:06,749 - INFO - Trial 151: Early stopping at epoch 88.
[I 2025-11-04 03:26:06,838] Trial 151 finished with value: 0.003380752181388711 and parameters: {'batch_size': 64, 'learning_rate': 0.0011929576990290277, 'nr_hidden_layers': 2, 'nr_neurons': 224, 'dropout_rate': 0.00010445474580343022, 'weight_decay': 0.0021458567244575528, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 03:28:46,746 - INFO - Trial 152: Early stopping at epoch 87.
[I 2025-11-04 03:28:46,822] Trial 152 finished with value: 0.003482655388725292 and parameters: {'batch_size': 64, 'learning_rate': 0.0011445817264393754, 'nr_hidden_layers': 2, 'nr_neurons': 155, 'dropout_rate': 3.1410990285483985e-05, 'weight_decay': 0.0019676266652507114, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 03:30:56,308] Trial 153 pruned. 
[I 2025-11-04 03:32:11,506] Trial 154 pruned. 
2025-11-04 03:35:23,280 - INFO - Trial 155: Early stopping at epoch 110.
[I 2025-11-04 03:35:23,355] Trial 155 finished with value: 0.003955517335334714 and parameters: {'batch_size': 64, 'learning_rate': 0.0010879048109849947, 'nr_hidden_layers': 2, 'nr_neurons': 139, 'dropout_rate': 0.0029649171588637118, 'weight_decay': 0.00198593659192311, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 03:40:29,670 - INFO - Trial 156: Early stopping at epoch 181.
[I 2025-11-04 03:40:29,746] Trial 156 finished with value: 0.002328564141507512 and parameters: {'batch_size': 64, 'learning_rate': 0.0010947994941510456, 'nr_hidden_layers': 2, 'nr_neurons': 155, 'dropout_rate': 4.888115736481258e-05, 'weight_decay': 0.0014817534065135192, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 03:44:33,641 - INFO - Trial 157: Early stopping at epoch 135.
[I 2025-11-04 03:44:33,725] Trial 157 finished with value: 0.002972831845756176 and parameters: {'batch_size': 64, 'learning_rate': 0.0010643863039157995, 'nr_hidden_layers': 2, 'nr_neurons': 133, 'dropout_rate': 0.00011243331790940854, 'weight_decay': 0.0015071054273934606, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 03:48:24,595 - INFO - Trial 158: Early stopping at epoch 135.
[I 2025-11-04 03:48:24,672] Trial 158 finished with value: 0.003766703532535838 and parameters: {'batch_size': 64, 'learning_rate': 0.0010564592038851983, 'nr_hidden_layers': 2, 'nr_neurons': 134, 'dropout_rate': 0.0017885198482670474, 'weight_decay': 0.0015201109936461162, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 03:52:48,607 - INFO - Trial 159: Early stopping at epoch 154.
[I 2025-11-04 03:52:48,684] Trial 159 finished with value: 0.003565666730247467 and parameters: {'batch_size': 64, 'learning_rate': 0.0011086600246829937, 'nr_hidden_layers': 2, 'nr_neurons': 136, 'dropout_rate': 0.0006406493243942525, 'weight_decay': 0.001443172282221923, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 03:54:01,283] Trial 160 pruned. 
2025-11-04 03:58:05,551 - INFO - Trial 161: Early stopping at epoch 142.
[I 2025-11-04 03:58:05,627] Trial 161 finished with value: 0.003097514507156064 and parameters: {'batch_size': 64, 'learning_rate': 0.0010696653293739559, 'nr_hidden_layers': 2, 'nr_neurons': 147, 'dropout_rate': 0.0002776680317550716, 'weight_decay': 0.002129112093937054, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 04:00:10,001] Trial 162 pruned. 
[I 2025-11-04 04:02:21,339] Trial 163 pruned. 
[I 2025-11-04 04:03:17,561] Trial 164 pruned. 
2025-11-04 04:06:44,340 - INFO - Trial 165: Early stopping at epoch 120.
[I 2025-11-04 04:06:44,420] Trial 165 finished with value: 0.0037885462127523212 and parameters: {'batch_size': 64, 'learning_rate': 0.0009303618008648239, 'nr_hidden_layers': 2, 'nr_neurons': 146, 'dropout_rate': 0.0010300934061516819, 'weight_decay': 0.0029551960700069284, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 04:09:36,743 - INFO - Trial 166: Early stopping at epoch 102.
[I 2025-11-04 04:09:36,828] Trial 166 finished with value: 0.004468470903971741 and parameters: {'batch_size': 64, 'learning_rate': 0.0012625990449779555, 'nr_hidden_layers': 2, 'nr_neurons': 126, 'dropout_rate': 0.0013537894857101342, 'weight_decay': 0.0016891978291789923, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 04:11:12,198] Trial 167 pruned. 
2025-11-04 04:14:12,979 - INFO - Trial 168: Early stopping at epoch 93.
[I 2025-11-04 04:14:13,056] Trial 168 finished with value: 0.00368665192570413 and parameters: {'batch_size': 64, 'learning_rate': 0.001111832720722653, 'nr_hidden_layers': 2, 'nr_neurons': 140, 'dropout_rate': 0.00012137135984066736, 'weight_decay': 0.0008866207670712296, 'activation_name': 'ReLU', 'loss_criterion': 'L1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 04:14:31,750] Trial 169 pruned. 
[I 2025-11-04 04:14:50,500] Trial 170 pruned. 
[I 2025-11-04 04:15:09,571] Trial 171 pruned. 
2025-11-04 04:19:26,706 - INFO - Trial 172: Early stopping at epoch 135.
[I 2025-11-04 04:19:26,783] Trial 172 finished with value: 0.003220403688457592 and parameters: {'batch_size': 64, 'learning_rate': 0.0010888404036678324, 'nr_hidden_layers': 2, 'nr_neurons': 142, 'dropout_rate': 3.216952986850809e-05, 'weight_decay': 0.0014357600177445581, 'activation_name': 'ReLU', 'loss_criterion': 'L1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 04:20:03,320] Trial 173 pruned. 
[I 2025-11-04 04:20:54,932] Trial 174 pruned. 
[I 2025-11-04 04:21:02,465] Trial 175 pruned. 
[I 2025-11-04 04:21:32,480] Trial 176 pruned. 
[I 2025-11-04 04:22:09,979] Trial 177 pruned. 
[I 2025-11-04 04:22:48,695] Trial 178 pruned. 
[I 2025-11-04 04:24:45,593] Trial 179 pruned. 
2025-11-04 04:27:00,558 - INFO - Trial 180: Early stopping at epoch 78.
[I 2025-11-04 04:27:00,636] Trial 180 finished with value: 0.004784647059353562 and parameters: {'batch_size': 64, 'learning_rate': 0.0012298665441504053, 'nr_hidden_layers': 2, 'nr_neurons': 158, 'dropout_rate': 0.00020538939515917792, 'weight_decay': 0.003907194937208135, 'activation_name': 'ReLU', 'loss_criterion': 'L1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 04:28:27,008] Trial 181 pruned. 
2025-11-04 04:33:27,702 - INFO - Trial 182: Early stopping at epoch 181.
[I 2025-11-04 04:33:27,781] Trial 182 finished with value: 0.00264414240248031 and parameters: {'batch_size': 64, 'learning_rate': 0.0010661421522244797, 'nr_hidden_layers': 2, 'nr_neurons': 116, 'dropout_rate': 0.00015030970776363934, 'weight_decay': 0.0011650831346495976, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 04:34:10,549] Trial 183 pruned. 
[I 2025-11-04 04:34:28,828] Trial 184 pruned. 
2025-11-04 04:37:03,929 - INFO - Trial 185: Early stopping at epoch 87.
[I 2025-11-04 04:37:04,012] Trial 185 finished with value: 0.004349431395194782 and parameters: {'batch_size': 64, 'learning_rate': 0.0013323848545496164, 'nr_hidden_layers': 2, 'nr_neurons': 117, 'dropout_rate': 0.0003394115049668758, 'weight_decay': 0.0020971260243644704, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 04:38:44,523 - INFO - Trial 186: Early stopping at epoch 60.
[I 2025-11-04 04:38:44,600] Trial 186 finished with value: 0.006809902959769582 and parameters: {'batch_size': 64, 'learning_rate': 0.0010059537924802047, 'nr_hidden_layers': 2, 'nr_neurons': 140, 'dropout_rate': 0.015947611409413177, 'weight_decay': 0.0017687535936336193, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 04:38:52,831] Trial 187 pruned. 
[I 2025-11-04 04:39:11,194] Trial 188 pruned. 
[I 2025-11-04 04:39:16,942] Trial 189 pruned. 
[I 2025-11-04 04:39:23,863] Trial 190 pruned. 
[I 2025-11-04 04:44:54,987] Trial 191 pruned. 
[I 2025-11-04 04:46:40,231] Trial 192 pruned. 
2025-11-04 04:50:34,899 - INFO - Trial 193: Early stopping at epoch 140.
[I 2025-11-04 04:50:34,978] Trial 193 finished with value: 0.003697778422669676 and parameters: {'batch_size': 64, 'learning_rate': 0.0011286732800895247, 'nr_hidden_layers': 2, 'nr_neurons': 111, 'dropout_rate': 0.0008729588490950459, 'weight_decay': 0.0014836291560913033, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 04:50:53,303] Trial 194 pruned. 
[I 2025-11-04 04:51:11,570] Trial 195 pruned. 
[I 2025-11-04 04:53:08,304] Trial 196 pruned. 
[I 2025-11-04 04:53:26,604] Trial 197 pruned. 
2025-11-04 04:55:53,140 - INFO - Trial 198: Early stopping at epoch 87.
[I 2025-11-04 04:55:53,216] Trial 198 finished with value: 0.0032644342895483997 and parameters: {'batch_size': 64, 'learning_rate': 0.0012241293461130367, 'nr_hidden_layers': 2, 'nr_neurons': 171, 'dropout_rate': 1.4562063274119638e-05, 'weight_decay': 0.0010707584342351275, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 04:56:11,650] Trial 199 pruned. 
2025-11-04 05:00:15,616 - INFO - Trial 200: Early stopping at epoch 122.
[I 2025-11-04 05:00:15,700] Trial 200 finished with value: 0.0040473558224578135 and parameters: {'batch_size': 64, 'learning_rate': 0.001700400356719344, 'nr_hidden_layers': 2, 'nr_neurons': 101, 'dropout_rate': 0.0007692929322914178, 'weight_decay': 0.0012062828279284143, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 05:03:17,806 - INFO - Trial 201: Early stopping at epoch 109.
[I 2025-11-04 05:03:17,882] Trial 201 finished with value: 0.003906489808201943 and parameters: {'batch_size': 64, 'learning_rate': 0.001090645161144671, 'nr_hidden_layers': 2, 'nr_neurons': 173, 'dropout_rate': 0.0008058767835497356, 'weight_decay': 0.0014726014381444123, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 05:06:13,628 - INFO - Trial 202: Early stopping at epoch 93.
[I 2025-11-04 05:06:13,713] Trial 202 finished with value: 0.004005666680507542 and parameters: {'batch_size': 64, 'learning_rate': 0.001924688070681475, 'nr_hidden_layers': 2, 'nr_neurons': 163, 'dropout_rate': 0.00015099423587086662, 'weight_decay': 0.0019392901701886878, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 05:08:23,226] Trial 203 pruned. 
[I 2025-11-04 05:09:31,105] Trial 204 pruned. 
[I 2025-11-04 05:10:08,846] Trial 205 pruned. 
2025-11-04 05:16:47,694 - INFO - Trial 206: Early stopping at epoch 225.
[I 2025-11-04 05:16:47,774] Trial 206 finished with value: 0.002189329047703308 and parameters: {'batch_size': 64, 'learning_rate': 0.0010729954221354095, 'nr_hidden_layers': 2, 'nr_neurons': 198, 'dropout_rate': 0.0001130589805357236, 'weight_decay': 0.00020584029170743782, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 05:17:30,998] Trial 207 pruned. 
[I 2025-11-04 05:17:49,864] Trial 208 pruned. 
[I 2025-11-04 05:18:08,276] Trial 209 pruned. 
[I 2025-11-04 05:18:14,835] Trial 210 pruned. 
2025-11-04 05:20:58,630 - INFO - Trial 211: Early stopping at epoch 93.
[I 2025-11-04 05:20:58,708] Trial 211 finished with value: 0.0037458191760280177 and parameters: {'batch_size': 64, 'learning_rate': 0.001138295683949767, 'nr_hidden_layers': 2, 'nr_neurons': 205, 'dropout_rate': 0.00016322118876689953, 'weight_decay': 0.0011719975687682976, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 05:24:23,014 - INFO - Trial 212: Early stopping at epoch 118.
[I 2025-11-04 05:24:23,093] Trial 212 finished with value: 0.0032936310253812912 and parameters: {'batch_size': 64, 'learning_rate': 0.0010780390059449067, 'nr_hidden_layers': 2, 'nr_neurons': 189, 'dropout_rate': 0.0002845702140844261, 'weight_decay': 0.00020234527929574188, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 05:24:58,138] Trial 213 pruned. 
2025-11-04 05:27:58,014 - INFO - Trial 214: Early stopping at epoch 108.
[I 2025-11-04 05:27:58,091] Trial 214 finished with value: 0.0031234550428902693 and parameters: {'batch_size': 64, 'learning_rate': 0.000937772835971642, 'nr_hidden_layers': 2, 'nr_neurons': 154, 'dropout_rate': 7.445767857633412e-05, 'weight_decay': 0.00017534149511559506, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 05:33:13,788 - INFO - Trial 215: Early stopping at epoch 185.
[I 2025-11-04 05:33:13,875] Trial 215 finished with value: 0.002526113692367512 and parameters: {'batch_size': 64, 'learning_rate': 0.0009070190303736628, 'nr_hidden_layers': 2, 'nr_neurons': 154, 'dropout_rate': 8.904488052556114e-05, 'weight_decay': 0.00017237477166894284, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 05:33:46,901] Trial 216 pruned. 
[I 2025-11-04 05:34:11,625] Trial 217 pruned. 
2025-11-04 05:38:21,638 - INFO - Trial 218: Early stopping at epoch 145.
[I 2025-11-04 05:38:21,716] Trial 218 finished with value: 0.002873904949904688 and parameters: {'batch_size': 64, 'learning_rate': 0.0008903800941555055, 'nr_hidden_layers': 2, 'nr_neurons': 160, 'dropout_rate': 0.00013315947604348056, 'weight_decay': 0.0001904763099848399, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 05:38:46,514] Trial 219 pruned. 
[I 2025-11-04 05:39:08,089] Trial 220 pruned. 
2025-11-04 05:42:29,001 - INFO - Trial 221: Early stopping at epoch 114.
[I 2025-11-04 05:42:29,080] Trial 221 finished with value: 0.004107235581999068 and parameters: {'batch_size': 64, 'learning_rate': 0.0010020365483636216, 'nr_hidden_layers': 2, 'nr_neurons': 145, 'dropout_rate': 0.000729138171612859, 'weight_decay': 0.00018670663143725385, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 05:42:52,389] Trial 222 pruned. 
[I 2025-11-04 05:43:10,713] Trial 223 pruned. 
2025-11-04 05:50:13,342 - INFO - Trial 224: Early stopping at epoch 244.
[I 2025-11-04 05:50:13,422] Trial 224 finished with value: 0.0021349352716399416 and parameters: {'batch_size': 64, 'learning_rate': 0.0012285746075680693, 'nr_hidden_layers': 2, 'nr_neurons': 160, 'dropout_rate': 5.3185948897159496e-05, 'weight_decay': 0.00021828754071910516, 'activation_name': 'ReLU', 'loss_criterion': 'L1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 05:51:20,555] Trial 225 pruned. 
[I 2025-11-04 05:51:48,831] Trial 226 pruned. 
2025-11-04 05:55:38,039 - INFO - Trial 227: Early stopping at epoch 136.
[I 2025-11-04 05:55:38,116] Trial 227 finished with value: 0.0026916802502238834 and parameters: {'batch_size': 64, 'learning_rate': 0.001265045935044363, 'nr_hidden_layers': 2, 'nr_neurons': 155, 'dropout_rate': 4.788795033306857e-06, 'weight_decay': 0.00013225936043057611, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 05:56:44,161] Trial 228 pruned. 
[I 2025-11-04 05:57:02,483] Trial 229 pruned. 
[I 2025-11-04 05:57:08,252] Trial 230 pruned. 
[I 2025-11-04 05:59:27,979] Trial 231 pruned. 
[I 2025-11-04 05:59:47,739] Trial 232 pruned. 
[I 2025-11-04 06:00:06,033] Trial 233 pruned. 
[I 2025-11-04 06:00:14,285] Trial 234 pruned. 
[I 2025-11-04 06:01:20,507] Trial 235 pruned. 
[I 2025-11-04 06:01:38,848] Trial 236 pruned. 
[I 2025-11-04 06:01:45,667] Trial 237 pruned. 
[I 2025-11-04 06:02:08,900] Trial 238 pruned. 
2025-11-04 06:06:44,310 - INFO - Trial 239: Early stopping at epoch 154.
[I 2025-11-04 06:06:44,389] Trial 239 finished with value: 0.0028141284094382875 and parameters: {'batch_size': 64, 'learning_rate': 0.0010738325520895221, 'nr_hidden_layers': 2, 'nr_neurons': 148, 'dropout_rate': 0.00032604859397397765, 'weight_decay': 0.00016243190450576094, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 06:09:40,410 - INFO - Trial 240: Early stopping at epoch 104.
[I 2025-11-04 06:09:40,491] Trial 240 finished with value: 0.003482996694768421 and parameters: {'batch_size': 64, 'learning_rate': 0.0010496308689748896, 'nr_hidden_layers': 2, 'nr_neurons': 144, 'dropout_rate': 0.00013305990971712874, 'weight_decay': 0.0001662755260744532, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 06:13:55,652 - INFO - Trial 241: Early stopping at epoch 149.
[I 2025-11-04 06:13:55,731] Trial 241 finished with value: 0.0032417757980888018 and parameters: {'batch_size': 64, 'learning_rate': 0.0010766012059939356, 'nr_hidden_layers': 2, 'nr_neurons': 149, 'dropout_rate': 0.00037492767703824827, 'weight_decay': 0.00013432714093688665, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 06:18:32,787 - INFO - Trial 242: Early stopping at epoch 163.
[I 2025-11-04 06:18:32,866] Trial 242 finished with value: 0.002181221830770796 and parameters: {'batch_size': 64, 'learning_rate': 0.001032143682646054, 'nr_hidden_layers': 2, 'nr_neurons': 149, 'dropout_rate': 1.0509703126559923e-05, 'weight_decay': 0.00013039390639909206, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 06:20:08,018] Trial 243 pruned. 
[I 2025-11-04 06:21:10,879] Trial 244 pruned. 
[I 2025-11-04 06:23:01,597] Trial 245 pruned. 
2025-11-04 06:26:31,386 - INFO - Trial 246: Early stopping at epoch 125.
[I 2025-11-04 06:26:31,465] Trial 246 finished with value: 0.0032172370914164417 and parameters: {'batch_size': 64, 'learning_rate': 0.0011053028674509631, 'nr_hidden_layers': 2, 'nr_neurons': 162, 'dropout_rate': 0.0003118993557702625, 'weight_decay': 9.639703543784781e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 06:27:06,242] Trial 247 pruned. 
2025-11-04 06:31:55,844 - INFO - Trial 248: Early stopping at epoch 174.
[I 2025-11-04 06:31:55,924] Trial 248 finished with value: 0.002689606236089681 and parameters: {'batch_size': 64, 'learning_rate': 0.0009318605761010236, 'nr_hidden_layers': 2, 'nr_neurons': 142, 'dropout_rate': 0.00010508633651321348, 'weight_decay': 0.00010482527104434738, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 06:32:14,280] Trial 249 pruned. 
[I 2025-11-04 06:32:32,667] Trial 250 pruned. 
[I 2025-11-04 06:32:51,101] Trial 251 pruned. 
2025-11-04 06:38:03,289 - INFO - Trial 252: Early stopping at epoch 182.
[I 2025-11-04 06:38:03,379] Trial 252 finished with value: 0.002621917981579163 and parameters: {'batch_size': 64, 'learning_rate': 0.000981131750161911, 'nr_hidden_layers': 2, 'nr_neurons': 172, 'dropout_rate': 6.660656036286866e-06, 'weight_decay': 6.448927567398765e-05, 'activation_name': 'ReLU', 'loss_criterion': 'L1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 06:38:22,110] Trial 253 pruned. 
[I 2025-11-04 06:38:40,855] Trial 254 pruned. 
[I 2025-11-04 06:38:59,592] Trial 255 pruned. 
[I 2025-11-04 06:39:06,185] Trial 256 pruned. 
[I 2025-11-04 06:39:24,842] Trial 257 pruned. 
[I 2025-11-04 06:39:43,604] Trial 258 pruned. 
[I 2025-11-04 06:40:01,912] Trial 259 pruned. 
[I 2025-11-04 06:40:20,146] Trial 260 pruned. 
[I 2025-11-04 06:40:38,478] Trial 261 pruned. 
[I 2025-11-04 06:40:56,795] Trial 262 pruned. 
[I 2025-11-04 06:41:15,556] Trial 263 pruned. 
[I 2025-11-04 06:41:37,159] Trial 264 pruned. 
2025-11-04 06:45:56,491 - INFO - Trial 265: Early stopping at epoch 150.
[I 2025-11-04 06:45:56,584] Trial 265 finished with value: 0.0028185947274756273 and parameters: {'batch_size': 64, 'learning_rate': 0.0010505105767477315, 'nr_hidden_layers': 2, 'nr_neurons': 180, 'dropout_rate': 0.00039296417516028985, 'weight_decay': 4.2642899274157143e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 06:46:04,834] Trial 266 pruned. 
[I 2025-11-04 06:46:27,918] Trial 267 pruned. 
[I 2025-11-04 06:46:33,678] Trial 268 pruned. 
[I 2025-11-04 06:46:55,711] Trial 269 pruned. 
[I 2025-11-04 06:47:36,701] Trial 270 pruned. 
[I 2025-11-04 06:47:43,470] Trial 271 pruned. 
[I 2025-11-04 06:48:01,829] Trial 272 pruned. 
[I 2025-11-04 06:48:18,290] Trial 273 pruned. 
[I 2025-11-04 06:49:29,657] Trial 274 pruned. 
2025-11-04 06:56:30,510 - INFO - Trial 275: Early stopping at epoch 248.
[I 2025-11-04 06:56:30,593] Trial 275 finished with value: 0.0022102894470309516 and parameters: {'batch_size': 64, 'learning_rate': 0.0011531787036974856, 'nr_hidden_layers': 2, 'nr_neurons': 155, 'dropout_rate': 0.000167980739332999, 'weight_decay': 0.00022182811200201075, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 06:56:54,065] Trial 276 pruned. 
[I 2025-11-04 06:57:12,439] Trial 277 pruned. 
[I 2025-11-04 06:57:30,882] Trial 278 pruned. 
[I 2025-11-04 06:57:50,940] Trial 279 pruned. 
[I 2025-11-04 06:58:09,768] Trial 280 pruned. 
[I 2025-11-04 06:58:28,172] Trial 281 pruned. 
[I 2025-11-04 06:58:48,269] Trial 282 pruned. 
[I 2025-11-04 06:59:12,979] Trial 283 pruned. 
[I 2025-11-04 06:59:19,540] Trial 284 pruned. 
2025-11-04 07:02:53,982 - INFO - Trial 285: Early stopping at epoch 128.
[I 2025-11-04 07:02:54,063] Trial 285 finished with value: 0.003219504349177117 and parameters: {'batch_size': 64, 'learning_rate': 0.0011760578135620115, 'nr_hidden_layers': 2, 'nr_neurons': 195, 'dropout_rate': 0.0003576078594976816, 'weight_decay': 0.0001248701612751741, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 07:03:15,638] Trial 286 pruned. 
[I 2025-11-04 07:03:34,405] Trial 287 pruned. 
[I 2025-11-04 07:04:40,668] Trial 288 pruned. 
2025-11-04 07:07:13,813 - INFO - Trial 289: Early stopping at epoch 88.
[I 2025-11-04 07:07:13,908] Trial 289 finished with value: 0.004394202377344986 and parameters: {'batch_size': 64, 'learning_rate': 0.001128665825536847, 'nr_hidden_layers': 2, 'nr_neurons': 189, 'dropout_rate': 0.000743980582671726, 'weight_decay': 0.0003072492943343599, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 07:11:17,800 - INFO - Trial 290: Early stopping at epoch 135.
[I 2025-11-04 07:11:17,882] Trial 290 finished with value: 0.003421820924228345 and parameters: {'batch_size': 64, 'learning_rate': 0.0014611070893308814, 'nr_hidden_layers': 2, 'nr_neurons': 199, 'dropout_rate': 0.0005367249677315195, 'weight_decay': 0.00013712152078507802, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 07:11:36,229] Trial 291 pruned. 
[I 2025-11-04 07:11:56,148] Trial 292 pruned. 
[I 2025-11-04 07:12:02,503] Trial 293 pruned. 
[I 2025-11-04 07:12:11,323] Trial 294 pruned. 
[I 2025-11-04 07:12:29,654] Trial 295 pruned. 
[I 2025-11-04 07:12:52,551] Trial 296 pruned. 
[I 2025-11-04 07:13:35,726] Trial 297 pruned. 
[I 2025-11-04 07:13:42,328] Trial 298 pruned. 
2025-11-04 07:16:50,730 - INFO - Trial 299: Early stopping at epoch 98.
[I 2025-11-04 07:16:50,813] Trial 299 finished with value: 0.0036472680439493645 and parameters: {'batch_size': 64, 'learning_rate': 0.0008415525060434176, 'nr_hidden_layers': 2, 'nr_neurons': 243, 'dropout_rate': 0.00010351875527725676, 'weight_decay': 0.00021502012737027048, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 07:17:11,296] Trial 300 pruned. 
[I 2025-11-04 07:17:46,249] Trial 301 pruned. 
[I 2025-11-04 07:18:04,567] Trial 302 pruned. 
[I 2025-11-04 07:18:22,839] Trial 303 pruned. 
[I 2025-11-04 07:19:06,028] Trial 304 pruned. 
[I 2025-11-04 07:19:25,449] Trial 305 pruned. 
[I 2025-11-04 07:19:50,665] Trial 306 pruned. 
[I 2025-11-04 07:20:09,462] Trial 307 pruned. 
[I 2025-11-04 07:20:36,082] Trial 308 pruned. 
[I 2025-11-04 07:20:54,496] Trial 309 pruned. 
[I 2025-11-04 07:21:01,250] Trial 310 pruned. 
[I 2025-11-04 07:21:19,609] Trial 311 pruned. 
[I 2025-11-04 07:21:41,277] Trial 312 pruned. 
2025-11-04 07:26:40,458 - INFO - Trial 313: Early stopping at epoch 174.
[I 2025-11-04 07:26:40,541] Trial 313 finished with value: 0.002581924520492699 and parameters: {'batch_size': 64, 'learning_rate': 0.0009305106370196334, 'nr_hidden_layers': 2, 'nr_neurons': 124, 'dropout_rate': 0.0003441810215180159, 'weight_decay': 0.00017552205509853232, 'activation_name': 'ReLU', 'loss_criterion': 'L1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 07:26:58,793] Trial 314 pruned. 
[I 2025-11-04 07:27:17,098] Trial 315 pruned. 
[I 2025-11-04 07:27:35,332] Trial 316 pruned. 
[I 2025-11-04 07:27:55,879] Trial 317 pruned. 
[I 2025-11-04 07:28:15,894] Trial 318 pruned. 
2025-11-04 07:31:37,804 - INFO - Trial 319: Early stopping at epoch 116.
[I 2025-11-04 07:31:37,887] Trial 319 finished with value: 0.00391905982737577 and parameters: {'batch_size': 64, 'learning_rate': 0.0009963874246856094, 'nr_hidden_layers': 2, 'nr_neurons': 134, 'dropout_rate': 0.0011974853113191483, 'weight_decay': 0.00032499764455842675, 'activation_name': 'ReLU', 'loss_criterion': 'L1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 07:31:49,853] Trial 320 pruned. 
[I 2025-11-04 07:31:55,962] Trial 321 pruned. 
[I 2025-11-04 07:32:14,401] Trial 322 pruned. 
[I 2025-11-04 07:32:23,156] Trial 323 pruned. 
[I 2025-11-04 07:32:44,716] Trial 324 pruned. 
[I 2025-11-04 07:32:51,462] Trial 325 pruned. 
[I 2025-11-04 07:33:23,583] Trial 326 pruned. 
[I 2025-11-04 07:33:49,936] Trial 327 pruned. 
[I 2025-11-04 07:34:08,339] Trial 328 pruned. 
[I 2025-11-04 07:34:26,708] Trial 329 pruned. 
2025-11-04 07:36:40,779 - INFO - Trial 330: Early stopping at epoch 75.
[I 2025-11-04 07:36:40,861] Trial 330 finished with value: 0.004239225331523972 and parameters: {'batch_size': 64, 'learning_rate': 0.0009524203141684051, 'nr_hidden_layers': 2, 'nr_neurons': 184, 'dropout_rate': 0.00017145126185885554, 'weight_decay': 0.00021869866850023845, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 07:37:00,104] Trial 331 pruned. 
[I 2025-11-04 07:37:18,905] Trial 332 pruned. 
[I 2025-11-04 07:37:43,929] Trial 333 pruned. 
[I 2025-11-04 07:38:02,341] Trial 334 pruned. 
[I 2025-11-04 07:38:20,753] Trial 335 pruned. 
[I 2025-11-04 07:38:39,161] Trial 336 pruned. 
[I 2025-11-04 07:38:57,546] Trial 337 pruned. 
[I 2025-11-04 07:39:21,575] Trial 338 pruned. 
[I 2025-11-04 07:39:28,253] Trial 339 pruned. 
2025-11-04 07:43:56,300 - INFO - Trial 340: Early stopping at epoch 159.
[I 2025-11-04 07:43:56,382] Trial 340 finished with value: 0.002818765902240196 and parameters: {'batch_size': 64, 'learning_rate': 0.0008796967388499717, 'nr_hidden_layers': 2, 'nr_neurons': 170, 'dropout_rate': 0.0001703833988702932, 'weight_decay': 0.00012844439753093687, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 07:48:00,617 - INFO - Trial 341: Early stopping at epoch 130.
[I 2025-11-04 07:48:00,703] Trial 341 finished with value: 0.002511789597956366 and parameters: {'batch_size': 64, 'learning_rate': 0.0008494003866116144, 'nr_hidden_layers': 3, 'nr_neurons': 166, 'dropout_rate': 4.9836970841759986e-05, 'weight_decay': 0.00014922195296788811, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 07:48:19,062] Trial 342 pruned. 
[I 2025-11-04 07:48:40,445] Trial 343 pruned. 
[I 2025-11-04 07:49:00,733] Trial 344 pruned. 
[I 2025-11-04 07:49:20,799] Trial 345 pruned. 
[I 2025-11-04 07:49:40,810] Trial 346 pruned. 
[I 2025-11-04 07:50:01,061] Trial 347 pruned. 
[I 2025-11-04 07:50:13,298] Trial 348 pruned. 
[I 2025-11-04 07:50:22,052] Trial 349 pruned. 
[I 2025-11-04 07:50:46,176] Trial 350 pruned. 
[I 2025-11-04 07:50:52,301] Trial 351 pruned. 
[I 2025-11-04 07:51:10,639] Trial 352 pruned. 
[I 2025-11-04 07:51:28,970] Trial 353 pruned. 
[I 2025-11-04 07:51:47,364] Trial 354 pruned. 
[I 2025-11-04 07:52:06,162] Trial 355 pruned. 
[I 2025-11-04 07:52:13,020] Trial 356 pruned. 
[I 2025-11-04 07:52:31,716] Trial 357 pruned. 
[I 2025-11-04 07:52:50,465] Trial 358 pruned. 
[I 2025-11-04 07:53:08,846] Trial 359 pruned. 
[I 2025-11-04 07:53:28,921] Trial 360 pruned. 
[I 2025-11-04 07:53:48,914] Trial 361 pruned. 
2025-11-04 07:56:54,517 - INFO - Trial 362: Early stopping at epoch 108.
[I 2025-11-04 07:56:54,612] Trial 362 finished with value: 0.0035166159479547623 and parameters: {'batch_size': 64, 'learning_rate': 0.0009985313954908822, 'nr_hidden_layers': 2, 'nr_neurons': 243, 'dropout_rate': 0.0006599489441831714, 'weight_decay': 0.00017240166215848812, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 07:57:12,950] Trial 363 pruned. 
2025-11-04 08:02:20,780 - INFO - Trial 364: Early stopping at epoch 168.
[I 2025-11-04 08:02:20,864] Trial 364 finished with value: 0.002545475465700974 and parameters: {'batch_size': 64, 'learning_rate': 0.0008063739044349488, 'nr_hidden_layers': 3, 'nr_neurons': 159, 'dropout_rate': 6.264900620925287e-05, 'weight_decay': 0.002698479876865853, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 08:02:40,904] Trial 365 pruned. 
[I 2025-11-04 08:03:01,570] Trial 366 pruned. 
[I 2025-11-04 08:03:08,404] Trial 367 pruned. 
[I 2025-11-04 08:03:28,613] Trial 368 pruned. 
[I 2025-11-04 08:03:48,875] Trial 369 pruned. 
[I 2025-11-04 08:04:08,949] Trial 370 pruned. 
[I 2025-11-04 08:04:30,730] Trial 371 pruned. 
[I 2025-11-04 08:04:50,950] Trial 372 pruned. 
[I 2025-11-04 08:05:11,611] Trial 373 pruned. 
[I 2025-11-04 08:05:23,805] Trial 374 pruned. 
[I 2025-11-04 08:05:43,624] Trial 375 pruned. 
[I 2025-11-04 08:06:16,720] Trial 376 pruned. 
[I 2025-11-04 08:06:34,955] Trial 377 pruned. 
[I 2025-11-04 08:06:43,204] Trial 378 pruned. 
[I 2025-11-04 08:06:48,988] Trial 379 pruned. 
[I 2025-11-04 08:07:07,588] Trial 380 pruned. 
2025-11-04 08:11:42,589 - INFO - Trial 381: Early stopping at epoch 161.
[I 2025-11-04 08:11:42,673] Trial 381 finished with value: 0.003316937539859509 and parameters: {'batch_size': 64, 'learning_rate': 0.0010333057337551306, 'nr_hidden_layers': 2, 'nr_neurons': 141, 'dropout_rate': 0.0005444908816880922, 'weight_decay': 0.00011171704216617433, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 08:12:01,084] Trial 382 pruned. 
[I 2025-11-04 08:12:08,002] Trial 383 pruned. 
[I 2025-11-04 08:12:26,475] Trial 384 pruned. 
[I 2025-11-04 08:12:49,789] Trial 385 pruned. 
[I 2025-11-04 08:13:08,145] Trial 386 pruned. 
[I 2025-11-04 08:13:26,940] Trial 387 pruned. 
[I 2025-11-04 08:13:45,230] Trial 388 pruned. 
2025-11-04 08:17:16,556 - INFO - Trial 389: Early stopping at epoch 115.
[I 2025-11-04 08:17:16,639] Trial 389 finished with value: 0.0033685195726641825 and parameters: {'batch_size': 64, 'learning_rate': 0.001055198675697974, 'nr_hidden_layers': 3, 'nr_neurons': 157, 'dropout_rate': 9.073700706268542e-05, 'weight_decay': 0.0001880616078850381, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 08:17:35,529] Trial 390 pruned. 
[I 2025-11-04 08:17:51,928] Trial 391 pruned. 
2025-11-04 08:20:21,857 - INFO - Trial 392: Early stopping at epoch 86.
[I 2025-11-04 08:20:21,938] Trial 392 finished with value: 0.003483344886475839 and parameters: {'batch_size': 64, 'learning_rate': 0.0012137206460128243, 'nr_hidden_layers': 2, 'nr_neurons': 256, 'dropout_rate': 0.00016732085021666282, 'weight_decay': 1.8001721906612216e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 08:20:40,682] Trial 393 pruned. 
[I 2025-11-04 08:20:59,040] Trial 394 pruned. 
[I 2025-11-04 08:21:05,605] Trial 395 pruned. 
[I 2025-11-04 08:21:23,999] Trial 396 pruned. 
[I 2025-11-04 08:21:44,107] Trial 397 pruned. 
[I 2025-11-04 08:22:27,780] Trial 398 pruned. 
[I 2025-11-04 08:22:46,750] Trial 399 pruned. 
2025-11-04 08:25:33,803 - INFO - Trial 400: Early stopping at epoch 100.
[I 2025-11-04 08:25:33,885] Trial 400 finished with value: 0.0035010058293389527 and parameters: {'batch_size': 64, 'learning_rate': 0.0013591800908396888, 'nr_hidden_layers': 2, 'nr_neurons': 77, 'dropout_rate': 1.4972267990123357e-05, 'weight_decay': 0.00018210655590833496, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 08:25:52,662] Trial 401 pruned. 
[I 2025-11-04 08:26:03,838] Trial 402 pruned. 
[I 2025-11-04 08:26:28,752] Trial 403 pruned. 
[I 2025-11-04 08:26:47,040] Trial 404 pruned. 
[I 2025-11-04 08:26:52,929] Trial 405 pruned. 
[I 2025-11-04 08:27:11,236] Trial 406 pruned. 
[I 2025-11-04 08:27:29,876] Trial 407 pruned. 
[I 2025-11-04 08:27:50,077] Trial 408 pruned. 
[I 2025-11-04 08:28:56,126] Trial 409 pruned. 
[I 2025-11-04 08:29:14,438] Trial 410 pruned. 
[I 2025-11-04 08:29:22,623] Trial 411 pruned. 
[I 2025-11-04 08:30:25,338] Trial 412 pruned. 
[I 2025-11-04 08:30:32,120] Trial 413 pruned. 
[I 2025-11-04 08:30:50,418] Trial 414 pruned. 
[I 2025-11-04 08:31:08,779] Trial 415 pruned. 
2025-11-04 08:37:02,802 - INFO - Trial 416: Early stopping at epoch 160.
[I 2025-11-04 08:37:02,886] Trial 416 finished with value: 0.003203570749033642 and parameters: {'batch_size': 64, 'learning_rate': 0.0010040266737558882, 'nr_hidden_layers': 4, 'nr_neurons': 244, 'dropout_rate': 0.00015189788521989298, 'weight_decay': 0.0010583247337491372, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 08:37:21,205] Trial 417 pruned. 
[I 2025-11-04 08:37:43,455] Trial 418 pruned. 
[I 2025-11-04 08:38:01,879] Trial 419 pruned. 
[I 2025-11-04 08:38:20,765] Trial 420 pruned. 
[I 2025-11-04 08:38:38,981] Trial 421 pruned. 
[I 2025-11-04 08:38:57,223] Trial 422 pruned. 
[I 2025-11-04 08:39:25,437] Trial 423 pruned. 
2025-11-04 08:43:11,229 - INFO - Trial 424: Early stopping at epoch 136.
[I 2025-11-04 08:43:11,313] Trial 424 finished with value: 0.003106484700324317 and parameters: {'batch_size': 64, 'learning_rate': 0.0012433534394549887, 'nr_hidden_layers': 2, 'nr_neurons': 137, 'dropout_rate': 0.00012206729989845428, 'weight_decay': 0.0023328049922080605, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 08:43:18,057] Trial 425 pruned. 
[I 2025-11-04 08:43:41,729] Trial 426 pruned. 
[I 2025-11-04 08:44:00,296] Trial 427 pruned. 
[I 2025-11-04 08:44:18,540] Trial 428 pruned. 
[I 2025-11-04 08:44:36,764] Trial 429 pruned. 
[I 2025-11-04 08:44:48,867] Trial 430 pruned. 
[I 2025-11-04 08:45:09,169] Trial 431 pruned. 
2025-11-04 08:47:47,337 - INFO - Trial 432: Early stopping at epoch 92.
[I 2025-11-04 08:47:47,420] Trial 432 finished with value: 0.003941979995882784 and parameters: {'batch_size': 64, 'learning_rate': 0.0010155788274317536, 'nr_hidden_layers': 2, 'nr_neurons': 221, 'dropout_rate': 0.0003836866708473759, 'weight_decay': 0.0002179631983992897, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 08:47:55,665] Trial 433 pruned. 
[I 2025-11-04 08:48:01,456] Trial 434 pruned. 
[I 2025-11-04 08:48:19,807] Trial 435 pruned. 
[I 2025-11-04 08:48:39,793] Trial 436 pruned. 
[I 2025-11-04 08:48:58,172] Trial 437 pruned. 
[I 2025-11-04 08:49:04,815] Trial 438 pruned. 
[I 2025-11-04 08:49:23,088] Trial 439 pruned. 
[I 2025-11-04 08:49:41,653] Trial 440 pruned. 
2025-11-04 08:54:51,809 - INFO - Trial 441: Early stopping at epoch 181.
[I 2025-11-04 08:54:51,894] Trial 441 finished with value: 0.002662070350764793 and parameters: {'batch_size': 64, 'learning_rate': 0.0012922940748408532, 'nr_hidden_layers': 2, 'nr_neurons': 139, 'dropout_rate': 8.687158584796603e-05, 'weight_decay': 0.0020946710786693126, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 08:55:15,972] Trial 442 pruned. 
[I 2025-11-04 08:55:40,967] Trial 443 pruned. 
[I 2025-11-04 08:55:59,350] Trial 444 pruned. 
[I 2025-11-04 08:56:20,896] Trial 445 pruned. 
[I 2025-11-04 08:57:24,716] Trial 446 pruned. 
[I 2025-11-04 08:57:42,964] Trial 447 pruned. 
[I 2025-11-04 08:58:50,599] Trial 448 pruned. 
[I 2025-11-04 08:59:35,899] Trial 449 pruned. 
[I 2025-11-04 08:59:42,435] Trial 450 pruned. 
[I 2025-11-04 09:00:18,916] Trial 451 pruned. 
[I 2025-11-04 09:00:37,265] Trial 452 pruned. 
[I 2025-11-04 09:00:55,430] Trial 453 pruned. 
[I 2025-11-04 09:01:14,342] Trial 454 pruned. 
[I 2025-11-04 09:01:34,213] Trial 455 pruned. 
[I 2025-11-04 09:01:54,407] Trial 456 pruned. 
[I 2025-11-04 09:02:12,709] Trial 457 pruned. 
2025-11-04 09:05:26,615 - INFO - Trial 458: Early stopping at epoch 116.
[I 2025-11-04 09:05:26,699] Trial 458 finished with value: 0.0032951229339875892 and parameters: {'batch_size': 64, 'learning_rate': 0.0011322478062870357, 'nr_hidden_layers': 2, 'nr_neurons': 160, 'dropout_rate': 0.0002316264140748946, 'weight_decay': 0.00016811442130984503, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 09:05:45,099] Trial 459 pruned. 
[I 2025-11-04 09:05:56,410] Trial 460 pruned. 
[I 2025-11-04 09:06:02,115] Trial 461 pruned. 
[I 2025-11-04 09:06:10,428] Trial 462 pruned. 
[I 2025-11-04 09:06:26,795] Trial 463 pruned. 
[I 2025-11-04 09:06:45,112] Trial 464 pruned. 
[I 2025-11-04 09:07:03,498] Trial 465 pruned. 
[I 2025-11-04 09:07:10,405] Trial 466 pruned. 
[I 2025-11-04 09:07:28,755] Trial 467 pruned. 
2025-11-04 09:11:53,771 - INFO - Trial 468: Early stopping at epoch 151.
[I 2025-11-04 09:11:53,856] Trial 468 finished with value: 0.0028866133632029375 and parameters: {'batch_size': 64, 'learning_rate': 0.0010211347025492912, 'nr_hidden_layers': 2, 'nr_neurons': 157, 'dropout_rate': 0.00028569006017758217, 'weight_decay': 0.0018376096021583451, 'activation_name': 'ReLU', 'loss_criterion': 'L1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 09:12:12,636] Trial 469 pruned. 
[I 2025-11-04 09:12:31,402] Trial 470 pruned. 
[I 2025-11-04 09:12:50,134] Trial 471 pruned. 
[I 2025-11-04 09:13:10,782] Trial 472 pruned. 
[I 2025-11-04 09:13:31,314] Trial 473 pruned. 
[I 2025-11-04 09:13:50,089] Trial 474 pruned. 
[I 2025-11-04 09:14:08,928] Trial 475 pruned. 
[I 2025-11-04 09:14:27,712] Trial 476 pruned. 
2025-11-04 09:18:39,246 - INFO - Trial 477: Early stopping at epoch 148.
[I 2025-11-04 09:18:39,337] Trial 477 finished with value: 0.0027654771089558675 and parameters: {'batch_size': 64, 'learning_rate': 0.001189878579742179, 'nr_hidden_layers': 2, 'nr_neurons': 244, 'dropout_rate': 4.6630291046736834e-05, 'weight_decay': 0.0001728366563108848, 'activation_name': 'LeakyReLU', 'loss_criterion': 'L1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 09:19:02,632] Trial 478 pruned. 
[I 2025-11-04 09:19:09,322] Trial 479 pruned. 
[I 2025-11-04 09:19:29,516] Trial 480 pruned. 
[I 2025-11-04 09:19:48,238] Trial 481 pruned. 
[I 2025-11-04 09:20:43,804] Trial 482 pruned. 
[I 2025-11-04 09:21:17,020] Trial 483 pruned. 
[I 2025-11-04 09:21:40,381] Trial 484 pruned. 
[I 2025-11-04 09:22:07,900] Trial 485 pruned. 
[I 2025-11-04 09:22:19,397] Trial 486 pruned. 
[I 2025-11-04 09:23:30,580] Trial 487 pruned. 
[I 2025-11-04 09:23:48,911] Trial 488 pruned. 
[I 2025-11-04 09:24:07,312] Trial 489 pruned. 
[I 2025-11-04 09:24:13,312] Trial 490 pruned. 
[I 2025-11-04 09:24:21,656] Trial 491 pruned. 
[I 2025-11-04 09:24:56,450] Trial 492 pruned. 
[I 2025-11-04 09:25:26,016] Trial 493 pruned. 
[I 2025-11-04 09:25:33,042] Trial 494 pruned. 
2025-11-04 09:28:59,499 - INFO - Trial 495: Early stopping at epoch 118.
[I 2025-11-04 09:28:59,586] Trial 495 finished with value: 0.0030087035701750918 and parameters: {'batch_size': 64, 'learning_rate': 0.0012165103716867433, 'nr_hidden_layers': 2, 'nr_neurons': 165, 'dropout_rate': 0.00029496233883280986, 'weight_decay': 0.00011333803541746249, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 09:29:20,964] Trial 496 pruned. 
[I 2025-11-04 09:29:48,350] Trial 497 pruned. 
2025-11-04 09:31:50,660 - INFO - Trial 498: Early stopping at epoch 73.
[I 2025-11-04 09:31:50,750] Trial 498 finished with value: 0.004463357596439904 and parameters: {'batch_size': 64, 'learning_rate': 0.0013596249523581947, 'nr_hidden_layers': 2, 'nr_neurons': 146, 'dropout_rate': 0.0004707919132224662, 'weight_decay': 0.0040479397404103255, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 09:32:09,013] Trial 499 pruned. 
[I 2025-11-04 09:32:29,148] Trial 500 pruned. 
[I 2025-11-04 09:32:47,484] Trial 501 pruned. 
[I 2025-11-04 09:33:05,808] Trial 502 pruned. 
[I 2025-11-04 09:33:24,370] Trial 503 pruned. 
[I 2025-11-04 09:33:42,663] Trial 504 pruned. 
2025-11-04 09:36:16,032 - INFO - Trial 505: Early stopping at epoch 91.
[I 2025-11-04 09:36:16,117] Trial 505 finished with value: 0.004012513259233835 and parameters: {'batch_size': 64, 'learning_rate': 0.0011275377105206472, 'nr_hidden_layers': 2, 'nr_neurons': 163, 'dropout_rate': 0.0002198762753988693, 'weight_decay': 7.963132454011398e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 09:36:22,728] Trial 506 pruned. 
[I 2025-11-04 09:36:56,726] Trial 507 pruned. 
[I 2025-11-04 09:37:15,145] Trial 508 pruned. 
[I 2025-11-04 09:37:35,585] Trial 509 pruned. 
[I 2025-11-04 09:37:53,859] Trial 510 pruned. 
[I 2025-11-04 09:38:12,289] Trial 511 pruned. 
[I 2025-11-04 09:38:30,658] Trial 512 pruned. 
[I 2025-11-04 09:38:50,886] Trial 513 pruned. 
[I 2025-11-04 09:39:09,746] Trial 514 pruned. 
[I 2025-11-04 09:39:21,088] Trial 515 pruned. 
[I 2025-11-04 09:39:39,363] Trial 516 pruned. 
[I 2025-11-04 09:39:45,211] Trial 517 pruned. 
[I 2025-11-04 09:39:53,432] Trial 518 pruned. 
[I 2025-11-04 09:40:15,932] Trial 519 pruned. 
[I 2025-11-04 09:40:34,699] Trial 520 pruned. 
[I 2025-11-04 09:40:53,053] Trial 521 pruned. 
[I 2025-11-04 09:41:00,087] Trial 522 pruned. 
[I 2025-11-04 09:41:18,360] Trial 523 pruned. 
[I 2025-11-04 09:41:36,720] Trial 524 pruned. 
[I 2025-11-04 09:41:57,363] Trial 525 pruned. 
[I 2025-11-04 09:42:15,625] Trial 526 pruned. 
2025-11-04 09:46:37,120 - INFO - Trial 527: Early stopping at epoch 163.
[I 2025-11-04 09:46:37,207] Trial 527 finished with value: 0.002793603955429796 and parameters: {'batch_size': 64, 'learning_rate': 0.00083115494204702, 'nr_hidden_layers': 1, 'nr_neurons': 214, 'dropout_rate': 0.00015145162611698363, 'weight_decay': 5.5726691189114415e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 09:46:53,698] Trial 528 pruned. 
[I 2025-11-04 09:47:14,107] Trial 529 pruned. 
[I 2025-11-04 09:47:30,574] Trial 530 pruned. 
[I 2025-11-04 09:48:28,654] Trial 531 pruned. 
[I 2025-11-04 09:48:45,124] Trial 532 pruned. 
[I 2025-11-04 09:49:05,006] Trial 533 pruned. 
2025-11-04 09:52:01,168 - INFO - Trial 534: Early stopping at epoch 114.
[I 2025-11-04 09:52:01,277] Trial 534 finished with value: 0.003056817628531319 and parameters: {'batch_size': 64, 'learning_rate': 0.0009511203100762786, 'nr_hidden_layers': 1, 'nr_neurons': 220, 'dropout_rate': 3.000555130172665e-05, 'weight_decay': 3.8225846139822414e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 09:52:18,872] Trial 535 pruned. 
[I 2025-11-04 09:52:25,236] Trial 536 pruned. 
[I 2025-11-04 09:52:46,242] Trial 537 pruned. 
[I 2025-11-04 09:53:06,891] Trial 538 pruned. 
[I 2025-11-04 09:53:28,960] Trial 539 pruned. 
[I 2025-11-04 09:53:45,575] Trial 540 pruned. 
[I 2025-11-04 09:54:09,173] Trial 541 pruned. 
[I 2025-11-04 09:54:33,753] Trial 542 pruned. 
[I 2025-11-04 09:54:53,998] Trial 543 pruned. 
[I 2025-11-04 09:55:09,208] Trial 544 pruned. 
[I 2025-11-04 09:55:15,057] Trial 545 pruned. 
[I 2025-11-04 09:55:33,428] Trial 546 pruned. 
[I 2025-11-04 09:55:41,756] Trial 547 pruned. 
[I 2025-11-04 09:56:02,432] Trial 548 pruned. 
[I 2025-11-04 09:56:20,695] Trial 549 pruned. 
[I 2025-11-04 09:56:37,117] Trial 550 pruned. 
2025-11-04 09:59:51,958 - INFO - Trial 551: Early stopping at epoch 115.
[I 2025-11-04 09:59:52,043] Trial 551 finished with value: 0.0033453628141976643 and parameters: {'batch_size': 64, 'learning_rate': 0.0013305642238148731, 'nr_hidden_layers': 2, 'nr_neurons': 169, 'dropout_rate': 0.0002718422986774735, 'weight_decay': 9.708974060128298e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 09:59:58,671] Trial 552 pruned. 
[I 2025-11-04 10:00:17,244] Trial 553 pruned. 
[I 2025-11-04 10:00:41,998] Trial 554 pruned. 
[I 2025-11-04 10:01:05,393] Trial 555 pruned. 
[I 2025-11-04 10:01:25,659] Trial 556 pruned. 
2025-11-04 10:05:27,641 - INFO - Trial 557: Early stopping at epoch 144.
[I 2025-11-04 10:05:27,729] Trial 557 finished with value: 0.0027228360401385723 and parameters: {'batch_size': 64, 'learning_rate': 0.0008111916003822477, 'nr_hidden_layers': 2, 'nr_neurons': 176, 'dropout_rate': 1.8654524740901882e-05, 'weight_decay': 0.00012000186746205188, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 10:05:46,238] Trial 558 pruned. 
[I 2025-11-04 10:06:07,930] Trial 559 pruned. 
[I 2025-11-04 10:06:30,600] Trial 560 pruned. 
[I 2025-11-04 10:06:52,769] Trial 561 pruned. 
[I 2025-11-04 10:07:11,150] Trial 562 pruned. 
[I 2025-11-04 10:07:31,361] Trial 563 pruned. 
[I 2025-11-04 10:07:37,940] Trial 564 pruned. 
[I 2025-11-04 10:07:56,122] Trial 565 pruned. 
[I 2025-11-04 10:08:17,737] Trial 566 pruned. 
[I 2025-11-04 10:08:36,159] Trial 567 pruned. 
[I 2025-11-04 10:08:56,187] Trial 568 pruned. 
[I 2025-11-04 10:09:07,845] Trial 569 pruned. 
[I 2025-11-04 10:09:26,181] Trial 570 pruned. 
[I 2025-11-04 10:09:44,530] Trial 571 pruned. 
[I 2025-11-04 10:10:11,288] Trial 572 pruned. 
[I 2025-11-04 10:10:17,126] Trial 573 pruned. 
[I 2025-11-04 10:10:35,561] Trial 574 pruned. 
[I 2025-11-04 10:10:43,783] Trial 575 pruned. 
[I 2025-11-04 10:11:04,080] Trial 576 pruned. 
[I 2025-11-04 10:11:27,062] Trial 577 pruned. 
[I 2025-11-04 10:11:34,165] Trial 578 pruned. 
[I 2025-11-04 10:11:52,231] Trial 579 pruned. 
2025-11-04 10:15:35,947 - INFO - Trial 580: Early stopping at epoch 130.
[I 2025-11-04 10:15:36,046] Trial 580 finished with value: 0.0030895912929733466 and parameters: {'batch_size': 64, 'learning_rate': 0.0009177960191529461, 'nr_hidden_layers': 2, 'nr_neurons': 130, 'dropout_rate': 2.2118962568899595e-05, 'weight_decay': 8.20058806788569e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 10:16:14,344] Trial 581 pruned. 
[I 2025-11-04 10:16:32,745] Trial 582 pruned. 
[I 2025-11-04 10:16:51,896] Trial 583 pruned. 
2025-11-04 10:19:43,900 - INFO - Trial 584: Early stopping at epoch 103.
[I 2025-11-04 10:19:43,985] Trial 584 finished with value: 0.0030987401315376675 and parameters: {'batch_size': 64, 'learning_rate': 0.001436347411080467, 'nr_hidden_layers': 2, 'nr_neurons': 149, 'dropout_rate': 1.6587103136166486e-05, 'weight_decay': 0.0001462176273748064, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 10:20:02,329] Trial 585 pruned. 
[I 2025-11-04 10:20:24,041] Trial 586 pruned. 
[I 2025-11-04 10:20:44,499] Trial 587 pruned. 
[I 2025-11-04 10:21:03,291] Trial 588 pruned. 
[I 2025-11-04 10:21:21,672] Trial 589 pruned. 
[I 2025-11-04 10:21:43,722] Trial 590 pruned. 
[I 2025-11-04 10:22:00,108] Trial 591 pruned. 
[I 2025-11-04 10:22:18,934] Trial 592 pruned. 
[I 2025-11-04 10:22:37,258] Trial 593 pruned. 
[I 2025-11-04 10:22:44,078] Trial 594 pruned. 
[I 2025-11-04 10:23:02,448] Trial 595 pruned. 
[I 2025-11-04 10:23:25,751] Trial 596 pruned. 
[I 2025-11-04 10:23:37,231] Trial 597 pruned. 
2025-11-04 10:26:25,562 - INFO - Trial 598: Early stopping at epoch 95.
[I 2025-11-04 10:26:25,650] Trial 598 finished with value: 0.003467743279122313 and parameters: {'batch_size': 64, 'learning_rate': 0.0012378262709268981, 'nr_hidden_layers': 2, 'nr_neurons': 196, 'dropout_rate': 0.0002812096346512399, 'weight_decay': 0.00011174672042288042, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 10:29:15,631 - INFO - Trial 599: Early stopping at epoch 99.
[I 2025-11-04 10:29:15,718] Trial 599 finished with value: 0.0032879148533706552 and parameters: {'batch_size': 64, 'learning_rate': 0.0009632441111991019, 'nr_hidden_layers': 2, 'nr_neurons': 163, 'dropout_rate': 6.120157381981351e-05, 'weight_decay': 0.00040102372642729177, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 10:29:35,947] Trial 600 pruned. 
[I 2025-11-04 10:29:41,795] Trial 601 pruned. 
[I 2025-11-04 10:30:00,975] Trial 602 pruned. 
[I 2025-11-04 10:30:10,093] Trial 603 pruned. 
[I 2025-11-04 10:30:44,265] Trial 604 pruned. 
[I 2025-11-04 10:31:04,504] Trial 605 pruned. 
[I 2025-11-04 10:31:11,355] Trial 606 pruned. 
[I 2025-11-04 10:31:30,136] Trial 607 pruned. 
[I 2025-11-04 10:31:56,551] Trial 608 pruned. 
[I 2025-11-04 10:32:13,119] Trial 609 pruned. 
[I 2025-11-04 10:32:33,174] Trial 610 pruned. 
[I 2025-11-04 10:33:20,258] Trial 611 pruned. 
[I 2025-11-04 10:33:39,115] Trial 612 pruned. 
[I 2025-11-04 10:33:57,604] Trial 613 pruned. 
[I 2025-11-04 10:34:16,109] Trial 614 pruned. 
[I 2025-11-04 10:34:36,464] Trial 615 pruned. 
[I 2025-11-04 10:34:59,895] Trial 616 pruned. 
[I 2025-11-04 10:35:18,690] Trial 617 pruned. 
[I 2025-11-04 10:35:57,009] Trial 618 pruned. 
[I 2025-11-04 10:36:03,562] Trial 619 pruned. 
2025-11-04 10:39:14,432 - INFO - Trial 620: Early stopping at epoch 104.
[I 2025-11-04 10:39:14,522] Trial 620 finished with value: 0.003725763771486219 and parameters: {'batch_size': 64, 'learning_rate': 0.001407264703741011, 'nr_hidden_layers': 2, 'nr_neurons': 151, 'dropout_rate': 0.00019912142791686448, 'weight_decay': 0.00012748612460530882, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 10:39:33,313] Trial 621 pruned. 
[I 2025-11-04 10:39:53,367] Trial 622 pruned. 
[I 2025-11-04 10:40:11,732] Trial 623 pruned. 
[I 2025-11-04 10:40:30,080] Trial 624 pruned. 
[I 2025-11-04 10:40:41,409] Trial 625 pruned. 
[I 2025-11-04 10:41:03,655] Trial 626 pruned. 
[I 2025-11-04 10:41:22,500] Trial 627 pruned. 
[I 2025-11-04 10:41:55,556] Trial 628 pruned. 
[I 2025-11-04 10:42:03,847] Trial 629 pruned. 
[I 2025-11-04 10:42:09,379] Trial 630 pruned. 
[I 2025-11-04 10:42:28,168] Trial 631 pruned. 
[I 2025-11-04 10:43:09,521] Trial 632 pruned. 
[I 2025-11-04 10:43:28,002] Trial 633 pruned. 
[I 2025-11-04 10:43:46,437] Trial 634 pruned. 
[I 2025-11-04 10:44:16,334] Trial 635 pruned. 
[I 2025-11-04 10:44:35,180] Trial 636 pruned. 
[I 2025-11-04 10:44:42,065] Trial 637 pruned. 
[I 2025-11-04 10:45:02,355] Trial 638 pruned. 
[I 2025-11-04 10:45:24,317] Trial 639 pruned. 
[I 2025-11-04 10:45:43,073] Trial 640 pruned. 
[I 2025-11-04 10:46:01,916] Trial 641 pruned. 
[I 2025-11-04 10:46:29,948] Trial 642 pruned. 
[I 2025-11-04 10:46:50,216] Trial 643 pruned. 
[I 2025-11-04 10:47:13,705] Trial 644 pruned. 
[I 2025-11-04 10:47:32,116] Trial 645 pruned. 
[I 2025-11-04 10:47:49,093] Trial 646 pruned. 
[I 2025-11-04 10:47:55,922] Trial 647 pruned. 
[I 2025-11-04 10:48:20,888] Trial 648 pruned. 
[I 2025-11-04 10:48:39,175] Trial 649 pruned. 
[I 2025-11-04 10:50:25,405] Trial 650 pruned. 
[I 2025-11-04 10:50:43,806] Trial 651 pruned. 
[I 2025-11-04 10:50:55,390] Trial 652 pruned. 
[I 2025-11-04 10:51:13,833] Trial 653 pruned. 
[I 2025-11-04 10:51:33,982] Trial 654 pruned. 
[I 2025-11-04 10:52:05,697] Trial 655 pruned. 
[I 2025-11-04 10:52:24,164] Trial 656 pruned. 
[I 2025-11-04 10:52:29,802] Trial 657 pruned. 
[I 2025-11-04 10:52:38,011] Trial 658 pruned. 
[I 2025-11-04 10:52:57,948] Trial 659 pruned. 
[I 2025-11-04 10:53:17,831] Trial 660 pruned. 
[I 2025-11-04 10:53:24,779] Trial 661 pruned. 
[I 2025-11-04 10:53:43,143] Trial 662 pruned. 
[I 2025-11-04 10:54:01,898] Trial 663 pruned. 
[I 2025-11-04 10:54:20,461] Trial 664 pruned. 
[I 2025-11-04 10:54:37,948] Trial 665 pruned. 
[I 2025-11-04 10:55:00,018] Trial 666 pruned. 
[I 2025-11-04 10:55:18,361] Trial 667 pruned. 
[I 2025-11-04 10:55:36,988] Trial 668 pruned. 
[I 2025-11-04 10:55:55,781] Trial 669 pruned. 
[I 2025-11-04 10:56:20,068] Trial 670 pruned. 
[I 2025-11-04 10:56:38,298] Trial 671 pruned. 
[I 2025-11-04 10:56:56,960] Trial 672 pruned. 
[I 2025-11-04 10:57:03,779] Trial 673 pruned. 
[I 2025-11-04 10:57:22,568] Trial 674 pruned. 
[I 2025-11-04 10:57:40,887] Trial 675 pruned. 
[I 2025-11-04 10:57:59,104] Trial 676 pruned. 
2025-11-04 11:01:17,563 - INFO - Trial 677: Early stopping at epoch 116.
[I 2025-11-04 11:01:17,656] Trial 677 finished with value: 0.003272620369068536 and parameters: {'batch_size': 64, 'learning_rate': 0.000865983072012581, 'nr_hidden_layers': 2, 'nr_neurons': 204, 'dropout_rate': 0.00020524418083713573, 'weight_decay': 0.00011960948707517143, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 11:01:37,923] Trial 678 pruned. 
[I 2025-11-04 11:01:56,726] Trial 679 pruned. 
[I 2025-11-04 11:02:15,088] Trial 680 pruned. 
[I 2025-11-04 11:02:26,410] Trial 681 pruned. 
[I 2025-11-04 11:02:44,736] Trial 682 pruned. 
[I 2025-11-04 11:03:01,309] Trial 683 pruned. 
[I 2025-11-04 11:03:09,570] Trial 684 pruned. 
[I 2025-11-04 11:03:15,517] Trial 685 pruned. 
[I 2025-11-04 11:03:37,568] Trial 686 pruned. 
[I 2025-11-04 11:04:00,832] Trial 687 pruned. 
[I 2025-11-04 11:04:19,225] Trial 688 pruned. 
[I 2025-11-04 11:04:26,067] Trial 689 pruned. 
[I 2025-11-04 11:04:46,642] Trial 690 pruned. 
[I 2025-11-04 11:05:05,015] Trial 691 pruned. 
[I 2025-11-04 11:05:23,290] Trial 692 pruned. 
[I 2025-11-04 11:05:41,484] Trial 693 pruned. 
[I 2025-11-04 11:05:59,917] Trial 694 pruned. 
[I 2025-11-04 11:06:18,273] Trial 695 pruned. 
[I 2025-11-04 11:06:37,083] Trial 696 pruned. 
[I 2025-11-04 11:07:02,027] Trial 697 pruned. 
2025-11-04 11:10:48,730 - INFO - Trial 698: Early stopping at epoch 131.
[I 2025-11-04 11:10:48,821] Trial 698 finished with value: 0.002702169407412958 and parameters: {'batch_size': 64, 'learning_rate': 0.0012072279189961354, 'nr_hidden_layers': 2, 'nr_neurons': 175, 'dropout_rate': 4.113375655503745e-05, 'weight_decay': 0.00015004207229189412, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 11:11:08,911] Trial 699 pruned. 
[I 2025-11-04 11:12:11,791] Trial 700 pruned. 
[I 2025-11-04 11:12:18,697] Trial 701 pruned. 
[I 2025-11-04 11:12:51,168] Trial 702 pruned. 
[I 2025-11-04 11:13:20,405] Trial 703 pruned. 
[I 2025-11-04 11:13:38,616] Trial 704 pruned. 
[I 2025-11-04 11:13:56,934] Trial 705 pruned. 
2025-11-04 11:18:14,393 - INFO - Trial 706: Early stopping at epoch 141.
[I 2025-11-04 11:18:14,484] Trial 706 finished with value: 0.0030068111061392353 and parameters: {'batch_size': 64, 'learning_rate': 0.0011456827283867648, 'nr_hidden_layers': 2, 'nr_neurons': 147, 'dropout_rate': 0.00012077873905486954, 'weight_decay': 0.0001660761744704108, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 11:18:33,267] Trial 707 pruned. 
[I 2025-11-04 11:18:45,455] Trial 708 pruned. 
[I 2025-11-04 11:19:06,849] Trial 709 pruned. 
[I 2025-11-04 11:19:36,701] Trial 710 pruned. 
[I 2025-11-04 11:22:08,086] Trial 711 pruned. 
[I 2025-11-04 11:22:14,056] Trial 712 pruned. 
[I 2025-11-04 11:22:22,869] Trial 713 pruned. 
[I 2025-11-04 11:22:42,465] Trial 714 pruned. 
2025-11-04 11:25:16,398 - INFO - Trial 715: Early stopping at epoch 86.
[I 2025-11-04 11:25:16,503] Trial 715 finished with value: 0.0038837499883564116 and parameters: {'batch_size': 64, 'learning_rate': 0.0011086400973334286, 'nr_hidden_layers': 2, 'nr_neurons': 242, 'dropout_rate': 0.00021179036886147725, 'weight_decay': 0.00011429684438493859, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 11:25:38,194] Trial 716 pruned. 
[I 2025-11-04 11:25:45,110] Trial 717 pruned. 
[I 2025-11-04 11:26:03,928] Trial 718 pruned. 
[I 2025-11-04 11:26:40,365] Trial 719 pruned. 
[I 2025-11-04 11:26:58,747] Trial 720 pruned. 
[I 2025-11-04 11:27:17,363] Trial 721 pruned. 
[I 2025-11-04 11:27:38,141] Trial 722 pruned. 
[I 2025-11-04 11:27:58,428] Trial 723 pruned. 
[I 2025-11-04 11:28:17,259] Trial 724 pruned. 
[I 2025-11-04 11:28:35,583] Trial 725 pruned. 
[I 2025-11-04 11:28:52,090] Trial 726 pruned. 
[I 2025-11-04 11:30:49,022] Trial 727 pruned. 
[I 2025-11-04 11:31:07,810] Trial 728 pruned. 
[I 2025-11-04 11:31:14,674] Trial 729 pruned. 
[I 2025-11-04 11:31:33,160] Trial 730 pruned. 
2025-11-04 11:34:29,461 - INFO - Trial 731: Early stopping at epoch 103.
[I 2025-11-04 11:34:29,558] Trial 731 finished with value: 0.0032658777126323237 and parameters: {'batch_size': 64, 'learning_rate': 0.0011610586962981138, 'nr_hidden_layers': 2, 'nr_neurons': 191, 'dropout_rate': 0.0001459289353949743, 'weight_decay': 0.000235714987740977, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 11:34:49,914] Trial 732 pruned. 
[I 2025-11-04 11:35:12,090] Trial 733 pruned. 
[I 2025-11-04 11:35:31,023] Trial 734 pruned. 
[I 2025-11-04 11:35:49,697] Trial 735 pruned. 
[I 2025-11-04 11:36:01,011] Trial 736 pruned. 
[I 2025-11-04 11:36:19,759] Trial 737 pruned. 
[I 2025-11-04 11:36:42,967] Trial 738 pruned. 
[I 2025-11-04 11:37:05,520] Trial 739 pruned. 
[I 2025-11-04 11:37:11,435] Trial 740 pruned. 
[I 2025-11-04 11:37:19,723] Trial 741 pruned. 
[I 2025-11-04 11:37:37,973] Trial 742 pruned. 
[I 2025-11-04 11:37:56,365] Trial 743 pruned. 
[I 2025-11-04 11:38:14,705] Trial 744 pruned. 
[I 2025-11-04 11:38:21,624] Trial 745 pruned. 
[I 2025-11-04 11:38:38,005] Trial 746 pruned. 
[I 2025-11-04 11:38:58,229] Trial 747 pruned. 
[I 2025-11-04 11:40:01,202] Trial 748 pruned. 
[I 2025-11-04 11:40:27,668] Trial 749 pruned. 
[I 2025-11-04 11:40:49,421] Trial 750 pruned. 
[I 2025-11-04 11:41:08,245] Trial 751 pruned. 
2025-11-04 11:46:15,882 - INFO - Trial 752: Early stopping at epoch 160.
[I 2025-11-04 11:46:15,974] Trial 752 finished with value: 0.0027550522842892593 and parameters: {'batch_size': 64, 'learning_rate': 0.0013543398034669047, 'nr_hidden_layers': 3, 'nr_neurons': 232, 'dropout_rate': 7.917347080779779e-05, 'weight_decay': 0.00012860767791620693, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 11:46:36,321] Trial 753 pruned. 
[I 2025-11-04 11:46:56,760] Trial 754 pruned. 
[I 2025-11-04 11:47:17,121] Trial 755 pruned. 
[I 2025-11-04 11:47:37,385] Trial 756 pruned. 
[I 2025-11-04 11:47:58,056] Trial 757 pruned. 
[I 2025-11-04 11:48:37,069] Trial 758 pruned. 
[I 2025-11-04 11:48:43,963] Trial 759 pruned. 
[I 2025-11-04 11:49:22,419] Trial 760 pruned. 
[I 2025-11-04 11:49:42,637] Trial 761 pruned. 
[I 2025-11-04 11:50:03,267] Trial 762 pruned. 
[I 2025-11-04 11:50:23,512] Trial 763 pruned. 
2025-11-04 11:52:36,628 - INFO - Trial 764: Early stopping at epoch 72.
[I 2025-11-04 11:52:36,724] Trial 764 finished with value: 0.00415789205896709 and parameters: {'batch_size': 64, 'learning_rate': 0.001366532689965723, 'nr_hidden_layers': 3, 'nr_neurons': 209, 'dropout_rate': 0.00012898108531335498, 'weight_decay': 0.0014700845329724444, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 11:52:48,841] Trial 765 pruned. 
[I 2025-11-04 11:53:09,088] Trial 766 pruned. 
[I 2025-11-04 11:53:33,085] Trial 767 pruned. 
[I 2025-11-04 11:53:41,945] Trial 768 pruned. 
[I 2025-11-04 11:53:47,644] Trial 769 pruned. 
[I 2025-11-04 11:54:09,501] Trial 770 pruned. 
[I 2025-11-04 11:55:20,447] Trial 771 pruned. 
[I 2025-11-04 11:55:40,538] Trial 772 pruned. 
[I 2025-11-04 11:56:01,223] Trial 773 pruned. 
[I 2025-11-04 11:56:07,948] Trial 774 pruned. 
[I 2025-11-04 11:56:26,456] Trial 775 pruned. 
[I 2025-11-04 11:56:44,776] Trial 776 pruned. 
[I 2025-11-04 11:57:05,057] Trial 777 pruned. 
[I 2025-11-04 11:57:23,413] Trial 778 pruned. 
[I 2025-11-04 11:57:40,303] Trial 779 pruned. 
[I 2025-11-04 11:57:58,695] Trial 780 pruned. 
2025-11-04 12:02:46,934 - INFO - Trial 781: Early stopping at epoch 166.
[I 2025-11-04 12:02:47,029] Trial 781 finished with value: 0.0026838720040663518 and parameters: {'batch_size': 64, 'learning_rate': 0.0011412559025528663, 'nr_hidden_layers': 2, 'nr_neurons': 183, 'dropout_rate': 7.99685369286372e-05, 'weight_decay': 0.00010988901407417564, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 12:03:10,385] Trial 782 pruned. 
[I 2025-11-04 12:03:28,774] Trial 783 pruned. 
[I 2025-11-04 12:03:57,099] Trial 784 pruned. 
[I 2025-11-04 12:04:15,932] Trial 785 pruned. 
[I 2025-11-04 12:04:22,502] Trial 786 pruned. 
[I 2025-11-04 12:04:40,876] Trial 787 pruned. 
[I 2025-11-04 12:04:59,280] Trial 788 pruned. 
[I 2025-11-04 12:05:18,100] Trial 789 pruned. 
[I 2025-11-04 12:05:36,496] Trial 790 pruned. 
[I 2025-11-04 12:06:06,112] Trial 791 pruned. 
[I 2025-11-04 12:06:36,095] Trial 792 pruned. 
[I 2025-11-04 12:06:54,317] Trial 793 pruned. 
[I 2025-11-04 12:07:05,611] Trial 794 pruned. 
[I 2025-11-04 12:07:24,460] Trial 795 pruned. 
[I 2025-11-04 12:07:30,132] Trial 796 pruned. 
[I 2025-11-04 12:07:48,345] Trial 797 pruned. 
2025-11-04 12:10:27,063 - INFO - Trial 798: Early stopping at epoch 89.
[I 2025-11-04 12:10:27,154] Trial 798 finished with value: 0.003588680761021956 and parameters: {'batch_size': 64, 'learning_rate': 0.0012775748195167434, 'nr_hidden_layers': 2, 'nr_neurons': 196, 'dropout_rate': 5.8216727685986005e-05, 'weight_decay': 0.006259492507697631, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 12:10:35,599] Trial 799 pruned. 
[I 2025-11-04 12:10:53,993] Trial 800 pruned. 
[I 2025-11-04 12:11:00,720] Trial 801 pruned. 
[I 2025-11-04 12:11:43,884] Trial 802 pruned. 
[I 2025-11-04 12:12:02,239] Trial 803 pruned. 
[I 2025-11-04 12:12:20,567] Trial 804 pruned. 
[I 2025-11-04 12:12:38,941] Trial 805 pruned. 
[I 2025-11-04 12:13:01,176] Trial 806 pruned. 
[I 2025-11-04 12:13:50,402] Trial 807 pruned. 
[I 2025-11-04 12:14:08,862] Trial 808 pruned. 
[I 2025-11-04 12:14:27,348] Trial 809 pruned. 
[I 2025-11-04 12:14:45,814] Trial 810 pruned. 
[I 2025-11-04 12:15:04,161] Trial 811 pruned. 
[I 2025-11-04 12:15:22,931] Trial 812 pruned. 
[I 2025-11-04 12:15:41,399] Trial 813 pruned. 
[I 2025-11-04 12:15:48,054] Trial 814 pruned. 
[I 2025-11-04 12:16:06,428] Trial 815 pruned. 
2025-11-04 12:18:05,442 - INFO - Trial 816: Early stopping at epoch 66.
[I 2025-11-04 12:18:05,560] Trial 816 finished with value: 0.005924343677810274 and parameters: {'batch_size': 64, 'learning_rate': 0.004510952689730438, 'nr_hidden_layers': 2, 'nr_neurons': 151, 'dropout_rate': 0.00022052408153789736, 'weight_decay': 0.000124098386570708, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 12:18:24,360] Trial 817 pruned. 
[I 2025-11-04 12:18:42,697] Trial 818 pruned. 
[I 2025-11-04 12:18:54,639] Trial 819 pruned. 
[I 2025-11-04 12:19:21,845] Trial 820 pruned. 
[I 2025-11-04 12:21:28,097] Trial 821 pruned. 
[I 2025-11-04 12:21:46,901] Trial 822 pruned. 
[I 2025-11-04 12:21:52,757] Trial 823 pruned. 
[I 2025-11-04 12:22:17,613] Trial 824 pruned. 
[I 2025-11-04 12:22:26,347] Trial 825 pruned. 
[I 2025-11-04 12:22:44,685] Trial 826 pruned. 
[I 2025-11-04 12:23:03,078] Trial 827 pruned. 
[I 2025-11-04 12:23:21,942] Trial 828 pruned. 
[I 2025-11-04 12:23:28,983] Trial 829 pruned. 
[I 2025-11-04 12:23:47,161] Trial 830 pruned. 
[I 2025-11-04 12:24:05,479] Trial 831 pruned. 
[I 2025-11-04 12:24:25,564] Trial 832 pruned. 
[I 2025-11-04 12:24:44,389] Trial 833 pruned. 
2025-11-04 12:30:01,778 - INFO - Trial 834: Early stopping at epoch 184.
[I 2025-11-04 12:30:01,881] Trial 834 finished with value: 0.002399620165715291 and parameters: {'batch_size': 64, 'learning_rate': 0.0007709428256605067, 'nr_hidden_layers': 2, 'nr_neurons': 242, 'dropout_rate': 5.118573615495788e-05, 'weight_decay': 0.0001521496255008386, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 12:30:20,447] Trial 835 pruned. 
[I 2025-11-04 12:30:38,897] Trial 836 pruned. 
[I 2025-11-04 12:30:59,211] Trial 837 pruned. 
[I 2025-11-04 12:31:17,624] Trial 838 pruned. 
[I 2025-11-04 12:31:37,666] Trial 839 pruned. 
[I 2025-11-04 12:31:56,084] Trial 840 pruned. 
[I 2025-11-04 12:32:20,056] Trial 841 pruned. 
[I 2025-11-04 12:32:41,640] Trial 842 pruned. 
[I 2025-11-04 12:32:48,226] Trial 843 pruned. 
[I 2025-11-04 12:33:06,645] Trial 844 pruned. 
[I 2025-11-04 12:33:25,053] Trial 845 pruned. 
[I 2025-11-04 12:33:46,647] Trial 846 pruned. 
[I 2025-11-04 12:34:06,865] Trial 847 pruned. 
[I 2025-11-04 12:34:18,258] Trial 848 pruned. 
[I 2025-11-04 12:34:38,501] Trial 849 pruned. 
[I 2025-11-04 12:34:58,995] Trial 850 pruned. 
[I 2025-11-04 12:35:17,391] Trial 851 pruned. 
[I 2025-11-04 12:35:23,262] Trial 852 pruned. 
[I 2025-11-04 12:35:32,325] Trial 853 pruned. 
[I 2025-11-04 12:35:50,691] Trial 854 pruned. 
[I 2025-11-04 12:36:09,106] Trial 855 pruned. 
[I 2025-11-04 12:36:27,491] Trial 856 pruned. 
[I 2025-11-04 12:36:34,612] Trial 857 pruned. 
[I 2025-11-04 12:36:55,265] Trial 858 pruned. 
2025-11-04 12:42:38,950 - INFO - Trial 859: Early stopping at epoch 192.
[I 2025-11-04 12:42:39,045] Trial 859 finished with value: 0.002578870692877365 and parameters: {'batch_size': 64, 'learning_rate': 0.000582826803813401, 'nr_hidden_layers': 2, 'nr_neurons': 200, 'dropout_rate': 0.0001377427046481637, 'weight_decay': 7.613459069026828e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 12:42:57,413] Trial 860 pruned. 
[I 2025-11-04 12:43:15,779] Trial 861 pruned. 
[I 2025-11-04 12:43:34,162] Trial 862 pruned. 
[I 2025-11-04 12:43:52,568] Trial 863 pruned. 
[I 2025-11-04 12:44:11,005] Trial 864 pruned. 
[I 2025-11-04 12:44:36,191] Trial 865 pruned. 
[I 2025-11-04 12:44:54,675] Trial 866 pruned. 
[I 2025-11-04 12:45:13,041] Trial 867 pruned. 
[I 2025-11-04 12:45:19,705] Trial 868 pruned. 
[I 2025-11-04 12:45:38,136] Trial 869 pruned. 
[I 2025-11-04 12:45:56,611] Trial 870 pruned. 
[I 2025-11-04 12:46:19,122] Trial 871 pruned. 
[I 2025-11-04 12:46:37,603] Trial 872 pruned. 
[I 2025-11-04 12:46:56,062] Trial 873 pruned. 
[I 2025-11-04 12:47:15,124] Trial 874 pruned. 
[I 2025-11-04 12:47:33,574] Trial 875 pruned. 
[I 2025-11-04 12:47:52,105] Trial 876 pruned. 
[I 2025-11-04 12:48:10,481] Trial 877 pruned. 
[I 2025-11-04 12:48:21,880] Trial 878 pruned. 
[I 2025-11-04 12:48:27,757] Trial 879 pruned. 
[I 2025-11-04 12:48:36,037] Trial 880 pruned. 
[I 2025-11-04 12:48:54,464] Trial 881 pruned. 
2025-11-04 12:52:57,092 - INFO - Trial 882: Early stopping at epoch 141.
[I 2025-11-04 12:52:57,185] Trial 882 finished with value: 0.002814664205413986 and parameters: {'batch_size': 64, 'learning_rate': 0.0007843085288100076, 'nr_hidden_layers': 2, 'nr_neurons': 159, 'dropout_rate': 7.515274679537542e-05, 'weight_decay': 0.00010871027783664393, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 12:53:15,468] Trial 883 pruned. 
[I 2025-11-04 12:53:22,395] Trial 884 pruned. 
[I 2025-11-04 12:53:47,179] Trial 885 pruned. 
[I 2025-11-04 12:54:05,556] Trial 886 pruned. 
[I 2025-11-04 12:54:24,476] Trial 887 pruned. 
[I 2025-11-04 12:54:42,923] Trial 888 pruned. 
[I 2025-11-04 12:55:01,351] Trial 889 pruned. 
[I 2025-11-04 12:55:19,845] Trial 890 pruned. 
[I 2025-11-04 12:55:38,332] Trial 891 pruned. 
[I 2025-11-04 12:55:56,793] Trial 892 pruned. 
[I 2025-11-04 12:56:19,764] Trial 893 pruned. 
[I 2025-11-04 12:56:40,023] Trial 894 pruned. 
[I 2025-11-04 12:57:11,634] Trial 895 pruned. 
[I 2025-11-04 12:57:41,356] Trial 896 pruned. 
2025-11-04 13:00:56,983 - INFO - Trial 897: Early stopping at epoch 115.
[I 2025-11-04 13:00:57,080] Trial 897 finished with value: 0.003082603936342349 and parameters: {'batch_size': 64, 'learning_rate': 0.001077396852133252, 'nr_hidden_layers': 2, 'nr_neurons': 151, 'dropout_rate': 2.915882485198505e-05, 'weight_decay': 0.0001461657161228833, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 13:01:15,536] Trial 898 pruned. 
[I 2025-11-04 13:01:33,971] Trial 899 pruned. 
[I 2025-11-04 13:01:40,588] Trial 900 pruned. 
[I 2025-11-04 13:02:02,185] Trial 901 pruned. 
[I 2025-11-04 13:02:13,539] Trial 902 pruned. 
[I 2025-11-04 13:02:51,925] Trial 903 pruned. 
[I 2025-11-04 13:03:10,406] Trial 904 pruned. 
2025-11-04 13:06:25,153 - INFO - Trial 905: Early stopping at epoch 116.
[I 2025-11-04 13:06:25,246] Trial 905 finished with value: 0.00347485917593844 and parameters: {'batch_size': 64, 'learning_rate': 0.0011015414426045849, 'nr_hidden_layers': 2, 'nr_neurons': 109, 'dropout_rate': 0.00016081021952781297, 'weight_decay': 0.00013193742261313556, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 13:06:43,584] Trial 906 pruned. 
[I 2025-11-04 13:06:49,428] Trial 907 pruned. 
[I 2025-11-04 13:07:07,818] Trial 908 pruned. 
[I 2025-11-04 13:07:16,116] Trial 909 pruned. 
[I 2025-11-04 13:07:41,033] Trial 910 pruned. 
[I 2025-11-04 13:07:59,471] Trial 911 pruned. 
[I 2025-11-04 13:08:06,241] Trial 912 pruned. 
[I 2025-11-04 13:08:27,981] Trial 913 pruned. 
[I 2025-11-04 13:08:46,362] Trial 914 pruned. 
[I 2025-11-04 13:09:11,445] Trial 915 pruned. 
[I 2025-11-04 13:09:31,341] Trial 916 pruned. 
[I 2025-11-04 13:09:49,690] Trial 917 pruned. 
[I 2025-11-04 13:10:28,363] Trial 918 pruned. 
[I 2025-11-04 13:10:46,801] Trial 919 pruned. 
2025-11-04 13:12:29,317 - INFO - Trial 920: Early stopping at epoch 60.
[I 2025-11-04 13:12:29,407] Trial 920 finished with value: 0.005226828014095859 and parameters: {'batch_size': 64, 'learning_rate': 0.001038583864361989, 'nr_hidden_layers': 2, 'nr_neurons': 190, 'dropout_rate': 0.0003091617742257452, 'weight_decay': 0.0002719697394515787, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 13:12:51,129] Trial 921 pruned. 
2025-11-04 13:17:24,025 - INFO - Trial 922: Early stopping at epoch 162.
[I 2025-11-04 13:17:24,357] Trial 922 finished with value: 0.0030119440140932356 and parameters: {'batch_size': 64, 'learning_rate': 0.0008885318759564818, 'nr_hidden_layers': 2, 'nr_neurons': 124, 'dropout_rate': 0.00020211041347898825, 'weight_decay': 9.356037917484593e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 13:17:42,664] Trial 923 pruned. 
[I 2025-11-04 13:17:49,247] Trial 924 pruned. 
[I 2025-11-04 13:18:07,636] Trial 925 pruned. 
[I 2025-11-04 13:18:26,062] Trial 926 pruned. 
[I 2025-11-04 13:18:44,419] Trial 927 pruned. 
[I 2025-11-04 13:19:02,791] Trial 928 pruned. 
[I 2025-11-04 13:19:24,467] Trial 929 pruned. 
2025-11-04 13:22:31,448 - INFO - Trial 930: Early stopping at epoch 107.
[I 2025-11-04 13:22:31,541] Trial 930 finished with value: 0.0041154446908949465 and parameters: {'batch_size': 64, 'learning_rate': 0.0012337679875024947, 'nr_hidden_layers': 2, 'nr_neurons': 86, 'dropout_rate': 0.0003296944475331378, 'weight_decay': 0.00023459848549878802, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 13:23:02,773] Trial 931 pruned. 
2025-11-04 13:28:18,642 - INFO - Trial 932: Early stopping at epoch 187.
[I 2025-11-04 13:28:18,736] Trial 932 finished with value: 0.0024523755907424043 and parameters: {'batch_size': 64, 'learning_rate': 0.0007820538918459391, 'nr_hidden_layers': 2, 'nr_neurons': 222, 'dropout_rate': 0.00018029364072616623, 'weight_decay': 3.220997270804075e-06, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 13:28:39,686] Trial 933 pruned. 
[I 2025-11-04 13:28:45,623] Trial 934 pruned. 
2025-11-04 13:33:52,410 - INFO - Trial 935: Early stopping at epoch 167.
[I 2025-11-04 13:33:52,505] Trial 935 finished with value: 0.002561773361626512 and parameters: {'batch_size': 64, 'learning_rate': 0.0007598881499351234, 'nr_hidden_layers': 2, 'nr_neurons': 230, 'dropout_rate': 0.00010461109127548193, 'weight_decay': 6.815055260249201e-06, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 13:34:03,934] Trial 936 pruned. 
[I 2025-11-04 13:34:12,346] Trial 937 pruned. 
[I 2025-11-04 13:34:31,250] Trial 938 pruned. 
[I 2025-11-04 13:34:49,906] Trial 939 pruned. 
[I 2025-11-04 13:35:08,465] Trial 940 pruned. 
[I 2025-11-04 13:35:15,276] Trial 941 pruned. 
[I 2025-11-04 13:35:33,520] Trial 942 pruned. 
[I 2025-11-04 13:35:52,023] Trial 943 pruned. 
[I 2025-11-04 13:36:10,516] Trial 944 pruned. 
[I 2025-11-04 13:36:32,356] Trial 945 pruned. 
[I 2025-11-04 13:36:51,472] Trial 946 pruned. 
[I 2025-11-04 13:37:10,180] Trial 947 pruned. 
[I 2025-11-04 13:37:29,471] Trial 948 pruned. 
[I 2025-11-04 13:37:48,055] Trial 949 pruned. 
[I 2025-11-04 13:38:06,643] Trial 950 pruned. 
[I 2025-11-04 13:38:25,438] Trial 951 pruned. 
[I 2025-11-04 13:38:43,839] Trial 952 pruned. 
[I 2025-11-04 13:39:02,280] Trial 953 pruned. 
[I 2025-11-04 13:39:08,945] Trial 954 pruned. 
[I 2025-11-04 13:39:27,772] Trial 955 pruned. 
[I 2025-11-04 13:39:46,391] Trial 956 pruned. 
[I 2025-11-04 13:40:04,846] Trial 957 pruned. 
[I 2025-11-04 13:40:28,641] Trial 958 pruned. 
[I 2025-11-04 13:41:03,058] Trial 959 pruned. 
[I 2025-11-04 13:41:14,442] Trial 960 pruned. 
[I 2025-11-04 13:41:32,951] Trial 961 pruned. 
[I 2025-11-04 13:41:52,078] Trial 962 pruned. 
[I 2025-11-04 13:41:58,151] Trial 963 pruned. 
[I 2025-11-04 13:42:16,550] Trial 964 pruned. 
[I 2025-11-04 13:42:24,846] Trial 965 pruned. 
[I 2025-11-04 13:42:48,235] Trial 966 pruned. 
[I 2025-11-04 13:43:06,882] Trial 967 pruned. 
[I 2025-11-04 13:43:25,769] Trial 968 pruned. 
[I 2025-11-04 13:43:32,688] Trial 969 pruned. 
[I 2025-11-04 13:43:51,097] Trial 970 pruned. 
[I 2025-11-04 13:44:11,089] Trial 971 pruned. 
[I 2025-11-04 13:44:31,810] Trial 972 pruned. 
2025-11-04 13:47:35,412 - INFO - Trial 973: Early stopping at epoch 109.
[I 2025-11-04 13:47:35,505] Trial 973 finished with value: 0.003529070100499114 and parameters: {'batch_size': 64, 'learning_rate': 0.0012556438453266705, 'nr_hidden_layers': 2, 'nr_neurons': 215, 'dropout_rate': 0.0005552799007601419, 'weight_decay': 3.0626924034326835e-06, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 13:47:53,857] Trial 974 pruned. 
[I 2025-11-04 13:48:12,184] Trial 975 pruned. 
[I 2025-11-04 13:48:31,032] Trial 976 pruned. 
[I 2025-11-04 13:48:49,792] Trial 977 pruned. 
[I 2025-11-04 13:49:08,214] Trial 978 pruned. 
[I 2025-11-04 13:49:29,950] Trial 979 pruned. 
[I 2025-11-04 13:49:51,703] Trial 980 pruned. 
[I 2025-11-04 13:49:58,341] Trial 981 pruned. 
[I 2025-11-04 13:50:17,011] Trial 982 pruned. 
[I 2025-11-04 13:50:35,449] Trial 983 pruned. 
2025-11-04 13:54:45,995 - INFO - Trial 984: Early stopping at epoch 144.
[I 2025-11-04 13:54:46,093] Trial 984 finished with value: 0.0029183261523016294 and parameters: {'batch_size': 64, 'learning_rate': 0.0007571109548136849, 'nr_hidden_layers': 2, 'nr_neurons': 256, 'dropout_rate': 0.00014976936722239546, 'weight_decay': 6.752276956070018e-06, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 13:55:04,719] Trial 985 pruned. 
[I 2025-11-04 13:55:23,109] Trial 986 pruned. 
2025-11-04 13:58:46,332 - INFO - Trial 987: Early stopping at epoch 109.
[I 2025-11-04 13:58:46,425] Trial 987 finished with value: 0.0035314898601312207 and parameters: {'batch_size': 64, 'learning_rate': 0.0011126958546489065, 'nr_hidden_layers': 2, 'nr_neurons': 167, 'dropout_rate': 0.00015125362366343324, 'weight_decay': 0.00012037408899601726, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 13:59:03,191] Trial 988 pruned. 
[I 2025-11-04 13:59:21,665] Trial 989 pruned. 
[I 2025-11-04 13:59:46,810] Trial 990 pruned. 
[I 2025-11-04 13:59:52,507] Trial 991 pruned. 
[I 2025-11-04 14:00:11,227] Trial 992 pruned. 
[I 2025-11-04 14:00:19,541] Trial 993 pruned. 
[I 2025-11-04 14:00:38,437] Trial 994 pruned. 
[I 2025-11-04 14:00:56,910] Trial 995 pruned. 
[I 2025-11-04 14:01:03,887] Trial 996 pruned. 
[I 2025-11-04 14:01:23,911] Trial 997 pruned. 
[I 2025-11-04 14:01:48,358] Trial 998 pruned. 
[I 2025-11-04 14:02:06,863] Trial 999 pruned. 
2025-11-04 14:02:06,915 - INFO - Optuna study complete. Best trial: 124
2025-11-04 14:02:06,964 - INFO - Best Loss: 0.0014025710088954345
2025-11-04 14:02:06,986 - INFO - Best Params: {'batch_size': 64, 'learning_rate': 0.0004941338722825084, 'nr_hidden_layers': 2, 'nr_neurons': 211, 'dropout_rate': 0.000634511537600873, 'weight_decay': 0.001615577890788605, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}
2025-11-04 14:02:06,987 - INFO - Training final model with best parameters...
2025-11-04 14:02:07,009 - INFO - Starting main training for labels ['Iso_distance']...
2025-11-04 14:02:08,297 - INFO - Final training: 47896 train samples, 11975 val samples, 25660 test samples.
2025-11-04 14:02:08,300 - INFO - Using SmoothL1Loss (Huber Loss)
2025-11-04 14:02:08,300 - INFO - Using CosineAnnealingLR with T_max=1000
2025-11-04 14:02:08,308 - INFO - Starting final training loop for max 1000 epochs (Patience=25)...
2025-11-04 14:02:09,926 - INFO - Epoch [1/1000], Train Loss: 0.008998, Val Loss: 0.004168, LR: 0.000494
2025-11-04 14:02:09,928 - INFO - New best model found at epoch 1 with val_loss: 0.004168
2025-11-04 14:02:11,549 - INFO - New best model found at epoch 2 with val_loss: 0.001793
2025-11-04 14:02:13,164 - INFO - New best model found at epoch 3 with val_loss: 0.001114
2025-11-04 14:02:16,399 - INFO - New best model found at epoch 5 with val_loss: 0.000813
2025-11-04 14:02:18,014 - INFO - New best model found at epoch 6 with val_loss: 0.000518
2025-11-04 14:02:22,872 - INFO - New best model found at epoch 9 with val_loss: 0.000427
2025-11-04 14:02:24,484 - INFO - New best model found at epoch 10 with val_loss: 0.000232
2025-11-04 14:02:26,108 - INFO - New best model found at epoch 11 with val_loss: 0.000134
2025-11-04 14:02:29,352 - INFO - New best model found at epoch 13 with val_loss: 0.000090
2025-11-04 14:02:34,209 - INFO - New best model found at epoch 16 with val_loss: 0.000090
2025-11-04 14:02:47,142 - INFO - New best model found at epoch 24 with val_loss: 0.000069
2025-11-04 14:02:51,988 - INFO - New best model found at epoch 27 with val_loss: 0.000041
2025-11-04 14:02:53,610 - INFO - New best model found at epoch 28 with val_loss: 0.000037
2025-11-04 14:02:56,852 - INFO - New best model found at epoch 30 with val_loss: 0.000031
2025-11-04 14:03:04,959 - INFO - New best model found at epoch 35 with val_loss: 0.000029
2025-11-04 14:03:09,807 - INFO - New best model found at epoch 38 with val_loss: 0.000027
2025-11-04 14:03:17,887 - INFO - New best model found at epoch 43 with val_loss: 0.000021
2025-11-04 14:03:25,926 - INFO - New best model found at epoch 48 with val_loss: 0.000021
2025-11-04 14:03:29,135 - INFO - Epoch [50/1000], Train Loss: 0.000044, Val Loss: 0.000017, LR: 0.000491
2025-11-04 14:03:29,137 - INFO - New best model found at epoch 50 with val_loss: 0.000017
2025-11-04 14:03:32,361 - INFO - New best model found at epoch 52 with val_loss: 0.000014
2025-11-04 14:03:40,385 - INFO - New best model found at epoch 57 with val_loss: 0.000014
2025-11-04 14:04:06,088 - INFO - New best model found at epoch 73 with val_loss: 0.000009
2025-11-04 14:04:33,455 - INFO - New best model found at epoch 90 with val_loss: 0.000008
2025-11-04 14:04:48,010 - INFO - New best model found at epoch 99 with val_loss: 0.000007
2025-11-04 14:04:49,632 - INFO - Epoch [100/1000], Train Loss: 0.000020, Val Loss: 0.000011, LR: 0.000482
2025-11-04 14:05:26,764 - INFO - New best model found at epoch 123 with val_loss: 0.000007
2025-11-04 14:05:28,387 - INFO - New best model found at epoch 124 with val_loss: 0.000006
2025-11-04 14:05:41,306 - INFO - New best model found at epoch 132 with val_loss: 0.000005
2025-11-04 14:06:10,419 - INFO - Epoch [150/1000], Train Loss: 0.000017, Val Loss: 0.000008, LR: 0.000467
2025-11-04 14:06:21,760 - INFO - Early stopping at epoch 157.
2025-11-04 14:06:21,760 - INFO - Training complete. Evaluating on test set...
2025-11-04 14:06:22,077 - INFO - Final Test Loss (SmoothL1): 0.000005
2025-11-04 14:06:22,077 - INFO - Inverting transforms and generating plots...
2025-11-04 14:06:22,078 - INFO - Calculating final metrics...
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [64, 1]                   --
ModuleList: 1-7                        --                        (recursive)
    Linear: 2-1                       [64, 211]                 2,110
    LeakyReLU: 2-2                    [64, 211]                 --
Dropout: 1-2                           [64, 211]                 --
ModuleList: 1-7                        --                        (recursive)
    Linear: 2-3                       [64, 211]                 44,732
    LeakyReLU: 2-4                    [64, 211]                 --
Dropout: 1-4                           [64, 211]                 --
ModuleList: 1-7                        --                        (recursive)
    Linear: 2-5                       [64, 211]                 44,732
    LeakyReLU: 2-6                    [64, 211]                 --
Dropout: 1-6                           [64, 211]                 --
ModuleList: 1-7                        --                        (recursive)
    Linear: 2-7                       [64, 1]                   212
==========================================================================================
Total params: 91,786
Trainable params: 91,786
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 5.87
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.32
Params size (MB): 0.37
Estimated Total Size (MB): 0.69
==========================================================================================
Traceback (most recent call last):
  File "/home/barattts/lavoltabuona/BA/run_optuna.py", line 238, in <module>
    final_model = main_train(
                  ^^^^^^^^^^^
  File "/home/barattts/lavoltabuona/BA/trainer.py", line 202, in main_train
    final_metrics = compute_regression_metrics(inverted_true_values, inverted_predictions)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/barattts/lavoltabuona/BA/utils.py", line 44, in compute_regression_metrics
    metrics["rmse"] = mean_squared_error(y_true, y_pred, squared=False)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/sklearn/utils/_param_validation.py", line 196, in wrapper
    params = func_sig.bind(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/inspect.py", line 3242, in bind
    return self._bind(args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/inspect.py", line 3231, in _bind
    raise TypeError(
TypeError: got an unexpected keyword argument 'squared'
Job finished.

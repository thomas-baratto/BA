Job started on argon-gtx
Job ID: 543
Working directory: /home/barattts/lavoltabuona/BA
---
Starting Python script...
Unable to determine the device handle for GPU0000:61:00.0: Unknown Error
Running: python run_optuna.py --target Iso_width --skip-optuna
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
2025-11-07 18:35:30,904 - INFO - Using device: cuda
2025-11-07 18:35:30,905 - INFO - Target labels for this run: ['Iso_width']
2025-11-07 18:35:30,905 - INFO - Skip Optuna: True
2025-11-07 18:35:30,906 - INFO - Skipping Optuna. Loading best parameters from study: nn_study_Iso_width...
2025-11-07 18:35:31,685 - ERROR - Study 'nn_study_Iso_width' not found in database. Available studies:
2025-11-07 18:35:59,948 - ERROR -   - nn_study_['Iso_distance']
2025-11-07 18:35:59,949 - ERROR -   - nn_study_['Area']
2025-11-07 18:35:59,949 - ERROR -   - nn_study_['Iso_width']
2025-11-07 18:35:59,949 - ERROR -   - nn_study_['Area', 'Iso_distance', 'Iso_width']
2025-11-07 18:35:59,949 - INFO - Falling back to default parameters...
2025-11-07 18:35:59,949 - INFO - Training final model with parameters...
2025-11-07 18:35:59,949 - INFO - Starting main training for labels ['Iso_width']...
2025-11-07 18:36:01,009 - INFO - Final training: 47896 train samples, 11975 val samples, 25660 test samples.
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
2025-11-07 18:36:01,539 - INFO - Using SmoothL1Loss (Huber Loss)
2025-11-07 18:36:04,381 - INFO - Using CosineAnnealingLR with T_max=1000
2025-11-07 18:36:04,382 - INFO - Added warmup for 10 epochs
2025-11-07 18:36:04,452 - INFO - Starting final training loop for max 1000 epochs (Patience=100)...
2025-11-07 18:36:06,751 - INFO - Epoch [1/1000], Train Loss: 0.017477, Val Loss: 0.003395, LR: 0.000190
2025-11-07 18:36:06,754 - INFO - New best model found at epoch 1 with val_loss: 0.003395
2025-11-07 18:36:09,716 - INFO - New best model found at epoch 2 with val_loss: 0.003246
2025-11-07 18:36:11,663 - INFO - New best model found at epoch 3 with val_loss: 0.003155
2025-11-07 18:36:13,581 - INFO - New best model found at epoch 4 with val_loss: 0.003080
2025-11-07 18:36:15,492 - INFO - New best model found at epoch 5 with val_loss: 0.002934
2025-11-07 18:36:17,456 - INFO - New best model found at epoch 6 with val_loss: 0.002913
2025-11-07 18:36:19,420 - INFO - New best model found at epoch 7 with val_loss: 0.002104
2025-11-07 18:36:21,384 - INFO - New best model found at epoch 8 with val_loss: 0.002039
2025-11-07 18:36:23,352 - INFO - New best model found at epoch 9 with val_loss: 0.001687
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
2025-11-07 18:36:25,317 - INFO - New best model found at epoch 10 with val_loss: 0.001507
2025-11-07 18:36:27,276 - INFO - New best model found at epoch 11 with val_loss: 0.001169
2025-11-07 18:36:29,232 - INFO - New best model found at epoch 12 with val_loss: 0.001023
2025-11-07 18:36:31,207 - INFO - New best model found at epoch 13 with val_loss: 0.000726
2025-11-07 18:36:33,167 - INFO - New best model found at epoch 14 with val_loss: 0.000549
2025-11-07 18:36:35,128 - INFO - New best model found at epoch 15 with val_loss: 0.000423
2025-11-07 18:36:37,094 - INFO - New best model found at epoch 16 with val_loss: 0.000263
2025-11-07 18:36:39,060 - INFO - New best model found at epoch 17 with val_loss: 0.000229
2025-11-07 18:36:42,994 - INFO - New best model found at epoch 19 with val_loss: 0.000114
2025-11-07 18:36:48,902 - INFO - New best model found at epoch 22 with val_loss: 0.000100
2025-11-07 18:36:58,757 - INFO - New best model found at epoch 27 with val_loss: 0.000083
2025-11-07 18:37:22,359 - INFO - New best model found at epoch 39 with val_loss: 0.000081
2025-11-07 18:37:28,261 - INFO - New best model found at epoch 42 with val_loss: 0.000045
2025-11-07 18:37:43,968 - INFO - Epoch [50/1000], Train Loss: 0.000223, Val Loss: 0.000067, LR: 0.000996
2025-11-07 18:37:51,827 - INFO - New best model found at epoch 54 with val_loss: 0.000039
2025-11-07 18:38:38,982 - INFO - New best model found at epoch 78 with val_loss: 0.000034
2025-11-07 18:39:08,451 - INFO - New best model found at epoch 93 with val_loss: 0.000033
2025-11-07 18:39:22,185 - INFO - Epoch [100/1000], Train Loss: 0.000164, Val Loss: 0.000050, LR: 0.000980
2025-11-07 18:39:24,144 - INFO - New best model found at epoch 101 with val_loss: 0.000028
2025-11-07 18:40:01,489 - INFO - New best model found at epoch 120 with val_loss: 0.000027
2025-11-07 18:40:15,269 - INFO - New best model found at epoch 127 with val_loss: 0.000025
2025-11-07 18:41:01,461 - INFO - Epoch [150/1000], Train Loss: 0.000145, Val Loss: 0.000030, LR: 0.000952
2025-11-07 18:41:11,347 - INFO - New best model found at epoch 155 with val_loss: 0.000025
slurmstepd-argon-gtx: error: *** JOB 543 ON argon-gtx CANCELLED AT 2025-11-07T18:41:55 ***

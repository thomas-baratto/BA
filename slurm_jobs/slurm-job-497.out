Job started on argon-gtx
Job ID: 497
Working directory: /home/barattts/lavoltabuona/BA
---
Starting Python script...
Running: python run_optuna.py --target Iso_width
2025-11-04 14:41:16,465 - INFO - Using device: cuda
2025-11-04 14:41:16,465 - INFO - Target labels for this run: ['Iso_width']
2025-11-04 14:41:16,466 - INFO - Loading data for Optuna study (Labels: ['Iso_width'])...
2025-11-04 14:41:16,649 - INFO - Starting Optuna study: nn_study_['Iso_width']...
[I 2025-11-04 14:41:17,416] Using an existing study with name 'nn_study_['Iso_width']' instead of creating a new one.
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
2025-11-04 14:43:06,685 - INFO - Trial 534: Early stopping at epoch 68.
[I 2025-11-04 14:43:06,789] Trial 534 finished with value: 0.0076433452777564526 and parameters: {'batch_size': 64, 'learning_rate': 0.005580433106853029, 'nr_hidden_layers': 1, 'nr_neurons': 203, 'dropout_rate': 0.017891839860515516, 'weight_decay': 1.8563155266579262e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 14:43:14,736] Trial 535 pruned. 
[I 2025-11-04 14:43:44,621] Trial 536 pruned. 
[I 2025-11-04 14:44:14,489] Trial 538 pruned. 
2025-11-04 14:46:10,287 - INFO - Trial 539: Early stopping at epoch 75.
[I 2025-11-04 14:46:10,381] Trial 539 finished with value: 0.005347693804651499 and parameters: {'batch_size': 64, 'learning_rate': 0.0060449725186759225, 'nr_hidden_layers': 1, 'nr_neurons': 157, 'dropout_rate': 0.0005937252381873233, 'weight_decay': 1.0890170278416654e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 14:46:26,822] Trial 541 pruned. 
[I 2025-11-04 14:46:43,240] Trial 542 pruned. 
[I 2025-11-04 14:49:35,265] Trial 543 pruned. 
[I 2025-11-04 14:50:25,035] Trial 545 pruned. 
2025-11-04 14:52:45,733 - INFO - Trial 546: Early stopping at epoch 94.
[I 2025-11-04 14:52:45,825] Trial 546 finished with value: 0.002946458524093032 and parameters: {'batch_size': 64, 'learning_rate': 0.006259914784514736, 'nr_hidden_layers': 1, 'nr_neurons': 167, 'dropout_rate': 0.0001287579114500365, 'weight_decay': 1.7668646973683585e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 14:53:02,371] Trial 547 pruned. 
[I 2025-11-04 14:53:21,823] Trial 548 pruned. 
2025-11-04 14:57:53,744 - INFO - Trial 549: Early stopping at epoch 181.
[I 2025-11-04 14:57:53,837] Trial 549 finished with value: 0.003403787035495043 and parameters: {'batch_size': 64, 'learning_rate': 0.005152849455488899, 'nr_hidden_layers': 1, 'nr_neurons': 24, 'dropout_rate': 6.277594572570911e-05, 'weight_decay': 2.544952654487296e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 14:58:10,434] Trial 558 pruned. 
2025-11-04 14:59:11,123 - INFO - Trial 560: Early stopping at epoch 40.
[I 2025-11-04 14:59:11,236] Trial 560 finished with value: 0.010160192847251892 and parameters: {'batch_size': 64, 'learning_rate': 0.004574667882688281, 'nr_hidden_layers': 1, 'nr_neurons': 163, 'dropout_rate': 0.024337422158665047, 'weight_decay': 3.7594438921016936e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 14:59:27,630] Trial 564 pruned. 
[I 2025-11-04 14:59:44,086] Trial 565 pruned. 
2025-11-04 15:00:58,111 - INFO - Trial 566: Early stopping at epoch 49.
[I 2025-11-04 15:00:58,227] Trial 566 finished with value: 0.007442132104188204 and parameters: {'batch_size': 64, 'learning_rate': 0.004204410997343054, 'nr_hidden_layers': 1, 'nr_neurons': 169, 'dropout_rate': 0.008969348249589946, 'weight_decay': 4.136199718465442e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 15:01:14,674] Trial 568 pruned. 
[I 2025-11-04 15:01:31,131] Trial 569 pruned. 
[I 2025-11-04 15:01:53,647] Trial 570 pruned. 
2025-11-04 15:02:32,697 - INFO - Trial 571: Early stopping at epoch 49.
[I 2025-11-04 15:02:32,818] Trial 571 finished with value: 0.008171368390321732 and parameters: {'batch_size': 256, 'learning_rate': 0.009278967795075756, 'nr_hidden_layers': 3, 'nr_neurons': 150, 'dropout_rate': 1.9371530378572673e-06, 'weight_decay': 2.1229030674154476e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 15:04:33,826 - INFO - Trial 572: Early stopping at epoch 79.
[I 2025-11-04 15:04:33,918] Trial 572 finished with value: 0.006970201153308153 and parameters: {'batch_size': 64, 'learning_rate': 0.0042462067932703676, 'nr_hidden_layers': 1, 'nr_neurons': 166, 'dropout_rate': 0.010094004488406768, 'weight_decay': 3.582088223150005e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 15:05:58,403] Trial 575 pruned. 
[I 2025-11-04 15:06:29,174] Trial 576 pruned. 
[I 2025-11-04 15:06:36,208] Trial 577 pruned. 
[I 2025-11-04 15:06:55,610] Trial 578 pruned. 
2025-11-04 15:08:44,504 - INFO - Trial 579: Early stopping at epoch 72.
[I 2025-11-04 15:08:44,597] Trial 579 finished with value: 0.004279813729226589 and parameters: {'batch_size': 64, 'learning_rate': 0.007204149414385551, 'nr_hidden_layers': 1, 'nr_neurons': 200, 'dropout_rate': 0.00014013319359580163, 'weight_decay': 2.944708275769383e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 15:12:17,707 - INFO - Trial 581: Early stopping at epoch 137.
[I 2025-11-04 15:12:17,810] Trial 581 finished with value: 0.0033125262707471848 and parameters: {'batch_size': 64, 'learning_rate': 0.0046200105051667625, 'nr_hidden_layers': 1, 'nr_neurons': 54, 'dropout_rate': 0.00013818247750408194, 'weight_decay': 5.007319662649321e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 15:12:40,324] Trial 584 pruned. 
[I 2025-11-04 15:13:06,538] Trial 585 pruned. 
[I 2025-11-04 15:13:54,643] Trial 586 pruned. 
[I 2025-11-04 15:14:26,344] Trial 588 pruned. 
[I 2025-11-04 15:14:32,939] Trial 589 pruned. 
[I 2025-11-04 15:15:04,967] Trial 590 pruned. 
2025-11-04 15:18:04,004 - INFO - Trial 592: Early stopping at epoch 113.
[I 2025-11-04 15:18:04,110] Trial 592 finished with value: 0.0056008510291576385 and parameters: {'batch_size': 64, 'learning_rate': 0.005163966843139537, 'nr_hidden_layers': 1, 'nr_neurons': 197, 'dropout_rate': 0.010263752786169901, 'weight_decay': 1.966066842951614e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 15:20:13,516 - INFO - Trial 596: Early stopping at epoch 86.
[I 2025-11-04 15:20:13,611] Trial 596 finished with value: 0.0055949026718735695 and parameters: {'batch_size': 64, 'learning_rate': 0.0062192934405649715, 'nr_hidden_layers': 1, 'nr_neurons': 159, 'dropout_rate': 0.008671268727589252, 'weight_decay': 2.6384301799316715e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 15:20:21,647] Trial 597 pruned. 
[I 2025-11-04 15:21:04,595] Trial 598 pruned. 
2025-11-04 15:22:21,714 - INFO - Trial 601: Early stopping at epoch 51.
[I 2025-11-04 15:22:21,807] Trial 601 finished with value: 0.009050053544342518 and parameters: {'batch_size': 64, 'learning_rate': 0.004329153158025063, 'nr_hidden_layers': 1, 'nr_neurons': 148, 'dropout_rate': 0.02500274320576604, 'weight_decay': 4.127664274146264e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 15:25:30,115 - INFO - Trial 602: Early stopping at epoch 126.
[I 2025-11-04 15:25:30,209] Trial 602 finished with value: 0.0028999783098697662 and parameters: {'batch_size': 64, 'learning_rate': 0.006650549280403282, 'nr_hidden_layers': 1, 'nr_neurons': 165, 'dropout_rate': 0.00020417299070616042, 'weight_decay': 5.2438736264238476e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 15:26:59,271] Trial 606 pruned. 
2025-11-04 15:28:44,949 - INFO - Trial 607: Early stopping at epoch 69.
[I 2025-11-04 15:28:45,044] Trial 607 finished with value: 0.007170436903834343 and parameters: {'batch_size': 64, 'learning_rate': 0.004662891363328785, 'nr_hidden_layers': 1, 'nr_neurons': 182, 'dropout_rate': 0.0162378610430617, 'weight_decay': 2.3376345417958618e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 15:30:56,943] Trial 608 pruned. 
[I 2025-11-04 15:31:13,676] Trial 613 pruned. 
2025-11-04 15:34:12,433 - INFO - Trial 614: Early stopping at epoch 113.
[I 2025-11-04 15:34:12,527] Trial 614 finished with value: 0.005577503703534603 and parameters: {'batch_size': 64, 'learning_rate': 0.005028264810244696, 'nr_hidden_layers': 1, 'nr_neurons': 201, 'dropout_rate': 0.008661270963490687, 'weight_decay': 2.0998431365944647e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 15:40:00,760 - INFO - Trial 619: Early stopping at epoch 221.
[I 2025-11-04 15:40:00,859] Trial 619 finished with value: 0.00183771678712219 and parameters: {'batch_size': 64, 'learning_rate': 0.003994540748456971, 'nr_hidden_layers': 1, 'nr_neurons': 184, 'dropout_rate': 6.102047305069155e-05, 'weight_decay': 3.145110525781732e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 15:40:17,743] Trial 621 pruned. 
[I 2025-11-04 15:40:34,613] Trial 622 pruned. 
[I 2025-11-04 15:40:51,470] Trial 623 pruned. 
[I 2025-11-04 15:41:14,022] Trial 624 pruned. 
[I 2025-11-04 15:41:22,131] Trial 625 pruned. 
2025-11-04 15:42:35,592 - INFO - Trial 626: Early stopping at epoch 48.
[I 2025-11-04 15:42:35,687] Trial 626 finished with value: 0.007909872569143772 and parameters: {'batch_size': 64, 'learning_rate': 0.007298118370462409, 'nr_hidden_layers': 1, 'nr_neurons': 175, 'dropout_rate': 0.000265059461813697, 'weight_decay': 3.2226162981420914e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 15:45:49,165 - INFO - Trial 627: Early stopping at epoch 127.
[I 2025-11-04 15:45:49,263] Trial 627 finished with value: 0.002917218254879117 and parameters: {'batch_size': 64, 'learning_rate': 0.004058823871415674, 'nr_hidden_layers': 1, 'nr_neurons': 223, 'dropout_rate': 0.00015115053048516474, 'weight_decay': 2.6737411214734513e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 15:46:06,240] Trial 631 pruned. 
[I 2025-11-04 15:46:13,264] Trial 632 pruned. 
[I 2025-11-04 15:46:29,740] Trial 633 pruned. 
[I 2025-11-04 15:47:06,924] Trial 635 pruned. 
[I 2025-11-04 15:47:25,241] Trial 637 pruned. 
[I 2025-11-04 15:47:41,705] Trial 638 pruned. 
[I 2025-11-04 15:47:47,507] Trial 639 pruned. 
[I 2025-11-04 15:48:12,031] Trial 640 pruned. 
2025-11-04 15:50:31,756 - INFO - Trial 641: Early stopping at epoch 92.
[I 2025-11-04 15:50:31,853] Trial 641 finished with value: 0.006288777105510235 and parameters: {'batch_size': 64, 'learning_rate': 0.004336673924559171, 'nr_hidden_layers': 1, 'nr_neurons': 175, 'dropout_rate': 0.008982759109112354, 'weight_decay': 3.631840613863313e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 15:51:32,280 - INFO - Trial 645: Early stopping at epoch 38.
[I 2025-11-04 15:51:32,390] Trial 645 finished with value: 0.009965376928448677 and parameters: {'batch_size': 64, 'learning_rate': 0.0059784289850734, 'nr_hidden_layers': 1, 'nr_neurons': 211, 'dropout_rate': 0.016844763454588, 'weight_decay': 0.0003443942646591703, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 15:51:49,313] Trial 646 pruned. 
[I 2025-11-04 15:52:06,429] Trial 647 pruned. 
2025-11-04 15:54:21,709 - INFO - Trial 648: Early stopping at epoch 89.
[I 2025-11-04 15:54:21,830] Trial 648 finished with value: 0.003807015949860215 and parameters: {'batch_size': 64, 'learning_rate': 0.006913204642428727, 'nr_hidden_layers': 1, 'nr_neurons': 187, 'dropout_rate': 0.000114841478526851, 'weight_decay': 2.1938160098804753e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 15:54:28,325] Trial 650 pruned. 
[I 2025-11-04 15:57:37,558] Trial 651 pruned. 
2025-11-04 16:02:17,485 - INFO - Trial 658: Early stopping at epoch 179.
[I 2025-11-04 16:02:17,583] Trial 658 finished with value: 0.002959741512313485 and parameters: {'batch_size': 64, 'learning_rate': 0.006262934276704704, 'nr_hidden_layers': 1, 'nr_neurons': 161, 'dropout_rate': 0.00014337553635333696, 'weight_decay': 3.854106933875711e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 16:02:23,471] Trial 666 pruned. 
[I 2025-11-04 16:04:01,713] Trial 667 pruned. 
2025-11-04 16:09:30,378 - INFO - Trial 668: Early stopping at epoch 218.
[I 2025-11-04 16:09:30,476] Trial 668 finished with value: 0.002338591730222106 and parameters: {'batch_size': 64, 'learning_rate': 0.001607746287383566, 'nr_hidden_layers': 1, 'nr_neurons': 190, 'dropout_rate': 0.0002571641744222263, 'weight_decay': 4.3316767310118354e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 16:09:37,031] Trial 671 pruned. 
2025-11-04 16:11:33,338 - INFO - Trial 672: Early stopping at epoch 76.
[I 2025-11-04 16:11:33,442] Trial 672 finished with value: 0.0037810225039720535 and parameters: {'batch_size': 64, 'learning_rate': 0.007100830097111859, 'nr_hidden_layers': 1, 'nr_neurons': 194, 'dropout_rate': 0.00022945357941589505, 'weight_decay': 4.6573486622412046e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 16:18:00,809 - INFO - Trial 673: Early stopping at epoch 255.
[I 2025-11-04 16:18:00,911] Trial 673 finished with value: 0.0017950269393622875 and parameters: {'batch_size': 64, 'learning_rate': 0.006524197349417674, 'nr_hidden_layers': 1, 'nr_neurons': 188, 'dropout_rate': 5.8614211751876604e-05, 'weight_decay': 0.0008166643372122072, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 16:18:17,965] Trial 684 pruned. 
[I 2025-11-04 16:21:14,150] Trial 685 pruned. 
2025-11-04 16:25:00,307 - INFO - Trial 688: Early stopping at epoch 144.
[I 2025-11-04 16:25:00,408] Trial 688 finished with value: 0.0039544557221233845 and parameters: {'batch_size': 64, 'learning_rate': 0.0018521162926763556, 'nr_hidden_layers': 1, 'nr_neurons': 198, 'dropout_rate': 0.009018826245476728, 'weight_decay': 2.5468317665277127e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 16:25:48,267] Trial 695 pruned. 
2025-11-04 16:27:25,219 - INFO - Trial 696: Early stopping at epoch 64.
[I 2025-11-04 16:27:25,320] Trial 696 finished with value: 0.008129359222948551 and parameters: {'batch_size': 64, 'learning_rate': 0.006598442983107178, 'nr_hidden_layers': 1, 'nr_neurons': 190, 'dropout_rate': 0.01958391533587038, 'weight_decay': 1.943827867022182e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 16:30:01,456] Trial 701 pruned. 
[I 2025-11-04 16:30:18,019] Trial 703 pruned. 
2025-11-04 16:32:45,026 - INFO - Trial 704: Early stopping at epoch 97.
[I 2025-11-04 16:32:45,134] Trial 704 finished with value: 0.00538899190723896 and parameters: {'batch_size': 64, 'learning_rate': 0.005546881119274574, 'nr_hidden_layers': 1, 'nr_neurons': 206, 'dropout_rate': 0.008952193478885838, 'weight_decay': 1.3098624890945327e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 16:33:01,689] Trial 707 pruned. 
[I 2025-11-04 16:33:18,257] Trial 708 pruned. 
[I 2025-11-04 16:33:34,837] Trial 710 pruned. 
2025-11-04 16:34:42,007 - INFO - Trial 712: Early stopping at epoch 44.
[I 2025-11-04 16:34:42,106] Trial 712 finished with value: 0.00905044749379158 and parameters: {'batch_size': 64, 'learning_rate': 0.003974629054895947, 'nr_hidden_layers': 1, 'nr_neurons': 179, 'dropout_rate': 0.01949545480930099, 'weight_decay': 1.7235375905533904e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 16:34:49,204] Trial 713 pruned. 
[I 2025-11-04 16:35:05,755] Trial 714 pruned. 
[I 2025-11-04 16:35:13,635] Trial 715 pruned. 
[I 2025-11-04 16:35:30,047] Trial 717 pruned. 
2025-11-04 16:42:53,916 - INFO - Trial 719: Early stopping at epoch 294.
[I 2025-11-04 16:42:54,037] Trial 719 finished with value: 0.0014767380198463798 and parameters: {'batch_size': 64, 'learning_rate': 0.003889223465628847, 'nr_hidden_layers': 1, 'nr_neurons': 174, 'dropout_rate': 0.0003049125031902612, 'weight_decay': 3.99193500357735e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 16:43:10,556] Trial 723 pruned. 
[I 2025-11-04 16:43:27,124] Trial 724 pruned. 
[I 2025-11-04 16:43:43,714] Trial 725 pruned. 
[I 2025-11-04 16:43:50,186] Trial 726 pruned. 
2025-11-04 16:45:52,621 - INFO - Trial 727: Early stopping at epoch 81.
[I 2025-11-04 16:45:52,722] Trial 727 finished with value: 0.0038562940899282694 and parameters: {'batch_size': 64, 'learning_rate': 0.007790671714145862, 'nr_hidden_layers': 1, 'nr_neurons': 191, 'dropout_rate': 0.00010878853318940082, 'weight_decay': 2.5856283248772156e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 16:46:12,238] Trial 732 pruned. 
[I 2025-11-04 16:46:43,963] Trial 733 pruned. 
[I 2025-11-04 16:49:37,136] Trial 734 pruned. 
[I 2025-11-04 16:49:53,760] Trial 735 pruned. 
[I 2025-11-04 16:50:10,616] Trial 736 pruned. 
[I 2025-11-04 16:50:27,292] Trial 737 pruned. 
[I 2025-11-04 16:50:43,905] Trial 738 pruned. 
[I 2025-11-04 16:51:03,493] Trial 740 pruned. 
[I 2025-11-04 16:51:29,757] Trial 741 pruned. 
2025-11-04 16:52:35,618 - INFO - Trial 742: Early stopping at epoch 35.
[I 2025-11-04 16:52:35,716] Trial 742 finished with value: 0.010039850138127804 and parameters: {'batch_size': 64, 'learning_rate': 0.003384416720787085, 'nr_hidden_layers': 3, 'nr_neurons': 193, 'dropout_rate': 0.025409486702626483, 'weight_decay': 3.369369267609818e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 16:52:42,721] Trial 743 pruned. 
[I 2025-11-04 16:53:03,291] Trial 744 pruned. 
2025-11-04 16:56:14,786 - INFO - Trial 745: Early stopping at epoch 125.
[I 2025-11-04 16:56:14,900] Trial 745 finished with value: 0.003930989187210798 and parameters: {'batch_size': 64, 'learning_rate': 0.006440606364804656, 'nr_hidden_layers': 1, 'nr_neurons': 37, 'dropout_rate': 0.00015353760962264864, 'weight_decay': 4.012510167962904e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 16:56:20,531] Trial 748 pruned. 
2025-11-04 16:57:49,979 - INFO - Trial 749: Early stopping at epoch 94.
[I 2025-11-04 16:57:50,096] Trial 749 finished with value: 0.006052106618881226 and parameters: {'batch_size': 128, 'learning_rate': 0.0039941917590679415, 'nr_hidden_layers': 1, 'nr_neurons': 211, 'dropout_rate': 0.010161225770815114, 'weight_decay': 2.9830498724371717e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 16:58:09,679] Trial 750 pruned. 
2025-11-04 16:59:55,396 - INFO - Trial 751: Early stopping at epoch 70.
[I 2025-11-04 16:59:55,567] Trial 751 finished with value: 0.007396193686872721 and parameters: {'batch_size': 64, 'learning_rate': 0.004384397185925423, 'nr_hidden_layers': 1, 'nr_neurons': 157, 'dropout_rate': 0.00972649100111599, 'weight_decay': 3.480168749164583e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 17:00:12,203] Trial 753 pruned. 
[I 2025-11-04 17:00:28,898] Trial 754 pruned. 
[I 2025-11-04 17:00:35,453] Trial 755 pruned. 
[I 2025-11-04 17:03:45,494] Trial 757 pruned. 
2025-11-04 17:05:30,870 - INFO - Trial 761: Early stopping at epoch 62.
[I 2025-11-04 17:05:30,974] Trial 761 finished with value: 0.007294951938092709 and parameters: {'batch_size': 64, 'learning_rate': 0.003969191854096387, 'nr_hidden_layers': 2, 'nr_neurons': 200, 'dropout_rate': 0.008367424002899079, 'weight_decay': 2.829973174005955e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 17:05:38,881] Trial 763 pruned. 
[I 2025-11-04 17:05:55,302] Trial 764 pruned. 
[I 2025-11-04 17:06:11,869] Trial 765 pruned. 
2025-11-04 17:08:06,041 - INFO - Trial 766: Early stopping at epoch 76.
[I 2025-11-04 17:08:06,143] Trial 766 finished with value: 0.007576255593448877 and parameters: {'batch_size': 64, 'learning_rate': 0.005374933890048761, 'nr_hidden_layers': 1, 'nr_neurons': 186, 'dropout_rate': 0.016486274591481814, 'weight_decay': 3.97561047502417e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 17:10:21,266 - INFO - Trial 768: Early stopping at epoch 90.
[I 2025-11-04 17:10:21,369] Trial 768 finished with value: 0.006544628646224737 and parameters: {'batch_size': 64, 'learning_rate': 0.00599995671101187, 'nr_hidden_layers': 1, 'nr_neurons': 239, 'dropout_rate': 0.017502165469377516, 'weight_decay': 5.6283297138083076e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 17:10:28,343] Trial 770 pruned. 
2025-11-04 17:12:45,676 - INFO - Trial 771: Early stopping at epoch 89.
[I 2025-11-04 17:12:45,780] Trial 771 finished with value: 0.003588966093957424 and parameters: {'batch_size': 64, 'learning_rate': 0.004763373270453342, 'nr_hidden_layers': 1, 'nr_neurons': 157, 'dropout_rate': 0.00016464868938296213, 'weight_decay': 2.7029370778862188e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 17:13:05,341] Trial 773 pruned. 
2025-11-04 17:16:17,036 - INFO - Trial 774: Early stopping at epoch 121.
[I 2025-11-04 17:16:17,142] Trial 774 finished with value: 0.005115842446684837 and parameters: {'batch_size': 64, 'learning_rate': 0.003800155500013863, 'nr_hidden_layers': 1, 'nr_neurons': 189, 'dropout_rate': 0.009859593899967644, 'weight_decay': 5.190660526305096e-06, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 17:16:28,023] Trial 779 pruned. 
[I 2025-11-04 17:16:50,033] Trial 781 pruned. 
[I 2025-11-04 17:17:06,506] Trial 783 pruned. 
2025-11-04 17:20:10,239 - INFO - Trial 785: Early stopping at epoch 123.
[I 2025-11-04 17:20:10,353] Trial 785 finished with value: 0.002985583385452628 and parameters: {'batch_size': 64, 'learning_rate': 0.004457558876099959, 'nr_hidden_layers': 1, 'nr_neurons': 151, 'dropout_rate': 1.419730906864573e-05, 'weight_decay': 2.7922671710727098e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 17:20:26,828] Trial 786 pruned. 
[I 2025-11-04 17:20:43,351] Trial 788 pruned. 
[I 2025-11-04 17:23:01,093] Trial 790 pruned. 
[I 2025-11-04 17:23:17,851] Trial 792 pruned. 
[I 2025-11-04 17:23:25,712] Trial 793 pruned. 
[I 2025-11-04 17:24:14,002] Trial 795 pruned. 
[I 2025-11-04 17:24:44,199] Trial 797 pruned. 
[I 2025-11-04 17:25:00,682] Trial 798 pruned. 
[I 2025-11-04 17:25:17,276] Trial 799 pruned. 
2025-11-04 17:27:59,552 - INFO - Trial 800: Early stopping at epoch 106.
[I 2025-11-04 17:27:59,681] Trial 800 finished with value: 0.005525806453078985 and parameters: {'batch_size': 64, 'learning_rate': 0.004260033322954256, 'nr_hidden_layers': 1, 'nr_neurons': 167, 'dropout_rate': 0.018384057399488365, 'weight_decay': 3.487183008560342e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 17:28:23,518] Trial 803 pruned. 
2025-11-04 17:33:45,998 - INFO - Trial 804: Early stopping at epoch 189.
[I 2025-11-04 17:33:46,109] Trial 804 finished with value: 0.002030448755249381 and parameters: {'batch_size': 64, 'learning_rate': 0.005150887770507016, 'nr_hidden_layers': 2, 'nr_neurons': 165, 'dropout_rate': 4.675987939603066e-05, 'weight_decay': 5.1592070315332736e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 17:33:52,920] Trial 810 pruned. 
[I 2025-11-04 17:34:11,271] Trial 811 pruned. 
2025-11-04 17:36:26,047 - INFO - Trial 812: Early stopping at epoch 80.
[I 2025-11-04 17:36:26,151] Trial 812 finished with value: 0.005461034364998341 and parameters: {'batch_size': 64, 'learning_rate': 0.00463703964100758, 'nr_hidden_layers': 2, 'nr_neurons': 154, 'dropout_rate': 0.009089516464380665, 'weight_decay': 5.731791743923699e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 17:38:14,636 - INFO - Trial 813: Early stopping at epoch 71.
[I 2025-11-04 17:38:14,747] Trial 813 finished with value: 0.005508674308657646 and parameters: {'batch_size': 64, 'learning_rate': 0.003703222766462814, 'nr_hidden_layers': 1, 'nr_neurons': 145, 'dropout_rate': 0.0002787173943386469, 'weight_decay': 6.73253871113958e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 17:38:37,012] Trial 815 pruned. 
[I 2025-11-04 17:38:57,382] Trial 817 pruned. 
2025-11-04 17:42:00,169 - INFO - Trial 818: Early stopping at epoch 106.
[I 2025-11-04 17:42:00,283] Trial 818 finished with value: 0.005317733157426119 and parameters: {'batch_size': 64, 'learning_rate': 0.005186388020476855, 'nr_hidden_layers': 2, 'nr_neurons': 179, 'dropout_rate': 0.01591230144833511, 'weight_decay': 6.516746658578823e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 17:42:21,091] Trial 819 pruned. 
2025-11-04 17:45:47,085 - INFO - Trial 820: Early stopping at epoch 120.
[I 2025-11-04 17:45:47,191] Trial 820 finished with value: 0.004504515323787928 and parameters: {'batch_size': 64, 'learning_rate': 0.0027639039086485434, 'nr_hidden_layers': 2, 'nr_neurons': 128, 'dropout_rate': 0.008593025127148175, 'weight_decay': 4.265043924785218e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 17:49:04,690 - INFO - Trial 825: Early stopping at epoch 131.
[I 2025-11-04 17:49:04,794] Trial 825 finished with value: 0.00325915333814919 and parameters: {'batch_size': 64, 'learning_rate': 0.004636105642233768, 'nr_hidden_layers': 1, 'nr_neurons': 179, 'dropout_rate': 0.000397537950637307, 'weight_decay': 3.093942874414048e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 17:49:11,751] Trial 827 pruned. 
[I 2025-11-04 17:49:29,544] Trial 828 pruned. 
2025-11-04 17:51:31,499 - INFO - Trial 830: Early stopping at epoch 79.
[I 2025-11-04 17:51:31,604] Trial 830 finished with value: 0.005282089579850435 and parameters: {'batch_size': 64, 'learning_rate': 0.00207984585146995, 'nr_hidden_layers': 1, 'nr_neurons': 136, 'dropout_rate': 5.1596938023242575e-05, 'weight_decay': 3.6396821952341194e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 17:52:07,721] Trial 834 pruned. 
2025-11-04 17:55:45,220 - INFO - Trial 835: Early stopping at epoch 141.
[I 2025-11-04 17:55:45,348] Trial 835 finished with value: 0.0027105628978461027 and parameters: {'batch_size': 64, 'learning_rate': 0.004302043955873468, 'nr_hidden_layers': 1, 'nr_neurons': 177, 'dropout_rate': 8.954481361064356e-05, 'weight_decay': 2.847206881774368e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 17:57:27,436 - INFO - Trial 838: Early stopping at epoch 67.
[I 2025-11-04 17:57:27,545] Trial 838 finished with value: 0.007135257590562105 and parameters: {'batch_size': 64, 'learning_rate': 0.005150027561119874, 'nr_hidden_layers': 1, 'nr_neurons': 206, 'dropout_rate': 0.014359315427526166, 'weight_decay': 3.2270007743185956e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 17:57:53,836] Trial 842 pruned. 
[I 2025-11-04 17:58:18,033] Trial 843 pruned. 
[I 2025-11-04 17:58:34,562] Trial 844 pruned. 
[I 2025-11-04 17:58:42,406] Trial 845 pruned. 
2025-11-04 18:00:15,887 - INFO - Trial 846: Early stopping at epoch 62.
[I 2025-11-04 18:00:15,998] Trial 846 finished with value: 0.007434121333062649 and parameters: {'batch_size': 64, 'learning_rate': 0.0063955642084524466, 'nr_hidden_layers': 1, 'nr_neurons': 196, 'dropout_rate': 0.0170592096998543, 'weight_decay': 6.508084079010897e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 18:00:32,578] Trial 848 pruned. 
2025-11-04 18:03:36,491 - INFO - Trial 849: Early stopping at epoch 122.
[I 2025-11-04 18:03:36,598] Trial 849 finished with value: 0.004556940868496895 and parameters: {'batch_size': 64, 'learning_rate': 0.0033637068702574756, 'nr_hidden_layers': 1, 'nr_neurons': 146, 'dropout_rate': 0.008223551317243734, 'weight_decay': 1.0652165874213581e-06, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 18:03:43,630] Trial 854 pruned. 
2025-11-04 18:08:56,916 - INFO - Trial 855: Early stopping at epoch 204.
[I 2025-11-04 18:08:57,021] Trial 855 finished with value: 0.002427763305604458 and parameters: {'batch_size': 64, 'learning_rate': 0.003986777641086288, 'nr_hidden_layers': 1, 'nr_neurons': 195, 'dropout_rate': 0.00027545491883457365, 'weight_decay': 0.0009558098306054284, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 18:11:03,401 - INFO - Trial 857: Early stopping at epoch 84.
[I 2025-11-04 18:11:03,504] Trial 857 finished with value: 0.006333028897643089 and parameters: {'batch_size': 64, 'learning_rate': 0.004484963909800993, 'nr_hidden_layers': 1, 'nr_neurons': 160, 'dropout_rate': 0.009622423057965915, 'weight_decay': 2.9785312328704078e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 18:11:21,909] Trial 860 pruned. 
[I 2025-11-04 18:11:38,398] Trial 863 pruned. 
[I 2025-11-04 18:11:44,903] Trial 864 pruned. 
[I 2025-11-04 18:12:01,354] Trial 865 pruned. 
[I 2025-11-04 18:12:17,785] Trial 866 pruned. 
2025-11-04 18:15:40,717 - INFO - Trial 867: Early stopping at epoch 133.
[I 2025-11-04 18:15:40,830] Trial 867 finished with value: 0.004393293056637049 and parameters: {'batch_size': 64, 'learning_rate': 0.004054057938287402, 'nr_hidden_layers': 1, 'nr_neurons': 187, 'dropout_rate': 0.008723034904729116, 'weight_decay': 3.326317943612678e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 18:19:01,133 - INFO - Trial 868: Early stopping at epoch 131.
[I 2025-11-04 18:19:01,238] Trial 868 finished with value: 0.0033021136187016964 and parameters: {'batch_size': 64, 'learning_rate': 0.002621155114281965, 'nr_hidden_layers': 1, 'nr_neurons': 196, 'dropout_rate': 0.00032272426519604637, 'weight_decay': 1.9999864501945463e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 18:19:25,203] Trial 872 pruned. 
2025-11-04 18:22:26,978 - INFO - Trial 873: Early stopping at epoch 119.
[I 2025-11-04 18:22:27,107] Trial 873 finished with value: 0.004918378312140703 and parameters: {'batch_size': 64, 'learning_rate': 0.0033358346960846905, 'nr_hidden_layers': 1, 'nr_neurons': 222, 'dropout_rate': 0.00856633717931172, 'weight_decay': 2.514194520594303e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 18:22:43,572] Trial 880 pruned. 
[I 2025-11-04 18:25:52,779] Trial 883 pruned. 
2025-11-04 18:28:33,794 - INFO - Trial 885: Early stopping at epoch 105.
[I 2025-11-04 18:28:33,899] Trial 885 finished with value: 0.003784750821068883 and parameters: {'batch_size': 64, 'learning_rate': 0.0040289787779297604, 'nr_hidden_layers': 1, 'nr_neurons': 202, 'dropout_rate': 0.000586644362645405, 'weight_decay': 1.78704344500092e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 18:28:44,430] Trial 886 pruned. 
[I 2025-11-04 18:30:59,149] Trial 887 pruned. 
[I 2025-11-04 18:31:15,704] Trial 890 pruned. 
[I 2025-11-04 18:34:38,783] Trial 891 pruned. 
2025-11-04 18:36:29,941 - INFO - Trial 895: Early stopping at epoch 74.
[I 2025-11-04 18:36:30,046] Trial 895 finished with value: 0.0060202451422810555 and parameters: {'batch_size': 64, 'learning_rate': 0.004656535950147101, 'nr_hidden_layers': 1, 'nr_neurons': 54, 'dropout_rate': 0.0001267606570923781, 'weight_decay': 3.4584245133761e-06, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 18:36:46,548] Trial 897 pruned. 
2025-11-04 18:41:19,687 - INFO - Trial 898: Early stopping at epoch 174.
[I 2025-11-04 18:41:19,804] Trial 898 finished with value: 0.002170334802940488 and parameters: {'batch_size': 64, 'learning_rate': 0.0041952612848073145, 'nr_hidden_layers': 1, 'nr_neurons': 165, 'dropout_rate': 8.244704500388997e-05, 'weight_decay': 2.3888416101491176e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 18:41:36,308] Trial 901 pruned. 
[I 2025-11-04 18:41:44,230] Trial 902 pruned. 
[I 2025-11-04 18:44:34,911] Trial 903 pruned. 
[I 2025-11-04 18:44:51,849] Trial 905 pruned. 
[I 2025-11-04 18:45:08,393] Trial 906 pruned. 
2025-11-04 18:48:29,107 - INFO - Trial 907: Early stopping at epoch 109.
[I 2025-11-04 18:48:29,228] Trial 907 finished with value: 0.004624646157026291 and parameters: {'batch_size': 64, 'learning_rate': 0.003204144189135886, 'nr_hidden_layers': 3, 'nr_neurons': 200, 'dropout_rate': 0.009558835192669882, 'weight_decay': 2.6816036052173378e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 18:50:26,474 - INFO - Trial 911: Early stopping at epoch 78.
[I 2025-11-04 18:50:26,580] Trial 911 finished with value: 0.0063277301378548145 and parameters: {'batch_size': 64, 'learning_rate': 0.003559942843807677, 'nr_hidden_layers': 1, 'nr_neurons': 180, 'dropout_rate': 0.008791864026084542, 'weight_decay': 3.8712397090103066e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 18:50:32,402] Trial 916 pruned. 
2025-11-04 18:52:13,531 - INFO - Trial 917: Early stopping at epoch 60.
[I 2025-11-04 18:52:13,637] Trial 917 finished with value: 0.0074768755584955215 and parameters: {'batch_size': 64, 'learning_rate': 0.004603581737978799, 'nr_hidden_layers': 2, 'nr_neurons': 175, 'dropout_rate': 0.017253491272464158, 'weight_decay': 4.837420482521822e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 18:52:44,992] Trial 918 pruned. 
[I 2025-11-04 18:52:51,379] Trial 920 pruned. 
[I 2025-11-04 18:53:08,073] Trial 921 pruned. 
[I 2025-11-04 18:53:24,685] Trial 922 pruned. 
[I 2025-11-04 18:53:41,292] Trial 923 pruned. 
2025-11-04 18:58:50,615 - INFO - Trial 924: Early stopping at epoch 200.
[I 2025-11-04 18:58:50,774] Trial 924 finished with value: 0.0019911364652216434 and parameters: {'batch_size': 64, 'learning_rate': 0.003537939086324083, 'nr_hidden_layers': 1, 'nr_neurons': 208, 'dropout_rate': 7.253723507514323e-05, 'weight_decay': 4.2194387052192505e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 18:59:07,375] Trial 930 pruned. 
[I 2025-11-04 18:59:23,982] Trial 932 pruned. 
2025-11-04 19:01:04,778 - INFO - Trial 934: Early stopping at epoch 63.
[I 2025-11-04 19:01:04,891] Trial 934 finished with value: 0.007824422791600227 and parameters: {'batch_size': 64, 'learning_rate': 0.004069911359305066, 'nr_hidden_layers': 1, 'nr_neurons': 221, 'dropout_rate': 0.02424902000054863, 'weight_decay': 6.514393966198934e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 19:01:28,999] Trial 936 pruned. 
2025-11-04 19:03:42,545 - INFO - Trial 937: Early stopping at epoch 87.
[I 2025-11-04 19:03:42,653] Trial 937 finished with value: 0.0063922470435500145 and parameters: {'batch_size': 64, 'learning_rate': 0.0033934057855656177, 'nr_hidden_layers': 1, 'nr_neurons': 204, 'dropout_rate': 0.01006441940617429, 'weight_decay': 3.645511347586176e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 19:03:59,093] Trial 939 pruned. 
[I 2025-11-04 19:04:05,958] Trial 940 pruned. 
[I 2025-11-04 19:07:15,028] Trial 941 pruned. 
[I 2025-11-04 19:07:51,914] Trial 942 pruned. 
[I 2025-11-04 19:10:49,815] Trial 943 pruned. 
[I 2025-11-04 19:11:06,478] Trial 946 pruned. 
[I 2025-11-04 19:14:02,152] Trial 948 pruned. 
2025-11-04 19:16:58,786 - INFO - Trial 952: Early stopping at epoch 111.
[I 2025-11-04 19:16:58,895] Trial 952 finished with value: 0.005152772646397352 and parameters: {'batch_size': 64, 'learning_rate': 0.0035387280110162093, 'nr_hidden_layers': 1, 'nr_neurons': 175, 'dropout_rate': 0.008791856608921348, 'weight_decay': 5.4175427115811823e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 19:21:50,570 - INFO - Trial 954: Early stopping at epoch 194.
[I 2025-11-04 19:21:50,681] Trial 954 finished with value: 0.0024084029719233513 and parameters: {'batch_size': 64, 'learning_rate': 0.0032823885695230618, 'nr_hidden_layers': 1, 'nr_neurons': 159, 'dropout_rate': 0.00022210645634034482, 'weight_decay': 0.00011784673785439088, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 19:22:07,357] Trial 956 pruned. 
[I 2025-11-04 19:22:15,303] Trial 957 pruned. 
2025-11-04 19:24:40,372 - INFO - Trial 958: Early stopping at epoch 94.
[I 2025-11-04 19:24:40,493] Trial 958 finished with value: 0.00400497717782855 and parameters: {'batch_size': 64, 'learning_rate': 0.003766962343960198, 'nr_hidden_layers': 1, 'nr_neurons': 184, 'dropout_rate': 0.0003297869276572388, 'weight_decay': 4.041220943996682e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 19:25:10,502] Trial 961 pruned. 
[I 2025-11-04 19:25:27,144] Trial 962 pruned. 
[I 2025-11-04 19:25:57,110] Trial 963 pruned. 
[I 2025-11-04 19:26:03,967] Trial 965 pruned. 
[I 2025-11-04 19:26:20,437] Trial 966 pruned. 
2025-11-04 19:28:27,158 - INFO - Trial 967: Early stopping at epoch 83.
[I 2025-11-04 19:28:27,265] Trial 967 finished with value: 0.006428183522075415 and parameters: {'batch_size': 64, 'learning_rate': 0.0038548778218015453, 'nr_hidden_layers': 1, 'nr_neurons': 169, 'dropout_rate': 0.009632677015171264, 'weight_decay': 4.00867500240477e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 19:32:35,594 - INFO - Trial 969: Early stopping at epoch 260.
[I 2025-11-04 19:32:35,704] Trial 969 finished with value: 0.0019478457979857922 and parameters: {'batch_size': 128, 'learning_rate': 0.004784440119955086, 'nr_hidden_layers': 1, 'nr_neurons': 132, 'dropout_rate': 0.00027323829217866947, 'weight_decay': 6.64100622434531e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 19:32:43,589] Trial 976 pruned. 
[I 2025-11-04 19:32:54,006] Trial 978 pruned. 
[I 2025-11-04 19:33:05,344] Trial 979 pruned. 
[I 2025-11-04 19:33:15,806] Trial 981 pruned. 
[I 2025-11-04 19:33:26,124] Trial 983 pruned. 
[I 2025-11-04 19:33:36,558] Trial 985 pruned. 
[I 2025-11-04 19:33:42,983] Trial 987 pruned. 
[I 2025-11-04 19:33:53,313] Trial 989 pruned. 
[I 2025-11-04 19:34:03,693] Trial 991 pruned. 
[I 2025-11-04 19:34:14,123] Trial 992 pruned. 
[I 2025-11-04 19:34:24,578] Trial 993 pruned. 
[I 2025-11-04 19:34:35,113] Trial 994 pruned. 
[I 2025-11-04 19:34:45,548] Trial 995 pruned. 
[I 2025-11-04 19:35:02,227] Trial 996 pruned. 
[I 2025-11-04 19:35:09,233] Trial 997 pruned. 
[I 2025-11-04 19:35:25,863] Trial 998 pruned. 
[I 2025-11-04 19:35:42,295] Trial 999 pruned. 
2025-11-04 19:39:28,296 - INFO - Trial 1000: Early stopping at epoch 150.
[I 2025-11-04 19:39:28,407] Trial 1000 finished with value: 0.0033769949804991484 and parameters: {'batch_size': 64, 'learning_rate': 0.002936062920529392, 'nr_hidden_layers': 1, 'nr_neurons': 149, 'dropout_rate': 0.00018662145062270694, 'weight_decay': 4.3547521450367445e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 19:42:16,155 - INFO - Trial 1003: Early stopping at epoch 111.
[I 2025-11-04 19:42:16,263] Trial 1003 finished with value: 0.005034726113080978 and parameters: {'batch_size': 64, 'learning_rate': 0.0034507445362116, 'nr_hidden_layers': 1, 'nr_neurons': 185, 'dropout_rate': 0.017265934770328187, 'weight_decay': 3.45025950081786e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 19:42:26,632] Trial 1005 pruned. 
[I 2025-11-04 19:42:43,005] Trial 1006 pruned. 
[I 2025-11-04 19:43:03,074] Trial 1008 pruned. 
2025-11-04 19:44:37,435 - INFO - Trial 1009: Early stopping at epoch 61.
[I 2025-11-04 19:44:37,567] Trial 1009 finished with value: 0.007461770437657833 and parameters: {'batch_size': 64, 'learning_rate': 0.004248039217399276, 'nr_hidden_layers': 1, 'nr_neurons': 114, 'dropout_rate': 0.008823216527631789, 'weight_decay': 0.0010213765816511513, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 19:44:54,156] Trial 1011 pruned. 
[I 2025-11-04 19:46:48,060] Trial 1012 pruned. 
2025-11-04 19:49:15,659 - INFO - Trial 1016: Early stopping at epoch 89.
[I 2025-11-04 19:49:15,768] Trial 1016 finished with value: 0.00669042719528079 and parameters: {'batch_size': 64, 'learning_rate': 0.004267492513446287, 'nr_hidden_layers': 1, 'nr_neurons': 163, 'dropout_rate': 0.009192391005570186, 'weight_decay': 3.864121851998406e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 19:50:28,843 - INFO - Trial 1018: Early stopping at epoch 48.
[I 2025-11-04 19:50:28,951] Trial 1018 finished with value: 0.008569944649934769 and parameters: {'batch_size': 64, 'learning_rate': 0.0036177551436271777, 'nr_hidden_layers': 1, 'nr_neurons': 176, 'dropout_rate': 0.0371870444526054, 'weight_decay': 3.0227379970957446e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 19:52:37,188 - INFO - Trial 1019: Early stopping at epoch 76.
[I 2025-11-04 19:52:37,299] Trial 1019 finished with value: 0.0037267166189849377 and parameters: {'batch_size': 64, 'learning_rate': 0.003262541874245929, 'nr_hidden_layers': 2, 'nr_neurons': 221, 'dropout_rate': 0.00037515569333076396, 'weight_decay': 5.066633033741405e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 19:52:44,336] Trial 1022 pruned. 
[I 2025-11-04 19:53:00,915] Trial 1024 pruned. 
2025-11-04 19:58:29,124 - INFO - Trial 1026: Early stopping at epoch 212.
[I 2025-11-04 19:58:29,237] Trial 1026 finished with value: 0.0019071614369750023 and parameters: {'batch_size': 64, 'learning_rate': 0.004116707688017062, 'nr_hidden_layers': 1, 'nr_neurons': 118, 'dropout_rate': 0.00011560875151566072, 'weight_decay': 4.2230723572053715e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 19:58:35,104] Trial 1031 pruned. 
[I 2025-11-04 19:58:57,242] Trial 1032 pruned. 
[I 2025-11-04 19:59:03,730] Trial 1033 pruned. 
[I 2025-11-04 19:59:31,639] Trial 1034 pruned. 
2025-11-04 20:02:50,095 - INFO - Trial 1036: Early stopping at epoch 132.
[I 2025-11-04 20:02:50,207] Trial 1036 finished with value: 0.004656778182834387 and parameters: {'batch_size': 64, 'learning_rate': 0.00438570750584739, 'nr_hidden_layers': 1, 'nr_neurons': 135, 'dropout_rate': 0.0086108086165191, 'weight_decay': 5.8904254286644906e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 20:03:06,873] Trial 1040 pruned. 
[I 2025-11-04 20:03:14,809] Trial 1042 pruned. 
[I 2025-11-04 20:03:38,773] Trial 1043 pruned. 
2025-11-04 20:09:14,374 - INFO - Trial 1046: Early stopping at epoch 221.
[I 2025-11-04 20:09:14,488] Trial 1046 finished with value: 0.0019221804104745388 and parameters: {'batch_size': 64, 'learning_rate': 0.0040611255215667105, 'nr_hidden_layers': 1, 'nr_neurons': 117, 'dropout_rate': 5.647332445388067e-05, 'weight_decay': 2.771782885695618e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 20:12:41,259 - INFO - Trial 1049: Early stopping at epoch 108.
[I 2025-11-04 20:12:41,380] Trial 1049 finished with value: 0.004483252763748169 and parameters: {'batch_size': 64, 'learning_rate': 0.0035801910884234052, 'nr_hidden_layers': 3, 'nr_neurons': 115, 'dropout_rate': 0.00024826496353736035, 'weight_decay': 4.865390985503541e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 20:12:58,408] Trial 1054 pruned. 
2025-11-04 20:14:48,462 - INFO - Trial 1055: Early stopping at epoch 69.
[I 2025-11-04 20:14:48,574] Trial 1055 finished with value: 0.007608142681419849 and parameters: {'batch_size': 64, 'learning_rate': 0.0040952949250792755, 'nr_hidden_layers': 1, 'nr_neurons': 112, 'dropout_rate': 0.009854074218123959, 'weight_decay': 2.469363180868434e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 20:14:54,509] Trial 1056 pruned. 
[I 2025-11-04 20:15:11,104] Trial 1057 pruned. 
[I 2025-11-04 20:15:35,167] Trial 1059 pruned. 
[I 2025-11-04 20:15:41,650] Trial 1061 pruned. 
2025-11-04 20:18:21,475 - INFO - Trial 1063: Early stopping at epoch 106.
[I 2025-11-04 20:18:21,588] Trial 1063 finished with value: 0.006002991460263729 and parameters: {'batch_size': 64, 'learning_rate': 0.004183509693271075, 'nr_hidden_layers': 1, 'nr_neurons': 124, 'dropout_rate': 0.009339566168098603, 'weight_decay': 4.470792211161759e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 20:18:32,032] Trial 1067 pruned. 
[I 2025-11-04 20:21:06,706] Trial 1068 pruned. 
[I 2025-11-04 20:24:14,269] Trial 1069 pruned. 
[I 2025-11-04 20:24:31,082] Trial 1073 pruned. 
2025-11-04 20:27:26,090 - INFO - Trial 1074: Early stopping at epoch 114.
[I 2025-11-04 20:27:26,204] Trial 1074 finished with value: 0.0026212334632873535 and parameters: {'batch_size': 64, 'learning_rate': 0.007537299811452894, 'nr_hidden_layers': 1, 'nr_neurons': 199, 'dropout_rate': 0.0001835849080770101, 'weight_decay': 3.7129313761683454e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 20:30:25,849 - INFO - Trial 1079: Early stopping at epoch 115.
[I 2025-11-04 20:30:25,962] Trial 1079 finished with value: 0.002767242258414626 and parameters: {'batch_size': 64, 'learning_rate': 0.005730449725294887, 'nr_hidden_layers': 1, 'nr_neurons': 174, 'dropout_rate': 6.918942081971941e-05, 'weight_decay': 2.5485379263146134e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 20:30:36,847] Trial 1082 pruned. 
2025-11-04 20:33:27,643 - INFO - Trial 1083: Early stopping at epoch 114.
[I 2025-11-04 20:33:27,781] Trial 1083 finished with value: 0.0038226621691137552 and parameters: {'batch_size': 64, 'learning_rate': 0.004019577861976297, 'nr_hidden_layers': 1, 'nr_neurons': 123, 'dropout_rate': 7.153135766331469e-05, 'weight_decay': 0.0011617539597323766, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 20:33:45,011] Trial 1084 pruned. 
[I 2025-11-04 20:33:50,617] Trial 1086 pruned. 
2025-11-04 20:36:06,737 - INFO - Trial 1088: Early stopping at epoch 87.
[I 2025-11-04 20:36:06,850] Trial 1088 finished with value: 0.005580785218626261 and parameters: {'batch_size': 64, 'learning_rate': 0.004095823605195721, 'nr_hidden_layers': 1, 'nr_neurons': 189, 'dropout_rate': 0.009566533672697365, 'weight_decay': 2.1547238492009892e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 20:36:23,424] Trial 1091 pruned. 
[I 2025-11-04 20:36:45,987] Trial 1092 pruned. 
[I 2025-11-04 20:37:02,657] Trial 1093 pruned. 
2025-11-04 20:39:14,668 - INFO - Trial 1094: Early stopping at epoch 78.
[I 2025-11-04 20:39:14,779] Trial 1094 finished with value: 0.006540084723383188 and parameters: {'batch_size': 64, 'learning_rate': 0.0055017186167213, 'nr_hidden_layers': 2, 'nr_neurons': 202, 'dropout_rate': 0.009012971075165879, 'weight_decay': 4.293348439557345e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 20:39:37,509] Trial 1096 pruned. 
2025-11-04 20:40:46,273 - INFO - Trial 1098: Early stopping at epoch 67.
[I 2025-11-04 20:40:46,409] Trial 1098 finished with value: 0.005297964904457331 and parameters: {'batch_size': 128, 'learning_rate': 0.003721568670953738, 'nr_hidden_layers': 1, 'nr_neurons': 175, 'dropout_rate': 0.00018913090603469952, 'weight_decay': 3.508627816330815e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 20:42:24,973 - INFO - Trial 1104: Early stopping at epoch 65.
[I 2025-11-04 20:42:25,084] Trial 1104 finished with value: 0.006804709788411856 and parameters: {'batch_size': 64, 'learning_rate': 0.005376121272363187, 'nr_hidden_layers': 1, 'nr_neurons': 213, 'dropout_rate': 0.008469693997678782, 'weight_decay': 5.487212351721377e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 20:42:41,783] Trial 1106 pruned. 
[I 2025-11-04 20:42:48,817] Trial 1108 pruned. 
[I 2025-11-04 20:43:05,475] Trial 1110 pruned. 
[I 2025-11-04 20:43:25,096] Trial 1111 pruned. 
[I 2025-11-04 20:46:28,228] Trial 1113 pruned. 
2025-11-04 20:48:25,754 - INFO - Trial 1118: Early stopping at epoch 75.
[I 2025-11-04 20:48:25,884] Trial 1118 finished with value: 0.006306310184299946 and parameters: {'batch_size': 64, 'learning_rate': 0.00879985211393226, 'nr_hidden_layers': 1, 'nr_neurons': 22, 'dropout_rate': 0.00044986860586896006, 'weight_decay': 4.5732516695394283e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 20:51:54,238 - INFO - Trial 1120: Early stopping at epoch 138.
[I 2025-11-04 20:51:54,351] Trial 1120 finished with value: 0.0024972334504127502 and parameters: {'batch_size': 64, 'learning_rate': 0.004098198785461688, 'nr_hidden_layers': 1, 'nr_neurons': 184, 'dropout_rate': 0.0001406682217871164, 'weight_decay': 3.8833033856299985e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 20:53:44,167 - INFO - Trial 1123: Early stopping at epoch 70.
[I 2025-11-04 20:53:44,281] Trial 1123 finished with value: 0.008114452473819256 and parameters: {'batch_size': 64, 'learning_rate': 0.004867085360246456, 'nr_hidden_layers': 1, 'nr_neurons': 198, 'dropout_rate': 0.02644522760581587, 'weight_decay': 2.258449617653916e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 20:55:59,997 - INFO - Trial 1128: Early stopping at epoch 143.
[I 2025-11-04 20:56:00,111] Trial 1128 finished with value: 0.0028579782228916883 and parameters: {'batch_size': 128, 'learning_rate': 0.007769230232176101, 'nr_hidden_layers': 1, 'nr_neurons': 160, 'dropout_rate': 0.00028344312545671314, 'weight_decay': 5.6372898072674226e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 20:57:40,497] Trial 1131 pruned. 
[I 2025-11-04 20:58:28,541] Trial 1133 pruned. 
2025-11-04 21:00:47,359 - INFO - Trial 1134: Early stopping at epoch 91.
[I 2025-11-04 21:00:47,478] Trial 1134 finished with value: 0.004742240998893976 and parameters: {'batch_size': 64, 'learning_rate': 0.003749288046378812, 'nr_hidden_layers': 1, 'nr_neurons': 131, 'dropout_rate': 5.3110037159739015e-05, 'weight_decay': 4.4355405308916717e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 21:01:56,659 - INFO - Trial 1137: Early stopping at epoch 40.
[I 2025-11-04 21:01:56,771] Trial 1137 finished with value: 0.009814086370170116 and parameters: {'batch_size': 64, 'learning_rate': 0.005361165583273823, 'nr_hidden_layers': 1, 'nr_neurons': 206, 'dropout_rate': 0.008940350703265975, 'weight_decay': 6.54741236122546e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 21:02:02,642] Trial 1138 pruned. 
[I 2025-11-04 21:02:28,874] Trial 1139 pruned. 
[I 2025-11-04 21:02:45,418] Trial 1140 pruned. 
[I 2025-11-04 21:02:52,049] Trial 1142 pruned. 
[I 2025-11-04 21:03:08,571] Trial 1143 pruned. 
2025-11-04 21:05:14,698 - INFO - Trial 1145: Early stopping at epoch 83.
[I 2025-11-04 21:05:14,811] Trial 1145 finished with value: 0.0037468215450644493 and parameters: {'batch_size': 64, 'learning_rate': 0.003563592737868259, 'nr_hidden_layers': 1, 'nr_neurons': 191, 'dropout_rate': 4.5614513800995674e-05, 'weight_decay': 2.153315304494887e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 21:08:47,289 - INFO - Trial 1150: Early stopping at epoch 141.
[I 2025-11-04 21:08:47,403] Trial 1150 finished with value: 0.0022651618346571922 and parameters: {'batch_size': 64, 'learning_rate': 0.0045942791285202645, 'nr_hidden_layers': 1, 'nr_neurons': 158, 'dropout_rate': 0.00016053205853251522, 'weight_decay': 3.923972045067764e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 21:08:55,487] Trial 1152 pruned. 
2025-11-04 21:11:22,884 - INFO - Trial 1153: Early stopping at epoch 96.
[I 2025-11-04 21:11:22,998] Trial 1153 finished with value: 0.005651755724102259 and parameters: {'batch_size': 64, 'learning_rate': 0.003974503729101605, 'nr_hidden_layers': 1, 'nr_neurons': 143, 'dropout_rate': 0.00825378004631881, 'weight_decay': 5.342173487230605e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 21:11:33,505] Trial 1155 pruned. 
2025-11-04 21:12:46,741 - INFO - Trial 1156: Early stopping at epoch 48.
[I 2025-11-04 21:12:46,854] Trial 1156 finished with value: 0.008182822726666927 and parameters: {'batch_size': 64, 'learning_rate': 0.004144021548247619, 'nr_hidden_layers': 1, 'nr_neurons': 173, 'dropout_rate': 0.010176876324427542, 'weight_decay': 2.9006680977674257e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 21:12:53,870] Trial 1159 pruned. 
[I 2025-11-04 21:15:45,193] Trial 1160 pruned. 
2025-11-04 21:17:35,995 - INFO - Trial 1163: Early stopping at epoch 71.
[I 2025-11-04 21:17:36,133] Trial 1163 finished with value: 0.004715363495051861 and parameters: {'batch_size': 64, 'learning_rate': 0.0030810725340313324, 'nr_hidden_layers': 1, 'nr_neurons': 195, 'dropout_rate': 0.00012584482559269518, 'weight_decay': 6.868486711453776e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 21:21:36,820 - INFO - Trial 1168: Early stopping at epoch 157.
[I 2025-11-04 21:21:36,936] Trial 1168 finished with value: 0.0031435098499059677 and parameters: {'batch_size': 64, 'learning_rate': 0.002619230505956099, 'nr_hidden_layers': 1, 'nr_neurons': 182, 'dropout_rate': 0.0002670279977639578, 'weight_decay': 3.898426981037298e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 21:21:47,463] Trial 1171 pruned. 
[I 2025-11-04 21:22:08,612] Trial 1172 pruned. 
[I 2025-11-04 21:25:15,853] Trial 1173 pruned. 
[I 2025-11-04 21:25:34,193] Trial 1175 pruned. 
2025-11-04 21:30:05,454 - INFO - Trial 1176: Early stopping at epoch 178.
[I 2025-11-04 21:30:05,570] Trial 1176 finished with value: 0.0026333939749747515 and parameters: {'batch_size': 64, 'learning_rate': 0.0034578631010760696, 'nr_hidden_layers': 1, 'nr_neurons': 170, 'dropout_rate': 0.00013016040103426947, 'weight_decay': 8.471383957492099e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 21:30:13,525] Trial 1179 pruned. 
[I 2025-11-04 21:30:36,030] Trial 1180 pruned. 
2025-11-04 21:33:02,371 - INFO - Trial 1181: Early stopping at epoch 97.
[I 2025-11-04 21:33:02,486] Trial 1181 finished with value: 0.0048898798413574696 and parameters: {'batch_size': 64, 'learning_rate': 0.00406035337695002, 'nr_hidden_layers': 1, 'nr_neurons': 190, 'dropout_rate': 0.008990100708953914, 'weight_decay': 2.447540427388485e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 21:36:40,596 - INFO - Trial 1184: Early stopping at epoch 144.
[I 2025-11-04 21:36:40,722] Trial 1184 finished with value: 0.002520072041079402 and parameters: {'batch_size': 64, 'learning_rate': 0.00471261599266969, 'nr_hidden_layers': 1, 'nr_neurons': 161, 'dropout_rate': 3.1510184159185407e-06, 'weight_decay': 2.440760557003239e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 21:36:51,239] Trial 1190 pruned. 
[I 2025-11-04 21:37:13,818] Trial 1192 pruned. 
[I 2025-11-04 21:37:27,400] Trial 1194 pruned. 
[I 2025-11-04 21:37:38,346] Trial 1195 pruned. 
[I 2025-11-04 21:37:50,808] Trial 1197 pruned. 
[I 2025-11-04 21:38:01,291] Trial 1199 pruned. 
[I 2025-11-04 21:38:11,792] Trial 1201 pruned. 
[I 2025-11-04 21:38:31,697] Trial 1203 pruned. 
[I 2025-11-04 21:38:42,143] Trial 1205 pruned. 
2025-11-04 21:39:48,138 - INFO - Trial 1206: Early stopping at epoch 69.
[I 2025-11-04 21:39:48,256] Trial 1206 finished with value: 0.007864236831665039 and parameters: {'batch_size': 128, 'learning_rate': 0.005901201745972439, 'nr_hidden_layers': 1, 'nr_neurons': 217, 'dropout_rate': 0.008771034471191435, 'weight_decay': 3.1937315516537026e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 21:39:54,143] Trial 1210 pruned. 
[I 2025-11-04 21:40:00,610] Trial 1212 pruned. 
2025-11-04 21:42:45,742 - INFO - Trial 1214: Early stopping at epoch 109.
[I 2025-11-04 21:42:45,858] Trial 1214 finished with value: 0.002628738060593605 and parameters: {'batch_size': 64, 'learning_rate': 0.005162002074962774, 'nr_hidden_layers': 1, 'nr_neurons': 154, 'dropout_rate': 0.00014078177767024944, 'weight_decay': 4.423508440227896e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 21:43:02,525] Trial 1219 pruned. 
2025-11-04 21:47:28,773 - INFO - Trial 1221: Early stopping at epoch 173.
[I 2025-11-04 21:47:28,891] Trial 1221 finished with value: 0.0019861471373587847 and parameters: {'batch_size': 64, 'learning_rate': 0.004510353429146874, 'nr_hidden_layers': 1, 'nr_neurons': 165, 'dropout_rate': 8.329963783899918e-06, 'weight_decay': 2.2540815027042445e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 21:50:09,878 - INFO - Trial 1225: Early stopping at epoch 102.
[I 2025-11-04 21:50:10,018] Trial 1225 finished with value: 0.0061503141187131405 and parameters: {'batch_size': 64, 'learning_rate': 0.004025179191952099, 'nr_hidden_layers': 1, 'nr_neurons': 154, 'dropout_rate': 0.015754984978798955, 'weight_decay': 1.6004293418670225e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 21:50:22,608] Trial 1227 pruned. 
[I 2025-11-04 21:50:39,274] Trial 1228 pruned. 
[I 2025-11-04 21:50:56,071] Trial 1229 pruned. 
[I 2025-11-04 21:51:12,706] Trial 1231 pruned. 
[I 2025-11-04 21:51:30,148] Trial 1232 pruned. 
2025-11-04 21:55:31,498 - INFO - Trial 1233: Early stopping at epoch 160.
[I 2025-11-04 21:55:31,614] Trial 1233 finished with value: 0.0027058410923928022 and parameters: {'batch_size': 64, 'learning_rate': 0.00449030953918153, 'nr_hidden_layers': 1, 'nr_neurons': 163, 'dropout_rate': 0.00021426886602409382, 'weight_decay': 2.115111385182299e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 21:55:48,218] Trial 1235 pruned. 
[I 2025-11-04 21:55:56,213] Trial 1236 pruned. 
[I 2025-11-04 21:56:06,949] Trial 1237 pruned. 
[I 2025-11-04 21:56:32,356] Trial 1238 pruned. 
2025-11-04 21:58:50,582 - INFO - Trial 1239: Early stopping at epoch 90.
[I 2025-11-04 21:58:50,703] Trial 1239 finished with value: 0.00534691009670496 and parameters: {'batch_size': 64, 'learning_rate': 0.003834244494362162, 'nr_hidden_layers': 1, 'nr_neurons': 173, 'dropout_rate': 0.008242162998228539, 'weight_decay': 5.962242471237337e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 22:01:34,280 - INFO - Trial 1240: Early stopping at epoch 107.
[I 2025-11-04 22:01:34,406] Trial 1240 finished with value: 0.0031468633096665144 and parameters: {'batch_size': 64, 'learning_rate': 0.004946897203535893, 'nr_hidden_layers': 1, 'nr_neurons': 147, 'dropout_rate': 0.000496373787873355, 'weight_decay': 4.715803304343826e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 22:03:38,038 - INFO - Trial 1244: Early stopping at epoch 81.
[I 2025-11-04 22:03:38,155] Trial 1244 finished with value: 0.007229519542306662 and parameters: {'batch_size': 64, 'learning_rate': 0.004578653774867971, 'nr_hidden_layers': 1, 'nr_neurons': 195, 'dropout_rate': 0.009604998512147416, 'weight_decay': 2.3987848999157834e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 22:03:54,683] Trial 1245 pruned. 
[I 2025-11-04 22:04:05,614] Trial 1247 pruned. 
[I 2025-11-04 22:04:51,447] Trial 1249 pruned. 
[I 2025-11-04 22:04:56,840] Trial 1251 pruned. 
[I 2025-11-04 22:05:18,372] Trial 1252 pruned. 
[I 2025-11-04 22:07:26,870] Trial 1253 pruned. 
2025-11-04 22:11:54,931 - INFO - Trial 1254: Early stopping at epoch 179.
[I 2025-11-04 22:11:55,050] Trial 1254 finished with value: 0.001926763099618256 and parameters: {'batch_size': 64, 'learning_rate': 0.005306834623124965, 'nr_hidden_layers': 1, 'nr_neurons': 173, 'dropout_rate': 3.39804715109911e-05, 'weight_decay': 2.9716559728253518e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 22:14:55,907 - INFO - Trial 1259: Early stopping at epoch 122.
[I 2025-11-04 22:14:56,025] Trial 1259 finished with value: 0.0037158012855798006 and parameters: {'batch_size': 64, 'learning_rate': 0.005182067702182405, 'nr_hidden_layers': 1, 'nr_neurons': 185, 'dropout_rate': 6.974947909672637e-05, 'weight_decay': 1.9679637596217796e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 22:15:12,488] Trial 1263 pruned. 
[I 2025-11-04 22:15:20,420] Trial 1264 pruned. 
2025-11-04 22:19:01,250 - INFO - Trial 1265: Early stopping at epoch 149.
[I 2025-11-04 22:19:01,368] Trial 1265 finished with value: 0.0025222396943718195 and parameters: {'batch_size': 64, 'learning_rate': 0.0048191492904461715, 'nr_hidden_layers': 1, 'nr_neurons': 175, 'dropout_rate': 2.2234814357279193e-05, 'weight_decay': 2.3061576049759334e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 22:20:38,311 - INFO - Trial 1272: Early stopping at epoch 58.
[I 2025-11-04 22:20:38,427] Trial 1272 finished with value: 0.008401475846767426 and parameters: {'batch_size': 64, 'learning_rate': 0.006590010810120795, 'nr_hidden_layers': 1, 'nr_neurons': 163, 'dropout_rate': 0.01627523668154933, 'weight_decay': 3.148332445573394e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 22:22:16,535 - INFO - Trial 1275: Early stopping at epoch 64.
[I 2025-11-04 22:22:16,651] Trial 1275 finished with value: 0.007360766176134348 and parameters: {'batch_size': 64, 'learning_rate': 0.005914168818373977, 'nr_hidden_layers': 1, 'nr_neurons': 185, 'dropout_rate': 0.00911702992259903, 'weight_decay': 1.6103953297823583e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 22:22:22,216] Trial 1278 pruned. 
[I 2025-11-04 22:22:34,469] Trial 1279 pruned. 
2025-11-04 22:24:25,030 - INFO - Trial 1280: Early stopping at epoch 74.
[I 2025-11-04 22:24:25,147] Trial 1280 finished with value: 0.006608858704566956 and parameters: {'batch_size': 64, 'learning_rate': 0.003979747763837569, 'nr_hidden_layers': 1, 'nr_neurons': 173, 'dropout_rate': 0.00888979766483645, 'weight_decay': 2.3457915634118584e-06, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 22:24:41,874] Trial 1282 pruned. 
[I 2025-11-04 22:25:11,355] Trial 1285 pruned. 
2025-11-04 22:26:20,327 - INFO - Trial 1286: Early stopping at epoch 44.
[I 2025-11-04 22:26:20,443] Trial 1286 finished with value: 0.007255854085087776 and parameters: {'batch_size': 64, 'learning_rate': 0.00539849097691652, 'nr_hidden_layers': 1, 'nr_neurons': 148, 'dropout_rate': 0.00015186379635693116, 'weight_decay': 0.00011628437191263797, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 22:26:36,896] Trial 1287 pruned. 
2025-11-04 22:30:45,261 - INFO - Trial 1288: Early stopping at epoch 163.
[I 2025-11-04 22:30:45,382] Trial 1288 finished with value: 0.0027542549651116133 and parameters: {'batch_size': 64, 'learning_rate': 0.005006126428091403, 'nr_hidden_layers': 1, 'nr_neurons': 157, 'dropout_rate': 5.326706343417615e-05, 'weight_decay': 2.5971019347355792e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 22:31:09,203] Trial 1292 pruned. 
[I 2025-11-04 22:31:17,029] Trial 1293 pruned. 
[I 2025-11-04 22:32:51,019] Trial 1294 pruned. 
[I 2025-11-04 22:32:58,010] Trial 1300 pruned. 
2025-11-04 22:34:36,610 - INFO - Trial 1301: Early stopping at epoch 66.
[I 2025-11-04 22:34:36,730] Trial 1301 finished with value: 0.007304036058485508 and parameters: {'batch_size': 64, 'learning_rate': 0.004529642705057541, 'nr_hidden_layers': 1, 'nr_neurons': 202, 'dropout_rate': 0.009483444517895403, 'weight_decay': 9.220556336112059e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 22:36:34,212 - INFO - Trial 1302: Early stopping at epoch 79.
[I 2025-11-04 22:36:34,330] Trial 1302 finished with value: 0.0075729223899543285 and parameters: {'batch_size': 64, 'learning_rate': 0.0053624258294487324, 'nr_hidden_layers': 1, 'nr_neurons': 106, 'dropout_rate': 0.017027249247900722, 'weight_decay': 3.233798577936763e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 22:39:09,333] Trial 1304 pruned. 
[I 2025-11-04 22:40:59,426] Trial 1308 pruned. 
[I 2025-11-04 22:41:05,871] Trial 1311 pruned. 
[I 2025-11-04 22:41:22,240] Trial 1312 pruned. 
[I 2025-11-04 22:41:53,206] Trial 1313 pruned. 
[I 2025-11-04 22:44:06,576] Trial 1315 pruned. 
[I 2025-11-04 22:44:23,033] Trial 1317 pruned. 
[I 2025-11-04 22:44:36,025] Trial 1319 pruned. 
[I 2025-11-04 22:44:43,863] Trial 1320 pruned. 
[I 2025-11-04 22:45:00,220] Trial 1322 pruned. 
2025-11-04 22:46:51,526 - INFO - Trial 1324: Early stopping at epoch 73.
[I 2025-11-04 22:46:51,651] Trial 1324 finished with value: 0.006980701815336943 and parameters: {'batch_size': 64, 'learning_rate': 0.00541522578893454, 'nr_hidden_layers': 1, 'nr_neurons': 152, 'dropout_rate': 0.008638254401913062, 'weight_decay': 4.096655193613716e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 22:48:08,449 - INFO - Trial 1327: Early stopping at epoch 50.
[I 2025-11-04 22:48:08,567] Trial 1327 finished with value: 0.007115877699106932 and parameters: {'batch_size': 64, 'learning_rate': 0.003631198374471937, 'nr_hidden_layers': 1, 'nr_neurons': 189, 'dropout_rate': 0.0002570399243934439, 'weight_decay': 5.059576212081665e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 22:48:18,891] Trial 1331 pruned. 
[I 2025-11-04 22:48:39,742] Trial 1333 pruned. 
[I 2025-11-04 22:48:45,491] Trial 1335 pruned. 
[I 2025-11-04 22:49:01,831] Trial 1336 pruned. 
2025-11-04 22:53:03,478 - INFO - Trial 1337: Early stopping at epoch 162.
[I 2025-11-04 22:53:03,612] Trial 1337 finished with value: 0.0030605727806687355 and parameters: {'batch_size': 64, 'learning_rate': 0.0038376234156637496, 'nr_hidden_layers': 1, 'nr_neurons': 194, 'dropout_rate': 0.00023436175275061595, 'weight_decay': 1.4357839719695533e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 22:53:09,858] Trial 1340 pruned. 
2025-11-04 22:57:07,555 - INFO - Trial 1341: Early stopping at epoch 159.
[I 2025-11-04 22:57:07,675] Trial 1341 finished with value: 0.0028652669861912727 and parameters: {'batch_size': 64, 'learning_rate': 0.0041863710475040445, 'nr_hidden_layers': 1, 'nr_neurons': 161, 'dropout_rate': 6.85564531024612e-05, 'weight_decay': 2.1413396533840245e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 22:57:30,815] Trial 1344 pruned. 
2025-11-04 23:00:32,076 - INFO - Trial 1345: Early stopping at epoch 122.
[I 2025-11-04 23:00:32,199] Trial 1345 finished with value: 0.002746582729741931 and parameters: {'batch_size': 64, 'learning_rate': 0.004597863080176057, 'nr_hidden_layers': 1, 'nr_neurons': 148, 'dropout_rate': 6.468413393396324e-06, 'weight_decay': 4.904883490395516e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 23:03:05,236 - INFO - Trial 1347: Early stopping at epoch 101.
[I 2025-11-04 23:03:05,362] Trial 1347 finished with value: 0.005997124593704939 and parameters: {'batch_size': 64, 'learning_rate': 0.003543211134187395, 'nr_hidden_layers': 1, 'nr_neurons': 173, 'dropout_rate': 0.015480313577969747, 'weight_decay': 3.4998756339989505e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 23:03:40,276] Trial 1348 pruned. 
[I 2025-11-04 23:03:56,678] Trial 1352 pruned. 
[I 2025-11-04 23:04:24,046] Trial 1353 pruned. 
[I 2025-11-04 23:04:40,426] Trial 1354 pruned. 
[I 2025-11-04 23:04:58,083] Trial 1355 pruned. 
[I 2025-11-04 23:05:04,907] Trial 1356 pruned. 
2025-11-04 23:07:51,457 - INFO - Trial 1357: Early stopping at epoch 111.
[I 2025-11-04 23:07:51,616] Trial 1357 finished with value: 0.005224487278610468 and parameters: {'batch_size': 64, 'learning_rate': 0.004105403639997482, 'nr_hidden_layers': 1, 'nr_neurons': 76, 'dropout_rate': 8.811842515683174e-05, 'weight_decay': 3.965318484487209e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 23:08:09,145] Trial 1361 pruned. 
2025-11-04 23:11:45,666 - INFO - Trial 1362: Early stopping at epoch 142.
[I 2025-11-04 23:11:45,785] Trial 1362 finished with value: 0.002116251504048705 and parameters: {'batch_size': 64, 'learning_rate': 0.005042520910286706, 'nr_hidden_layers': 1, 'nr_neurons': 151, 'dropout_rate': 3.352108290520674e-05, 'weight_decay': 5.2246953381594354e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 23:12:02,617] Trial 1368 pruned. 
2025-11-04 23:14:49,084 - INFO - Trial 1369: Early stopping at epoch 111.
[I 2025-11-04 23:14:49,204] Trial 1369 finished with value: 0.002961925696581602 and parameters: {'batch_size': 64, 'learning_rate': 0.006209379291530678, 'nr_hidden_layers': 1, 'nr_neurons': 134, 'dropout_rate': 3.2536692538287284e-05, 'weight_decay': 6.867858562367806e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 23:17:20,318] Trial 1372 pruned. 
2025-11-04 23:21:08,582 - INFO - Trial 1377: Early stopping at epoch 153.
[I 2025-11-04 23:21:08,704] Trial 1377 finished with value: 0.0021693198941648006 and parameters: {'batch_size': 64, 'learning_rate': 0.005390420080559626, 'nr_hidden_layers': 1, 'nr_neurons': 138, 'dropout_rate': 0.00015788489944666554, 'weight_decay': 4.87673719907848e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 23:21:19,086] Trial 1381 pruned. 
[I 2025-11-04 23:21:35,509] Trial 1382 pruned. 
2025-11-04 23:23:11,147 - INFO - Trial 1383: Early stopping at epoch 64.
[I 2025-11-04 23:23:11,264] Trial 1383 finished with value: 0.006803516764193773 and parameters: {'batch_size': 64, 'learning_rate': 0.0033674661539207823, 'nr_hidden_layers': 1, 'nr_neurons': 131, 'dropout_rate': 0.009441006817993643, 'weight_decay': 6.722393515167633e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 23:25:11,272] Trial 1387 pruned. 
2025-11-04 23:28:20,177 - INFO - Trial 1392: Early stopping at epoch 127.
[I 2025-11-04 23:28:20,298] Trial 1392 finished with value: 0.002535359701141715 and parameters: {'batch_size': 64, 'learning_rate': 0.005891267927073615, 'nr_hidden_layers': 1, 'nr_neurons': 162, 'dropout_rate': 0.00026526097583272573, 'weight_decay': 8.64669500778971e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 23:28:36,758] Trial 1395 pruned. 
2025-11-04 23:32:34,302 - INFO - Trial 1396: Early stopping at epoch 158.
[I 2025-11-04 23:32:34,458] Trial 1396 finished with value: 0.0024232626892626286 and parameters: {'batch_size': 64, 'learning_rate': 0.005129348431510859, 'nr_hidden_layers': 1, 'nr_neurons': 170, 'dropout_rate': 0.00015101915404973278, 'weight_decay': 4.099790949687232e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 23:32:50,456] Trial 1403 pruned. 
[I 2025-11-04 23:32:58,005] Trial 1405 pruned. 
[I 2025-11-04 23:33:19,482] Trial 1406 pruned. 
[I 2025-11-04 23:33:35,426] Trial 1409 pruned. 
[I 2025-11-04 23:33:42,006] Trial 1410 pruned. 
[I 2025-11-04 23:33:52,898] Trial 1411 pruned. 
[I 2025-11-04 23:34:22,268] Trial 1412 pruned. 
[I 2025-11-04 23:34:38,183] Trial 1413 pruned. 
[I 2025-11-04 23:34:53,927] Trial 1414 pruned. 
2025-11-04 23:36:19,385 - INFO - Trial 1415: Early stopping at epoch 57.
[I 2025-11-04 23:36:19,506] Trial 1415 finished with value: 0.007331407628953457 and parameters: {'batch_size': 64, 'learning_rate': 0.004130461871151951, 'nr_hidden_layers': 1, 'nr_neurons': 135, 'dropout_rate': 0.00982278764754785, 'weight_decay': 3.43028225759425e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 23:36:35,761] Trial 1419 pruned. 
[I 2025-11-04 23:36:50,648] Trial 1420 pruned. 
[I 2025-11-04 23:36:57,071] Trial 1421 pruned. 
[I 2025-11-04 23:37:15,226] Trial 1422 pruned. 
2025-11-04 23:41:06,458 - INFO - Trial 1423: Early stopping at epoch 149.
[I 2025-11-04 23:41:06,580] Trial 1423 finished with value: 0.002212553983554244 and parameters: {'batch_size': 64, 'learning_rate': 0.005249515039198832, 'nr_hidden_layers': 1, 'nr_neurons': 178, 'dropout_rate': 0.00010031424503546226, 'weight_decay': 4.197976027202462e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 23:42:18,818 - INFO - Trial 1425: Early stopping at epoch 48.
[I 2025-11-04 23:42:18,944] Trial 1425 finished with value: 0.008873775601387024 and parameters: {'batch_size': 64, 'learning_rate': 0.0046414547999655215, 'nr_hidden_layers': 1, 'nr_neurons': 166, 'dropout_rate': 0.019692380719824456, 'weight_decay': 2.7034908540962548e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-04 23:48:15,300 - INFO - Trial 1428: Early stopping at epoch 237.
[I 2025-11-04 23:48:15,424] Trial 1428 finished with value: 0.0018768394365906715 and parameters: {'batch_size': 64, 'learning_rate': 0.004080784501570581, 'nr_hidden_layers': 1, 'nr_neurons': 192, 'dropout_rate': 5.925099341761657e-05, 'weight_decay': 5.025166050134913e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 23:48:31,744] Trial 1433 pruned. 
[I 2025-11-04 23:48:48,155] Trial 1434 pruned. 
[I 2025-11-04 23:49:05,042] Trial 1435 pruned. 
[I 2025-11-04 23:49:28,991] Trial 1436 pruned. 
[I 2025-11-04 23:49:36,010] Trial 1437 pruned. 
[I 2025-11-04 23:49:52,632] Trial 1439 pruned. 
[I 2025-11-04 23:50:09,043] Trial 1441 pruned. 
2025-11-04 23:53:03,017 - INFO - Trial 1444: Early stopping at epoch 117.
[I 2025-11-04 23:53:03,141] Trial 1444 finished with value: 0.003695270512253046 and parameters: {'batch_size': 64, 'learning_rate': 0.003607424315154928, 'nr_hidden_layers': 1, 'nr_neurons': 188, 'dropout_rate': 0.00027522413461244773, 'weight_decay': 2.7675452080182207e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-04 23:55:57,337] Trial 1447 pruned. 
2025-11-04 23:58:12,815 - INFO - Trial 1451: Early stopping at epoch 90.
[I 2025-11-04 23:58:12,936] Trial 1451 finished with value: 0.006630396470427513 and parameters: {'batch_size': 64, 'learning_rate': 0.0027273261708392837, 'nr_hidden_layers': 1, 'nr_neurons': 182, 'dropout_rate': 0.017008138530234387, 'weight_decay': 9.330914052182677e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-05 00:00:58,993 - INFO - Trial 1454: Early stopping at epoch 109.
[I 2025-11-05 00:00:59,120] Trial 1454 finished with value: 0.004342987667769194 and parameters: {'batch_size': 64, 'learning_rate': 0.003333874990967763, 'nr_hidden_layers': 1, 'nr_neurons': 231, 'dropout_rate': 0.0003556163313472232, 'weight_decay': 4.254498499357467e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 00:01:06,989] Trial 1458 pruned. 
[I 2025-11-05 00:01:23,445] Trial 1459 pruned. 
[I 2025-11-05 00:02:53,808] Trial 1460 pruned. 
[I 2025-11-05 00:03:04,114] Trial 1461 pruned. 
[I 2025-11-05 00:03:20,490] Trial 1462 pruned. 
2025-11-05 00:05:05,954 - INFO - Trial 1463: Early stopping at epoch 72.
[I 2025-11-05 00:05:06,075] Trial 1463 finished with value: 0.005317699629813433 and parameters: {'batch_size': 64, 'learning_rate': 0.0037113094058936784, 'nr_hidden_layers': 1, 'nr_neurons': 207, 'dropout_rate': 0.00017585855868595127, 'weight_decay': 4.8026455377425584e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 00:05:22,351] Trial 1464 pruned. 
2025-11-05 00:06:59,115 - INFO - Trial 1465: Early stopping at epoch 58.
[I 2025-11-05 00:06:59,234] Trial 1465 finished with value: 0.00607100035995245 and parameters: {'batch_size': 64, 'learning_rate': 0.004242947153655964, 'nr_hidden_layers': 2, 'nr_neurons': 189, 'dropout_rate': 0.010300304231749297, 'weight_decay': 2.1711754725459893e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 00:07:15,670] Trial 1466 pruned. 
[I 2025-11-05 00:07:31,940] Trial 1467 pruned. 
[I 2025-11-05 00:07:48,246] Trial 1468 pruned. 
[I 2025-11-05 00:09:28,836] Trial 1469 pruned. 
[I 2025-11-05 00:09:39,154] Trial 1470 pruned. 
[I 2025-11-05 00:09:44,892] Trial 1471 pruned. 
[I 2025-11-05 00:10:02,502] Trial 1472 pruned. 
[I 2025-11-05 00:10:19,001] Trial 1473 pruned. 
2025-11-05 00:12:48,876 - INFO - Trial 1474: Early stopping at epoch 100.
[I 2025-11-05 00:12:48,997] Trial 1474 finished with value: 0.0036861924454569817 and parameters: {'batch_size': 64, 'learning_rate': 0.004690417026826083, 'nr_hidden_layers': 1, 'nr_neurons': 223, 'dropout_rate': 0.00021180593697501897, 'weight_decay': 3.599801110480425e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 00:12:55,432] Trial 1475 pruned. 
2025-11-05 00:14:40,805 - INFO - Trial 1476: Early stopping at epoch 70.
[I 2025-11-05 00:14:40,926] Trial 1476 finished with value: 0.006686413194984198 and parameters: {'batch_size': 64, 'learning_rate': 0.0034414147277880207, 'nr_hidden_layers': 1, 'nr_neurons': 194, 'dropout_rate': 0.009125387565897676, 'weight_decay': 2.7284985978789864e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-05 00:18:36,468 - INFO - Trial 1477: Early stopping at epoch 117.
[I 2025-11-05 00:18:36,592] Trial 1477 finished with value: 0.0038544652052223682 and parameters: {'batch_size': 64, 'learning_rate': 0.004940188622468925, 'nr_hidden_layers': 4, 'nr_neurons': 107, 'dropout_rate': 7.86170859142434e-05, 'weight_decay': 0.00022261206199359707, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 00:18:52,962] Trial 1478 pruned. 
[I 2025-11-05 00:19:10,499] Trial 1479 pruned. 
[I 2025-11-05 00:19:20,810] Trial 1480 pruned. 
[I 2025-11-05 00:22:11,689] Trial 1481 pruned. 
[I 2025-11-05 00:22:33,286] Trial 1482 pruned. 
[I 2025-11-05 00:22:40,953] Trial 1483 pruned. 
[I 2025-11-05 00:22:57,096] Trial 1484 pruned. 
2025-11-05 00:26:46,037 - INFO - Trial 1485: Early stopping at epoch 159.
[I 2025-11-05 00:26:46,165] Trial 1485 finished with value: 0.0023577138781547546 and parameters: {'batch_size': 64, 'learning_rate': 0.003340222043888904, 'nr_hidden_layers': 1, 'nr_neurons': 168, 'dropout_rate': 0.0003540142067855379, 'weight_decay': 3.217010772190846e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 00:27:08,374] Trial 1486 pruned. 
2025-11-05 00:28:48,309 - INFO - Trial 1487: Early stopping at epoch 67.
[I 2025-11-05 00:28:48,430] Trial 1487 finished with value: 0.007391722407191992 and parameters: {'batch_size': 64, 'learning_rate': 0.004518067391016425, 'nr_hidden_layers': 1, 'nr_neurons': 185, 'dropout_rate': 0.009073797918693715, 'weight_decay': 2.0798699344539276e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-05 00:30:06,335 - INFO - Trial 1488: Early stopping at epoch 52.
[I 2025-11-05 00:30:06,456] Trial 1488 finished with value: 0.007683370262384415 and parameters: {'batch_size': 64, 'learning_rate': 0.0037262984771440585, 'nr_hidden_layers': 1, 'nr_neurons': 205, 'dropout_rate': 0.014746408907476645, 'weight_decay': 3.787678794020341e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-05 00:32:54,439 - INFO - Trial 1489: Early stopping at epoch 114.
[I 2025-11-05 00:32:54,564] Trial 1489 finished with value: 0.003793272888287902 and parameters: {'batch_size': 64, 'learning_rate': 0.005611927034069167, 'nr_hidden_layers': 1, 'nr_neurons': 101, 'dropout_rate': 0.0002270832408108535, 'weight_decay': 0.0002951614852609243, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 00:33:04,875] Trial 1490 pruned. 
2025-11-05 00:34:25,805 - INFO - Trial 1491: Early stopping at epoch 54.
[I 2025-11-05 00:34:25,932] Trial 1491 finished with value: 0.008416833356022835 and parameters: {'batch_size': 64, 'learning_rate': 0.004173906908800846, 'nr_hidden_layers': 1, 'nr_neurons': 176, 'dropout_rate': 0.024990147553970738, 'weight_decay': 5.055108210600308e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 00:34:42,205] Trial 1492 pruned. 
[I 2025-11-05 00:34:48,942] Trial 1493 pruned. 
[I 2025-11-05 00:35:05,216] Trial 1494 pruned. 
2025-11-05 00:39:01,758 - INFO - Trial 1495: Early stopping at epoch 162.
[I 2025-11-05 00:39:01,883] Trial 1495 finished with value: 0.002357252174988389 and parameters: {'batch_size': 64, 'learning_rate': 0.0052887716718879865, 'nr_hidden_layers': 1, 'nr_neurons': 178, 'dropout_rate': 1.4137724687520906e-05, 'weight_decay': 2.2871732406162995e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 00:41:35,480] Trial 1496 pruned. 
[I 2025-11-05 00:41:41,331] Trial 1497 pruned. 
2025-11-05 00:44:25,744 - INFO - Trial 1498: Early stopping at epoch 115.
[I 2025-11-05 00:44:25,867] Trial 1498 finished with value: 0.0028166244737803936 and parameters: {'batch_size': 64, 'learning_rate': 0.007191620578926085, 'nr_hidden_layers': 1, 'nr_neurons': 168, 'dropout_rate': 3.983328287366695e-05, 'weight_decay': 3.629287701340055e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-05 00:47:15,911 - INFO - Trial 1499: Early stopping at epoch 104.
[I 2025-11-05 00:47:16,034] Trial 1499 finished with value: 0.005717256106436253 and parameters: {'batch_size': 64, 'learning_rate': 0.004901734129514199, 'nr_hidden_layers': 2, 'nr_neurons': 189, 'dropout_rate': 0.010411750063612444, 'weight_decay': 1.892549443608857e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 00:47:26,025] Trial 1500 pruned. 
2025-11-05 00:50:28,731 - INFO - Trial 1501: Early stopping at epoch 120.
[I 2025-11-05 00:50:28,857] Trial 1501 finished with value: 0.0034266114234924316 and parameters: {'batch_size': 64, 'learning_rate': 0.00329002624618684, 'nr_hidden_layers': 1, 'nr_neurons': 221, 'dropout_rate': 0.0001886561247212759, 'weight_decay': 4.311434578493445e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-05 00:52:45,060 - INFO - Trial 1502: Early stopping at epoch 87.
[I 2025-11-05 00:52:45,233] Trial 1502 finished with value: 0.005881860386580229 and parameters: {'batch_size': 64, 'learning_rate': 0.0041749427014418, 'nr_hidden_layers': 1, 'nr_neurons': 180, 'dropout_rate': 0.009231973517198512, 'weight_decay': 3.132749689371437e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 00:52:51,478] Trial 1503 pruned. 
2025-11-05 00:55:06,793 - INFO - Trial 1504: Early stopping at epoch 87.
[I 2025-11-05 00:55:06,917] Trial 1504 finished with value: 0.006134600844234228 and parameters: {'batch_size': 64, 'learning_rate': 0.0039061590704927247, 'nr_hidden_layers': 1, 'nr_neurons': 201, 'dropout_rate': 0.008804111044889713, 'weight_decay': 3.756140517942011e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 00:55:23,360] Trial 1505 pruned. 
2025-11-05 00:57:59,922 - INFO - Trial 1506: Early stopping at epoch 104.
[I 2025-11-05 00:58:00,045] Trial 1506 finished with value: 0.0037902062758803368 and parameters: {'batch_size': 64, 'learning_rate': 0.004551293159423296, 'nr_hidden_layers': 1, 'nr_neurons': 160, 'dropout_rate': 0.000151757005857659, 'weight_decay': 4.9716493579052273e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 00:58:23,664] Trial 1507 pruned. 
[I 2025-11-05 00:58:40,401] Trial 1508 pruned. 
[I 2025-11-05 00:59:01,791] Trial 1509 pruned. 
[I 2025-11-05 00:59:11,728] Trial 1510 pruned. 
2025-11-05 01:00:35,740 - INFO - Trial 1511: Early stopping at epoch 58.
[I 2025-11-05 01:00:35,878] Trial 1511 finished with value: 0.008211788721382618 and parameters: {'batch_size': 64, 'learning_rate': 0.005002342382373554, 'nr_hidden_layers': 1, 'nr_neurons': 168, 'dropout_rate': 0.009545109670404579, 'weight_decay': 3.7945226003588447e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 01:01:21,490] Trial 1512 pruned. 
[I 2025-11-05 01:01:37,416] Trial 1513 pruned. 
[I 2025-11-05 01:01:44,980] Trial 1514 pruned. 
[I 2025-11-05 01:02:14,899] Trial 1515 pruned. 
[I 2025-11-05 01:02:37,745] Trial 1516 pruned. 
[I 2025-11-05 01:02:53,538] Trial 1517 pruned. 
[I 2025-11-05 01:03:00,106] Trial 1518 pruned. 
[I 2025-11-05 01:03:44,083] Trial 1519 pruned. 
2025-11-05 01:08:02,452 - INFO - Trial 1520: Early stopping at epoch 179.
[I 2025-11-05 01:08:02,576] Trial 1520 finished with value: 0.0021170801483094692 and parameters: {'batch_size': 64, 'learning_rate': 0.003705514345948699, 'nr_hidden_layers': 1, 'nr_neurons': 196, 'dropout_rate': 0.0001722890376837745, 'weight_decay': 2.042875398566084e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 01:08:12,520] Trial 1521 pruned. 
[I 2025-11-05 01:08:35,981] Trial 1522 pruned. 
2025-11-05 01:10:15,246 - INFO - Trial 1523: Early stopping at epoch 61.
[I 2025-11-05 01:10:15,369] Trial 1523 finished with value: 0.007579224184155464 and parameters: {'batch_size': 64, 'learning_rate': 0.0032004925361871946, 'nr_hidden_layers': 1, 'nr_neurons': 181, 'dropout_rate': 0.00930607143401886, 'weight_decay': 0.008154368238005697, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-05 01:12:46,173 - INFO - Trial 1524: Early stopping at epoch 99.
[I 2025-11-05 01:12:46,296] Trial 1524 finished with value: 0.004333598539233208 and parameters: {'batch_size': 64, 'learning_rate': 0.004184968349090614, 'nr_hidden_layers': 1, 'nr_neurons': 212, 'dropout_rate': 9.873083363258679e-05, 'weight_decay': 7.969880712444269e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 01:13:02,664] Trial 1525 pruned. 
[I 2025-11-05 01:13:08,442] Trial 1526 pruned. 
2025-11-05 01:15:28,800 - INFO - Trial 1527: Early stopping at epoch 96.
[I 2025-11-05 01:15:28,923] Trial 1527 finished with value: 0.004272783640772104 and parameters: {'batch_size': 64, 'learning_rate': 0.005116792942084496, 'nr_hidden_layers': 1, 'nr_neurons': 186, 'dropout_rate': 5.839272754720439e-05, 'weight_decay': 2.282169727803981e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 01:15:51,862] Trial 1528 pruned. 
[I 2025-11-05 01:15:58,070] Trial 1529 pruned. 
2025-11-05 01:19:29,167 - INFO - Trial 1530: Early stopping at epoch 148.
[I 2025-11-05 01:19:29,292] Trial 1530 finished with value: 0.003039720468223095 and parameters: {'batch_size': 64, 'learning_rate': 0.00997593849781133, 'nr_hidden_layers': 1, 'nr_neurons': 173, 'dropout_rate': 0.00013688108572314803, 'weight_decay': 2.6710313351719704e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 01:19:41,176] Trial 1531 pruned. 
[I 2025-11-05 01:19:57,041] Trial 1532 pruned. 
[I 2025-11-05 01:20:12,838] Trial 1533 pruned. 
[I 2025-11-05 01:20:44,304] Trial 1534 pruned. 
[I 2025-11-05 01:21:10,585] Trial 1535 pruned. 
2025-11-05 01:22:25,709 - INFO - Trial 1536: Early stopping at epoch 52.
[I 2025-11-05 01:22:25,837] Trial 1536 finished with value: 0.009095331653952599 and parameters: {'batch_size': 64, 'learning_rate': 0.004283681989143656, 'nr_hidden_layers': 1, 'nr_neurons': 118, 'dropout_rate': 0.024327923469492342, 'weight_decay': 3.0356227980099827e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-05 01:24:07,264 - INFO - Trial 1537: Early stopping at epoch 63.
[I 2025-11-05 01:24:07,386] Trial 1537 finished with value: 0.004090779460966587 and parameters: {'batch_size': 64, 'learning_rate': 0.003960630135910088, 'nr_hidden_layers': 2, 'nr_neurons': 167, 'dropout_rate': 0.00010632729699824937, 'weight_decay': 2.320060298674442e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 01:24:15,018] Trial 1538 pruned. 
2025-11-05 01:26:14,954 - INFO - Trial 1539: Early stopping at epoch 81.
[I 2025-11-05 01:26:15,077] Trial 1539 finished with value: 0.007367576006799936 and parameters: {'batch_size': 64, 'learning_rate': 0.005758166794695527, 'nr_hidden_layers': 1, 'nr_neurons': 192, 'dropout_rate': 0.016411297088613892, 'weight_decay': 1.7394727643849674e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-05 01:27:35,849 - INFO - Trial 1540: Early stopping at epoch 55.
[I 2025-11-05 01:27:35,971] Trial 1540 finished with value: 0.007243768312036991 and parameters: {'batch_size': 64, 'learning_rate': 0.003777086543735181, 'nr_hidden_layers': 1, 'nr_neurons': 179, 'dropout_rate': 0.009808086818440016, 'weight_decay': 4.44675590068432e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 01:27:49,434] Trial 1541 pruned. 
[I 2025-11-05 01:28:18,676] Trial 1542 pruned. 
2025-11-05 01:29:45,228 - INFO - Trial 1543: Early stopping at epoch 60.
[I 2025-11-05 01:29:45,351] Trial 1543 finished with value: 0.006422009319067001 and parameters: {'batch_size': 64, 'learning_rate': 0.0028326678440065635, 'nr_hidden_layers': 1, 'nr_neurons': 186, 'dropout_rate': 0.009073596912237143, 'weight_decay': 2.5994750252673564e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 01:30:02,252] Trial 1544 pruned. 
[I 2025-11-05 01:30:18,044] Trial 1545 pruned. 
[I 2025-11-05 01:30:24,781] Trial 1546 pruned. 
[I 2025-11-05 01:30:44,132] Trial 1547 pruned. 
[I 2025-11-05 01:30:59,890] Trial 1548 pruned. 
[I 2025-11-05 01:31:17,080] Trial 1549 pruned. 
[I 2025-11-05 01:31:34,461] Trial 1550 pruned. 
[I 2025-11-05 01:31:45,688] Trial 1551 pruned. 
2025-11-05 01:33:15,904 - INFO - Trial 1552: Early stopping at epoch 59.
[I 2025-11-05 01:33:16,027] Trial 1552 finished with value: 0.007991648279130459 and parameters: {'batch_size': 64, 'learning_rate': 0.006989629226822939, 'nr_hidden_layers': 1, 'nr_neurons': 229, 'dropout_rate': 0.00902311935957067, 'weight_decay': 8.047807530706799e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 01:33:36,778] Trial 1553 pruned. 
2025-11-05 01:35:55,999 - INFO - Trial 1554: Early stopping at epoch 94.
[I 2025-11-05 01:35:56,123] Trial 1554 finished with value: 0.00663372129201889 and parameters: {'batch_size': 64, 'learning_rate': 0.005919146677838932, 'nr_hidden_layers': 1, 'nr_neurons': 125, 'dropout_rate': 0.008764499648742602, 'weight_decay': 1.514676598077065e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 01:36:01,891] Trial 1555 pruned. 
[I 2025-11-05 01:36:18,260] Trial 1556 pruned. 
[I 2025-11-05 01:36:24,643] Trial 1557 pruned. 
2025-11-05 01:39:39,103 - INFO - Trial 1558: Early stopping at epoch 129.
[I 2025-11-05 01:39:39,228] Trial 1558 finished with value: 0.0030773833859711885 and parameters: {'batch_size': 64, 'learning_rate': 0.003455810897866856, 'nr_hidden_layers': 1, 'nr_neurons': 163, 'dropout_rate': 0.00033549066371453816, 'weight_decay': 2.7866452897672433e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 01:40:05,339] Trial 1559 pruned. 
2025-11-05 01:41:13,123 - INFO - Trial 1560: Early stopping at epoch 45.
[I 2025-11-05 01:41:13,259] Trial 1560 finished with value: 0.008732163347303867 and parameters: {'batch_size': 64, 'learning_rate': 0.006520387814721438, 'nr_hidden_layers': 1, 'nr_neurons': 198, 'dropout_rate': 0.009144681033033885, 'weight_decay': 2.0235976358728413e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 01:41:23,578] Trial 1561 pruned. 
[I 2025-11-05 01:41:39,868] Trial 1562 pruned. 
[I 2025-11-05 01:42:03,579] Trial 1563 pruned. 
2025-11-05 01:46:38,031 - INFO - Trial 1564: Early stopping at epoch 180.
[I 2025-11-05 01:46:38,156] Trial 1564 finished with value: 0.0031518228352069855 and parameters: {'batch_size': 64, 'learning_rate': 0.004307931132463936, 'nr_hidden_layers': 1, 'nr_neurons': 166, 'dropout_rate': 0.0004166787431798217, 'weight_decay': 3.088035012154195e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-05 01:49:23,234 - INFO - Trial 1565: Early stopping at epoch 108.
[I 2025-11-05 01:49:23,384] Trial 1565 finished with value: 0.0032017237972468138 and parameters: {'batch_size': 64, 'learning_rate': 0.004924882144016902, 'nr_hidden_layers': 1, 'nr_neurons': 220, 'dropout_rate': 2.370106636466685e-05, 'weight_decay': 5.467261390285468e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 01:49:31,159] Trial 1566 pruned. 
[I 2025-11-05 01:51:20,838] Trial 1567 pruned. 
2025-11-05 01:53:17,716 - INFO - Trial 1568: Early stopping at epoch 69.
[I 2025-11-05 01:53:17,842] Trial 1568 finished with value: 0.006059759296476841 and parameters: {'batch_size': 64, 'learning_rate': 0.004537317324157089, 'nr_hidden_layers': 2, 'nr_neurons': 150, 'dropout_rate': 0.00902748083025275, 'weight_decay': 2.7138658063997544e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-05 01:54:48,319 - INFO - Trial 1569: Early stopping at epoch 59.
[I 2025-11-05 01:54:48,443] Trial 1569 finished with value: 0.007117004599422216 and parameters: {'batch_size': 64, 'learning_rate': 0.00607997656894156, 'nr_hidden_layers': 1, 'nr_neurons': 180, 'dropout_rate': 0.00874769220856981, 'weight_decay': 6.413422848470073e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 01:55:04,803] Trial 1570 pruned. 
[I 2025-11-05 01:55:20,671] Trial 1571 pruned. 
2025-11-05 01:57:10,952 - INFO - Trial 1572: Early stopping at epoch 75.
[I 2025-11-05 01:57:11,076] Trial 1572 finished with value: 0.004430381115525961 and parameters: {'batch_size': 64, 'learning_rate': 0.006931741337114502, 'nr_hidden_layers': 1, 'nr_neurons': 157, 'dropout_rate': 0.00035363329462987123, 'weight_decay': 2.3296498197458732e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-05 01:59:44,600 - INFO - Trial 1573: Early stopping at epoch 102.
[I 2025-11-05 01:59:44,725] Trial 1573 finished with value: 0.0030047630425542593 and parameters: {'batch_size': 64, 'learning_rate': 0.008048896328544403, 'nr_hidden_layers': 1, 'nr_neurons': 187, 'dropout_rate': 6.285242626032965e-05, 'weight_decay': 4.7772640036774633e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 02:00:01,037] Trial 1574 pruned. 
[I 2025-11-05 02:00:17,406] Trial 1575 pruned. 
2025-11-05 02:03:07,198 - INFO - Trial 1576: Early stopping at epoch 112.
[I 2025-11-05 02:03:07,323] Trial 1576 finished with value: 0.0032971638720482588 and parameters: {'batch_size': 64, 'learning_rate': 0.0055322425103323915, 'nr_hidden_layers': 1, 'nr_neurons': 147, 'dropout_rate': 0.0001423456745639945, 'weight_decay': 5.538330540245931e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 02:03:23,697] Trial 1577 pruned. 
[I 2025-11-05 02:03:41,240] Trial 1578 pruned. 
[I 2025-11-05 02:03:48,226] Trial 1579 pruned. 
[I 2025-11-05 02:04:04,606] Trial 1580 pruned. 
[I 2025-11-05 02:04:10,301] Trial 1581 pruned. 
[I 2025-11-05 02:04:20,616] Trial 1582 pruned. 
2025-11-05 02:05:50,318 - INFO - Trial 1583: Early stopping at epoch 57.
[I 2025-11-05 02:05:50,442] Trial 1583 finished with value: 0.008112520910799503 and parameters: {'batch_size': 64, 'learning_rate': 0.004094999007765706, 'nr_hidden_layers': 1, 'nr_neurons': 160, 'dropout_rate': 0.015624737393216933, 'weight_decay': 3.779109138513504e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
2025-11-05 02:06:47,368 - INFO - Trial 1584: Early stopping at epoch 37.
[I 2025-11-05 02:06:47,491] Trial 1584 finished with value: 0.008884410373866558 and parameters: {'batch_size': 64, 'learning_rate': 0.006382880781486591, 'nr_hidden_layers': 1, 'nr_neurons': 187, 'dropout_rate': 0.008975374988026096, 'weight_decay': 0.0021445319367270005, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 719 with value: 0.0014767380198463798.
[I 2025-11-05 02:06:53,863] Trial 1585 pruned. 
2025-11-05 02:15:40,242 - INFO - Trial 1586: Early stopping at epoch 354.
[I 2025-11-05 02:15:40,374] Trial 1586 finished with value: 0.0013657298404723406 and parameters: {'batch_size': 64, 'learning_rate': 0.0032218094521860984, 'nr_hidden_layers': 1, 'nr_neurons': 131, 'dropout_rate': 0.00020487014126456662, 'weight_decay': 4.902611157384792e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 1586 with value: 0.0013657298404723406.
[I 2025-11-05 02:15:56,504] Trial 1587 pruned. 
2025-11-05 02:19:33,059 - INFO - Trial 1588: Early stopping at epoch 148.
[I 2025-11-05 02:19:33,186] Trial 1588 finished with value: 0.003986076917499304 and parameters: {'batch_size': 64, 'learning_rate': 0.002897966771831257, 'nr_hidden_layers': 1, 'nr_neurons': 120, 'dropout_rate': 3.105075234810181e-05, 'weight_decay': 7.193037283008248e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 1586 with value: 0.0013657298404723406.
[I 2025-11-05 02:19:49,371] Trial 1589 pruned. 
[I 2025-11-05 02:20:05,513] Trial 1590 pruned. 
[I 2025-11-05 02:20:15,656] Trial 1591 pruned. 
[I 2025-11-05 02:20:31,806] Trial 1592 pruned. 
[I 2025-11-05 02:20:48,809] Trial 1593 pruned. 
[I 2025-11-05 02:20:56,625] Trial 1594 pruned. 
2025-11-05 02:22:51,403 - INFO - Trial 1595: Early stopping at epoch 64.
[I 2025-11-05 02:22:51,528] Trial 1595 finished with value: 0.004722165409475565 and parameters: {'batch_size': 64, 'learning_rate': 0.00312358476755636, 'nr_hidden_layers': 3, 'nr_neurons': 123, 'dropout_rate': 3.304608483740973e-05, 'weight_decay': 7.205630018824654e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'L1'}. Best is trial 1586 with value: 0.0013657298404723406.
[I 2025-11-05 02:25:02,443] Trial 1596 pruned. 
2025-11-05 02:26:45,619 - INFO - Trial 1597: Early stopping at epoch 53.
[I 2025-11-05 02:26:45,745] Trial 1597 finished with value: 0.006020798347890377 and parameters: {'batch_size': 64, 'learning_rate': 0.0033297192380733285, 'nr_hidden_layers': 4, 'nr_neurons': 120, 'dropout_rate': 0.00910288227721445, 'weight_decay': 5.893547589890322e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 1586 with value: 0.0013657298404723406.
[I 2025-11-05 02:27:02,558] Trial 1598 pruned. 
[I 2025-11-05 02:27:22,059] Trial 1599 pruned. 
[I 2025-11-05 02:27:38,891] Trial 1600 pruned. 
[I 2025-11-05 02:27:45,657] Trial 1601 pruned. 
[I 2025-11-05 02:27:56,179] Trial 1602 pruned. 
[I 2025-11-05 02:30:38,429] Trial 1603 pruned. 
[I 2025-11-05 02:30:55,291] Trial 1604 pruned. 
2025-11-05 02:32:43,683 - INFO - Trial 1605: Early stopping at epoch 71.
[I 2025-11-05 02:32:43,809] Trial 1605 finished with value: 0.0069521330296993256 and parameters: {'batch_size': 64, 'learning_rate': 0.0035114687498879237, 'nr_hidden_layers': 1, 'nr_neurons': 132, 'dropout_rate': 0.009222399451542065, 'weight_decay': 6.0759149763504826e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 1586 with value: 0.0013657298404723406.
[I 2025-11-05 02:32:59,953] Trial 1606 pruned. 
[I 2025-11-05 02:33:22,741] Trial 1607 pruned. 
[I 2025-11-05 02:33:28,363] Trial 1608 pruned. 
[I 2025-11-05 02:33:51,646] Trial 1609 pruned. 
[I 2025-11-05 02:36:32,892] Trial 1610 pruned. 
[I 2025-11-05 02:36:49,105] Trial 1611 pruned. 
[I 2025-11-05 02:36:59,402] Trial 1612 pruned. 
[I 2025-11-05 02:37:05,665] Trial 1613 pruned. 
2025-11-05 02:38:53,149 - INFO - Trial 1614: Early stopping at epoch 66.
[I 2025-11-05 02:38:53,300] Trial 1614 finished with value: 0.00781573262065649 and parameters: {'batch_size': 64, 'learning_rate': 0.0035803889981005583, 'nr_hidden_layers': 2, 'nr_neurons': 120, 'dropout_rate': 0.02207610230259904, 'weight_decay': 0.0002458895616377379, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 1586 with value: 0.0013657298404723406.
2025-11-05 02:43:17,721 - INFO - Trial 1615: Early stopping at epoch 172.
[I 2025-11-05 02:43:17,850] Trial 1615 finished with value: 0.0025179926306009293 and parameters: {'batch_size': 64, 'learning_rate': 0.0039049192529418786, 'nr_hidden_layers': 1, 'nr_neurons': 146, 'dropout_rate': 0.0001771001081605995, 'weight_decay': 3.7995749873430506e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 1586 with value: 0.0013657298404723406.
2025-11-05 02:52:22,246 - INFO - Trial 1616: Early stopping at epoch 375.
[I 2025-11-05 02:52:22,380] Trial 1616 finished with value: 0.0011460189707577229 and parameters: {'batch_size': 64, 'learning_rate': 0.003384871040990215, 'nr_hidden_layers': 1, 'nr_neurons': 112, 'dropout_rate': 0.00014697292771531992, 'weight_decay': 4.3897138187438567e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
2025-11-05 02:54:19,970 - INFO - Trial 1617: Early stopping at epoch 79.
[I 2025-11-05 02:54:20,097] Trial 1617 finished with value: 0.0060326047241687775 and parameters: {'batch_size': 64, 'learning_rate': 0.0029737655843712863, 'nr_hidden_layers': 1, 'nr_neurons': 112, 'dropout_rate': 0.0002200575553713427, 'weight_decay': 5.645325819598191e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 02:54:36,779] Trial 1618 pruned. 
[I 2025-11-05 02:54:53,569] Trial 1619 pruned. 
2025-11-05 02:59:05,627 - INFO - Trial 1620: Early stopping at epoch 160.
[I 2025-11-05 02:59:05,755] Trial 1620 finished with value: 0.0033833645284175873 and parameters: {'batch_size': 64, 'learning_rate': 0.0027200075974705877, 'nr_hidden_layers': 1, 'nr_neurons': 104, 'dropout_rate': 7.261538025095477e-05, 'weight_decay': 4.733223276557617e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'L1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 02:59:13,581] Trial 1621 pruned. 
[I 2025-11-05 02:59:29,737] Trial 1622 pruned. 
[I 2025-11-05 02:59:39,818] Trial 1623 pruned. 
2025-11-05 03:03:21,442 - INFO - Trial 1624: Early stopping at epoch 156.
[I 2025-11-05 03:03:21,570] Trial 1624 finished with value: 0.0028681973926723003 and parameters: {'batch_size': 64, 'learning_rate': 0.003013270436048816, 'nr_hidden_layers': 1, 'nr_neurons': 125, 'dropout_rate': 5.6667009743119334e-05, 'weight_decay': 7.608098382682727e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 03:03:37,359] Trial 1625 pruned. 
2025-11-05 03:06:39,288 - INFO - Trial 1626: Early stopping at epoch 119.
[I 2025-11-05 03:06:39,415] Trial 1626 finished with value: 0.005280340556055307 and parameters: {'batch_size': 64, 'learning_rate': 0.002466857350975426, 'nr_hidden_layers': 1, 'nr_neurons': 121, 'dropout_rate': 0.009695809055527289, 'weight_decay': 8.412339894760448e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 03:06:55,739] Trial 1627 pruned. 
[I 2025-11-05 03:14:03,685] Trial 1628 pruned. 
[I 2025-11-05 03:14:10,265] Trial 1629 pruned. 
[I 2025-11-05 03:14:26,088] Trial 1630 pruned. 
[I 2025-11-05 03:14:48,723] Trial 1631 pruned. 
[I 2025-11-05 03:15:08,705] Trial 1632 pruned. 
[I 2025-11-05 03:15:18,689] Trial 1633 pruned. 
2025-11-05 03:17:34,030 - INFO - Trial 1634: Early stopping at epoch 86.
[I 2025-11-05 03:17:34,158] Trial 1634 finished with value: 0.0064697302877902985 and parameters: {'batch_size': 64, 'learning_rate': 0.0028776952941644176, 'nr_hidden_layers': 1, 'nr_neurons': 123, 'dropout_rate': 0.031084674342779523, 'weight_decay': 3.730081044796915e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 03:17:50,457] Trial 1635 pruned. 
[I 2025-11-05 03:17:56,051] Trial 1636 pruned. 
[I 2025-11-05 03:18:12,332] Trial 1637 pruned. 
2025-11-05 03:20:31,805 - INFO - Trial 1638: Early stopping at epoch 94.
[I 2025-11-05 03:20:31,951] Trial 1638 finished with value: 0.005747767630964518 and parameters: {'batch_size': 64, 'learning_rate': 0.00718629888311853, 'nr_hidden_layers': 1, 'nr_neurons': 137, 'dropout_rate': 0.009556387918668256, 'weight_decay': 5.414329633223625e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 03:20:55,487] Trial 1639 pruned. 
[I 2025-11-05 03:21:12,357] Trial 1640 pruned. 
[I 2025-11-05 03:21:33,102] Trial 1641 pruned. 
[I 2025-11-05 03:21:39,512] Trial 1642 pruned. 
[I 2025-11-05 03:21:49,871] Trial 1643 pruned. 
[I 2025-11-05 03:22:06,932] Trial 1644 pruned. 
2025-11-05 03:27:32,823 - INFO - Trial 1645: Early stopping at epoch 213.
[I 2025-11-05 03:27:32,994] Trial 1645 finished with value: 0.0023781792260706425 and parameters: {'batch_size': 64, 'learning_rate': 0.006630832643331362, 'nr_hidden_layers': 1, 'nr_neurons': 119, 'dropout_rate': 0.0003737431089866832, 'weight_decay': 4.044354541974386e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 03:27:49,341] Trial 1646 pruned. 
[I 2025-11-05 03:28:11,240] Trial 1647 pruned. 
[I 2025-11-05 03:28:27,629] Trial 1648 pruned. 
2025-11-05 03:31:56,129 - INFO - Trial 1649: Early stopping at epoch 121.
[I 2025-11-05 03:31:56,258] Trial 1649 finished with value: 0.002106187166646123 and parameters: {'batch_size': 64, 'learning_rate': 0.003362743354653577, 'nr_hidden_layers': 2, 'nr_neurons': 127, 'dropout_rate': 0.00021451940170867125, 'weight_decay': 8.411374214832728e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 03:32:19,901] Trial 1650 pruned. 
[I 2025-11-05 03:32:27,791] Trial 1651 pruned. 
[I 2025-11-05 03:32:51,403] Trial 1652 pruned. 
[I 2025-11-05 03:33:01,895] Trial 1653 pruned. 
[I 2025-11-05 03:33:19,398] Trial 1654 pruned. 
[I 2025-11-05 03:33:35,700] Trial 1655 pruned. 
2025-11-05 03:37:12,931 - INFO - Trial 1656: Early stopping at epoch 147.
[I 2025-11-05 03:37:13,089] Trial 1656 finished with value: 0.0025292974896728992 and parameters: {'batch_size': 64, 'learning_rate': 0.006713482416384874, 'nr_hidden_layers': 1, 'nr_neurons': 145, 'dropout_rate': 0.00017648124588257096, 'weight_decay': 5.8844681514560085e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 03:37:20,044] Trial 1657 pruned. 
[I 2025-11-05 03:37:36,792] Trial 1658 pruned. 
2025-11-05 03:39:41,779 - INFO - Trial 1659: Early stopping at epoch 84.
[I 2025-11-05 03:39:41,914] Trial 1659 finished with value: 0.006205803249031305 and parameters: {'batch_size': 64, 'learning_rate': 0.0030792640800205466, 'nr_hidden_layers': 1, 'nr_neurons': 220, 'dropout_rate': 0.009287334621109302, 'weight_decay': 4.041747543406061e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 03:40:23,758] Trial 1660 pruned. 
2025-11-05 03:43:18,092 - INFO - Trial 1661: Early stopping at epoch 119.
[I 2025-11-05 03:43:18,221] Trial 1661 finished with value: 0.003017629962414503 and parameters: {'batch_size': 64, 'learning_rate': 0.004012223282815099, 'nr_hidden_layers': 1, 'nr_neurons': 107, 'dropout_rate': 1.2389124010500673e-05, 'weight_decay': 5.301815450011817e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 03:43:34,032] Trial 1662 pruned. 
[I 2025-11-05 03:43:44,520] Trial 1663 pruned. 
[I 2025-11-05 03:43:50,091] Trial 1664 pruned. 
2025-11-05 03:45:59,355 - INFO - Trial 1665: Early stopping at epoch 74.
[I 2025-11-05 03:45:59,484] Trial 1665 finished with value: 0.004714482463896275 and parameters: {'batch_size': 64, 'learning_rate': 0.00851329738262832, 'nr_hidden_layers': 2, 'nr_neurons': 131, 'dropout_rate': 3.6970958162544105e-05, 'weight_decay': 4.0917240158890924e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 03:46:16,314] Trial 1666 pruned. 
2025-11-05 03:47:42,688 - INFO - Trial 1667: Early stopping at epoch 58.
[I 2025-11-05 03:47:42,827] Trial 1667 finished with value: 0.008036511950194836 and parameters: {'batch_size': 64, 'learning_rate': 0.00723469105940986, 'nr_hidden_layers': 1, 'nr_neurons': 125, 'dropout_rate': 0.009373742316232139, 'weight_decay': 4.767118652355105e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 03:48:18,328] Trial 1668 pruned. 
[I 2025-11-05 03:48:34,649] Trial 1669 pruned. 
[I 2025-11-05 03:48:41,079] Trial 1670 pruned. 
2025-11-05 03:51:37,110 - INFO - Trial 1671: Early stopping at epoch 119.
[I 2025-11-05 03:51:37,239] Trial 1671 finished with value: 0.002960922196507454 and parameters: {'batch_size': 64, 'learning_rate': 0.004203697151905739, 'nr_hidden_layers': 1, 'nr_neurons': 210, 'dropout_rate': 5.9145161366060735e-05, 'weight_decay': 3.99849560014745e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 03:53:44,670] Trial 1672 pruned. 
2025-11-05 03:56:37,797 - INFO - Trial 1673: Early stopping at epoch 182.
[I 2025-11-05 03:56:37,927] Trial 1673 finished with value: 0.002331911586225033 and parameters: {'batch_size': 128, 'learning_rate': 0.006420618056792146, 'nr_hidden_layers': 1, 'nr_neurons': 144, 'dropout_rate': 0.00013293816703772578, 'weight_decay': 6.804955454383068e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 03:56:54,439] Trial 1674 pruned. 
[I 2025-11-05 03:57:10,786] Trial 1675 pruned. 
[I 2025-11-05 03:57:27,174] Trial 1676 pruned. 
[I 2025-11-05 03:57:43,849] Trial 1677 pruned. 
[I 2025-11-05 03:58:00,645] Trial 1678 pruned. 
[I 2025-11-05 03:58:16,986] Trial 1679 pruned. 
[I 2025-11-05 03:58:36,380] Trial 1680 pruned. 
[I 2025-11-05 03:58:45,122] Trial 1681 pruned. 
[I 2025-11-05 03:59:19,701] Trial 1682 pruned. 
[I 2025-11-05 03:59:29,661] Trial 1683 pruned. 
[I 2025-11-05 03:59:45,426] Trial 1684 pruned. 
[I 2025-11-05 04:00:01,190] Trial 1685 pruned. 
[I 2025-11-05 04:00:07,989] Trial 1686 pruned. 
[I 2025-11-05 04:00:23,811] Trial 1687 pruned. 
[I 2025-11-05 04:00:39,650] Trial 1688 pruned. 
[I 2025-11-05 04:00:55,462] Trial 1689 pruned. 
2025-11-05 04:05:13,064 - INFO - Trial 1690: Early stopping at epoch 176.
[I 2025-11-05 04:05:13,194] Trial 1690 finished with value: 0.0022862395271658897 and parameters: {'batch_size': 64, 'learning_rate': 0.003728640066939978, 'nr_hidden_layers': 1, 'nr_neurons': 166, 'dropout_rate': 0.00018095398635320088, 'weight_decay': 7.369727778262674e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 04:05:18,901] Trial 1691 pruned. 
[I 2025-11-05 04:05:36,093] Trial 1692 pruned. 
[I 2025-11-05 04:05:46,123] Trial 1693 pruned. 
[I 2025-11-05 04:06:01,928] Trial 1694 pruned. 
2025-11-05 04:09:01,241 - INFO - Trial 1695: Early stopping at epoch 120.
[I 2025-11-05 04:09:01,370] Trial 1695 finished with value: 0.0048056431114673615 and parameters: {'batch_size': 64, 'learning_rate': 0.003992928158738795, 'nr_hidden_layers': 1, 'nr_neurons': 177, 'dropout_rate': 0.008419792637635879, 'weight_decay': 4.1692652932393875e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 04:09:07,593] Trial 1696 pruned. 
[I 2025-11-05 04:09:23,307] Trial 1697 pruned. 
[I 2025-11-05 04:09:54,826] Trial 1698 pruned. 
[I 2025-11-05 04:10:11,199] Trial 1699 pruned. 
[I 2025-11-05 04:10:27,598] Trial 1700 pruned. 
[I 2025-11-05 04:10:43,893] Trial 1701 pruned. 
2025-11-05 04:13:00,697 - INFO - Trial 1702: Early stopping at epoch 92.
[I 2025-11-05 04:13:00,829] Trial 1702 finished with value: 0.004442793317139149 and parameters: {'batch_size': 64, 'learning_rate': 0.0046480334718809035, 'nr_hidden_layers': 1, 'nr_neurons': 170, 'dropout_rate': 0.00018510973759299567, 'weight_decay': 2.5981148016585738e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 04:13:11,399] Trial 1703 pruned. 
[I 2025-11-05 04:13:27,728] Trial 1704 pruned. 
[I 2025-11-05 04:13:35,561] Trial 1705 pruned. 
2025-11-05 04:16:00,404 - INFO - Trial 1706: Early stopping at epoch 91.
[I 2025-11-05 04:16:00,533] Trial 1706 finished with value: 0.00372610567137599 and parameters: {'batch_size': 64, 'learning_rate': 0.006377994574178741, 'nr_hidden_layers': 1, 'nr_neurons': 112, 'dropout_rate': 0.00018954310640401925, 'weight_decay': 8.660532000262627e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 04:16:16,333] Trial 1707 pruned. 
[I 2025-11-05 04:16:32,130] Trial 1708 pruned. 
2025-11-05 04:19:04,322 - INFO - Trial 1709: Early stopping at epoch 101.
[I 2025-11-05 04:19:04,452] Trial 1709 finished with value: 0.004489126615226269 and parameters: {'batch_size': 64, 'learning_rate': 0.002983846845652595, 'nr_hidden_layers': 1, 'nr_neurons': 203, 'dropout_rate': 5.178923324767172e-06, 'weight_decay': 0.0009987280229207236, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 04:19:20,324] Trial 1710 pruned. 
[I 2025-11-05 04:22:28,721] Trial 1711 pruned. 
[I 2025-11-05 04:22:35,892] Trial 1712 pruned. 
[I 2025-11-05 04:22:55,152] Trial 1713 pruned. 
[I 2025-11-05 04:23:10,824] Trial 1714 pruned. 
[I 2025-11-05 04:23:27,684] Trial 1715 pruned. 
2025-11-05 04:25:17,489 - INFO - Trial 1716: Early stopping at epoch 63.
[I 2025-11-05 04:25:17,618] Trial 1716 finished with value: 0.004880140535533428 and parameters: {'batch_size': 64, 'learning_rate': 0.0035095788667556874, 'nr_hidden_layers': 2, 'nr_neurons': 118, 'dropout_rate': 0.00023305610219611083, 'weight_decay': 2.1462651197799804e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 04:26:10,745] Trial 1717 pruned. 
[I 2025-11-05 04:26:16,505] Trial 1718 pruned. 
[I 2025-11-05 04:26:59,144] Trial 1719 pruned. 
[I 2025-11-05 04:27:15,022] Trial 1720 pruned. 
2025-11-05 04:28:51,047 - INFO - Trial 1721: Early stopping at epoch 65.
[I 2025-11-05 04:28:51,176] Trial 1721 finished with value: 0.00698093930259347 and parameters: {'batch_size': 64, 'learning_rate': 0.002255619800270858, 'nr_hidden_layers': 1, 'nr_neurons': 146, 'dropout_rate': 0.016548846408448843, 'weight_decay': 2.5419288452695477e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 04:29:22,572] Trial 1722 pruned. 
[I 2025-11-05 04:29:28,832] Trial 1723 pruned. 
[I 2025-11-05 04:29:38,802] Trial 1724 pruned. 
[I 2025-11-05 04:29:56,014] Trial 1725 pruned. 
[I 2025-11-05 04:30:11,885] Trial 1726 pruned. 
[I 2025-11-05 04:30:50,447] Trial 1727 pruned. 
2025-11-05 04:36:09,322 - INFO - Trial 1728: Early stopping at epoch 211.
[I 2025-11-05 04:36:09,458] Trial 1728 finished with value: 0.0025274641811847687 and parameters: {'batch_size': 64, 'learning_rate': 0.004135585495772878, 'nr_hidden_layers': 1, 'nr_neurons': 214, 'dropout_rate': 0.00016881502818998865, 'weight_decay': 4.591925044626137e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 04:36:31,727] Trial 1729 pruned. 
[I 2025-11-05 04:36:48,161] Trial 1730 pruned. 
[I 2025-11-05 04:36:55,999] Trial 1731 pruned. 
[I 2025-11-05 04:37:19,446] Trial 1732 pruned. 
[I 2025-11-05 04:37:35,352] Trial 1733 pruned. 
[I 2025-11-05 04:37:45,287] Trial 1734 pruned. 
2025-11-05 04:39:59,225 - INFO - Trial 1735: Early stopping at epoch 93.
[I 2025-11-05 04:39:59,365] Trial 1735 finished with value: 0.006383722182363272 and parameters: {'batch_size': 64, 'learning_rate': 0.005913552137642331, 'nr_hidden_layers': 1, 'nr_neurons': 188, 'dropout_rate': 0.009154008262522988, 'weight_decay': 6.185282978698763e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 04:40:33,549] Trial 1736 pruned. 
[I 2025-11-05 04:40:49,934] Trial 1737 pruned. 
2025-11-05 04:43:37,430 - INFO - Trial 1738: Early stopping at epoch 113.
[I 2025-11-05 04:43:37,564] Trial 1738 finished with value: 0.005615334026515484 and parameters: {'batch_size': 64, 'learning_rate': 0.006837073005219377, 'nr_hidden_layers': 1, 'nr_neurons': 203, 'dropout_rate': 0.008739531340562294, 'weight_decay': 2.280199507606478e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 04:43:44,320] Trial 1739 pruned. 
[I 2025-11-05 04:47:24,808] Trial 1740 pruned. 
[I 2025-11-05 04:47:40,594] Trial 1741 pruned. 
2025-11-05 04:50:26,681 - INFO - Trial 1742: Early stopping at epoch 88.
[I 2025-11-05 04:50:26,812] Trial 1742 finished with value: 0.005723792593926191 and parameters: {'batch_size': 64, 'learning_rate': 0.004049170107664409, 'nr_hidden_layers': 3, 'nr_neurons': 167, 'dropout_rate': 0.009107329556336936, 'weight_decay': 0.0005058929859103701, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 04:50:54,714] Trial 1743 pruned. 
2025-11-05 04:53:02,262 - INFO - Trial 1744: Early stopping at epoch 86.
[I 2025-11-05 04:53:02,392] Trial 1744 finished with value: 0.007039593532681465 and parameters: {'batch_size': 64, 'learning_rate': 0.005799973440398949, 'nr_hidden_layers': 1, 'nr_neurons': 196, 'dropout_rate': 0.016060867227738074, 'weight_decay': 2.8180069928606838e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 04:53:13,597] Trial 1745 pruned. 
[I 2025-11-05 04:53:19,209] Trial 1746 pruned. 
[I 2025-11-05 04:53:35,449] Trial 1747 pruned. 
[I 2025-11-05 04:53:53,008] Trial 1748 pruned. 
2025-11-05 04:55:46,085 - INFO - Trial 1749: Early stopping at epoch 73.
[I 2025-11-05 04:55:46,217] Trial 1749 finished with value: 0.006468211300671101 and parameters: {'batch_size': 64, 'learning_rate': 0.0036774025241157844, 'nr_hidden_layers': 1, 'nr_neurons': 164, 'dropout_rate': 0.009450655691461538, 'weight_decay': 1.3790394909920373e-06, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
2025-11-05 04:58:53,222 - INFO - Trial 1750: Early stopping at epoch 127.
[I 2025-11-05 04:58:53,357] Trial 1750 finished with value: 0.0031283781863749027 and parameters: {'batch_size': 64, 'learning_rate': 0.00545417066187565, 'nr_hidden_layers': 1, 'nr_neurons': 132, 'dropout_rate': 0.0002580832222457229, 'weight_decay': 2.1480628048525053e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 04:59:00,226] Trial 1751 pruned. 
[I 2025-11-05 04:59:16,489] Trial 1752 pruned. 
[I 2025-11-05 04:59:33,323] Trial 1753 pruned. 
[I 2025-11-05 04:59:52,116] Trial 1754 pruned. 
[I 2025-11-05 05:00:02,924] Trial 1755 pruned. 
[I 2025-11-05 05:00:19,318] Trial 1756 pruned. 
[I 2025-11-05 05:00:35,731] Trial 1757 pruned. 
[I 2025-11-05 05:01:04,067] Trial 1758 pruned. 
2025-11-05 05:05:45,602 - INFO - Trial 1759: Early stopping at epoch 185.
[I 2025-11-05 05:05:45,735] Trial 1759 finished with value: 0.0018905490869656205 and parameters: {'batch_size': 64, 'learning_rate': 0.004410089523315924, 'nr_hidden_layers': 1, 'nr_neurons': 200, 'dropout_rate': 8.498771729592755e-05, 'weight_decay': 4.219534915597718e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 05:05:55,053] Trial 1760 pruned. 
[I 2025-11-05 05:06:19,821] Trial 1761 pruned. 
[I 2025-11-05 05:06:46,598] Trial 1762 pruned. 
[I 2025-11-05 05:09:01,299] Trial 1763 pruned. 
[I 2025-11-05 05:09:17,128] Trial 1764 pruned. 
2025-11-05 05:11:57,748 - INFO - Trial 1765: Early stopping at epoch 173.
[I 2025-11-05 05:11:57,873] Trial 1765 finished with value: 0.0031925339717417955 and parameters: {'batch_size': 128, 'learning_rate': 0.003383086352652705, 'nr_hidden_layers': 1, 'nr_neurons': 207, 'dropout_rate': 0.0003999839910557377, 'weight_decay': 4.026426776339469e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
2025-11-05 05:17:24,280 - INFO - Trial 1766: Early stopping at epoch 220.
[I 2025-11-05 05:17:24,414] Trial 1766 finished with value: 0.0023093216586858034 and parameters: {'batch_size': 64, 'learning_rate': 0.004346322432911889, 'nr_hidden_layers': 1, 'nr_neurons': 202, 'dropout_rate': 0.000238544171748908, 'weight_decay': 2.963525685859571e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 05:17:47,280] Trial 1767 pruned. 
2025-11-05 05:20:01,954 - INFO - Trial 1768: Early stopping at epoch 94.
[I 2025-11-05 05:20:02,086] Trial 1768 finished with value: 0.006236943881958723 and parameters: {'batch_size': 64, 'learning_rate': 0.0038036627996490013, 'nr_hidden_layers': 1, 'nr_neurons': 75, 'dropout_rate': 0.008969045068718824, 'weight_decay': 0.00026975890680234663, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 05:20:08,702] Trial 1769 pruned. 
2025-11-05 05:22:30,953 - INFO - Trial 1770: Early stopping at epoch 97.
[I 2025-11-05 05:22:31,095] Trial 1770 finished with value: 0.0034752727951854467 and parameters: {'batch_size': 64, 'learning_rate': 0.0033975428287534464, 'nr_hidden_layers': 1, 'nr_neurons': 223, 'dropout_rate': 2.6942770147341226e-05, 'weight_decay': 2.8462225843644892e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 05:22:47,157] Trial 1771 pruned. 
2025-11-05 05:24:37,369 - INFO - Trial 1772: Early stopping at epoch 72.
[I 2025-11-05 05:24:37,499] Trial 1772 finished with value: 0.006310597062110901 and parameters: {'batch_size': 64, 'learning_rate': 0.0037179337554097, 'nr_hidden_layers': 1, 'nr_neurons': 245, 'dropout_rate': 0.008803242369621067, 'weight_decay': 2.1891133837843502e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
2025-11-05 05:30:48,705 - INFO - Trial 1773: Early stopping at epoch 251.
[I 2025-11-05 05:30:48,838] Trial 1773 finished with value: 0.0013791760429739952 and parameters: {'batch_size': 64, 'learning_rate': 0.004063820444564375, 'nr_hidden_layers': 1, 'nr_neurons': 216, 'dropout_rate': 7.573966110592825e-05, 'weight_decay': 4.108947745763851e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 05:30:54,231] Trial 1774 pruned. 
[I 2025-11-05 05:31:10,059] Trial 1775 pruned. 
[I 2025-11-05 05:31:20,144] Trial 1776 pruned. 
2025-11-05 05:33:54,596 - INFO - Trial 1777: Early stopping at epoch 105.
[I 2025-11-05 05:33:54,728] Trial 1777 finished with value: 0.005564787425100803 and parameters: {'batch_size': 64, 'learning_rate': 0.004757889657421109, 'nr_hidden_layers': 1, 'nr_neurons': 237, 'dropout_rate': 0.009156389728309986, 'weight_decay': 5.1338358585772304e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 05:34:11,773] Trial 1778 pruned. 
[I 2025-11-05 05:34:28,005] Trial 1779 pruned. 
[I 2025-11-05 05:34:34,268] Trial 1780 pruned. 
[I 2025-11-05 05:34:51,490] Trial 1781 pruned. 
[I 2025-11-05 05:35:12,277] Trial 1782 pruned. 
[I 2025-11-05 05:35:30,532] Trial 1783 pruned. 
[I 2025-11-05 05:35:49,796] Trial 1784 pruned. 
[I 2025-11-05 05:36:01,188] Trial 1785 pruned. 
2025-11-05 05:38:13,417 - INFO - Trial 1786: Early stopping at epoch 87.
[I 2025-11-05 05:38:13,548] Trial 1786 finished with value: 0.006011619698256254 and parameters: {'batch_size': 64, 'learning_rate': 0.005028679390132513, 'nr_hidden_layers': 1, 'nr_neurons': 210, 'dropout_rate': 0.008173687402074645, 'weight_decay': 3.60841272616909e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
2025-11-05 05:40:11,871 - INFO - Trial 1787: Early stopping at epoch 80.
[I 2025-11-05 05:40:12,006] Trial 1787 finished with value: 0.007177271414548159 and parameters: {'batch_size': 64, 'learning_rate': 0.00408534210291125, 'nr_hidden_layers': 1, 'nr_neurons': 243, 'dropout_rate': 0.018574200490757163, 'weight_decay': 4.8373059037099115e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 05:40:27,880] Trial 1788 pruned. 
[I 2025-11-05 05:40:35,444] Trial 1789 pruned. 
[I 2025-11-05 05:40:58,271] Trial 1790 pruned. 
2025-11-05 05:44:52,296 - INFO - Trial 1791: Early stopping at epoch 154.
[I 2025-11-05 05:44:52,429] Trial 1791 finished with value: 0.0033237822353839874 and parameters: {'batch_size': 64, 'learning_rate': 0.004014310867269076, 'nr_hidden_layers': 1, 'nr_neurons': 215, 'dropout_rate': 0.00016000945684943696, 'weight_decay': 1.4964477018312655e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 05:45:09,773] Trial 1792 pruned. 
2025-11-05 05:47:25,664 - INFO - Trial 1793: Early stopping at epoch 94.
[I 2025-11-05 05:47:25,797] Trial 1793 finished with value: 0.0046980613842606544 and parameters: {'batch_size': 64, 'learning_rate': 0.004538870976413898, 'nr_hidden_layers': 1, 'nr_neurons': 202, 'dropout_rate': 0.00035799731286313165, 'weight_decay': 3.219695349157264e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 05:47:41,611] Trial 1794 pruned. 
[I 2025-11-05 05:47:51,556] Trial 1795 pruned. 
2025-11-05 05:51:24,965 - INFO - Trial 1796: Early stopping at epoch 148.
[I 2025-11-05 05:51:25,099] Trial 1796 finished with value: 0.0032761397305876017 and parameters: {'batch_size': 64, 'learning_rate': 0.004462755168581827, 'nr_hidden_layers': 1, 'nr_neurons': 207, 'dropout_rate': 5.882163787180401e-06, 'weight_decay': 3.7073789130825405e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 05:51:31,904] Trial 1797 pruned. 
[I 2025-11-05 05:54:17,167] Trial 1798 pruned. 
[I 2025-11-05 05:54:33,066] Trial 1799 pruned. 
[I 2025-11-05 05:54:48,876] Trial 1800 pruned. 
[I 2025-11-05 05:55:37,408] Trial 1801 pruned. 
2025-11-05 05:56:57,810 - INFO - Trial 1802: Early stopping at epoch 53.
[I 2025-11-05 05:56:57,942] Trial 1802 finished with value: 0.006847518030554056 and parameters: {'batch_size': 64, 'learning_rate': 0.003684243391744105, 'nr_hidden_layers': 1, 'nr_neurons': 198, 'dropout_rate': 0.009340338018888287, 'weight_decay': 6.916983894128835e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 05:57:03,573] Trial 1803 pruned. 
2025-11-05 06:01:39,473 - INFO - Trial 1804: Early stopping at epoch 186.
[I 2025-11-05 06:01:39,607] Trial 1804 finished with value: 0.0024179716128855944 and parameters: {'batch_size': 64, 'learning_rate': 0.004237737944753007, 'nr_hidden_layers': 1, 'nr_neurons': 211, 'dropout_rate': 1.9208483203048046e-05, 'weight_decay': 5.360730713831031e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 06:01:55,406] Trial 1805 pruned. 
[I 2025-11-05 06:02:05,372] Trial 1806 pruned. 
[I 2025-11-05 06:02:11,579] Trial 1807 pruned. 
[I 2025-11-05 06:02:27,296] Trial 1808 pruned. 
[I 2025-11-05 06:02:42,967] Trial 1809 pruned. 
[I 2025-11-05 06:05:26,365] Trial 1810 pruned. 
[I 2025-11-05 06:05:42,304] Trial 1811 pruned. 
[I 2025-11-05 06:05:58,124] Trial 1812 pruned. 
2025-11-05 06:08:20,472 - INFO - Trial 1813: Early stopping at epoch 100.
[I 2025-11-05 06:08:20,605] Trial 1813 finished with value: 0.004549448378384113 and parameters: {'batch_size': 64, 'learning_rate': 0.003492255711319319, 'nr_hidden_layers': 1, 'nr_neurons': 109, 'dropout_rate': 0.00019178474513269423, 'weight_decay': 0.00014877855513390292, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 06:10:04,053] Trial 1814 pruned. 
[I 2025-11-05 06:10:16,363] Trial 1815 pruned. 
2025-11-05 06:11:41,962 - INFO - Trial 1816: Early stopping at epoch 56.
[I 2025-11-05 06:11:42,087] Trial 1816 finished with value: 0.008573979139328003 and parameters: {'batch_size': 64, 'learning_rate': 0.005022202965309846, 'nr_hidden_layers': 1, 'nr_neurons': 130, 'dropout_rate': 0.010155478470052128, 'weight_decay': 2.6759509164402022e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 06:11:49,667] Trial 1817 pruned. 
2025-11-05 06:16:13,903 - INFO - Trial 1818: Early stopping at epoch 182.
[I 2025-11-05 06:16:14,037] Trial 1818 finished with value: 0.0020386131945997477 and parameters: {'batch_size': 64, 'learning_rate': 0.003741600055456007, 'nr_hidden_layers': 1, 'nr_neurons': 193, 'dropout_rate': 2.0066521716818422e-05, 'weight_decay': 4.6054376713813054e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 06:16:31,600] Trial 1819 pruned. 
[I 2025-11-05 06:16:47,363] Trial 1820 pruned. 
[I 2025-11-05 06:17:03,105] Trial 1821 pruned. 
[I 2025-11-05 06:17:19,012] Trial 1822 pruned. 
[I 2025-11-05 06:17:34,890] Trial 1823 pruned. 
[I 2025-11-05 06:17:41,494] Trial 1824 pruned. 
[I 2025-11-05 06:18:05,556] Trial 1825 pruned. 
[I 2025-11-05 06:18:16,050] Trial 1826 pruned. 
[I 2025-11-05 06:18:31,781] Trial 1827 pruned. 
[I 2025-11-05 06:20:50,205] Trial 1828 pruned. 
[I 2025-11-05 06:23:32,919] Trial 1829 pruned. 
[I 2025-11-05 06:23:38,523] Trial 1830 pruned. 
[I 2025-11-05 06:23:54,343] Trial 1831 pruned. 
[I 2025-11-05 06:25:00,598] Trial 1832 pruned. 
2025-11-05 06:28:23,309 - INFO - Trial 1833: Early stopping at epoch 134.
[I 2025-11-05 06:28:23,442] Trial 1833 finished with value: 0.0028758631087839603 and parameters: {'batch_size': 64, 'learning_rate': 0.0035409445734503257, 'nr_hidden_layers': 1, 'nr_neurons': 203, 'dropout_rate': 0.0001897105600457324, 'weight_decay': 2.7611343732804858e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 06:28:46,091] Trial 1834 pruned. 
2025-11-05 06:32:00,475 - INFO - Trial 1835: Early stopping at epoch 131.
[I 2025-11-05 06:32:00,608] Trial 1835 finished with value: 0.004716545343399048 and parameters: {'batch_size': 64, 'learning_rate': 0.0038944402574516293, 'nr_hidden_layers': 1, 'nr_neurons': 184, 'dropout_rate': 0.00830968347360608, 'weight_decay': 5.8152539889003426e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 06:32:10,549] Trial 1836 pruned. 
[I 2025-11-05 06:32:16,753] Trial 1837 pruned. 
[I 2025-11-05 06:32:39,541] Trial 1838 pruned. 
2025-11-05 06:33:47,422 - INFO - Trial 1839: Early stopping at epoch 47.
[I 2025-11-05 06:33:47,548] Trial 1839 finished with value: 0.007921740412712097 and parameters: {'batch_size': 64, 'learning_rate': 0.004586533871220245, 'nr_hidden_layers': 1, 'nr_neurons': 185, 'dropout_rate': 0.009617212529736538, 'weight_decay': 4.2623807210067704e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 06:34:05,250] Trial 1840 pruned. 
[I 2025-11-05 06:34:21,409] Trial 1841 pruned. 
2025-11-05 06:37:29,198 - INFO - Trial 1842: Early stopping at epoch 127.
[I 2025-11-05 06:37:29,332] Trial 1842 finished with value: 0.002748610218986869 and parameters: {'batch_size': 64, 'learning_rate': 0.006588971734388881, 'nr_hidden_layers': 1, 'nr_neurons': 211, 'dropout_rate': 0.00022537938420930895, 'weight_decay': 1.741935876550297e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 06:37:37,154] Trial 1843 pruned. 
[I 2025-11-05 06:38:37,351] Trial 1844 pruned. 
[I 2025-11-05 06:38:56,694] Trial 1845 pruned. 
[I 2025-11-05 06:39:07,760] Trial 1846 pruned. 
[I 2025-11-05 06:39:24,369] Trial 1847 pruned. 
[I 2025-11-05 06:39:40,165] Trial 1848 pruned. 
[I 2025-11-05 06:40:03,061] Trial 1849 pruned. 
2025-11-05 06:44:06,775 - INFO - Trial 1850: Early stopping at epoch 169.
[I 2025-11-05 06:44:06,905] Trial 1850 finished with value: 0.002149811713024974 and parameters: {'batch_size': 64, 'learning_rate': 0.004810595735392382, 'nr_hidden_layers': 1, 'nr_neurons': 189, 'dropout_rate': 0.00014993570307751206, 'weight_decay': 4.4908203968243775e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 06:44:13,525] Trial 1851 pruned. 
[I 2025-11-05 06:45:00,528] Trial 1852 pruned. 
[I 2025-11-05 06:45:16,691] Trial 1853 pruned. 
[I 2025-11-05 06:45:32,476] Trial 1854 pruned. 
2025-11-05 06:48:43,340 - INFO - Trial 1855: Early stopping at epoch 131.
[I 2025-11-05 06:48:43,472] Trial 1855 finished with value: 0.00462911743670702 and parameters: {'batch_size': 64, 'learning_rate': 0.0028042876780952296, 'nr_hidden_layers': 1, 'nr_neurons': 190, 'dropout_rate': 0.009536986124443567, 'weight_decay': 6.987948102423807e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 06:48:53,451] Trial 1856 pruned. 
2025-11-05 06:50:31,576 - INFO - Trial 1857: Early stopping at epoch 68.
[I 2025-11-05 06:50:31,709] Trial 1857 finished with value: 0.0076484689489007 and parameters: {'batch_size': 64, 'learning_rate': 0.004073470656498864, 'nr_hidden_layers': 1, 'nr_neurons': 178, 'dropout_rate': 0.016759365170732687, 'weight_decay': 3.951636600349702e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 06:50:37,163] Trial 1858 pruned. 
[I 2025-11-05 06:50:58,471] Trial 1859 pruned. 
2025-11-05 06:54:37,665 - INFO - Trial 1860: Early stopping at epoch 154.
[I 2025-11-05 06:54:37,824] Trial 1860 finished with value: 0.002379376906901598 and parameters: {'batch_size': 64, 'learning_rate': 0.004689546721978384, 'nr_hidden_layers': 1, 'nr_neurons': 136, 'dropout_rate': 0.00010409945352438267, 'weight_decay': 3.445444720864996e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 06:54:53,488] Trial 1861 pruned. 
[I 2025-11-05 06:54:59,505] Trial 1862 pruned. 
2025-11-05 06:57:17,948 - INFO - Trial 1863: Early stopping at epoch 92.
[I 2025-11-05 06:57:18,083] Trial 1863 finished with value: 0.006378484889864922 and parameters: {'batch_size': 64, 'learning_rate': 0.002030868500712947, 'nr_hidden_layers': 1, 'nr_neurons': 216, 'dropout_rate': 0.035228200680056596, 'weight_decay': 3.0118876157613202e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 06:57:33,890] Trial 1864 pruned. 
[I 2025-11-05 06:57:49,655] Trial 1865 pruned. 
[I 2025-11-05 06:58:12,677] Trial 1866 pruned. 
[I 2025-11-05 06:58:23,523] Trial 1867 pruned. 
[I 2025-11-05 07:00:48,267] Trial 1868 pruned. 
[I 2025-11-05 07:01:11,178] Trial 1869 pruned. 
[I 2025-11-05 07:01:18,797] Trial 1870 pruned. 
[I 2025-11-05 07:01:50,632] Trial 1871 pruned. 
[I 2025-11-05 07:02:06,493] Trial 1872 pruned. 
2025-11-05 07:04:24,413 - INFO - Trial 1873: Early stopping at epoch 91.
[I 2025-11-05 07:04:24,546] Trial 1873 finished with value: 0.004362273961305618 and parameters: {'batch_size': 64, 'learning_rate': 0.004467243312249992, 'nr_hidden_layers': 1, 'nr_neurons': 207, 'dropout_rate': 1.9143687813995107e-05, 'weight_decay': 3.7239037061502413e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 07:05:30,839] Trial 1874 pruned. 
2025-11-05 07:08:41,825 - INFO - Trial 1875: Early stopping at epoch 132.
[I 2025-11-05 07:08:41,953] Trial 1875 finished with value: 0.002823411487042904 and parameters: {'batch_size': 64, 'learning_rate': 0.005741571029700308, 'nr_hidden_layers': 1, 'nr_neurons': 165, 'dropout_rate': 6.0698729900358186e-05, 'weight_decay': 5.750330610027117e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 07:08:51,922] Trial 1876 pruned. 
[I 2025-11-05 07:11:07,476] Trial 1877 pruned. 
[I 2025-11-05 07:11:14,144] Trial 1878 pruned. 
2025-11-05 07:16:15,002 - INFO - Trial 1879: Early stopping at epoch 208.
[I 2025-11-05 07:16:15,131] Trial 1879 finished with value: 0.002067247172817588 and parameters: {'batch_size': 64, 'learning_rate': 0.0035008391082661876, 'nr_hidden_layers': 1, 'nr_neurons': 127, 'dropout_rate': 0.0002600235663843286, 'weight_decay': 2.014635929940348e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 07:16:30,963] Trial 1880 pruned. 
[I 2025-11-05 07:16:59,429] Trial 1881 pruned. 
[I 2025-11-05 07:17:15,217] Trial 1882 pruned. 
[I 2025-11-05 07:17:31,674] Trial 1883 pruned. 
2025-11-05 07:19:53,497 - INFO - Trial 1884: Early stopping at epoch 95.
[I 2025-11-05 07:19:53,631] Trial 1884 finished with value: 0.006195591762661934 and parameters: {'batch_size': 64, 'learning_rate': 0.004030814732769865, 'nr_hidden_layers': 1, 'nr_neurons': 159, 'dropout_rate': 0.009979904264591114, 'weight_decay': 3.964058532875371e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 07:19:59,264] Trial 1885 pruned. 
[I 2025-11-05 07:20:22,190] Trial 1886 pruned. 
[I 2025-11-05 07:20:34,642] Trial 1887 pruned. 
[I 2025-11-05 07:20:50,663] Trial 1888 pruned. 
[I 2025-11-05 07:20:56,845] Trial 1889 pruned. 
2025-11-05 07:24:15,072 - INFO - Trial 1890: Early stopping at epoch 134.
[I 2025-11-05 07:24:15,205] Trial 1890 finished with value: 0.002212060382589698 and parameters: {'batch_size': 64, 'learning_rate': 0.005810810909424581, 'nr_hidden_layers': 1, 'nr_neurons': 168, 'dropout_rate': 9.406940091454916e-06, 'weight_decay': 3.4151966361782776e-06, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 07:24:31,415] Trial 1891 pruned. 
[I 2025-11-05 07:24:53,055] Trial 1892 pruned. 
2025-11-05 07:30:54,260 - INFO - Trial 1893: Early stopping at epoch 253.
[I 2025-11-05 07:30:54,402] Trial 1893 finished with value: 0.0016953138401731849 and parameters: {'batch_size': 64, 'learning_rate': 0.0030823343339913506, 'nr_hidden_layers': 1, 'nr_neurons': 110, 'dropout_rate': 5.27558513913503e-05, 'weight_decay': 2.2542083405785278e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 07:31:10,139] Trial 1894 pruned. 
[I 2025-11-05 07:31:25,940] Trial 1895 pruned. 
[I 2025-11-05 07:31:41,730] Trial 1896 pruned. 
[I 2025-11-05 07:31:51,710] Trial 1897 pruned. 
[I 2025-11-05 07:32:07,466] Trial 1898 pruned. 
[I 2025-11-05 07:32:14,984] Trial 1899 pruned. 
[I 2025-11-05 07:32:32,121] Trial 1900 pruned. 
[I 2025-11-05 07:32:54,944] Trial 1901 pruned. 
[I 2025-11-05 07:33:10,745] Trial 1902 pruned. 
[I 2025-11-05 07:33:26,566] Trial 1903 pruned. 
[I 2025-11-05 07:33:42,764] Trial 1904 pruned. 
[I 2025-11-05 07:33:58,562] Trial 1905 pruned. 
[I 2025-11-05 07:36:38,381] Trial 1906 pruned. 
[I 2025-11-05 07:36:45,164] Trial 1907 pruned. 
[I 2025-11-05 07:36:55,079] Trial 1908 pruned. 
[I 2025-11-05 07:37:12,240] Trial 1909 pruned. 
2025-11-05 07:39:55,160 - INFO - Trial 1910: Early stopping at epoch 105.
[I 2025-11-05 07:39:55,293] Trial 1910 finished with value: 0.003786189714446664 and parameters: {'batch_size': 64, 'learning_rate': 0.0025072256848784943, 'nr_hidden_layers': 1, 'nr_neurons': 119, 'dropout_rate': 0.0001947275092676553, 'weight_decay': 2.3367494436410202e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
2025-11-05 07:43:04,282 - INFO - Trial 1911: Early stopping at epoch 131.
[I 2025-11-05 07:43:04,419] Trial 1911 finished with value: 0.0036670768167823553 and parameters: {'batch_size': 64, 'learning_rate': 0.003316949302449879, 'nr_hidden_layers': 1, 'nr_neurons': 113, 'dropout_rate': 0.00015644646117745216, 'weight_decay': 1.769017968519246e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 07:43:10,021] Trial 1912 pruned. 
2025-11-05 07:46:58,200 - INFO - Trial 1913: Early stopping at epoch 161.
[I 2025-11-05 07:46:58,334] Trial 1913 finished with value: 0.0022562097292393446 and parameters: {'batch_size': 64, 'learning_rate': 0.0060567307031538994, 'nr_hidden_layers': 1, 'nr_neurons': 121, 'dropout_rate': 3.541918404180642e-05, 'weight_decay': 2.3957705158361835e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 07:47:14,048] Trial 1914 pruned. 
[I 2025-11-05 07:47:29,820] Trial 1915 pruned. 
[I 2025-11-05 07:47:46,007] Trial 1916 pruned. 
[I 2025-11-05 07:47:52,223] Trial 1917 pruned. 
[I 2025-11-05 07:48:03,769] Trial 1918 pruned. 
[I 2025-11-05 07:48:32,116] Trial 1919 pruned. 
[I 2025-11-05 07:48:48,125] Trial 1920 pruned. 
2025-11-05 07:52:27,046 - INFO - Trial 1921: Early stopping at epoch 154.
[I 2025-11-05 07:52:27,183] Trial 1921 finished with value: 0.002460105111822486 and parameters: {'batch_size': 64, 'learning_rate': 0.005589576810308011, 'nr_hidden_layers': 1, 'nr_neurons': 116, 'dropout_rate': 0.00029276007240177987, 'weight_decay': 2.7713266758539232e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 07:52:42,875] Trial 1922 pruned. 
[I 2025-11-05 07:53:14,928] Trial 1923 pruned. 
[I 2025-11-05 07:53:30,640] Trial 1924 pruned. 
[I 2025-11-05 07:53:38,204] Trial 1925 pruned. 
[I 2025-11-05 07:53:53,976] Trial 1926 pruned. 
[I 2025-11-05 07:54:09,804] Trial 1927 pruned. 
[I 2025-11-05 07:54:22,689] Trial 1928 pruned. 
[I 2025-11-05 07:54:38,811] Trial 1929 pruned. 
[I 2025-11-05 07:54:55,314] Trial 1930 pruned. 
2025-11-05 07:57:22,464 - INFO - Trial 1931: Early stopping at epoch 103.
[I 2025-11-05 07:57:22,598] Trial 1931 finished with value: 0.005515363533049822 and parameters: {'batch_size': 64, 'learning_rate': 0.003914800835740741, 'nr_hidden_layers': 1, 'nr_neurons': 116, 'dropout_rate': 0.008939161089815892, 'weight_decay': 1.913384195473997e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 07:57:38,370] Trial 1932 pruned. 
[I 2025-11-05 07:57:45,028] Trial 1933 pruned. 
2025-11-05 07:59:16,836 - INFO - Trial 1934: Early stopping at epoch 58.
[I 2025-11-05 07:59:16,962] Trial 1934 finished with value: 0.005376874003559351 and parameters: {'batch_size': 64, 'learning_rate': 0.003614439260270124, 'nr_hidden_layers': 1, 'nr_neurons': 145, 'dropout_rate': 0.00041125822554862737, 'weight_decay': 3.078764605911186e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 07:59:32,688] Trial 1935 pruned. 
[I 2025-11-05 07:59:48,388] Trial 1936 pruned. 
[I 2025-11-05 08:00:22,682] Trial 1937 pruned. 
[I 2025-11-05 08:00:32,670] Trial 1938 pruned. 
2025-11-05 08:02:39,543 - INFO - Trial 1939: Early stopping at epoch 76.
[I 2025-11-05 08:02:39,672] Trial 1939 finished with value: 0.004677638877183199 and parameters: {'batch_size': 64, 'learning_rate': 0.0063645357252009645, 'nr_hidden_layers': 1, 'nr_neurons': 154, 'dropout_rate': 0.00011504907606698015, 'weight_decay': 2.0461437414085305e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
2025-11-05 08:05:42,582 - INFO - Trial 1940: Early stopping at epoch 126.
[I 2025-11-05 08:05:42,711] Trial 1940 finished with value: 0.004645947832614183 and parameters: {'batch_size': 64, 'learning_rate': 0.0039466811386277235, 'nr_hidden_layers': 1, 'nr_neurons': 174, 'dropout_rate': 0.008881071455153584, 'weight_decay': 3.546449718826946e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 08:05:58,941] Trial 1941 pruned. 
2025-11-05 08:09:27,474 - INFO - Trial 1942: Early stopping at epoch 144.
[I 2025-11-05 08:09:27,609] Trial 1942 finished with value: 0.0028625258710235357 and parameters: {'batch_size': 64, 'learning_rate': 0.004360157587980249, 'nr_hidden_layers': 1, 'nr_neurons': 110, 'dropout_rate': 0.00010020626408245187, 'weight_decay': 8.248576730631122e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 08:09:34,043] Trial 1943 pruned. 
[I 2025-11-05 08:09:39,454] Trial 1944 pruned. 
2025-11-05 08:13:15,368 - INFO - Trial 1945: Early stopping at epoch 139.
[I 2025-11-05 08:13:15,507] Trial 1945 finished with value: 0.003141326829791069 and parameters: {'batch_size': 64, 'learning_rate': 0.0071590340048351105, 'nr_hidden_layers': 1, 'nr_neurons': 132, 'dropout_rate': 0.00029160321123348874, 'weight_decay': 2.429199290788536e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 08:13:58,359] Trial 1946 pruned. 
2025-11-05 08:15:48,578 - INFO - Trial 1947: Early stopping at epoch 74.
[I 2025-11-05 08:15:48,714] Trial 1947 finished with value: 0.006976067088544369 and parameters: {'batch_size': 64, 'learning_rate': 0.005027368733130844, 'nr_hidden_layers': 1, 'nr_neurons': 147, 'dropout_rate': 0.01635815631097133, 'weight_decay': 2.0733040947775816e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 08:15:58,670] Trial 1948 pruned. 
[I 2025-11-05 08:16:14,497] Trial 1949 pruned. 
[I 2025-11-05 08:16:31,338] Trial 1950 pruned. 
[I 2025-11-05 08:16:47,192] Trial 1951 pruned. 
[I 2025-11-05 08:17:03,026] Trial 1952 pruned. 
[I 2025-11-05 08:17:10,752] Trial 1953 pruned. 
[I 2025-11-05 08:17:26,569] Trial 1954 pruned. 
[I 2025-11-05 08:17:43,779] Trial 1955 pruned. 
[I 2025-11-05 08:17:59,656] Trial 1956 pruned. 
[I 2025-11-05 08:18:15,483] Trial 1957 pruned. 
[I 2025-11-05 08:18:25,984] Trial 1958 pruned. 
[I 2025-11-05 08:18:57,499] Trial 1959 pruned. 
[I 2025-11-05 08:19:13,338] Trial 1960 pruned. 
[I 2025-11-05 08:19:19,969] Trial 1961 pruned. 
[I 2025-11-05 08:19:36,938] Trial 1962 pruned. 
[I 2025-11-05 08:22:47,853] Trial 1963 pruned. 
2025-11-05 08:25:50,888 - INFO - Trial 1964: Early stopping at epoch 127.
[I 2025-11-05 08:25:51,022] Trial 1964 finished with value: 0.0030180143658071756 and parameters: {'batch_size': 64, 'learning_rate': 0.00469958872150744, 'nr_hidden_layers': 1, 'nr_neurons': 105, 'dropout_rate': 0.00030716202878740013, 'weight_decay': 2.9491784565427195e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 08:26:06,911] Trial 1965 pruned. 
[I 2025-11-05 08:26:23,191] Trial 1966 pruned. 
[I 2025-11-05 08:26:28,821] Trial 1967 pruned. 
2025-11-05 08:28:46,363 - INFO - Trial 1968: Early stopping at epoch 92.
[I 2025-11-05 08:28:46,490] Trial 1968 finished with value: 0.0042626094073057175 and parameters: {'batch_size': 64, 'learning_rate': 0.0025086876718781845, 'nr_hidden_layers': 1, 'nr_neurons': 191, 'dropout_rate': 0.00012224594236467533, 'weight_decay': 4.4270842033504474e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 08:28:56,461] Trial 1969 pruned. 
[I 2025-11-05 08:29:30,732] Trial 1970 pruned. 
[I 2025-11-05 08:29:48,477] Trial 1971 pruned. 
[I 2025-11-05 08:29:54,703] Trial 1972 pruned. 
2025-11-05 08:32:43,109 - INFO - Trial 1973: Early stopping at epoch 114.
[I 2025-11-05 08:32:43,258] Trial 1973 finished with value: 0.0031620510853827 and parameters: {'batch_size': 64, 'learning_rate': 0.0038814917292204825, 'nr_hidden_layers': 1, 'nr_neurons': 151, 'dropout_rate': 0.00027063372106846735, 'weight_decay': 2.9164360915170787e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 08:32:58,998] Trial 1974 pruned. 
[I 2025-11-05 08:33:14,901] Trial 1975 pruned. 
[I 2025-11-05 08:33:30,627] Trial 1976 pruned. 
[I 2025-11-05 08:33:46,386] Trial 1977 pruned. 
[I 2025-11-05 08:33:59,930] Trial 1978 pruned. 
2025-11-05 08:35:51,876 - INFO - Trial 1979: Early stopping at epoch 78.
[I 2025-11-05 08:35:52,004] Trial 1979 finished with value: 0.00593554275110364 and parameters: {'batch_size': 64, 'learning_rate': 0.004240239431550373, 'nr_hidden_layers': 1, 'nr_neurons': 183, 'dropout_rate': 0.008552876678193972, 'weight_decay': 0.00016368933851655865, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 08:36:13,367] Trial 1980 pruned. 
2025-11-05 08:40:08,563 - INFO - Trial 1981: Early stopping at epoch 165.
[I 2025-11-05 08:40:08,703] Trial 1981 finished with value: 0.002645107451826334 and parameters: {'batch_size': 64, 'learning_rate': 0.003899979080344258, 'nr_hidden_layers': 1, 'nr_neurons': 112, 'dropout_rate': 0.00014817033730963924, 'weight_decay': 5.3547928603736834e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 08:41:51,438] Trial 1982 pruned. 
[I 2025-11-05 08:41:59,050] Trial 1983 pruned. 
[I 2025-11-05 08:42:20,568] Trial 1984 pruned. 
[I 2025-11-05 08:42:37,812] Trial 1985 pruned. 
[I 2025-11-05 08:42:53,603] Trial 1986 pruned. 
[I 2025-11-05 08:43:09,451] Trial 1987 pruned. 
[I 2025-11-05 08:43:19,488] Trial 1988 pruned. 
[I 2025-11-05 08:43:26,319] Trial 1989 pruned. 
[I 2025-11-05 08:43:47,831] Trial 1990 pruned. 
[I 2025-11-05 08:44:04,459] Trial 1991 pruned. 
[I 2025-11-05 08:44:20,374] Trial 1992 pruned. 
[I 2025-11-05 08:44:36,266] Trial 1993 pruned. 
[I 2025-11-05 08:44:52,123] Trial 1994 pruned. 
2025-11-05 08:46:03,342 - INFO - Trial 1995: Early stopping at epoch 49.
[I 2025-11-05 08:46:03,480] Trial 1995 finished with value: 0.007918017916381359 and parameters: {'batch_size': 64, 'learning_rate': 0.0026479935680846127, 'nr_hidden_layers': 1, 'nr_neurons': 193, 'dropout_rate': 0.016888765327374402, 'weight_decay': 4.132902637090853e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
2025-11-05 08:49:36,250 - INFO - Trial 1996: Early stopping at epoch 146.
[I 2025-11-05 08:49:36,388] Trial 1996 finished with value: 0.002527868142351508 and parameters: {'batch_size': 64, 'learning_rate': 0.004394120644567116, 'nr_hidden_layers': 1, 'nr_neurons': 177, 'dropout_rate': 5.308671122032245e-05, 'weight_decay': 2.089289145745408e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1616 with value: 0.0011460189707577229.
[I 2025-11-05 08:49:48,293] Trial 1997 pruned. 
[I 2025-11-05 08:49:53,930] Trial 1998 pruned. 
[I 2025-11-05 08:50:39,462] Trial 1999 pruned. 
2025-11-05 08:50:39,559 - INFO - Optuna study complete. Best trial: 1616
2025-11-05 08:50:39,650 - INFO - Best Loss: 0.0011460189707577229
2025-11-05 08:50:39,676 - INFO - Best Params: {'batch_size': 64, 'learning_rate': 0.003384871040990215, 'nr_hidden_layers': 1, 'nr_neurons': 112, 'dropout_rate': 0.00014697292771531992, 'weight_decay': 4.3897138187438567e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}
2025-11-05 08:50:39,676 - INFO - Training final model with best parameters...
2025-11-05 08:50:39,702 - INFO - Starting main training for labels ['Iso_width']...
2025-11-05 08:50:40,693 - INFO - Final training: 47896 train samples, 11975 val samples, 25660 test samples.
2025-11-05 08:50:40,696 - INFO - Using SmoothL1Loss (Huber Loss)
2025-11-05 08:50:40,696 - INFO - Using CosineAnnealingLR with T_max=1000
2025-11-05 08:50:40,703 - INFO - Starting final training loop for max 1000 epochs (Patience=25)...
2025-11-05 08:50:42,051 - INFO - Epoch [1/1000], Train Loss: 0.003993, Val Loss: 0.002834, LR: 0.003385
2025-11-05 08:50:42,052 - INFO - New best model found at epoch 1 with val_loss: 0.002834
2025-11-05 08:50:43,399 - INFO - New best model found at epoch 2 with val_loss: 0.001682
2025-11-05 08:50:46,102 - INFO - New best model found at epoch 4 with val_loss: 0.000709
2025-11-05 08:50:47,456 - INFO - New best model found at epoch 5 with val_loss: 0.000402
2025-11-05 08:50:48,803 - INFO - New best model found at epoch 6 with val_loss: 0.000280
2025-11-05 08:50:50,152 - INFO - New best model found at epoch 7 with val_loss: 0.000245
2025-11-05 08:50:51,508 - INFO - New best model found at epoch 8 with val_loss: 0.000175
2025-11-05 08:50:55,572 - INFO - New best model found at epoch 11 with val_loss: 0.000088
2025-11-05 08:50:58,264 - INFO - New best model found at epoch 13 with val_loss: 0.000087
2025-11-05 08:51:00,965 - INFO - New best model found at epoch 15 with val_loss: 0.000082
2025-11-05 08:51:02,314 - INFO - New best model found at epoch 16 with val_loss: 0.000075
2025-11-05 08:51:05,012 - INFO - New best model found at epoch 18 with val_loss: 0.000036
2025-11-05 08:51:21,197 - INFO - New best model found at epoch 30 with val_loss: 0.000032
2025-11-05 08:51:22,546 - INFO - New best model found at epoch 31 with val_loss: 0.000029
2025-11-05 08:51:23,899 - INFO - New best model found at epoch 32 with val_loss: 0.000018
2025-11-05 08:51:48,199 - INFO - Epoch [50/1000], Train Loss: 0.000029, Val Loss: 0.000014, LR: 0.003364
2025-11-05 08:51:48,200 - INFO - New best model found at epoch 50 with val_loss: 0.000014
2025-11-05 08:51:50,904 - INFO - New best model found at epoch 52 with val_loss: 0.000014
2025-11-05 08:52:00,356 - INFO - New best model found at epoch 59 with val_loss: 0.000012
2025-11-05 08:52:17,897 - INFO - New best model found at epoch 72 with val_loss: 0.000010
2025-11-05 08:52:31,406 - INFO - New best model found at epoch 82 with val_loss: 0.000009
2025-11-05 08:52:38,154 - INFO - New best model found at epoch 87 with val_loss: 0.000008
2025-11-05 08:52:43,561 - INFO - New best model found at epoch 91 with val_loss: 0.000008
2025-11-05 08:52:47,615 - INFO - New best model found at epoch 94 with val_loss: 0.000006
2025-11-05 08:52:55,713 - INFO - Epoch [100/1000], Train Loss: 0.000018, Val Loss: 0.000008, LR: 0.003302
2025-11-05 08:53:21,347 - INFO - Early stopping at epoch 119.
2025-11-05 08:53:21,347 - INFO - Training complete. Evaluating on test set...
2025-11-05 08:53:21,626 - INFO - Final Test Loss (SmoothL1): 0.000006
2025-11-05 08:53:21,626 - INFO - Inverting transforms and generating plots...
2025-11-05 08:53:21,627 - INFO - Calculating final metrics...
2025-11-05 08:53:21,632 - INFO - Final Test MAE: 0.404121
2025-11-05 08:53:21,632 - INFO - Final Test RMSE: 0.726822
2025-11-05 08:53:21,632 - INFO - Final Test R2: 0.999650
2025-11-05 08:53:21,632 - INFO - Final Test MEDAE: 0.210930
2025-11-05 08:53:21,632 - INFO - Final Test MAPE: 0.012711
2025-11-05 08:53:21,632 - INFO - Final Test REL_ERR_STD: 0.027236
2025-11-05 08:53:21,632 - INFO - Final Test REL_ERR_MEAN_ABS: 0.012711
2025-11-05 08:53:22,263 - INFO - Logging plots to tensorboard...
2025-11-05 08:53:22,412 - INFO - Main training function finished.
2025-11-05 08:53:22,418 - INFO - Final model saved to runs/run_20251104-144116_['Iso_width']/final_model/best_model.pt
2025-11-05 08:53:22,418 - INFO - --- Run complete ---
2025-11-05 08:53:22,418 - INFO - To view Optuna results: optuna-dashboard sqlite:///runs/optuna_study.db
2025-11-05 08:53:22,418 - INFO - To view TensorBoard logs: tensorboard --logdir runs/run_20251104-144116_['Iso_width']/
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [64, 1]                   --
ModuleList: 1-5                        --                        (recursive)
    Linear: 2-1                       [64, 112]                 1,120
    GELU: 2-2                         [64, 112]                 --
Dropout: 1-2                           [64, 112]                 --
ModuleList: 1-5                        --                        (recursive)
    Linear: 2-3                       [64, 112]                 12,656
    GELU: 2-4                         [64, 112]                 --
Dropout: 1-4                           [64, 112]                 --
ModuleList: 1-5                        --                        (recursive)
    Linear: 2-5                       [64, 1]                   113
==========================================================================================
Total params: 13,889
Trainable params: 13,889
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 0.89
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.12
Params size (MB): 0.06
Estimated Total Size (MB): 0.17
==========================================================================================
Job finished.

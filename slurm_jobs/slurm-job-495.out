Job started on argon-gtx
Job ID: 495
Working directory: /home/barattts/lavoltabuona/BA
---
Starting Python script...
Running: python run_optuna.py --target Iso_width
2025-11-04 00:09:53,772 - INFO - Using device: cuda
2025-11-04 00:09:53,774 - INFO - Target labels for this run: ['Iso_width']
2025-11-04 00:09:53,775 - INFO - Loading data for Optuna study (Labels: ['Iso_width'])...
2025-11-04 00:09:53,945 - INFO - Starting Optuna study: nn_study_['Iso_width']...
[I 2025-11-04 00:09:54,600] A new study created in RDB with name: nn_study_['Iso_width']
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
2025-11-04 00:11:01,654 - INFO - Trial 0: Early stopping at epoch 29.
[I 2025-11-04 00:11:01,730] Trial 0 finished with value: 0.020114634262711213 and parameters: {'batch_size': 64, 'learning_rate': 0.0037621727550669454, 'nr_hidden_layers': 5, 'nr_neurons': 191, 'dropout_rate': 0.11374248648849222, 'weight_decay': 7.567391166895222e-06, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 0 with value: 0.020114634262711213.
2025-11-04 00:14:47,128 - INFO - Trial 1: Early stopping at epoch 142.
[I 2025-11-04 00:14:47,191] Trial 1 finished with value: 0.020159762315831713 and parameters: {'batch_size': 64, 'learning_rate': 0.0025416310447702083, 'nr_hidden_layers': 1, 'nr_neurons': 60, 'dropout_rate': 0.11479979677471774, 'weight_decay': 0.00456105591291658, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 0 with value: 0.020114634262711213.
2025-11-04 00:15:23,845 - INFO - Trial 2: Early stopping at epoch 31.
[I 2025-11-04 00:15:23,906] Trial 2 finished with value: 0.04788345130722091 and parameters: {'batch_size': 128, 'learning_rate': 0.0056957002000229745, 'nr_hidden_layers': 4, 'nr_neurons': 51, 'dropout_rate': 0.21193640627458105, 'weight_decay': 4.4981048025105616e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 0 with value: 0.020114634262711213.
2025-11-04 00:18:25,280 - INFO - Trial 3: Early stopping at epoch 322.
[I 2025-11-04 00:18:25,349] Trial 3 finished with value: 0.01733200639534235 and parameters: {'batch_size': 512, 'learning_rate': 0.0009311863193833471, 'nr_hidden_layers': 1, 'nr_neurons': 43, 'dropout_rate': 0.14345776424233958, 'weight_decay': 0.0018176028192564767, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 3 with value: 0.01733200639534235.
2025-11-04 00:20:50,749 - INFO - Trial 4: Early stopping at epoch 80.
[I 2025-11-04 00:20:50,814] Trial 4 finished with value: 0.05940705347069646 and parameters: {'batch_size': 64, 'learning_rate': 0.0005910757756656557, 'nr_hidden_layers': 3, 'nr_neurons': 31, 'dropout_rate': 0.35695445060517544, 'weight_decay': 0.00010176479426222242, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 3 with value: 0.01733200639534235.
2025-11-04 00:21:45,130 - INFO - Trial 5: Early stopping at epoch 79.
[I 2025-11-04 00:21:45,194] Trial 5 finished with value: 0.03662001926117372 and parameters: {'batch_size': 256, 'learning_rate': 0.003967023997780323, 'nr_hidden_layers': 1, 'nr_neurons': 50, 'dropout_rate': 0.34761025242100974, 'weight_decay': 0.005245884230293198, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 3 with value: 0.01733200639534235.
[I 2025-11-04 00:21:54,736] Trial 6 pruned. 
2025-11-04 00:22:52,662 - INFO - Trial 7: Early stopping at epoch 49.
[I 2025-11-04 00:22:52,727] Trial 7 finished with value: 0.02703549451489613 and parameters: {'batch_size': 128, 'learning_rate': 0.0004004662227765888, 'nr_hidden_layers': 4, 'nr_neurons': 152, 'dropout_rate': 0.12171441889827417, 'weight_decay': 0.0013218588111676755, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 3 with value: 0.01733200639534235.
[I 2025-11-04 00:22:59,547] Trial 8 pruned. 
[I 2025-11-04 00:23:05,488] Trial 9 pruned. 
[I 2025-11-04 00:23:11,981] Trial 10 pruned. 
[I 2025-11-04 00:23:19,119] Trial 11 pruned. 
[I 2025-11-04 00:23:26,364] Trial 12 pruned. 
2025-11-04 00:28:23,570 - INFO - Trial 13: Early stopping at epoch 179.
[I 2025-11-04 00:28:23,637] Trial 13 finished with value: 0.010189172793358712 and parameters: {'batch_size': 64, 'learning_rate': 0.0008031328328169919, 'nr_hidden_layers': 2, 'nr_neurons': 86, 'dropout_rate': 0.2194249332639078, 'weight_decay': 1.4291563611093635e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 13 with value: 0.010189172793358712.
[I 2025-11-04 00:28:29,242] Trial 14 pruned. 
[I 2025-11-04 00:28:35,989] Trial 15 pruned. 
[I 2025-11-04 00:28:54,276] Trial 16 pruned. 
[I 2025-11-04 00:29:00,656] Trial 17 pruned. 
[I 2025-11-04 00:29:08,925] Trial 18 pruned. 
[I 2025-11-04 00:29:52,373] Trial 19 pruned. 
[I 2025-11-04 00:29:59,052] Trial 20 pruned. 
2025-11-04 00:31:27,802 - INFO - Trial 21: Early stopping at epoch 41.
[I 2025-11-04 00:31:27,865] Trial 21 finished with value: 0.020649791033279 and parameters: {'batch_size': 64, 'learning_rate': 0.0032945215262031994, 'nr_hidden_layers': 5, 'nr_neurons': 195, 'dropout_rate': 0.11577019052825292, 'weight_decay': 6.276570729934244e-06, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 13 with value: 0.010189172793358712.
2025-11-04 00:32:54,362 - INFO - Trial 22: Early stopping at epoch 51.
[I 2025-11-04 00:32:54,425] Trial 22 finished with value: 0.018695150618663305 and parameters: {'batch_size': 64, 'learning_rate': 0.001131385908732899, 'nr_hidden_layers': 2, 'nr_neurons': 189, 'dropout_rate': 0.17132442575403992, 'weight_decay': 3.0633864197630074e-06, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 13 with value: 0.010189172793358712.
2025-11-04 00:35:24,733 - INFO - Trial 23: Early stopping at epoch 92.
[I 2025-11-04 00:35:24,809] Trial 23 finished with value: 0.011625637740829893 and parameters: {'batch_size': 64, 'learning_rate': 0.0011903498110175659, 'nr_hidden_layers': 2, 'nr_neurons': 109, 'dropout_rate': 0.21289004945107848, 'weight_decay': 1.918293200247294e-06, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 13 with value: 0.010189172793358712.
[I 2025-11-04 00:35:42,686] Trial 24 pruned. 
[I 2025-11-04 00:35:48,351] Trial 25 pruned. 
[I 2025-11-04 00:35:56,788] Trial 26 pruned. 
[I 2025-11-04 00:36:07,753] Trial 27 pruned. 
[I 2025-11-04 00:36:14,041] Trial 28 pruned. 
2025-11-04 00:40:08,135 - INFO - Trial 29: Early stopping at epoch 125.
[I 2025-11-04 00:40:08,200] Trial 29 finished with value: 0.014084361864118065 and parameters: {'batch_size': 64, 'learning_rate': 0.002314529506354613, 'nr_hidden_layers': 3, 'nr_neurons': 107, 'dropout_rate': 0.31804815291220007, 'weight_decay': 8.911752240993759e-06, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 13 with value: 0.010189172793358712.
[I 2025-11-04 00:40:33,143] Trial 30 pruned. 
[I 2025-11-04 00:43:13,669] Trial 31 pruned. 
2025-11-04 00:45:38,061 - INFO - Trial 32: Early stopping at epoch 87.
[I 2025-11-04 00:45:38,127] Trial 32 finished with value: 0.010586175997271508 and parameters: {'batch_size': 64, 'learning_rate': 0.0018591328931432203, 'nr_hidden_layers': 2, 'nr_neurons': 166, 'dropout_rate': 0.2225338714711777, 'weight_decay': 1.3835307698233377e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 13 with value: 0.010189172793358712.
2025-11-04 00:47:54,773 - INFO - Trial 33: Early stopping at epoch 65.
[I 2025-11-04 00:47:54,837] Trial 33 finished with value: 0.01416315312160188 and parameters: {'batch_size': 64, 'learning_rate': 0.002346296081267659, 'nr_hidden_layers': 4, 'nr_neurons': 171, 'dropout_rate': 0.23709459626864504, 'weight_decay': 1.6660629147614645e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 13 with value: 0.010189172793358712.
[I 2025-11-04 00:48:15,133] Trial 34 pruned. 
2025-11-04 00:52:20,588 - INFO - Trial 35: Early stopping at epoch 136.
[I 2025-11-04 00:52:20,654] Trial 35 finished with value: 0.011909132346801694 and parameters: {'batch_size': 64, 'learning_rate': 0.0018158764613968323, 'nr_hidden_layers': 3, 'nr_neurons': 122, 'dropout_rate': 0.2731659715626291, 'weight_decay': 1.8005587293203782e-06, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 13 with value: 0.010189172793358712.
2025-11-04 00:53:53,918 - INFO - Trial 36: Early stopping at epoch 55.
[I 2025-11-04 00:53:53,983] Trial 36 finished with value: 0.013215794467111486 and parameters: {'batch_size': 64, 'learning_rate': 0.0017210861625692494, 'nr_hidden_layers': 2, 'nr_neurons': 125, 'dropout_rate': 0.26938826391327086, 'weight_decay': 1.648835286261924e-06, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 13 with value: 0.010189172793358712.
[I 2025-11-04 00:54:15,689] Trial 37 pruned. 
[I 2025-11-04 00:54:51,437] Trial 38 pruned. 
[I 2025-11-04 00:55:04,240] Trial 39 pruned. 
[I 2025-11-04 00:55:12,786] Trial 40 pruned. 
2025-11-04 00:58:23,710 - INFO - Trial 41: Early stopping at epoch 118.
[I 2025-11-04 00:58:23,784] Trial 41 finished with value: 0.011644370120434773 and parameters: {'batch_size': 64, 'learning_rate': 0.002058965654097014, 'nr_hidden_layers': 2, 'nr_neurons': 122, 'dropout_rate': 0.2526428277645423, 'weight_decay': 1.6841315855634703e-06, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 13 with value: 0.010189172793358712.
2025-11-04 01:01:44,332 - INFO - Trial 42: Early stopping at epoch 123.
[I 2025-11-04 01:01:44,399] Trial 42 finished with value: 0.0108337412417774 and parameters: {'batch_size': 64, 'learning_rate': 0.0018936613414308936, 'nr_hidden_layers': 2, 'nr_neurons': 125, 'dropout_rate': 0.2446680262595851, 'weight_decay': 6.62133938791575e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 13 with value: 0.010189172793358712.
2025-11-04 01:03:15,879 - INFO - Trial 43: Early stopping at epoch 56.
[I 2025-11-04 01:03:15,945] Trial 43 finished with value: 0.015311018248069788 and parameters: {'batch_size': 64, 'learning_rate': 0.0030657046709894856, 'nr_hidden_layers': 2, 'nr_neurons': 78, 'dropout_rate': 0.2459170824583302, 'weight_decay': 6.580241580778141e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 13 with value: 0.010189172793358712.
[I 2025-11-04 01:03:33,797] Trial 44 pruned. 
2025-11-04 01:07:27,955 - INFO - Trial 45: Early stopping at epoch 137.
[I 2025-11-04 01:07:28,022] Trial 45 finished with value: 0.009494535505051681 and parameters: {'batch_size': 64, 'learning_rate': 0.00181168563899337, 'nr_hidden_layers': 2, 'nr_neurons': 202, 'dropout_rate': 0.24812039532449925, 'weight_decay': 0.00032290026191630775, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 45 with value: 0.009494535505051681.
[I 2025-11-04 01:07:33,513] Trial 46 pruned. 
[I 2025-11-04 01:07:40,275] Trial 47 pruned. 
[I 2025-11-04 01:07:56,840] Trial 48 pruned. 
2025-11-04 01:08:45,446 - INFO - Trial 49: Early stopping at epoch 46.
[I 2025-11-04 01:08:45,511] Trial 49 finished with value: 0.01104500551776009 and parameters: {'batch_size': 128, 'learning_rate': 0.0027926278313790995, 'nr_hidden_layers': 2, 'nr_neurons': 245, 'dropout_rate': 0.08374698348413909, 'weight_decay': 0.00011762451223474695, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 45 with value: 0.009494535505051681.
2025-11-04 01:09:44,128 - INFO - Trial 50: Early stopping at epoch 56.
[I 2025-11-04 01:09:44,193] Trial 50 finished with value: 0.012021700536975363 and parameters: {'batch_size': 128, 'learning_rate': 0.002595282618037811, 'nr_hidden_layers': 2, 'nr_neurons': 252, 'dropout_rate': 0.09130896482778993, 'weight_decay': 0.00012115039858072712, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 45 with value: 0.009494535505051681.
[I 2025-11-04 01:09:55,300] Trial 51 pruned. 
[I 2025-11-04 01:10:24,019] Trial 52 pruned. 
[I 2025-11-04 01:10:38,440] Trial 53 pruned. 
[I 2025-11-04 01:10:48,925] Trial 54 pruned. 
2025-11-04 01:13:24,678 - INFO - Trial 55: Early stopping at epoch 103.
[I 2025-11-04 01:13:24,771] Trial 55 finished with value: 0.00652036357143139 and parameters: {'batch_size': 64, 'learning_rate': 0.002859715321601918, 'nr_hidden_layers': 1, 'nr_neurons': 189, 'dropout_rate': 0.03337497599536432, 'weight_decay': 0.0001542610644846871, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 55 with value: 0.00652036357143139.
2025-11-04 01:16:38,060 - INFO - Trial 56: Early stopping at epoch 130.
[I 2025-11-04 01:16:38,126] Trial 56 finished with value: 0.00795240232443456 and parameters: {'batch_size': 64, 'learning_rate': 0.007493683138169599, 'nr_hidden_layers': 1, 'nr_neurons': 201, 'dropout_rate': 0.012405591537879502, 'weight_decay': 0.00018093835574780134, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 55 with value: 0.00652036357143139.
2025-11-04 01:22:15,059 - INFO - Trial 57: Early stopping at epoch 226.
[I 2025-11-04 01:22:15,138] Trial 57 finished with value: 0.004833357860985194 and parameters: {'batch_size': 64, 'learning_rate': 0.009735684813299521, 'nr_hidden_layers': 1, 'nr_neurons': 182, 'dropout_rate': 0.016467455923118737, 'weight_decay': 0.000184826610144164, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 57 with value: 0.004833357860985194.
2025-11-04 01:23:50,926 - INFO - Trial 58: Early stopping at epoch 64.
[I 2025-11-04 01:23:50,995] Trial 58 finished with value: 0.008212815975690232 and parameters: {'batch_size': 64, 'learning_rate': 0.008720998379770402, 'nr_hidden_layers': 1, 'nr_neurons': 196, 'dropout_rate': 0.017093524137688228, 'weight_decay': 0.0013687197446424523, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 57 with value: 0.004833357860985194.
2025-11-04 01:25:18,232 - INFO - Trial 59: Early stopping at epoch 58.
[I 2025-11-04 01:25:18,297] Trial 59 finished with value: 0.012069400730540959 and parameters: {'batch_size': 64, 'learning_rate': 0.009442051484132297, 'nr_hidden_layers': 1, 'nr_neurons': 187, 'dropout_rate': 0.010788077145125433, 'weight_decay': 0.0016228021341354326, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 57 with value: 0.004833357860985194.
[I 2025-11-04 01:25:25,063] Trial 60 pruned. 
2025-11-04 01:28:11,869 - INFO - Trial 61: Early stopping at epoch 112.
[I 2025-11-04 01:28:11,936] Trial 61 finished with value: 0.006790305253974651 and parameters: {'batch_size': 64, 'learning_rate': 0.007665273664908052, 'nr_hidden_layers': 1, 'nr_neurons': 199, 'dropout_rate': 0.031964346618772, 'weight_decay': 0.00018403337356297271, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 57 with value: 0.004833357860985194.
2025-11-04 01:30:24,418 - INFO - Trial 62: Early stopping at epoch 90.
[I 2025-11-04 01:30:24,485] Trial 62 finished with value: 0.008127984872147343 and parameters: {'batch_size': 64, 'learning_rate': 0.00802452269125374, 'nr_hidden_layers': 1, 'nr_neurons': 208, 'dropout_rate': 0.03927233130007354, 'weight_decay': 0.00022850984100953483, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 57 with value: 0.004833357860985194.
2025-11-04 01:33:14,693 - INFO - Trial 63: Early stopping at epoch 116.
[I 2025-11-04 01:33:14,761] Trial 63 finished with value: 0.007746622213655569 and parameters: {'batch_size': 64, 'learning_rate': 0.007353561810998067, 'nr_hidden_layers': 1, 'nr_neurons': 197, 'dropout_rate': 0.033950489500605224, 'weight_decay': 0.00019669236289341304, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 57 with value: 0.004833357860985194.
2025-11-04 01:36:42,694 - INFO - Trial 64: Early stopping at epoch 140.
[I 2025-11-04 01:36:42,764] Trial 64 finished with value: 0.006230502547984098 and parameters: {'batch_size': 64, 'learning_rate': 0.007430876197782131, 'nr_hidden_layers': 1, 'nr_neurons': 184, 'dropout_rate': 0.024470955280768484, 'weight_decay': 0.0001832865620641494, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 57 with value: 0.004833357860985194.
2025-11-04 01:38:58,419 - INFO - Trial 65: Early stopping at epoch 88.
[I 2025-11-04 01:38:58,495] Trial 65 finished with value: 0.0043388827686869315 and parameters: {'batch_size': 64, 'learning_rate': 0.007267945562967462, 'nr_hidden_layers': 1, 'nr_neurons': 226, 'dropout_rate': 0.0008295915731585859, 'weight_decay': 0.00017545831807666256, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 65 with value: 0.0043388827686869315.
2025-11-04 01:41:50,251 - INFO - Trial 66: Early stopping at epoch 117.
[I 2025-11-04 01:41:50,348] Trial 66 finished with value: 0.008649898600247763 and parameters: {'batch_size': 64, 'learning_rate': 0.007143001505168876, 'nr_hidden_layers': 1, 'nr_neurons': 224, 'dropout_rate': 0.05345663477391968, 'weight_decay': 0.00014414394032617067, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 65 with value: 0.0043388827686869315.
[I 2025-11-04 01:41:56,059] Trial 67 pruned. 
[I 2025-11-04 01:43:11,861] Trial 68 pruned. 
[I 2025-11-04 01:43:29,101] Trial 69 pruned. 
2025-11-04 01:46:09,503 - INFO - Trial 70: Early stopping at epoch 106.
[I 2025-11-04 01:46:09,570] Trial 70 finished with value: 0.008222648312384746 and parameters: {'batch_size': 64, 'learning_rate': 0.005204510622850811, 'nr_hidden_layers': 1, 'nr_neurons': 254, 'dropout_rate': 0.057486004954479836, 'weight_decay': 0.0005259999182675654, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 65 with value: 0.0043388827686869315.
2025-11-04 01:47:59,593 - INFO - Trial 71: Early stopping at epoch 69.
[I 2025-11-04 01:47:59,659] Trial 71 finished with value: 0.009303435852598347 and parameters: {'batch_size': 64, 'learning_rate': 0.008255881589471298, 'nr_hidden_layers': 1, 'nr_neurons': 189, 'dropout_rate': 0.04369888321696672, 'weight_decay': 0.00024122349641665525, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 65 with value: 0.0043388827686869315.
2025-11-04 01:50:54,055 - INFO - Trial 72: Early stopping at epoch 111.
[I 2025-11-04 01:50:54,121] Trial 72 finished with value: 0.00630756674619171 and parameters: {'batch_size': 64, 'learning_rate': 0.003981155947324783, 'nr_hidden_layers': 1, 'nr_neurons': 154, 'dropout_rate': 0.01886558643828945, 'weight_decay': 0.00016898319990362948, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 65 with value: 0.0043388827686869315.
2025-11-04 01:55:26,725 - INFO - Trial 73: Early stopping at epoch 185.
[I 2025-11-04 01:55:26,793] Trial 73 finished with value: 0.0026357933807288677 and parameters: {'batch_size': 64, 'learning_rate': 0.003893126539356505, 'nr_hidden_layers': 1, 'nr_neurons': 175, 'dropout_rate': 0.00028770182669147007, 'weight_decay': 0.00016480702662140644, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
[I 2025-11-04 01:55:33,046] Trial 74 pruned. 
2025-11-04 01:57:57,228 - INFO - Trial 75: Early stopping at epoch 91.
[I 2025-11-04 01:57:57,296] Trial 75 finished with value: 0.00951098931967579 and parameters: {'batch_size': 64, 'learning_rate': 0.0044654492235339455, 'nr_hidden_layers': 1, 'nr_neurons': 174, 'dropout_rate': 0.07300917538918521, 'weight_decay': 0.00013601685302703075, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
2025-11-04 01:59:49,505 - INFO - Trial 76: Early stopping at epoch 76.
[I 2025-11-04 01:59:49,574] Trial 76 finished with value: 0.005284554039193988 and parameters: {'batch_size': 64, 'learning_rate': 0.0035267832177471896, 'nr_hidden_layers': 1, 'nr_neurons': 146, 'dropout_rate': 0.001503241146929308, 'weight_decay': 0.0001742872356879843, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
[I 2025-11-04 01:59:57,293] Trial 77 pruned. 
2025-11-04 02:02:03,300 - INFO - Trial 78: Early stopping at epoch 81.
[I 2025-11-04 02:02:03,369] Trial 78 finished with value: 0.009900345848229266 and parameters: {'batch_size': 64, 'learning_rate': 0.0034882736325294707, 'nr_hidden_layers': 1, 'nr_neurons': 153, 'dropout_rate': 0.09610842508010714, 'weight_decay': 0.00029482220511673114, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 73 with value: 0.0026357933807288677.
2025-11-04 02:04:15,773 - INFO - Trial 79: Early stopping at epoch 89.
[I 2025-11-04 02:04:15,842] Trial 79 finished with value: 0.00836176202227317 and parameters: {'batch_size': 64, 'learning_rate': 0.00567992291241505, 'nr_hidden_layers': 1, 'nr_neurons': 178, 'dropout_rate': 0.054311257210064814, 'weight_decay': 0.00015989766544245468, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
[I 2025-11-04 02:04:22,734] Trial 80 pruned. 
2025-11-04 02:07:26,370 - INFO - Trial 81: Early stopping at epoch 124.
[I 2025-11-04 02:07:26,440] Trial 81 finished with value: 0.0029385660042173657 and parameters: {'batch_size': 64, 'learning_rate': 0.006510456167356621, 'nr_hidden_layers': 1, 'nr_neurons': 167, 'dropout_rate': 0.0002400420590371391, 'weight_decay': 0.00020486457444461584, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
2025-11-04 02:10:24,918 - INFO - Trial 82: Early stopping at epoch 116.
[I 2025-11-04 02:10:25,006] Trial 82 finished with value: 0.002681314488762086 and parameters: {'batch_size': 64, 'learning_rate': 0.005491192675031949, 'nr_hidden_layers': 1, 'nr_neurons': 169, 'dropout_rate': 0.00010549549985361243, 'weight_decay': 4.656202308947114e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
2025-11-04 02:12:28,850 - INFO - Trial 83: Early stopping at epoch 84.
[I 2025-11-04 02:12:28,921] Trial 83 finished with value: 0.005257982305986624 and parameters: {'batch_size': 64, 'learning_rate': 0.0054600147959539234, 'nr_hidden_layers': 1, 'nr_neurons': 164, 'dropout_rate': 0.0019478462531539766, 'weight_decay': 5.353899807824751e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
2025-11-04 02:16:01,500 - INFO - Trial 84: Early stopping at epoch 145.
[I 2025-11-04 02:16:01,570] Trial 84 finished with value: 0.00343238144621441 and parameters: {'batch_size': 64, 'learning_rate': 0.005400180802503405, 'nr_hidden_layers': 1, 'nr_neurons': 132, 'dropout_rate': 0.0012693087221367038, 'weight_decay': 3.20510576739599e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
2025-11-04 02:18:59,392 - INFO - Trial 85: Early stopping at epoch 121.
[I 2025-11-04 02:18:59,462] Trial 85 finished with value: 0.0031840170597327985 and parameters: {'batch_size': 64, 'learning_rate': 0.005390885823070886, 'nr_hidden_layers': 1, 'nr_neurons': 130, 'dropout_rate': 0.00025661040756532263, 'weight_decay': 2.9113334721274278e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
[I 2025-11-04 02:19:05,348] Trial 86 pruned. 
2025-11-04 02:21:11,639 - INFO - Trial 87: Early stopping at epoch 84.
[I 2025-11-04 02:21:11,710] Trial 87 finished with value: 0.005190067365525441 and parameters: {'batch_size': 64, 'learning_rate': 0.006393014970530788, 'nr_hidden_layers': 1, 'nr_neurons': 116, 'dropout_rate': 0.0004568663144758825, 'weight_decay': 4.654914430340526e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
[I 2025-11-04 02:21:17,995] Trial 88 pruned. 
[I 2025-11-04 02:21:34,611] Trial 89 pruned. 
[I 2025-11-04 02:23:26,751] Trial 90 pruned. 
2025-11-04 02:26:15,860 - INFO - Trial 91: Early stopping at epoch 110.
[I 2025-11-04 02:26:15,930] Trial 91 finished with value: 0.005735644394501418 and parameters: {'batch_size': 64, 'learning_rate': 0.005299826735177966, 'nr_hidden_layers': 1, 'nr_neurons': 117, 'dropout_rate': 0.008915967384619077, 'weight_decay': 2.8553432976626502e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
2025-11-04 02:27:46,254 - INFO - Trial 92: Early stopping at epoch 61.
[I 2025-11-04 02:27:46,326] Trial 92 finished with value: 0.006942697671553628 and parameters: {'batch_size': 64, 'learning_rate': 0.00633202161585539, 'nr_hidden_layers': 1, 'nr_neurons': 137, 'dropout_rate': 0.0038704368250773733, 'weight_decay': 5.4557944710145994e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
2025-11-04 02:34:55,043 - INFO - Trial 93: Early stopping at epoch 282.
[I 2025-11-04 02:34:55,115] Trial 93 finished with value: 0.0035344815769166116 and parameters: {'batch_size': 64, 'learning_rate': 0.00423800789613858, 'nr_hidden_layers': 1, 'nr_neurons': 16, 'dropout_rate': 0.00022760033354911227, 'weight_decay': 4.0781757928271e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
[I 2025-11-04 02:35:11,216] Trial 94 pruned. 
[I 2025-11-04 02:35:27,400] Trial 95 pruned. 
[I 2025-11-04 02:35:50,665] Trial 96 pruned. 
2025-11-04 02:38:04,358 - INFO - Trial 97: Early stopping at epoch 87.
[I 2025-11-04 02:38:04,430] Trial 97 finished with value: 0.00879998406031715 and parameters: {'batch_size': 64, 'learning_rate': 0.004144078958869966, 'nr_hidden_layers': 1, 'nr_neurons': 79, 'dropout_rate': 0.04629930170790629, 'weight_decay': 1.1784885121889708e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
[I 2025-11-04 02:38:12,198] Trial 98 pruned. 
2025-11-04 02:39:50,991 - INFO - Trial 99: Early stopping at epoch 67.
[I 2025-11-04 02:39:51,060] Trial 99 finished with value: 0.008165042490554096 and parameters: {'batch_size': 64, 'learning_rate': 0.008830167324857467, 'nr_hidden_layers': 1, 'nr_neurons': 40, 'dropout_rate': 0.013107464528205, 'weight_decay': 8.032652771447366e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
[I 2025-11-04 02:40:08,385] Trial 100 pruned. 
2025-11-04 02:42:46,854 - INFO - Trial 101: Early stopping at epoch 103.
[I 2025-11-04 02:42:46,924] Trial 101 finished with value: 0.003526586785945749 and parameters: {'batch_size': 64, 'learning_rate': 0.0098853839126759, 'nr_hidden_layers': 1, 'nr_neurons': 145, 'dropout_rate': 0.0004334657449039251, 'weight_decay': 4.3793346258404326e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
2025-11-04 02:43:37,262 - INFO - Trial 102: Early stopping at epoch 32.
[I 2025-11-04 02:43:37,331] Trial 102 finished with value: 0.011368144113272294 and parameters: {'batch_size': 64, 'learning_rate': 0.009964735829290052, 'nr_hidden_layers': 1, 'nr_neurons': 169, 'dropout_rate': 0.013147281673724094, 'weight_decay': 4.2988183928474735e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
2025-11-04 02:46:42,243 - INFO - Trial 103: Early stopping at epoch 126.
[I 2025-11-04 02:46:42,315] Trial 103 finished with value: 0.0066020298932031925 and parameters: {'batch_size': 64, 'learning_rate': 0.008224351555587359, 'nr_hidden_layers': 1, 'nr_neurons': 161, 'dropout_rate': 0.03129453584315997, 'weight_decay': 2.3681524722805997e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
[I 2025-11-04 02:46:58,517] Trial 104 pruned. 
2025-11-04 02:48:27,417 - INFO - Trial 105: Early stopping at epoch 58.
[I 2025-11-04 02:48:27,487] Trial 105 finished with value: 0.008284708812097183 and parameters: {'batch_size': 64, 'learning_rate': 0.006154005079410211, 'nr_hidden_layers': 1, 'nr_neurons': 173, 'dropout_rate': 0.04088893942192497, 'weight_decay': 6.171080765873857e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
[I 2025-11-04 02:52:14,299] Trial 106 pruned. 
2025-11-04 02:55:20,996 - INFO - Trial 107: Early stopping at epoch 125.
[I 2025-11-04 02:55:21,071] Trial 107 finished with value: 0.007041994179291708 and parameters: {'batch_size': 64, 'learning_rate': 0.008648033909322403, 'nr_hidden_layers': 1, 'nr_neurons': 115, 'dropout_rate': 0.011452274462422925, 'weight_decay': 4.246226298330194e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
[I 2025-11-04 02:55:27,876] Trial 108 pruned. 
2025-11-04 02:57:39,371 - INFO - Trial 109: Early stopping at epoch 87.
[I 2025-11-04 02:57:39,442] Trial 109 finished with value: 0.00564560374503591 and parameters: {'batch_size': 64, 'learning_rate': 0.00488869120417828, 'nr_hidden_layers': 1, 'nr_neurons': 143, 'dropout_rate': 0.009056461610628059, 'weight_decay': 2.5193197958588616e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
[I 2025-11-04 02:57:44,939] Trial 110 pruned. 
2025-11-04 03:01:18,154 - INFO - Trial 111: Early stopping at epoch 142.
[I 2025-11-04 03:01:18,229] Trial 111 finished with value: 0.0028898766229392423 and parameters: {'batch_size': 64, 'learning_rate': 0.0036221395883638684, 'nr_hidden_layers': 1, 'nr_neurons': 159, 'dropout_rate': 2.6950031684878277e-05, 'weight_decay': 6.865598635825137e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
2025-11-04 03:05:16,897 - INFO - Trial 112: Early stopping at epoch 160.
[I 2025-11-04 03:05:16,968] Trial 112 finished with value: 0.0032031471417769556 and parameters: {'batch_size': 64, 'learning_rate': 0.004330796726501679, 'nr_hidden_layers': 1, 'nr_neurons': 159, 'dropout_rate': 0.001057980447960279, 'weight_decay': 7.306017603705252e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
2025-11-04 03:08:23,126 - INFO - Trial 113: Early stopping at epoch 125.
[I 2025-11-04 03:08:23,197] Trial 113 finished with value: 0.006527775233130996 and parameters: {'batch_size': 64, 'learning_rate': 0.0031836890749065484, 'nr_hidden_layers': 1, 'nr_neurons': 138, 'dropout_rate': 0.03560559597755683, 'weight_decay': 6.098565585392641e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
2025-11-04 03:10:22,444 - INFO - Trial 114: Early stopping at epoch 80.
[I 2025-11-04 03:10:22,515] Trial 114 finished with value: 0.007002798491036851 and parameters: {'batch_size': 64, 'learning_rate': 0.0036482353387916385, 'nr_hidden_layers': 1, 'nr_neurons': 123, 'dropout_rate': 0.020611300199602525, 'weight_decay': 0.0001273852330096908, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
[I 2025-11-04 03:10:28,811] Trial 115 pruned. 
2025-11-04 03:13:22,439 - INFO - Trial 116: Early stopping at epoch 102.
[I 2025-11-04 03:13:22,513] Trial 116 finished with value: 0.00412420248441362 and parameters: {'batch_size': 64, 'learning_rate': 0.0029027416074064124, 'nr_hidden_layers': 1, 'nr_neurons': 158, 'dropout_rate': 0.0006130226272702847, 'weight_decay': 3.361459974921659e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
[I 2025-11-04 03:13:44,181] Trial 117 pruned. 
[I 2025-11-04 03:14:00,317] Trial 118 pruned. 
2025-11-04 03:16:31,435 - INFO - Trial 119: Early stopping at epoch 101.
[I 2025-11-04 03:16:31,507] Trial 119 finished with value: 0.007692364939273213 and parameters: {'batch_size': 64, 'learning_rate': 0.004055927971894788, 'nr_hidden_layers': 1, 'nr_neurons': 210, 'dropout_rate': 0.041071329041570806, 'weight_decay': 9.897814194893203e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
2025-11-04 03:18:25,941 - INFO - Trial 120: Early stopping at epoch 76.
[I 2025-11-04 03:18:26,012] Trial 120 finished with value: 0.006800392564809931 and parameters: {'batch_size': 64, 'learning_rate': 0.0046964517312391525, 'nr_hidden_layers': 1, 'nr_neurons': 187, 'dropout_rate': 0.019804671035496706, 'weight_decay': 7.133516934782117e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 73 with value: 0.0026357933807288677.
2025-11-04 03:22:34,846 - INFO - Trial 121: Early stopping at epoch 169.
[I 2025-11-04 03:22:34,920] Trial 121 finished with value: 0.002558183847361341 and parameters: {'batch_size': 64, 'learning_rate': 0.0033088131611360106, 'nr_hidden_layers': 1, 'nr_neurons': 147, 'dropout_rate': 0.0004945402057110683, 'weight_decay': 4.9676509884029045e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 121 with value: 0.002558183847361341.
2025-11-04 03:24:42,833 - INFO - Trial 122: Early stopping at epoch 86.
[I 2025-11-04 03:24:42,906] Trial 122 finished with value: 0.0055923387103271405 and parameters: {'batch_size': 64, 'learning_rate': 0.003420019248587052, 'nr_hidden_layers': 1, 'nr_neurons': 163, 'dropout_rate': 0.008314772140961508, 'weight_decay': 3.22116887523612e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 121 with value: 0.002558183847361341.
2025-11-04 03:28:29,598 - INFO - Trial 123: Early stopping at epoch 147.
[I 2025-11-04 03:28:29,671] Trial 123 finished with value: 0.0034914845089748636 and parameters: {'batch_size': 64, 'learning_rate': 0.003934810571499384, 'nr_hidden_layers': 1, 'nr_neurons': 144, 'dropout_rate': 0.0011798010107835787, 'weight_decay': 0.00025152022576044233, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 121 with value: 0.002558183847361341.
2025-11-04 03:31:52,931 - INFO - Trial 124: Early stopping at epoch 138.
[I 2025-11-04 03:31:53,001] Trial 124 finished with value: 0.003470993545084438 and parameters: {'batch_size': 64, 'learning_rate': 0.0023233642401515194, 'nr_hidden_layers': 1, 'nr_neurons': 144, 'dropout_rate': 0.0006705350331982934, 'weight_decay': 0.00035996258155381565, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 121 with value: 0.002558183847361341.
2025-11-04 03:34:21,939 - INFO - Trial 125: Early stopping at epoch 96.
[I 2025-11-04 03:34:22,010] Trial 125 finished with value: 0.007630962449133245 and parameters: {'batch_size': 64, 'learning_rate': 0.0027954500567576057, 'nr_hidden_layers': 1, 'nr_neurons': 135, 'dropout_rate': 0.02615714923427188, 'weight_decay': 0.0032817712122010234, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 121 with value: 0.002558183847361341.
[I 2025-11-04 03:34:29,738] Trial 126 pruned. 
2025-11-04 03:35:43,917 - INFO - Trial 127: Early stopping at epoch 49.
[I 2025-11-04 03:35:43,988] Trial 127 finished with value: 0.008982958030785648 and parameters: {'batch_size': 64, 'learning_rate': 0.003740076467537465, 'nr_hidden_layers': 1, 'nr_neurons': 145, 'dropout_rate': 0.032697678977421374, 'weight_decay': 0.0003266286004441926, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 121 with value: 0.002558183847361341.
2025-11-04 03:37:36,592 - INFO - Trial 128: Early stopping at epoch 73.
[I 2025-11-04 03:37:36,669] Trial 128 finished with value: 0.0074303453392182495 and parameters: {'batch_size': 64, 'learning_rate': 0.0032656124752918035, 'nr_hidden_layers': 1, 'nr_neurons': 157, 'dropout_rate': 0.012355665996757885, 'weight_decay': 0.0005653526305421393, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 121 with value: 0.002558183847361341.
[I 2025-11-04 03:37:52,861] Trial 129 pruned. 
[I 2025-11-04 03:37:59,798] Trial 130 pruned. 
2025-11-04 03:43:03,596 - INFO - Trial 131: Early stopping at epoch 195.
[I 2025-11-04 03:43:03,671] Trial 131 finished with value: 0.0026941311253907982 and parameters: {'batch_size': 64, 'learning_rate': 0.0023378095870500034, 'nr_hidden_layers': 1, 'nr_neurons': 142, 'dropout_rate': 0.0006917186754564469, 'weight_decay': 4.872541467847261e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 121 with value: 0.002558183847361341.
2025-11-04 03:45:44,105 - INFO - Trial 132: Early stopping at epoch 107.
[I 2025-11-04 03:45:44,188] Trial 132 finished with value: 0.004403131772891411 and parameters: {'batch_size': 64, 'learning_rate': 0.0024220115614085164, 'nr_hidden_layers': 1, 'nr_neurons': 141, 'dropout_rate': 0.007757528867479073, 'weight_decay': 4.5066753344669495e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 121 with value: 0.002558183847361341.
2025-11-04 03:47:35,218 - INFO - Trial 133: Early stopping at epoch 69.
[I 2025-11-04 03:47:35,292] Trial 133 finished with value: 0.005370815700681642 and parameters: {'batch_size': 64, 'learning_rate': 0.0037128225538739673, 'nr_hidden_layers': 1, 'nr_neurons': 165, 'dropout_rate': 0.0012861662376662272, 'weight_decay': 5.942666010924446e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 121 with value: 0.002558183847361341.
2025-11-04 03:49:56,797 - INFO - Trial 134: Early stopping at epoch 96.
[I 2025-11-04 03:49:56,869] Trial 134 finished with value: 0.006235069876815121 and parameters: {'batch_size': 64, 'learning_rate': 0.0039587483436045266, 'nr_hidden_layers': 1, 'nr_neurons': 124, 'dropout_rate': 0.01959644662964829, 'weight_decay': 4.998921535676662e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 121 with value: 0.002558183847361341.
2025-11-04 03:52:44,432 - INFO - Trial 135: Early stopping at epoch 111.
[I 2025-11-04 03:52:44,503] Trial 135 finished with value: 0.006015745536607544 and parameters: {'batch_size': 64, 'learning_rate': 0.0026614573038233557, 'nr_hidden_layers': 1, 'nr_neurons': 170, 'dropout_rate': 0.039451969764863225, 'weight_decay': 3.6207455749506894e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 121 with value: 0.002558183847361341.
2025-11-04 03:54:21,793 - INFO - Trial 136: Early stopping at epoch 103.
[I 2025-11-04 03:54:21,865] Trial 136 finished with value: 0.004765369614735861 and parameters: {'batch_size': 128, 'learning_rate': 0.002301708925188263, 'nr_hidden_layers': 1, 'nr_neurons': 150, 'dropout_rate': 0.011094555242298017, 'weight_decay': 6.958545719765347e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 121 with value: 0.002558183847361341.
[I 2025-11-04 03:54:38,971] Trial 137 pruned. 
[I 2025-11-04 03:54:44,710] Trial 138 pruned. 
[I 2025-11-04 03:55:01,008] Trial 139 pruned. 
[I 2025-11-04 03:55:17,237] Trial 140 pruned. 
2025-11-04 04:02:09,002 - INFO - Trial 141: Early stopping at epoch 276.
[I 2025-11-04 04:02:09,078] Trial 141 finished with value: 0.001739473392331576 and parameters: {'batch_size': 64, 'learning_rate': 0.004463853265803938, 'nr_hidden_layers': 1, 'nr_neurons': 170, 'dropout_rate': 0.00028441343038313957, 'weight_decay': 0.0002826395136742748, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 04:04:09,507 - INFO - Trial 142: Early stopping at epoch 78.
[I 2025-11-04 04:04:09,580] Trial 142 finished with value: 0.006664361008800595 and parameters: {'batch_size': 64, 'learning_rate': 0.004149050309076421, 'nr_hidden_layers': 1, 'nr_neurons': 176, 'dropout_rate': 0.008668798526103574, 'weight_decay': 0.0002768668213495633, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 04:07:19,107 - INFO - Trial 143: Early stopping at epoch 126.
[I 2025-11-04 04:07:19,181] Trial 143 finished with value: 0.006007714331568784 and parameters: {'batch_size': 64, 'learning_rate': 0.004684330814978185, 'nr_hidden_layers': 1, 'nr_neurons': 150, 'dropout_rate': 0.021127671589443967, 'weight_decay': 0.0002110804222624788, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 04:09:50,696 - INFO - Trial 144: Early stopping at epoch 101.
[I 2025-11-04 04:09:50,778] Trial 144 finished with value: 0.0036710478555338484 and parameters: {'batch_size': 64, 'learning_rate': 0.00523585721885608, 'nr_hidden_layers': 1, 'nr_neurons': 160, 'dropout_rate': 5.167950794696431e-05, 'weight_decay': 0.00045955793611840814, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 04:11:21,224 - INFO - Trial 145: Early stopping at epoch 61.
[I 2025-11-04 04:11:21,296] Trial 145 finished with value: 0.009571633031908548 and parameters: {'batch_size': 64, 'learning_rate': 0.005051416828240394, 'nr_hidden_layers': 1, 'nr_neurons': 169, 'dropout_rate': 0.032515593380427796, 'weight_decay': 0.00047726576271173, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
[I 2025-11-04 04:11:27,571] Trial 146 pruned. 
2025-11-04 04:14:07,238 - INFO - Trial 147: Early stopping at epoch 107.
[I 2025-11-04 04:14:07,310] Trial 147 finished with value: 0.006157284469487231 and parameters: {'batch_size': 64, 'learning_rate': 0.005355399595690515, 'nr_hidden_layers': 1, 'nr_neurons': 186, 'dropout_rate': 0.013879592119873852, 'weight_decay': 0.00037191751304227716, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
[I 2025-11-04 04:15:05,367] Trial 148 pruned. 
[I 2025-11-04 04:15:21,541] Trial 149 pruned. 
[I 2025-11-04 04:15:38,124] Trial 150 pruned. 
2025-11-04 04:17:46,893 - INFO - Trial 151: Early stopping at epoch 85.
[I 2025-11-04 04:17:46,965] Trial 151 finished with value: 0.004955825820932952 and parameters: {'batch_size': 64, 'learning_rate': 0.0030906315911052393, 'nr_hidden_layers': 1, 'nr_neurons': 155, 'dropout_rate': 0.0014346552642294519, 'weight_decay': 3.975717444026886e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 04:20:37,291 - INFO - Trial 152: Early stopping at epoch 116.
[I 2025-11-04 04:20:37,366] Trial 152 finished with value: 0.0041969110089381525 and parameters: {'batch_size': 64, 'learning_rate': 0.0020386692372820992, 'nr_hidden_layers': 1, 'nr_neurons': 160, 'dropout_rate': 0.0006621816372957191, 'weight_decay': 0.00041705884156361935, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 04:24:04,802 - INFO - Trial 153: Early stopping at epoch 141.
[I 2025-11-04 04:24:04,877] Trial 153 finished with value: 0.005708989506319352 and parameters: {'batch_size': 64, 'learning_rate': 0.004443086115683911, 'nr_hidden_layers': 1, 'nr_neurons': 142, 'dropout_rate': 0.018284986501512526, 'weight_decay': 5.3498028386237786e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 04:26:07,066 - INFO - Trial 154: Early stopping at epoch 79.
[I 2025-11-04 04:26:07,140] Trial 154 finished with value: 0.00610826843700467 and parameters: {'batch_size': 64, 'learning_rate': 0.003371001663657207, 'nr_hidden_layers': 1, 'nr_neurons': 197, 'dropout_rate': 0.009889370585830651, 'weight_decay': 9.18120804949502e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 04:29:36,287 - INFO - Trial 155: Early stopping at epoch 139.
[I 2025-11-04 04:29:36,362] Trial 155 finished with value: 0.0028327729737802148 and parameters: {'batch_size': 64, 'learning_rate': 0.00396578052632732, 'nr_hidden_layers': 1, 'nr_neurons': 176, 'dropout_rate': 4.955178274187995e-05, 'weight_decay': 0.00024060167401902414, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 04:31:34,721 - INFO - Trial 156: Early stopping at epoch 79.
[I 2025-11-04 04:31:34,794] Trial 156 finished with value: 0.007852410932950079 and parameters: {'batch_size': 64, 'learning_rate': 0.004031824142255418, 'nr_hidden_layers': 1, 'nr_neurons': 175, 'dropout_rate': 0.02959962798828761, 'weight_decay': 0.0002560442934499014, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
[I 2025-11-04 04:31:42,555] Trial 157 pruned. 
[I 2025-11-04 04:33:48,527] Trial 158 pruned. 
2025-11-04 04:36:18,598 - INFO - Trial 159: Early stopping at epoch 94.
[I 2025-11-04 04:36:18,672] Trial 159 finished with value: 0.006062408840712136 and parameters: {'batch_size': 64, 'learning_rate': 0.005964677103932475, 'nr_hidden_layers': 1, 'nr_neurons': 148, 'dropout_rate': 0.011034495189451226, 'weight_decay': 0.0003372767798682707, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 04:37:59,351 - INFO - Trial 160: Early stopping at epoch 68.
[I 2025-11-04 04:37:59,424] Trial 160 finished with value: 0.008260922241368207 and parameters: {'batch_size': 64, 'learning_rate': 0.003626223602026497, 'nr_hidden_layers': 1, 'nr_neurons': 193, 'dropout_rate': 0.03434570004295715, 'weight_decay': 0.0004560078780201137, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 04:41:46,506 - INFO - Trial 161: Early stopping at epoch 136.
[I 2025-11-04 04:41:46,582] Trial 161 finished with value: 0.004769277105181795 and parameters: {'batch_size': 64, 'learning_rate': 0.0027433343033175218, 'nr_hidden_layers': 1, 'nr_neurons': 167, 'dropout_rate': 0.0056518209540285785, 'weight_decay': 2.8943919304953976e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 04:45:45,813 - INFO - Trial 162: Early stopping at epoch 161.
[I 2025-11-04 04:45:45,888] Trial 162 finished with value: 0.0024357207040882293 and parameters: {'batch_size': 64, 'learning_rate': 0.003964337422320415, 'nr_hidden_layers': 1, 'nr_neurons': 161, 'dropout_rate': 9.578214668305544e-05, 'weight_decay': 6.969988219057375e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 04:47:52,917 - INFO - Trial 163: Early stopping at epoch 86.
[I 2025-11-04 04:47:52,992] Trial 163 finished with value: 0.006591367210849137 and parameters: {'batch_size': 64, 'learning_rate': 0.004301486456850179, 'nr_hidden_layers': 1, 'nr_neurons': 164, 'dropout_rate': 0.01823412887902267, 'weight_decay': 6.925609871184821e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 04:50:17,444 - INFO - Trial 164: Early stopping at epoch 95.
[I 2025-11-04 04:50:17,518] Trial 164 finished with value: 0.00432003917944281 and parameters: {'batch_size': 64, 'learning_rate': 0.0038276116393626937, 'nr_hidden_layers': 1, 'nr_neurons': 175, 'dropout_rate': 0.0006505281953776377, 'weight_decay': 0.00011450684776093878, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 04:52:37,245 - INFO - Trial 165: Early stopping at epoch 90.
[I 2025-11-04 04:52:37,319] Trial 165 finished with value: 0.006010977669169652 and parameters: {'batch_size': 64, 'learning_rate': 0.0045274485263287305, 'nr_hidden_layers': 1, 'nr_neurons': 155, 'dropout_rate': 0.009617884858504086, 'weight_decay': 8.15746748792849e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 04:55:43,877 - INFO - Trial 166: Early stopping at epoch 126.
[I 2025-11-04 04:55:43,954] Trial 166 finished with value: 0.004889407956152983 and parameters: {'batch_size': 64, 'learning_rate': 0.004968532600289452, 'nr_hidden_layers': 1, 'nr_neurons': 145, 'dropout_rate': 0.0001595452739806279, 'weight_decay': 5.3342976919842695e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 04:57:49,823 - INFO - Trial 167: Early stopping at epoch 85.
[I 2025-11-04 04:57:49,897] Trial 167 finished with value: 0.007374453874178789 and parameters: {'batch_size': 64, 'learning_rate': 0.003418632664344338, 'nr_hidden_layers': 1, 'nr_neurons': 128, 'dropout_rate': 0.02607777745526062, 'weight_decay': 0.0001480151480168774, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
[I 2025-11-04 04:57:56,633] Trial 168 pruned. 
2025-11-04 05:00:57,529 - INFO - Trial 169: Early stopping at epoch 122.
[I 2025-11-04 05:00:57,608] Trial 169 finished with value: 0.0055419211734935685 and parameters: {'batch_size': 64, 'learning_rate': 0.004200361919409561, 'nr_hidden_layers': 1, 'nr_neurons': 169, 'dropout_rate': 0.010264677016595416, 'weight_decay': 4.309810969970804e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
[I 2025-11-04 05:01:07,883] Trial 170 pruned. 
2025-11-04 05:09:15,710 - INFO - Trial 171: Early stopping at epoch 312.
[I 2025-11-04 05:09:15,788] Trial 171 finished with value: 0.001790586958065211 and parameters: {'batch_size': 64, 'learning_rate': 0.0031099430540115235, 'nr_hidden_layers': 1, 'nr_neurons': 157, 'dropout_rate': 0.001230439846909611, 'weight_decay': 3.7484707143574385e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 05:11:34,927 - INFO - Trial 172: Early stopping at epoch 88.
[I 2025-11-04 05:11:35,002] Trial 172 finished with value: 0.006660442581674458 and parameters: {'batch_size': 64, 'learning_rate': 0.0031885817018910746, 'nr_hidden_layers': 1, 'nr_neurons': 151, 'dropout_rate': 0.009686683103386266, 'weight_decay': 3.8091640192194306e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 05:13:22,591 - INFO - Trial 173: Early stopping at epoch 70.
[I 2025-11-04 05:13:22,666] Trial 173 finished with value: 0.005837976041300877 and parameters: {'batch_size': 64, 'learning_rate': 0.003744847294201038, 'nr_hidden_layers': 1, 'nr_neurons': 160, 'dropout_rate': 0.0004839938529950016, 'weight_decay': 4.6554524634495144e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
[I 2025-11-04 05:13:47,984] Trial 174 pruned. 
[I 2025-11-04 05:14:11,763] Trial 175 pruned. 
[I 2025-11-04 05:14:17,649] Trial 176 pruned. 
[I 2025-11-04 05:17:53,604] Trial 177 pruned. 
2025-11-04 05:22:26,010 - INFO - Trial 178: Early stopping at epoch 176.
[I 2025-11-04 05:22:26,084] Trial 178 finished with value: 0.002956450830887542 and parameters: {'batch_size': 64, 'learning_rate': 0.004690030987229059, 'nr_hidden_layers': 1, 'nr_neurons': 173, 'dropout_rate': 0.0007530429465350177, 'weight_decay': 9.880746510124914e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
[I 2025-11-04 05:22:59,455] Trial 179 pruned. 
[I 2025-11-04 05:23:05,765] Trial 180 pruned. 
[I 2025-11-04 05:23:31,288] Trial 181 pruned. 
2025-11-04 05:25:58,577 - INFO - Trial 182: Early stopping at epoch 98.
[I 2025-11-04 05:25:58,651] Trial 182 finished with value: 0.004306110635463108 and parameters: {'batch_size': 64, 'learning_rate': 0.004756391992829283, 'nr_hidden_layers': 1, 'nr_neurons': 152, 'dropout_rate': 0.0017439865334550322, 'weight_decay': 3.628921451737604e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 05:28:51,244 - INFO - Trial 183: Early stopping at epoch 117.
[I 2025-11-04 05:28:51,320] Trial 183 finished with value: 0.0033557151349592005 and parameters: {'batch_size': 64, 'learning_rate': 0.005263025712463947, 'nr_hidden_layers': 1, 'nr_neurons': 167, 'dropout_rate': 5.7909294686770466e-05, 'weight_decay': 6.458198106129404e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
[I 2025-11-04 05:32:00,427] Trial 184 pruned. 
2025-11-04 05:35:06,189 - INFO - Trial 185: Early stopping at epoch 123.
[I 2025-11-04 05:35:06,266] Trial 185 finished with value: 0.0030904279371951537 and parameters: {'batch_size': 64, 'learning_rate': 0.003949738658063371, 'nr_hidden_layers': 1, 'nr_neurons': 136, 'dropout_rate': 0.0002788642568784692, 'weight_decay': 5.6760768838697966e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 05:37:04,235 - INFO - Trial 186: Early stopping at epoch 78.
[I 2025-11-04 05:37:04,310] Trial 186 finished with value: 0.008365191001465686 and parameters: {'batch_size': 64, 'learning_rate': 0.003981890735363302, 'nr_hidden_layers': 1, 'nr_neurons': 137, 'dropout_rate': 0.029348549713327517, 'weight_decay': 5.4855497225824095e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 05:40:27,081 - INFO - Trial 187: Early stopping at epoch 138.
[I 2025-11-04 05:40:27,157] Trial 187 finished with value: 0.0056689677522438605 and parameters: {'batch_size': 64, 'learning_rate': 0.004673314413215529, 'nr_hidden_layers': 1, 'nr_neurons': 123, 'dropout_rate': 0.013573142466019992, 'weight_decay': 8.594650547767379e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
[I 2025-11-04 05:43:36,744] Trial 188 pruned. 
2025-11-04 05:48:27,300 - INFO - Trial 189: Early stopping at epoch 190.
[I 2025-11-04 05:48:27,377] Trial 189 finished with value: 0.002554628273702739 and parameters: {'batch_size': 64, 'learning_rate': 0.003578055148202052, 'nr_hidden_layers': 1, 'nr_neurons': 145, 'dropout_rate': 0.00013988088967617246, 'weight_decay': 4.86522824210335e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 05:50:17,558 - INFO - Trial 190: Early stopping at epoch 71.
[I 2025-11-04 05:50:17,633] Trial 190 finished with value: 0.006225727643008421 and parameters: {'batch_size': 64, 'learning_rate': 0.003574983702423834, 'nr_hidden_layers': 1, 'nr_neurons': 150, 'dropout_rate': 0.0117841573863797, 'weight_decay': 0.00014454054416848425, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 05:52:31,846 - INFO - Trial 191: Early stopping at epoch 89.
[I 2025-11-04 05:52:31,920] Trial 191 finished with value: 0.0036872012842669257 and parameters: {'batch_size': 64, 'learning_rate': 0.0037688991899123407, 'nr_hidden_layers': 1, 'nr_neurons': 143, 'dropout_rate': 8.397317058747174e-05, 'weight_decay': 7.227123997579676e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 141 with value: 0.001739473392331576.
2025-11-04 05:59:34,449 - INFO - Trial 192: Early stopping at epoch 279.
[I 2025-11-04 05:59:34,526] Trial 192 finished with value: 0.0016149684023931267 and parameters: {'batch_size': 64, 'learning_rate': 0.002506927165033992, 'nr_hidden_layers': 1, 'nr_neurons': 164, 'dropout_rate': 0.0005106782352009127, 'weight_decay': 4.356867105041896e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 06:01:14,305 - INFO - Trial 193: Early stopping at epoch 65.
[I 2025-11-04 06:01:14,384] Trial 193 finished with value: 0.007025320935838269 and parameters: {'batch_size': 64, 'learning_rate': 0.0028195096782476876, 'nr_hidden_layers': 1, 'nr_neurons': 167, 'dropout_rate': 0.008599839884673326, 'weight_decay': 5.094695156143813e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 06:01:30,690] Trial 194 pruned. 
2025-11-04 06:04:48,457 - INFO - Trial 195: Early stopping at epoch 134.
[I 2025-11-04 06:04:48,532] Trial 195 finished with value: 0.004471704531633612 and parameters: {'batch_size': 64, 'learning_rate': 0.002096869124529131, 'nr_hidden_layers': 1, 'nr_neurons': 183, 'dropout_rate': 0.010680691043346503, 'weight_decay': 0.0001002461918299403, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 06:07:36,733 - INFO - Trial 196: Early stopping at epoch 110.
[I 2025-11-04 06:07:36,809] Trial 196 finished with value: 0.005825645375631982 and parameters: {'batch_size': 64, 'learning_rate': 0.0025672106507163, 'nr_hidden_layers': 1, 'nr_neurons': 160, 'dropout_rate': 0.01833043974688943, 'weight_decay': 5.092201288921155e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 06:07:44,588] Trial 197 pruned. 
2025-11-04 06:11:38,323 - INFO - Trial 198: Early stopping at epoch 155.
[I 2025-11-04 06:11:38,400] Trial 198 finished with value: 0.0039141491746781725 and parameters: {'batch_size': 64, 'learning_rate': 0.003033667666801651, 'nr_hidden_layers': 1, 'nr_neurons': 153, 'dropout_rate': 0.007972788333563808, 'weight_decay': 8.102065067712403e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 06:16:13,980 - INFO - Trial 199: Early stopping at epoch 184.
[I 2025-11-04 06:16:14,056] Trial 199 finished with value: 0.00220405049303428 and parameters: {'batch_size': 64, 'learning_rate': 0.0032976201177852002, 'nr_hidden_layers': 1, 'nr_neurons': 174, 'dropout_rate': 0.00026146105885918407, 'weight_decay': 4.3306259248608395e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 06:18:19,846 - INFO - Trial 200: Early stopping at epoch 83.
[I 2025-11-04 06:18:19,938] Trial 200 finished with value: 0.00725131106327572 and parameters: {'batch_size': 64, 'learning_rate': 0.003252702241732318, 'nr_hidden_layers': 1, 'nr_neurons': 171, 'dropout_rate': 0.017365818627555592, 'weight_decay': 4.512404245656683e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 06:22:43,559 - INFO - Trial 201: Early stopping at epoch 179.
[I 2025-11-04 06:22:43,636] Trial 201 finished with value: 0.002563813679105316 and parameters: {'batch_size': 64, 'learning_rate': 0.00350030379227603, 'nr_hidden_layers': 1, 'nr_neurons': 180, 'dropout_rate': 0.0002496889289774181, 'weight_decay': 4.038717102599223e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 06:25:30,808 - INFO - Trial 202: Early stopping at epoch 107.
[I 2025-11-04 06:25:30,885] Trial 202 finished with value: 0.004023922746944984 and parameters: {'batch_size': 64, 'learning_rate': 0.0034247632739390576, 'nr_hidden_layers': 1, 'nr_neurons': 180, 'dropout_rate': 0.001157083858376385, 'weight_decay': 3.0215239545408237e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 06:27:49,093 - INFO - Trial 203: Early stopping at epoch 92.
[I 2025-11-04 06:27:49,171] Trial 203 finished with value: 0.0055197008552160505 and parameters: {'batch_size': 64, 'learning_rate': 0.0027451179776994783, 'nr_hidden_layers': 1, 'nr_neurons': 165, 'dropout_rate': 0.010678350805715183, 'weight_decay': 3.7607609736773754e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 06:30:37,150 - INFO - Trial 204: Early stopping at epoch 112.
[I 2025-11-04 06:30:37,227] Trial 204 finished with value: 0.005259152518455117 and parameters: {'batch_size': 64, 'learning_rate': 0.005523052765939302, 'nr_hidden_layers': 1, 'nr_neurons': 187, 'dropout_rate': 0.0116747497784918, 'weight_decay': 4.301817335179619e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 06:30:53,472] Trial 205 pruned. 
2025-11-04 06:33:13,253 - INFO - Trial 206: Early stopping at epoch 92.
[I 2025-11-04 06:33:13,330] Trial 206 finished with value: 0.004378835684563869 and parameters: {'batch_size': 64, 'learning_rate': 0.004171397735666527, 'nr_hidden_layers': 1, 'nr_neurons': 206, 'dropout_rate': 0.000847681476175941, 'weight_decay': 5.852273961394403e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 06:34:34,812 - INFO - Trial 207: Early stopping at epoch 51.
[I 2025-11-04 06:34:34,887] Trial 207 finished with value: 0.008382966275295662 and parameters: {'batch_size': 64, 'learning_rate': 0.0030608658889525538, 'nr_hidden_layers': 1, 'nr_neurons': 159, 'dropout_rate': 0.023060242718646158, 'weight_decay': 4.884476777185266e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 06:37:10,286 - INFO - Trial 208: Early stopping at epoch 99.
[I 2025-11-04 06:37:10,360] Trial 208 finished with value: 0.006205174701108419 and parameters: {'batch_size': 64, 'learning_rate': 0.00448082688931042, 'nr_hidden_layers': 1, 'nr_neurons': 154, 'dropout_rate': 0.008800970501877696, 'weight_decay': 3.670006064068808e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 06:37:17,030] Trial 209 pruned. 
2025-11-04 06:40:16,492 - INFO - Trial 210: Early stopping at epoch 187.
[I 2025-11-04 06:40:16,569] Trial 210 finished with value: 0.0032153764246368407 and parameters: {'batch_size': 128, 'learning_rate': 0.0037698247747639077, 'nr_hidden_layers': 1, 'nr_neurons': 178, 'dropout_rate': 6.640553767574633e-05, 'weight_decay': 2.81656350040967e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 06:42:34,923 - INFO - Trial 211: Early stopping at epoch 149.
[I 2025-11-04 06:42:35,000] Trial 211 finished with value: 0.0038093484094958757 and parameters: {'batch_size': 128, 'learning_rate': 0.003788838803712987, 'nr_hidden_layers': 1, 'nr_neurons': 179, 'dropout_rate': 0.00030873651321774943, 'weight_decay': 1.672276266302946e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 06:43:57,847 - INFO - Trial 212: Early stopping at epoch 88.
[I 2025-11-04 06:43:57,922] Trial 212 finished with value: 0.006212140797935296 and parameters: {'batch_size': 128, 'learning_rate': 0.003333082830347097, 'nr_hidden_layers': 1, 'nr_neurons': 169, 'dropout_rate': 0.016033811240132447, 'weight_decay': 1.9969193787333648e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 06:44:08,153] Trial 213 pruned. 
[I 2025-11-04 06:44:18,415] Trial 214 pruned. 
[I 2025-11-04 06:44:43,493] Trial 215 pruned. 
2025-11-04 06:47:18,517 - INFO - Trial 216: Early stopping at epoch 102.
[I 2025-11-04 06:47:18,606] Trial 216 finished with value: 0.005544716933501002 and parameters: {'batch_size': 64, 'learning_rate': 0.004009470971285773, 'nr_hidden_layers': 1, 'nr_neurons': 187, 'dropout_rate': 0.011077827114984574, 'weight_decay': 5.203615583379862e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 06:50:18,921 - INFO - Trial 217: Early stopping at epoch 192.
[I 2025-11-04 06:50:18,998] Trial 217 finished with value: 0.0026304343985923883 and parameters: {'batch_size': 128, 'learning_rate': 0.0047394465350600245, 'nr_hidden_layers': 1, 'nr_neurons': 170, 'dropout_rate': 9.48241297827571e-05, 'weight_decay': 2.8809914329688278e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 06:50:29,470] Trial 218 pruned. 
[I 2025-11-04 06:50:35,231] Trial 219 pruned. 
[I 2025-11-04 06:50:47,652] Trial 220 pruned. 
[I 2025-11-04 06:50:57,919] Trial 221 pruned. 
2025-11-04 06:52:26,230 - INFO - Trial 222: Early stopping at epoch 92.
[I 2025-11-04 06:52:26,302] Trial 222 finished with value: 0.005768381386859271 and parameters: {'batch_size': 128, 'learning_rate': 0.003861414895860713, 'nr_hidden_layers': 1, 'nr_neurons': 140, 'dropout_rate': 0.00879614828841667, 'weight_decay': 6.18108632483186e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 06:56:00,278 - INFO - Trial 223: Early stopping at epoch 145.
[I 2025-11-04 06:56:00,357] Trial 223 finished with value: 0.0028864479449983004 and parameters: {'batch_size': 64, 'learning_rate': 0.0032786495437791574, 'nr_hidden_layers': 1, 'nr_neurons': 155, 'dropout_rate': 0.000159987438864396, 'weight_decay': 3.795580152267221e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 06:57:17,001 - INFO - Trial 224: Early stopping at epoch 49.
[I 2025-11-04 06:57:17,077] Trial 224 finished with value: 0.006154288174361413 and parameters: {'batch_size': 64, 'learning_rate': 0.003195229980394965, 'nr_hidden_layers': 1, 'nr_neurons': 157, 'dropout_rate': 0.00010816016038692307, 'weight_decay': 3.657829475721842e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 06:57:27,359] Trial 225 pruned. 
2025-11-04 07:00:09,715 - INFO - Trial 226: Early stopping at epoch 101.
[I 2025-11-04 07:00:09,797] Trial 226 finished with value: 0.003404210304060178 and parameters: {'batch_size': 64, 'learning_rate': 0.0057460887686489335, 'nr_hidden_layers': 1, 'nr_neurons': 180, 'dropout_rate': 0.0005227439679040293, 'weight_decay': 4.1409742026417615e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 07:04:00,433 - INFO - Trial 227: Early stopping at epoch 149.
[I 2025-11-04 07:04:00,512] Trial 227 finished with value: 0.002685755737131898 and parameters: {'batch_size': 64, 'learning_rate': 0.002978844249627382, 'nr_hidden_layers': 1, 'nr_neurons': 186, 'dropout_rate': 5.810916386540056e-05, 'weight_decay': 4.3373225774180025e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 07:04:06,874] Trial 228 pruned. 
2025-11-04 07:07:27,030 - INFO - Trial 229: Early stopping at epoch 136.
[I 2025-11-04 07:07:27,108] Trial 229 finished with value: 0.003034900209625494 and parameters: {'batch_size': 64, 'learning_rate': 0.0027205851188930514, 'nr_hidden_layers': 1, 'nr_neurons': 188, 'dropout_rate': 4.2952262370931586e-06, 'weight_decay': 8.460613132268249e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 07:09:00,668 - INFO - Trial 230: Early stopping at epoch 63.
[I 2025-11-04 07:09:00,743] Trial 230 finished with value: 0.006767712410008084 and parameters: {'batch_size': 64, 'learning_rate': 0.0025339994444413968, 'nr_hidden_layers': 1, 'nr_neurons': 188, 'dropout_rate': 0.012205843317355074, 'weight_decay': 8.498484017856626e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 07:11:32,409 - INFO - Trial 231: Early stopping at epoch 101.
[I 2025-11-04 07:11:32,487] Trial 231 finished with value: 0.004329621318786838 and parameters: {'batch_size': 64, 'learning_rate': 0.0027274669222990306, 'nr_hidden_layers': 1, 'nr_neurons': 174, 'dropout_rate': 0.0007197583315990635, 'weight_decay': 7.025004874839436e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 07:13:46,407 - INFO - Trial 232: Early stopping at epoch 89.
[I 2025-11-04 07:13:46,485] Trial 232 finished with value: 0.006033152969499352 and parameters: {'batch_size': 64, 'learning_rate': 0.0032711957182626566, 'nr_hidden_layers': 1, 'nr_neurons': 198, 'dropout_rate': 0.00867194202489213, 'weight_decay': 5.625769721256511e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 07:15:51,956 - INFO - Trial 233: Early stopping at epoch 83.
[I 2025-11-04 07:15:52,032] Trial 233 finished with value: 0.005957620170964286 and parameters: {'batch_size': 64, 'learning_rate': 0.0029630855926725632, 'nr_hidden_layers': 1, 'nr_neurons': 183, 'dropout_rate': 0.01732846808945679, 'weight_decay': 9.83126672017366e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 07:19:35,630] Trial 234 pruned. 
2025-11-04 07:24:09,013 - INFO - Trial 235: Early stopping at epoch 179.
[I 2025-11-04 07:24:09,125] Trial 235 finished with value: 0.0023056379851437232 and parameters: {'batch_size': 64, 'learning_rate': 0.0032462915849780023, 'nr_hidden_layers': 1, 'nr_neurons': 155, 'dropout_rate': 2.9093459048028004e-05, 'weight_decay': 4.0830338709298e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 07:26:05,205 - INFO - Trial 236: Early stopping at epoch 77.
[I 2025-11-04 07:26:05,287] Trial 236 finished with value: 0.006321708723851395 and parameters: {'batch_size': 64, 'learning_rate': 0.003113999585513646, 'nr_hidden_layers': 1, 'nr_neurons': 153, 'dropout_rate': 0.019584501189457666, 'weight_decay': 4.170602882745987e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 07:28:09,831 - INFO - Trial 237: Early stopping at epoch 80.
[I 2025-11-04 07:28:09,909] Trial 237 finished with value: 0.006511029230794129 and parameters: {'batch_size': 64, 'learning_rate': 0.0027902610065718573, 'nr_hidden_layers': 1, 'nr_neurons': 160, 'dropout_rate': 0.00918795466505444, 'weight_decay': 4.86099779468782e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 07:31:43,871 - INFO - Trial 238: Early stopping at epoch 133.
[I 2025-11-04 07:31:43,950] Trial 238 finished with value: 0.0033459536655616024 and parameters: {'batch_size': 64, 'learning_rate': 0.0033362657303605777, 'nr_hidden_layers': 1, 'nr_neurons': 149, 'dropout_rate': 0.0003243357974240024, 'weight_decay': 3.5103541581018604e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 07:33:37,173 - INFO - Trial 239: Early stopping at epoch 73.
[I 2025-11-04 07:33:37,280] Trial 239 finished with value: 0.006823761987698666 and parameters: {'batch_size': 64, 'learning_rate': 0.0037827028645584207, 'nr_hidden_layers': 1, 'nr_neurons': 175, 'dropout_rate': 0.026313276482853698, 'weight_decay': 3.1694734562428474e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 07:35:00,475 - INFO - Trial 240: Early stopping at epoch 56.
[I 2025-11-04 07:35:00,553] Trial 240 finished with value: 0.007361896282508346 and parameters: {'batch_size': 64, 'learning_rate': 0.0031152759349137357, 'nr_hidden_layers': 1, 'nr_neurons': 187, 'dropout_rate': 0.010196717194106822, 'weight_decay': 0.00012350303515636972, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 07:37:12,370 - INFO - Trial 241: Early stopping at epoch 88.
[I 2025-11-04 07:37:12,448] Trial 241 finished with value: 0.004812379699704577 and parameters: {'batch_size': 64, 'learning_rate': 0.003357598455726661, 'nr_hidden_layers': 1, 'nr_neurons': 149, 'dropout_rate': 9.089064450866382e-05, 'weight_decay': 3.835872204370565e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 07:39:21,598 - INFO - Trial 242: Early stopping at epoch 87.
[I 2025-11-04 07:39:21,700] Trial 242 finished with value: 0.006352221527655713 and parameters: {'batch_size': 64, 'learning_rate': 0.003642617028228562, 'nr_hidden_layers': 1, 'nr_neurons': 157, 'dropout_rate': 0.008753931068531817, 'weight_decay': 3.397487723127102e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 07:41:50,909 - INFO - Trial 243: Early stopping at epoch 99.
[I 2025-11-04 07:41:51,001] Trial 243 finished with value: 0.004444035336867124 and parameters: {'batch_size': 64, 'learning_rate': 0.00411915347683591, 'nr_hidden_layers': 1, 'nr_neurons': 149, 'dropout_rate': 0.0010455222750249565, 'weight_decay': 4.196470236088875e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 07:43:34,667 - INFO - Trial 244: Early stopping at epoch 66.
[I 2025-11-04 07:43:34,745] Trial 244 finished with value: 0.005510795794101965 and parameters: {'batch_size': 64, 'learning_rate': 0.0026874715973426375, 'nr_hidden_layers': 1, 'nr_neurons': 162, 'dropout_rate': 4.236607217863615e-05, 'weight_decay': 5.138122995848913e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 07:46:15,976 - INFO - Trial 245: Early stopping at epoch 102.
[I 2025-11-04 07:46:16,054] Trial 245 finished with value: 0.005837807474751837 and parameters: {'batch_size': 64, 'learning_rate': 0.0033438193322248067, 'nr_hidden_layers': 1, 'nr_neurons': 173, 'dropout_rate': 0.01712748007274916, 'weight_decay': 2.8506774049067773e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 07:46:24,266] Trial 246 pruned. 
[I 2025-11-04 07:48:53,592] Trial 247 pruned. 
2025-11-04 07:52:56,622 - INFO - Trial 248: Early stopping at epoch 163.
[I 2025-11-04 07:52:56,702] Trial 248 finished with value: 0.0027597228907752726 and parameters: {'batch_size': 64, 'learning_rate': 0.002859935720432965, 'nr_hidden_layers': 1, 'nr_neurons': 153, 'dropout_rate': 0.00018171786480786008, 'weight_decay': 5.783512852296312e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 07:57:22,809] Trial 249 pruned. 
2025-11-04 08:00:26,966 - INFO - Trial 250: Early stopping at epoch 121.
[I 2025-11-04 08:00:27,049] Trial 250 finished with value: 0.0056253645057759245 and parameters: {'batch_size': 64, 'learning_rate': 0.0028869476111641266, 'nr_hidden_layers': 1, 'nr_neurons': 190, 'dropout_rate': 0.024096542052453863, 'weight_decay': 8.289611391269362e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 08:00:37,308] Trial 251 pruned. 
2025-11-04 08:03:37,937 - INFO - Trial 252: Early stopping at epoch 110.
[I 2025-11-04 08:03:38,016] Trial 252 finished with value: 0.0062300465068520685 and parameters: {'batch_size': 64, 'learning_rate': 0.0029276312428698527, 'nr_hidden_layers': 1, 'nr_neurons': 63, 'dropout_rate': 0.011698674639113383, 'weight_decay': 6.230683380142344e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 08:04:02,125] Trial 253 pruned. 
[I 2025-11-04 08:04:18,365] Trial 254 pruned. 
[I 2025-11-04 08:04:25,193] Trial 255 pruned. 
2025-11-04 08:09:56,895 - INFO - Trial 256: Early stopping at epoch 210.
[I 2025-11-04 08:09:56,977] Trial 256 finished with value: 0.0024726514863790184 and parameters: {'batch_size': 64, 'learning_rate': 0.004578263959613588, 'nr_hidden_layers': 1, 'nr_neurons': 156, 'dropout_rate': 0.00017120478330011292, 'weight_decay': 0.0002132182311444884, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 08:12:54,524 - INFO - Trial 257: Early stopping at epoch 111.
[I 2025-11-04 08:12:54,613] Trial 257 finished with value: 0.005896475367189352 and parameters: {'batch_size': 64, 'learning_rate': 0.004771281130662249, 'nr_hidden_layers': 1, 'nr_neurons': 154, 'dropout_rate': 0.009355591175750777, 'weight_decay': 0.0001617044724298101, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 08:13:11,382] Trial 258 pruned. 
[I 2025-11-04 08:15:20,918] Trial 259 pruned. 
[I 2025-11-04 08:15:37,653] Trial 260 pruned. 
2025-11-04 08:17:36,336 - INFO - Trial 261: Early stopping at epoch 77.
[I 2025-11-04 08:17:36,415] Trial 261 finished with value: 0.0071764460590647014 and parameters: {'batch_size': 64, 'learning_rate': 0.002447316034126352, 'nr_hidden_layers': 1, 'nr_neurons': 134, 'dropout_rate': 0.009164267911854328, 'weight_decay': 0.00022300381397332697, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 08:22:10,431 - INFO - Trial 262: Early stopping at epoch 183.
[I 2025-11-04 08:22:10,511] Trial 262 finished with value: 0.002460622321292672 and parameters: {'batch_size': 64, 'learning_rate': 0.004287091945075302, 'nr_hidden_layers': 1, 'nr_neurons': 164, 'dropout_rate': 6.893710227736504e-05, 'weight_decay': 0.00029416418790255487, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 08:24:18,798 - INFO - Trial 263: Early stopping at epoch 80.
[I 2025-11-04 08:24:18,877] Trial 263 finished with value: 0.0057096961583133835 and parameters: {'batch_size': 64, 'learning_rate': 0.002952887586043242, 'nr_hidden_layers': 1, 'nr_neurons': 170, 'dropout_rate': 0.00017381255961499808, 'weight_decay': 0.00018137954048997825, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 08:27:06,170 - INFO - Trial 264: Early stopping at epoch 113.
[I 2025-11-04 08:27:06,252] Trial 264 finished with value: 0.005456749600939961 and parameters: {'batch_size': 64, 'learning_rate': 0.004268184947444034, 'nr_hidden_layers': 1, 'nr_neurons': 196, 'dropout_rate': 0.015836846535281786, 'weight_decay': 0.0002646389587150029, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 08:27:22,534] Trial 265 pruned. 
[I 2025-11-04 08:27:28,434] Trial 266 pruned. 
2025-11-04 08:30:13,183 - INFO - Trial 267: Early stopping at epoch 110.
[I 2025-11-04 08:30:13,266] Trial 267 finished with value: 0.0051527807888826615 and parameters: {'batch_size': 64, 'learning_rate': 0.003787291058867507, 'nr_hidden_layers': 1, 'nr_neurons': 204, 'dropout_rate': 0.010625184794245086, 'weight_decay': 5.6791237399342743e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 08:32:27,975 - INFO - Trial 268: Early stopping at epoch 91.
[I 2025-11-04 08:32:28,055] Trial 268 finished with value: 0.006537846372295004 and parameters: {'batch_size': 64, 'learning_rate': 0.004627607962224846, 'nr_hidden_layers': 1, 'nr_neurons': 164, 'dropout_rate': 0.017378572345093442, 'weight_decay': 0.0002988435531360531, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 08:32:34,387] Trial 269 pruned. 
2025-11-04 08:35:31,319 - INFO - Trial 270: Early stopping at epoch 114.
[I 2025-11-04 08:35:31,416] Trial 270 finished with value: 0.005907773081541062 and parameters: {'batch_size': 64, 'learning_rate': 0.0034096580950088713, 'nr_hidden_layers': 1, 'nr_neurons': 154, 'dropout_rate': 0.02372316563971378, 'weight_decay': 4.270490744349612e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 08:39:56,058 - INFO - Trial 271: Early stopping at epoch 171.
[I 2025-11-04 08:39:56,139] Trial 271 finished with value: 0.00274913490386611 and parameters: {'batch_size': 64, 'learning_rate': 0.002766420968633757, 'nr_hidden_layers': 1, 'nr_neurons': 142, 'dropout_rate': 0.00044631275856492087, 'weight_decay': 4.98895662777938e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 08:41:47,485 - INFO - Trial 272: Early stopping at epoch 74.
[I 2025-11-04 08:41:47,574] Trial 272 finished with value: 0.006338242338208887 and parameters: {'batch_size': 64, 'learning_rate': 0.002721850233866486, 'nr_hidden_layers': 1, 'nr_neurons': 143, 'dropout_rate': 0.009485386351066008, 'weight_decay': 5.2332440316407385e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 08:43:23,113 - INFO - Trial 273: Early stopping at epoch 64.
[I 2025-11-04 08:43:23,192] Trial 273 finished with value: 0.009202911890738859 and parameters: {'batch_size': 64, 'learning_rate': 0.002961769585288296, 'nr_hidden_layers': 1, 'nr_neurons': 175, 'dropout_rate': 0.036753064148359646, 'weight_decay': 0.0001327579165335581, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 08:47:50,247 - INFO - Trial 274: Early stopping at epoch 180.
[I 2025-11-04 08:47:50,330] Trial 274 finished with value: 0.0026421419142335033 and parameters: {'batch_size': 64, 'learning_rate': 0.0024344336156249544, 'nr_hidden_layers': 1, 'nr_neurons': 164, 'dropout_rate': 0.0004813443373055519, 'weight_decay': 6.511121771528159e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 08:48:06,600] Trial 275 pruned. 
2025-11-04 08:50:50,387 - INFO - Trial 276: Early stopping at epoch 110.
[I 2025-11-04 08:50:50,471] Trial 276 finished with value: 0.005110799654196444 and parameters: {'batch_size': 64, 'learning_rate': 0.0024174556092330887, 'nr_hidden_layers': 1, 'nr_neurons': 190, 'dropout_rate': 0.00845302258383518, 'weight_decay': 0.00019966461572831702, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 08:52:11,035 - INFO - Trial 277: Early stopping at epoch 50.
[I 2025-11-04 08:52:11,114] Trial 277 finished with value: 0.007617829139901344 and parameters: {'batch_size': 64, 'learning_rate': 0.002745703030244655, 'nr_hidden_layers': 1, 'nr_neurons': 180, 'dropout_rate': 0.009753734760070496, 'weight_decay': 4.482148052259677e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 08:52:28,882] Trial 278 pruned. 
[I 2025-11-04 08:52:36,673] Trial 279 pruned. 
2025-11-04 08:54:31,505 - INFO - Trial 280: Early stopping at epoch 63.
[I 2025-11-04 08:54:31,586] Trial 280 finished with value: 0.006688886193368526 and parameters: {'batch_size': 64, 'learning_rate': 0.0026358179951358695, 'nr_hidden_layers': 3, 'nr_neurons': 169, 'dropout_rate': 0.016752344867468485, 'weight_decay': 6.997020132417697e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 08:54:48,291] Trial 281 pruned. 
2025-11-04 08:59:33,901 - INFO - Trial 282: Early stopping at epoch 186.
[I 2025-11-04 08:59:33,983] Trial 282 finished with value: 0.0029690364350268444 and parameters: {'batch_size': 64, 'learning_rate': 0.00227123794649769, 'nr_hidden_layers': 1, 'nr_neurons': 180, 'dropout_rate': 0.0004347126115386165, 'weight_decay': 3.83342301918044e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 09:02:32,705 - INFO - Trial 283: Early stopping at epoch 116.
[I 2025-11-04 09:02:32,788] Trial 283 finished with value: 0.004538914299402811 and parameters: {'batch_size': 64, 'learning_rate': 0.002294391444000726, 'nr_hidden_layers': 1, 'nr_neurons': 174, 'dropout_rate': 0.009106685403398328, 'weight_decay': 3.931284630183366e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 09:02:49,033] Trial 284 pruned. 
[I 2025-11-04 09:03:05,325] Trial 285 pruned. 
[I 2025-11-04 09:03:12,180] Trial 286 pruned. 
2025-11-04 09:04:19,409 - INFO - Trial 287: Early stopping at epoch 45.
[I 2025-11-04 09:04:19,490] Trial 287 finished with value: 0.006655453025664624 and parameters: {'batch_size': 64, 'learning_rate': 0.0035329487768783804, 'nr_hidden_layers': 1, 'nr_neurons': 164, 'dropout_rate': 8.127202891411933e-05, 'weight_decay': 4.46674260743156e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 09:06:02,038 - INFO - Trial 288: Early stopping at epoch 69.
[I 2025-11-04 09:06:02,138] Trial 288 finished with value: 0.006240934205754515 and parameters: {'batch_size': 64, 'learning_rate': 0.003144417819759753, 'nr_hidden_layers': 1, 'nr_neurons': 181, 'dropout_rate': 0.011961469246044373, 'weight_decay': 5.6000459127285716e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 09:09:30,178 - INFO - Trial 289: Early stopping at epoch 141.
[I 2025-11-04 09:09:30,259] Trial 289 finished with value: 0.0047817863594063195 and parameters: {'batch_size': 64, 'learning_rate': 0.0029117730102842234, 'nr_hidden_layers': 1, 'nr_neurons': 171, 'dropout_rate': 0.009672120284430178, 'weight_decay': 0.0003656633543187689, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 09:12:08,733 - INFO - Trial 290: Early stopping at epoch 107.
[I 2025-11-04 09:12:08,815] Trial 290 finished with value: 0.005351127861432237 and parameters: {'batch_size': 64, 'learning_rate': 0.002115254252150226, 'nr_hidden_layers': 1, 'nr_neurons': 159, 'dropout_rate': 0.019238835534282916, 'weight_decay': 3.6531205329056403e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 09:12:14,549] Trial 291 pruned. 
2025-11-04 09:15:26,659 - INFO - Trial 292: Early stopping at epoch 125.
[I 2025-11-04 09:15:26,746] Trial 292 finished with value: 0.003007579756144692 and parameters: {'batch_size': 64, 'learning_rate': 0.004349215481248669, 'nr_hidden_layers': 1, 'nr_neurons': 155, 'dropout_rate': 0.0001710915799538979, 'weight_decay': 0.0001585646967136144, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 09:15:43,176] Trial 293 pruned. 
[I 2025-11-04 09:16:00,917] Trial 294 pruned. 
[I 2025-11-04 09:16:07,368] Trial 295 pruned. 
[I 2025-11-04 09:16:23,978] Trial 296 pruned. 
2025-11-04 09:18:54,199 - INFO - Trial 297: Early stopping at epoch 93.
[I 2025-11-04 09:18:54,280] Trial 297 finished with value: 0.006556081931211323 and parameters: {'batch_size': 64, 'learning_rate': 0.0025189036017061487, 'nr_hidden_layers': 1, 'nr_neurons': 165, 'dropout_rate': 0.017897849362370554, 'weight_decay': 0.00022948133142349923, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 09:19:10,627] Trial 298 pruned. 
[I 2025-11-04 09:19:26,946] Trial 299 pruned. 
[I 2025-11-04 09:19:49,135] Trial 300 pruned. 
2025-11-04 09:21:15,933 - INFO - Trial 301: Early stopping at epoch 58.
[I 2025-11-04 09:21:16,014] Trial 301 finished with value: 0.0058117792331311875 and parameters: {'batch_size': 64, 'learning_rate': 0.003475598506993216, 'nr_hidden_layers': 1, 'nr_neurons': 164, 'dropout_rate': 0.000190115700406944, 'weight_decay': 3.569814535458621e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 09:24:07,324 - INFO - Trial 302: Early stopping at epoch 109.
[I 2025-11-04 09:24:07,436] Trial 302 finished with value: 0.006860843590743578 and parameters: {'batch_size': 64, 'learning_rate': 0.004565837867726534, 'nr_hidden_layers': 1, 'nr_neurons': 149, 'dropout_rate': 0.01773880454491759, 'weight_decay': 4.701721272535375e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 09:24:23,743] Trial 303 pruned. 
[I 2025-11-04 09:24:40,136] Trial 304 pruned. 
[I 2025-11-04 09:24:47,938] Trial 305 pruned. 
[I 2025-11-04 09:25:04,182] Trial 306 pruned. 
[I 2025-11-04 09:25:20,836] Trial 307 pruned. 
[I 2025-11-04 09:26:08,120] Trial 308 pruned. 
2025-11-04 09:30:02,050 - INFO - Trial 309: Early stopping at epoch 140.
[I 2025-11-04 09:30:02,136] Trial 309 finished with value: 0.004524005599625019 and parameters: {'batch_size': 64, 'learning_rate': 0.0027159446209231285, 'nr_hidden_layers': 1, 'nr_neurons': 207, 'dropout_rate': 0.009125089480365455, 'weight_decay': 4.7178325646059524e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 09:32:37,814 - INFO - Trial 310: Early stopping at epoch 103.
[I 2025-11-04 09:32:37,898] Trial 310 finished with value: 0.004274526377813663 and parameters: {'batch_size': 64, 'learning_rate': 0.00492419781227754, 'nr_hidden_layers': 1, 'nr_neurons': 145, 'dropout_rate': 0.00025144270163429336, 'weight_decay': 0.00025268732163414757, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 09:33:07,814] Trial 311 pruned. 
[I 2025-11-04 09:33:14,517] Trial 312 pruned. 
[I 2025-11-04 09:33:30,733] Trial 313 pruned. 
2025-11-04 09:38:50,316 - INFO - Trial 314: Early stopping at epoch 212.
[I 2025-11-04 09:38:50,400] Trial 314 finished with value: 0.0022382635637276 and parameters: {'batch_size': 64, 'learning_rate': 0.003297919201058435, 'nr_hidden_layers': 1, 'nr_neurons': 131, 'dropout_rate': 5.710582968366768e-05, 'weight_decay': 3.866080777764065e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 09:39:06,691] Trial 315 pruned. 
2025-11-04 09:41:17,981 - INFO - Trial 316: Early stopping at epoch 84.
[I 2025-11-04 09:41:18,062] Trial 316 finished with value: 0.006488409260459361 and parameters: {'batch_size': 64, 'learning_rate': 0.0037372294008803427, 'nr_hidden_layers': 1, 'nr_neurons': 136, 'dropout_rate': 0.008973164992717938, 'weight_decay': 9.109633901120124e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 09:43:26,726 - INFO - Trial 317: Early stopping at epoch 87.
[I 2025-11-04 09:43:26,821] Trial 317 finished with value: 0.0065571622351616714 and parameters: {'batch_size': 64, 'learning_rate': 0.0032174560565205166, 'nr_hidden_layers': 1, 'nr_neurons': 126, 'dropout_rate': 0.017920133748104757, 'weight_decay': 7.287885623502188e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 09:43:32,593] Trial 318 pruned. 
[I 2025-11-04 09:44:25,554] Trial 319 pruned. 
[I 2025-11-04 09:44:42,312] Trial 320 pruned. 
2025-11-04 09:47:39,252 - INFO - Trial 321: Early stopping at epoch 117.
[I 2025-11-04 09:47:39,335] Trial 321 finished with value: 0.0038817323589901177 and parameters: {'batch_size': 64, 'learning_rate': 0.0040035187332326146, 'nr_hidden_layers': 1, 'nr_neurons': 160, 'dropout_rate': 0.0005116651155800225, 'weight_decay': 3.400426920785052e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 09:47:45,728] Trial 322 pruned. 
2025-11-04 09:49:34,706 - INFO - Trial 323: Early stopping at epoch 52.
[I 2025-11-04 09:49:34,788] Trial 323 finished with value: 0.009170077196787271 and parameters: {'batch_size': 64, 'learning_rate': 0.005672360953234577, 'nr_hidden_layers': 4, 'nr_neurons': 156, 'dropout_rate': 0.0003015804156813762, 'weight_decay': 4.0634467557671654e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 09:52:58,420] Trial 324 pruned. 
[I 2025-11-04 09:53:14,794] Trial 325 pruned. 
[I 2025-11-04 09:53:41,050] Trial 326 pruned. 
2025-11-04 09:55:47,774 - INFO - Trial 327: Early stopping at epoch 74.
[I 2025-11-04 09:55:47,859] Trial 327 finished with value: 0.0067583552719488425 and parameters: {'batch_size': 64, 'learning_rate': 0.0031261513684664815, 'nr_hidden_layers': 1, 'nr_neurons': 159, 'dropout_rate': 0.01033198883728986, 'weight_decay': 7.109127650517244e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 09:56:04,208] Trial 328 pruned. 
2025-11-04 09:57:24,460 - INFO - Trial 329: Early stopping at epoch 53.
[I 2025-11-04 09:57:24,542] Trial 329 finished with value: 0.00800934413837757 and parameters: {'batch_size': 64, 'learning_rate': 0.003978780196895534, 'nr_hidden_layers': 1, 'nr_neurons': 152, 'dropout_rate': 0.008771449573576699, 'weight_decay': 6.111183665173363e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 09:59:37,857 - INFO - Trial 330: Early stopping at epoch 88.
[I 2025-11-04 09:59:37,940] Trial 330 finished with value: 0.007127005394292188 and parameters: {'batch_size': 64, 'learning_rate': 0.0034643169571387626, 'nr_hidden_layers': 1, 'nr_neurons': 128, 'dropout_rate': 0.019866834348676074, 'weight_decay': 3.591549301513874e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 10:02:51,910 - INFO - Trial 331: Early stopping at epoch 126.
[I 2025-11-04 10:02:51,994] Trial 331 finished with value: 0.005252697713522237 and parameters: {'batch_size': 64, 'learning_rate': 0.004736073837895869, 'nr_hidden_layers': 1, 'nr_neurons': 164, 'dropout_rate': 0.008449280427862213, 'weight_decay': 4.309336436406843e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 10:04:12,073] Trial 332 pruned. 
[I 2025-11-04 10:04:28,398] Trial 333 pruned. 
2025-11-04 10:08:17,076 - INFO - Trial 334: Early stopping at epoch 151.
[I 2025-11-04 10:08:17,159] Trial 334 finished with value: 0.002313037133717642 and parameters: {'batch_size': 64, 'learning_rate': 0.005981564753312436, 'nr_hidden_layers': 1, 'nr_neurons': 179, 'dropout_rate': 0.00022166383418159797, 'weight_decay': 2.1164749037147258e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 10:08:24,945] Trial 335 pruned. 
2025-11-04 10:11:37,437 - INFO - Trial 336: Early stopping at epoch 125.
[I 2025-11-04 10:11:37,524] Trial 336 finished with value: 0.005055010964990198 and parameters: {'batch_size': 64, 'learning_rate': 0.0065278855492432826, 'nr_hidden_layers': 1, 'nr_neurons': 69, 'dropout_rate': 0.00880186476448498, 'weight_decay': 3.019559411214461e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 10:11:53,819] Trial 337 pruned. 
2025-11-04 10:14:28,421 - INFO - Trial 338: Early stopping at epoch 104.
[I 2025-11-04 10:14:28,505] Trial 338 finished with value: 0.00619850157517581 and parameters: {'batch_size': 64, 'learning_rate': 0.0035816930281410858, 'nr_hidden_layers': 1, 'nr_neurons': 159, 'dropout_rate': 0.016826179862901008, 'weight_decay': 1.4731743143274579e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 10:16:30,150 - INFO - Trial 339: Early stopping at epoch 82.
[I 2025-11-04 10:16:30,232] Trial 339 finished with value: 0.005492028642241535 and parameters: {'batch_size': 64, 'learning_rate': 0.00681778019934555, 'nr_hidden_layers': 1, 'nr_neurons': 195, 'dropout_rate': 0.00924675466205948, 'weight_decay': 2.0064538417677857e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 10:16:37,118] Trial 340 pruned. 
[I 2025-11-04 10:16:48,271] Trial 341 pruned. 
2025-11-04 10:20:26,871 - INFO - Trial 342: Early stopping at epoch 144.
[I 2025-11-04 10:20:26,955] Trial 342 finished with value: 0.004273419400403797 and parameters: {'batch_size': 64, 'learning_rate': 0.0030686758426597565, 'nr_hidden_layers': 1, 'nr_neurons': 165, 'dropout_rate': 0.008688400723951282, 'weight_decay': 1.262694733545674e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 10:22:38,254 - INFO - Trial 343: Early stopping at epoch 88.
[I 2025-11-04 10:22:38,338] Trial 343 finished with value: 0.0066817558796485104 and parameters: {'batch_size': 64, 'learning_rate': 0.003986781159982973, 'nr_hidden_layers': 1, 'nr_neurons': 143, 'dropout_rate': 0.015483049739924358, 'weight_decay': 2.4656563638886502e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 10:24:37,020 - INFO - Trial 344: Early stopping at epoch 80.
[I 2025-11-04 10:24:37,104] Trial 344 finished with value: 0.005050101818494122 and parameters: {'batch_size': 64, 'learning_rate': 0.003418884513192517, 'nr_hidden_layers': 1, 'nr_neurons': 183, 'dropout_rate': 0.0004694562427383252, 'weight_decay': 0.00023223557074239027, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 10:24:43,109] Trial 345 pruned. 
2025-11-04 10:26:36,800 - INFO - Trial 346: Early stopping at epoch 73.
[I 2025-11-04 10:26:36,883] Trial 346 finished with value: 0.006786449628863424 and parameters: {'batch_size': 64, 'learning_rate': 0.0028162568039298364, 'nr_hidden_layers': 1, 'nr_neurons': 158, 'dropout_rate': 0.023618288856205483, 'weight_decay': 5.456125207183436e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 10:27:51,813 - INFO - Trial 347: Early stopping at epoch 50.
[I 2025-11-04 10:27:51,896] Trial 347 finished with value: 0.00958999794512662 and parameters: {'batch_size': 64, 'learning_rate': 0.0051764588333351085, 'nr_hidden_layers': 1, 'nr_neurons': 175, 'dropout_rate': 0.015117571519893262, 'weight_decay': 4.4309416076388016e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 10:28:08,185] Trial 348 pruned. 
[I 2025-11-04 10:28:25,922] Trial 349 pruned. 
2025-11-04 10:29:48,782 - INFO - Trial 350: Early stopping at epoch 54.
[I 2025-11-04 10:29:48,888] Trial 350 finished with value: 0.006301100500279117 and parameters: {'batch_size': 64, 'learning_rate': 0.004188712094504981, 'nr_hidden_layers': 1, 'nr_neurons': 168, 'dropout_rate': 0.0004028411831248649, 'weight_decay': 3.108411524378118e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 10:32:40,526 - INFO - Trial 351: Early stopping at epoch 113.
[I 2025-11-04 10:32:40,609] Trial 351 finished with value: 0.005101884852454846 and parameters: {'batch_size': 64, 'learning_rate': 0.0024803294167812587, 'nr_hidden_layers': 1, 'nr_neurons': 202, 'dropout_rate': 0.01069882994666517, 'weight_decay': 5.429787776853824e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 10:32:46,996] Trial 352 pruned. 
[I 2025-11-04 10:33:03,340] Trial 353 pruned. 
2025-11-04 10:35:06,993 - INFO - Trial 354: Early stopping at epoch 80.
[I 2025-11-04 10:35:07,077] Trial 354 finished with value: 0.007262929643470931 and parameters: {'batch_size': 64, 'learning_rate': 0.003831310355873808, 'nr_hidden_layers': 1, 'nr_neurons': 160, 'dropout_rate': 0.010307292830267926, 'weight_decay': 0.0002589501616727631, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 10:35:17,351] Trial 355 pruned. 
[I 2025-11-04 10:35:33,591] Trial 356 pruned. 
[I 2025-11-04 10:36:26,597] Trial 357 pruned. 
2025-11-04 10:38:57,252 - INFO - Trial 358: Early stopping at epoch 102.
[I 2025-11-04 10:38:57,337] Trial 358 finished with value: 0.005396955107746915 and parameters: {'batch_size': 64, 'learning_rate': 0.003723491335993133, 'nr_hidden_layers': 1, 'nr_neurons': 190, 'dropout_rate': 0.008698014874189117, 'weight_decay': 0.00014735834303343162, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 10:40:51,615 - INFO - Trial 359: Early stopping at epoch 75.
[I 2025-11-04 10:40:51,714] Trial 359 finished with value: 0.005722030639628092 and parameters: {'batch_size': 64, 'learning_rate': 0.0030526273144966857, 'nr_hidden_layers': 1, 'nr_neurons': 178, 'dropout_rate': 0.00025810260198567357, 'weight_decay': 0.00037196065285861906, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 10:41:08,052] Trial 360 pruned. 
[I 2025-11-04 10:44:14,193] Trial 361 pruned. 
2025-11-04 10:46:44,869 - INFO - Trial 362: Early stopping at epoch 97.
[I 2025-11-04 10:46:44,955] Trial 362 finished with value: 0.004433102308396243 and parameters: {'batch_size': 64, 'learning_rate': 0.004831680668024266, 'nr_hidden_layers': 1, 'nr_neurons': 154, 'dropout_rate': 0.0008045171060140934, 'weight_decay': 4.0709737643043475e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 10:47:02,407] Trial 363 pruned. 
[I 2025-11-04 10:47:10,207] Trial 364 pruned. 
2025-11-04 10:51:01,642 - INFO - Trial 365: Early stopping at epoch 156.
[I 2025-11-04 10:51:01,728] Trial 365 finished with value: 0.0024292849850250536 and parameters: {'batch_size': 64, 'learning_rate': 0.003990624239549981, 'nr_hidden_layers': 1, 'nr_neurons': 176, 'dropout_rate': 4.907423183192936e-05, 'weight_decay': 2.5384101844368638e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 10:51:18,002] Trial 366 pruned. 
2025-11-04 10:53:21,039 - INFO - Trial 367: Early stopping at epoch 80.
[I 2025-11-04 10:53:21,127] Trial 367 finished with value: 0.006725421900280299 and parameters: {'batch_size': 64, 'learning_rate': 0.0036133328740450784, 'nr_hidden_layers': 1, 'nr_neurons': 183, 'dropout_rate': 0.017071825573232193, 'weight_decay': 1.7089317601512752e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 10:53:28,119] Trial 368 pruned. 
[I 2025-11-04 10:53:44,259] Trial 369 pruned. 
2025-11-04 10:55:13,766 - INFO - Trial 370: Early stopping at epoch 51.
[I 2025-11-04 10:55:13,850] Trial 370 finished with value: 0.0069478325520329004 and parameters: {'batch_size': 64, 'learning_rate': 0.0032270931359787663, 'nr_hidden_layers': 1, 'nr_neurons': 159, 'dropout_rate': 0.009725588234738512, 'weight_decay': 2.2490566498091055e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 10:55:24,255] Trial 371 pruned. 
[I 2025-11-04 10:55:42,497] Trial 372 pruned. 
2025-11-04 10:57:03,973 - INFO - Trial 373: Early stopping at epoch 51.
[I 2025-11-04 10:57:04,064] Trial 373 finished with value: 0.008429023564921588 and parameters: {'batch_size': 64, 'learning_rate': 0.004544069752370112, 'nr_hidden_layers': 1, 'nr_neurons': 190, 'dropout_rate': 0.020465987412370337, 'weight_decay': 2.6702406558261665e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 10:57:09,605] Trial 374 pruned. 
2025-11-04 11:00:04,205 - INFO - Trial 375: Early stopping at epoch 117.
[I 2025-11-04 11:00:04,297] Trial 375 finished with value: 0.004731510356774863 and parameters: {'batch_size': 64, 'learning_rate': 0.00292553390041691, 'nr_hidden_layers': 1, 'nr_neurons': 162, 'dropout_rate': 0.0094947234183665, 'weight_decay': 3.362594339009452e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 11:02:18,241 - INFO - Trial 376: Early stopping at epoch 87.
[I 2025-11-04 11:02:18,334] Trial 376 finished with value: 0.007174037215127915 and parameters: {'batch_size': 64, 'learning_rate': 0.0038636138606478266, 'nr_hidden_layers': 1, 'nr_neurons': 205, 'dropout_rate': 0.03203577244109049, 'weight_decay': 7.127502493701618e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 11:02:34,611] Trial 377 pruned. 
[I 2025-11-04 11:02:50,915] Trial 378 pruned. 
[I 2025-11-04 11:03:07,105] Trial 379 pruned. 
[I 2025-11-04 11:03:13,527] Trial 380 pruned. 
[I 2025-11-04 11:03:29,798] Trial 381 pruned. 
[I 2025-11-04 11:03:47,208] Trial 382 pruned. 
[I 2025-11-04 11:04:03,525] Trial 383 pruned. 
2025-11-04 11:06:39,713 - INFO - Trial 384: Early stopping at epoch 101.
[I 2025-11-04 11:06:39,799] Trial 384 finished with value: 0.005188460363619547 and parameters: {'batch_size': 64, 'learning_rate': 0.005073019999302444, 'nr_hidden_layers': 1, 'nr_neurons': 155, 'dropout_rate': 0.009687770444208746, 'weight_decay': 3.919144381628456e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 11:06:50,263] Trial 385 pruned. 
[I 2025-11-04 11:07:09,510] Trial 386 pruned. 
2025-11-04 11:09:51,810 - INFO - Trial 387: Early stopping at epoch 110.
[I 2025-11-04 11:09:51,895] Trial 387 finished with value: 0.005214465819417387 and parameters: {'batch_size': 64, 'learning_rate': 0.003199439365100332, 'nr_hidden_layers': 1, 'nr_neurons': 146, 'dropout_rate': 0.00819677757064755, 'weight_decay': 2.3518546009699325e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 11:12:15,453 - INFO - Trial 388: Early stopping at epoch 79.
[I 2025-11-04 11:12:15,537] Trial 388 finished with value: 0.00746879976076569 and parameters: {'batch_size': 64, 'learning_rate': 0.0043527412852905805, 'nr_hidden_layers': 3, 'nr_neurons': 182, 'dropout_rate': 0.015010850333683044, 'weight_decay': 6.743191977396283e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 11:12:31,765] Trial 389 pruned. 
[I 2025-11-04 11:12:48,460] Trial 390 pruned. 
[I 2025-11-04 11:12:56,284] Trial 391 pruned. 
[I 2025-11-04 11:16:35,945] Trial 392 pruned. 
2025-11-04 11:18:43,496 - INFO - Trial 393: Early stopping at epoch 86.
[I 2025-11-04 11:18:43,583] Trial 393 finished with value: 0.006640189575985945 and parameters: {'batch_size': 64, 'learning_rate': 0.004495157344843434, 'nr_hidden_layers': 1, 'nr_neurons': 136, 'dropout_rate': 0.009048994794440674, 'weight_decay': 2.6420146239299795e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 11:19:07,104] Trial 394 pruned. 
2025-11-04 11:23:36,637 - INFO - Trial 395: Early stopping at epoch 179.
[I 2025-11-04 11:23:36,725] Trial 395 finished with value: 0.002752147357494377 and parameters: {'batch_size': 64, 'learning_rate': 0.004063303499997992, 'nr_hidden_layers': 1, 'nr_neurons': 147, 'dropout_rate': 0.0006428469009373146, 'weight_decay': 7.604888462143975e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 11:24:51,855 - INFO - Trial 396: Early stopping at epoch 50.
[I 2025-11-04 11:24:51,941] Trial 396 finished with value: 0.00795001077352873 and parameters: {'batch_size': 64, 'learning_rate': 0.004077743581080425, 'nr_hidden_layers': 1, 'nr_neurons': 143, 'dropout_rate': 0.008930932032450467, 'weight_decay': 7.984958689119649e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 11:24:58,628] Trial 397 pruned. 
[I 2025-11-04 11:25:14,835] Trial 398 pruned. 
[I 2025-11-04 11:27:20,545] Trial 399 pruned. 
[I 2025-11-04 11:27:36,866] Trial 400 pruned. 
[I 2025-11-04 11:27:47,165] Trial 401 pruned. 
[I 2025-11-04 11:31:25,356] Trial 402 pruned. 
[I 2025-11-04 11:31:31,143] Trial 403 pruned. 
[I 2025-11-04 11:34:40,506] Trial 404 pruned. 
[I 2025-11-04 11:34:56,807] Trial 405 pruned. 
[I 2025-11-04 11:35:17,849] Trial 406 pruned. 
[I 2025-11-04 11:35:24,246] Trial 407 pruned. 
2025-11-04 11:37:52,813 - INFO - Trial 408: Early stopping at epoch 98.
[I 2025-11-04 11:37:52,916] Trial 408 finished with value: 0.00404605879415207 and parameters: {'batch_size': 64, 'learning_rate': 0.0029899650807747465, 'nr_hidden_layers': 1, 'nr_neurons': 160, 'dropout_rate': 0.00025323974939884137, 'weight_decay': 8.939456435055497e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 11:39:18,156 - INFO - Trial 409: Early stopping at epoch 57.
[I 2025-11-04 11:39:18,243] Trial 409 finished with value: 0.007509038020113606 and parameters: {'batch_size': 64, 'learning_rate': 0.003907456391264744, 'nr_hidden_layers': 1, 'nr_neurons': 175, 'dropout_rate': 0.010319906837505288, 'weight_decay': 5.0001559680168785e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 11:39:37,115] Trial 410 pruned. 
2025-11-04 11:42:33,624 - INFO - Trial 411: Early stopping at epoch 112.
[I 2025-11-04 11:42:33,710] Trial 411 finished with value: 0.006307975658768186 and parameters: {'batch_size': 64, 'learning_rate': 0.002688593802986039, 'nr_hidden_layers': 1, 'nr_neurons': 150, 'dropout_rate': 0.010941111217518514, 'weight_decay': 0.003982257196622013, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 11:45:00,945 - INFO - Trial 412: Early stopping at epoch 96.
[I 2025-11-04 11:45:01,034] Trial 412 finished with value: 0.003832615493253317 and parameters: {'batch_size': 64, 'learning_rate': 0.005126355710304913, 'nr_hidden_layers': 1, 'nr_neurons': 180, 'dropout_rate': 0.00013262170960848555, 'weight_decay': 7.549888390684082e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 11:47:33,522] Trial 413 pruned. 
2025-11-04 11:49:28,046 - INFO - Trial 414: Early stopping at epoch 68.
[I 2025-11-04 11:49:28,138] Trial 414 finished with value: 0.0056708403485090115 and parameters: {'batch_size': 64, 'learning_rate': 0.0042047518258644554, 'nr_hidden_layers': 2, 'nr_neurons': 199, 'dropout_rate': 0.012535893691486983, 'weight_decay': 0.0003978867029720054, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 11:50:58,776 - INFO - Trial 415: Early stopping at epoch 60.
[I 2025-11-04 11:50:58,864] Trial 415 finished with value: 0.0065007567763226025 and parameters: {'batch_size': 64, 'learning_rate': 0.0024350431615357167, 'nr_hidden_layers': 1, 'nr_neurons': 171, 'dropout_rate': 0.008816660134416614, 'weight_decay': 0.00022567059790839508, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 11:51:15,164] Trial 416 pruned. 
[I 2025-11-04 11:51:31,543] Trial 417 pruned. 
[I 2025-11-04 11:51:39,392] Trial 418 pruned. 
[I 2025-11-04 11:55:23,755] Trial 419 pruned. 
2025-11-04 11:57:10,366 - INFO - Trial 420: Early stopping at epoch 64.
[I 2025-11-04 11:57:10,453] Trial 420 finished with value: 0.007381857138145435 and parameters: {'batch_size': 64, 'learning_rate': 0.005800036002879429, 'nr_hidden_layers': 1, 'nr_neurons': 164, 'dropout_rate': 0.008811665085603, 'weight_decay': 3.521269720179449e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 11:57:26,746] Trial 421 pruned. 
[I 2025-11-04 11:57:43,059] Trial 422 pruned. 
2025-11-04 12:00:29,151 - INFO - Trial 423: Early stopping at epoch 112.
[I 2025-11-04 12:00:29,241] Trial 423 finished with value: 0.0038301113560714342 and parameters: {'batch_size': 64, 'learning_rate': 0.0031378590004628244, 'nr_hidden_layers': 1, 'nr_neurons': 167, 'dropout_rate': 0.000128151774900478, 'weight_decay': 2.7730140232969135e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 12:00:36,178] Trial 424 pruned. 
[I 2025-11-04 12:00:52,896] Trial 425 pruned. 
[I 2025-11-04 12:01:09,203] Trial 426 pruned. 
[I 2025-11-04 12:01:25,582] Trial 427 pruned. 
2025-11-04 12:04:05,447 - INFO - Trial 428: Early stopping at epoch 107.
[I 2025-11-04 12:04:05,535] Trial 428 finished with value: 0.005122145778867819 and parameters: {'batch_size': 64, 'learning_rate': 0.0050990322561875155, 'nr_hidden_layers': 1, 'nr_neurons': 210, 'dropout_rate': 0.008660527204691001, 'weight_decay': 2.094702327524556e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 12:04:11,266] Trial 429 pruned. 
[I 2025-11-04 12:04:27,511] Trial 430 pruned. 
[I 2025-11-04 12:04:37,788] Trial 431 pruned. 
[I 2025-11-04 12:04:54,195] Trial 432 pruned. 
2025-11-04 12:08:08,782 - INFO - Trial 433: Early stopping at epoch 131.
[I 2025-11-04 12:08:08,872] Trial 433 finished with value: 0.00285294170295375 and parameters: {'batch_size': 64, 'learning_rate': 0.0036730020102238125, 'nr_hidden_layers': 1, 'nr_neurons': 159, 'dropout_rate': 0.0005598995879567183, 'weight_decay': 4.246686373949933e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 12:11:55,278 - INFO - Trial 434: Early stopping at epoch 151.
[I 2025-11-04 12:11:55,368] Trial 434 finished with value: 0.002959094349181506 and parameters: {'batch_size': 64, 'learning_rate': 0.004241829755308739, 'nr_hidden_layers': 1, 'nr_neurons': 119, 'dropout_rate': 0.0004411246364387916, 'weight_decay': 6.612038853129337e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 12:18:03,966 - INFO - Trial 435: Early stopping at epoch 240.
[I 2025-11-04 12:18:04,063] Trial 435 finished with value: 0.0027097564482646934 and parameters: {'batch_size': 64, 'learning_rate': 0.003648774243747677, 'nr_hidden_layers': 1, 'nr_neurons': 194, 'dropout_rate': 0.00014787119705661527, 'weight_decay': 0.00026727271044771887, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 12:18:20,818] Trial 436 pruned. 
2025-11-04 12:22:53,095 - INFO - Trial 437: Early stopping at epoch 178.
[I 2025-11-04 12:22:53,195] Trial 437 finished with value: 0.002400878358855766 and parameters: {'batch_size': 64, 'learning_rate': 0.003988995719266325, 'nr_hidden_layers': 1, 'nr_neurons': 202, 'dropout_rate': 0.00017644317881345187, 'weight_decay': 1.10860784647517e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 12:23:09,523] Trial 438 pruned. 
2025-11-04 12:24:44,860 - INFO - Trial 439: Early stopping at epoch 62.
[I 2025-11-04 12:24:44,950] Trial 439 finished with value: 0.00766709312152784 and parameters: {'batch_size': 64, 'learning_rate': 0.004411841791391173, 'nr_hidden_layers': 1, 'nr_neurons': 194, 'dropout_rate': 0.010341923803286577, 'weight_decay': 5.485796874513993e-06, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 12:24:51,555] Trial 440 pruned. 
[I 2025-11-04 12:25:13,758] Trial 441 pruned. 
2025-11-04 12:27:08,864 - INFO - Trial 442: Early stopping at epoch 66.
[I 2025-11-04 12:27:08,951] Trial 442 finished with value: 0.007073733810740129 and parameters: {'batch_size': 64, 'learning_rate': 0.005398261772113521, 'nr_hidden_layers': 2, 'nr_neurons': 41, 'dropout_rate': 0.009718757431100787, 'weight_decay': 8.002357259498891e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 12:31:36,668 - INFO - Trial 443: Early stopping at epoch 177.
[I 2025-11-04 12:31:36,758] Trial 443 finished with value: 0.003131517084128898 and parameters: {'batch_size': 64, 'learning_rate': 0.004126174189003723, 'nr_hidden_layers': 1, 'nr_neurons': 235, 'dropout_rate': 0.00013242232347284084, 'weight_decay': 1.1951974711276242e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 12:32:56,466] Trial 444 pruned. 
2025-11-04 12:34:16,633 - INFO - Trial 445: Early stopping at epoch 46.
[I 2025-11-04 12:34:16,720] Trial 445 finished with value: 0.008438006446985046 and parameters: {'batch_size': 64, 'learning_rate': 0.003923422390959698, 'nr_hidden_layers': 1, 'nr_neurons': 186, 'dropout_rate': 0.01598961534889583, 'weight_decay': 0.0002888010483521547, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 12:34:24,670] Trial 446 pruned. 
2025-11-04 12:35:39,969 - INFO - Trial 447: Early stopping at epoch 76.
[I 2025-11-04 12:35:40,057] Trial 447 finished with value: 0.006803755332095752 and parameters: {'batch_size': 128, 'learning_rate': 0.0025862956125029908, 'nr_hidden_layers': 1, 'nr_neurons': 188, 'dropout_rate': 0.01823491705221904, 'weight_decay': 5.345644683407308e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 12:37:23,810 - INFO - Trial 448: Early stopping at epoch 68.
[I 2025-11-04 12:37:23,897] Trial 448 finished with value: 0.006573558008268922 and parameters: {'batch_size': 64, 'learning_rate': 0.003078950607466004, 'nr_hidden_layers': 1, 'nr_neurons': 207, 'dropout_rate': 0.008069838885462345, 'weight_decay': 4.9086060540881265e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 12:37:40,671] Trial 449 pruned. 
2025-11-04 12:41:24,598 - INFO - Trial 450: Early stopping at epoch 145.
[I 2025-11-04 12:41:24,703] Trial 450 finished with value: 0.003290980420486757 and parameters: {'batch_size': 64, 'learning_rate': 0.0034378928007650373, 'nr_hidden_layers': 1, 'nr_neurons': 183, 'dropout_rate': 0.00033719077649890675, 'weight_decay': 1.615680187950919e-05, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 12:41:41,480] Trial 451 pruned. 
[I 2025-11-04 12:41:58,126] Trial 452 pruned. 
[I 2025-11-04 12:42:05,031] Trial 453 pruned. 
2025-11-04 12:43:46,910 - INFO - Trial 454: Early stopping at epoch 65.
[I 2025-11-04 12:43:46,999] Trial 454 finished with value: 0.0067985084210276485 and parameters: {'batch_size': 64, 'learning_rate': 0.0036930961650062815, 'nr_hidden_layers': 1, 'nr_neurons': 225, 'dropout_rate': 0.010198430218127332, 'weight_decay': 0.0003546789913980136, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 12:45:53,947 - INFO - Trial 455: Early stopping at epoch 81.
[I 2025-11-04 12:45:54,036] Trial 455 finished with value: 0.004977387149576319 and parameters: {'batch_size': 64, 'learning_rate': 0.003282991404202482, 'nr_hidden_layers': 1, 'nr_neurons': 169, 'dropout_rate': 3.2529336905951054e-05, 'weight_decay': 5.5516026632550964e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 12:47:46,803 - INFO - Trial 456: Early stopping at epoch 72.
[I 2025-11-04 12:47:46,894] Trial 456 finished with value: 0.007504252982143394 and parameters: {'batch_size': 64, 'learning_rate': 0.0023527344326271854, 'nr_hidden_layers': 1, 'nr_neurons': 147, 'dropout_rate': 0.017220506916572044, 'weight_decay': 0.00020294660538711548, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 12:51:04,772] Trial 457 pruned. 
2025-11-04 12:53:44,749 - INFO - Trial 458: Early stopping at epoch 107.
[I 2025-11-04 12:53:44,841] Trial 458 finished with value: 0.003646488451035974 and parameters: {'batch_size': 64, 'learning_rate': 0.0026309441373380082, 'nr_hidden_layers': 1, 'nr_neurons': 163, 'dropout_rate': 0.00015698549150687725, 'weight_decay': 2.5843799718106796e-06, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 12:55:40,487] Trial 459 pruned. 
2025-11-04 12:58:17,590 - INFO - Trial 460: Early stopping at epoch 105.
[I 2025-11-04 12:58:17,707] Trial 460 finished with value: 0.00598322163208244 and parameters: {'batch_size': 64, 'learning_rate': 0.0031232692483707056, 'nr_hidden_layers': 1, 'nr_neurons': 127, 'dropout_rate': 0.012253248979760777, 'weight_decay': 6.230165981368898e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 12:58:23,536] Trial 461 pruned. 
[I 2025-11-04 12:58:33,823] Trial 462 pruned. 
2025-11-04 13:00:29,143 - INFO - Trial 463: Early stopping at epoch 76.
[I 2025-11-04 13:00:29,238] Trial 463 finished with value: 0.00734764539819164 and parameters: {'batch_size': 64, 'learning_rate': 0.003640167641624291, 'nr_hidden_layers': 1, 'nr_neurons': 203, 'dropout_rate': 0.0242162808068878, 'weight_decay': 2.390182904160447e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 13:00:35,639] Trial 464 pruned. 
2025-11-04 13:02:41,914 - INFO - Trial 465: Early stopping at epoch 82.
[I 2025-11-04 13:02:42,013] Trial 465 finished with value: 0.004149850641914424 and parameters: {'batch_size': 64, 'learning_rate': 0.004309599293987106, 'nr_hidden_layers': 1, 'nr_neurons': 166, 'dropout_rate': 0.0002408001627987319, 'weight_decay': 3.9381024655515715e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 13:02:59,725] Trial 466 pruned. 
[I 2025-11-04 13:03:18,643] Trial 467 pruned. 
[I 2025-11-04 13:04:01,325] Trial 468 pruned. 
[I 2025-11-04 13:04:18,099] Trial 469 pruned. 
[I 2025-11-04 13:04:38,108] Trial 470 pruned. 
2025-11-04 13:06:11,387 - INFO - Trial 471: Early stopping at epoch 62.
[I 2025-11-04 13:06:11,475] Trial 471 finished with value: 0.0071779857035186665 and parameters: {'batch_size': 64, 'learning_rate': 0.0031119497121149717, 'nr_hidden_layers': 1, 'nr_neurons': 146, 'dropout_rate': 0.015362653929050545, 'weight_decay': 0.0002232180481016712, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 13:08:58,312 - INFO - Trial 472: Early stopping at epoch 112.
[I 2025-11-04 13:08:58,402] Trial 472 finished with value: 0.005194833741164531 and parameters: {'batch_size': 64, 'learning_rate': 0.0027698267751866176, 'nr_hidden_layers': 1, 'nr_neurons': 186, 'dropout_rate': 0.009079319077156572, 'weight_decay': 6.8182528275863e-06, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 13:09:23,728] Trial 473 pruned. 
[I 2025-11-04 13:09:31,715] Trial 474 pruned. 
2025-11-04 13:11:46,269 - INFO - Trial 475: Early stopping at epoch 91.
[I 2025-11-04 13:11:46,366] Trial 475 finished with value: 0.006116208349384502 and parameters: {'batch_size': 64, 'learning_rate': 0.0049165968117239455, 'nr_hidden_layers': 1, 'nr_neurons': 134, 'dropout_rate': 0.008162361512804589, 'weight_decay': 0.00013897870369195475, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 13:13:05,683 - INFO - Trial 476: Early stopping at epoch 83.
[I 2025-11-04 13:13:05,774] Trial 476 finished with value: 0.006822223989654923 and parameters: {'batch_size': 128, 'learning_rate': 0.004528148072316665, 'nr_hidden_layers': 1, 'nr_neurons': 212, 'dropout_rate': 0.008473976171413716, 'weight_decay': 0.0001081966612065584, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 13:13:32,103] Trial 477 pruned. 
2025-11-04 13:15:48,809 - INFO - Trial 478: Early stopping at epoch 90.
[I 2025-11-04 13:15:48,911] Trial 478 finished with value: 0.006637897702760346 and parameters: {'batch_size': 64, 'learning_rate': 0.00396957366687169, 'nr_hidden_layers': 1, 'nr_neurons': 153, 'dropout_rate': 0.01881438736635318, 'weight_decay': 7.895344192770737e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 13:20:44,652 - INFO - Trial 479: Early stopping at epoch 190.
[I 2025-11-04 13:20:44,743] Trial 479 finished with value: 0.0025397293361118286 and parameters: {'batch_size': 64, 'learning_rate': 0.0031527569891333027, 'nr_hidden_layers': 1, 'nr_neurons': 165, 'dropout_rate': 0.0009592235889547681, 'weight_decay': 4.230999591951018e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 13:21:06,723] Trial 480 pruned. 
[I 2025-11-04 13:21:13,513] Trial 481 pruned. 
2025-11-04 13:23:05,753 - INFO - Trial 482: Early stopping at epoch 75.
[I 2025-11-04 13:23:05,843] Trial 482 finished with value: 0.006185570139475328 and parameters: {'batch_size': 64, 'learning_rate': 0.0037567706801425443, 'nr_hidden_layers': 1, 'nr_neurons': 193, 'dropout_rate': 0.009217494584505435, 'weight_decay': 2.834123474252683e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 13:23:22,215] Trial 483 pruned. 
2025-11-04 13:24:42,797 - INFO - Trial 484: Early stopping at epoch 53.
[I 2025-11-04 13:24:42,887] Trial 484 finished with value: 0.008420973806880047 and parameters: {'batch_size': 64, 'learning_rate': 0.004325009460950157, 'nr_hidden_layers': 1, 'nr_neurons': 166, 'dropout_rate': 0.016822632651971016, 'weight_decay': 3.544686349316141e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 13:25:03,560] Trial 485 pruned. 
2025-11-04 13:29:32,245 - INFO - Trial 486: Early stopping at epoch 171.
[I 2025-11-04 13:29:32,336] Trial 486 finished with value: 0.0023706382177771626 and parameters: {'batch_size': 64, 'learning_rate': 0.005486079039960543, 'nr_hidden_layers': 1, 'nr_neurons': 177, 'dropout_rate': 0.0002104066323240501, 'weight_decay': 3.912520596776553e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 13:29:51,627] Trial 487 pruned. 
2025-11-04 13:33:27,724 - INFO - Trial 488: Early stopping at epoch 143.
[I 2025-11-04 13:33:27,815] Trial 488 finished with value: 0.001948371682690061 and parameters: {'batch_size': 64, 'learning_rate': 0.006294594791204076, 'nr_hidden_layers': 1, 'nr_neurons': 200, 'dropout_rate': 0.00010018388803775875, 'weight_decay': 3.812937069585117e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 13:33:33,569] Trial 489 pruned. 
2025-11-04 13:36:08,298 - INFO - Trial 490: Early stopping at epoch 103.
[I 2025-11-04 13:36:08,405] Trial 490 finished with value: 0.002832156628934829 and parameters: {'batch_size': 64, 'learning_rate': 0.006338316391751277, 'nr_hidden_layers': 1, 'nr_neurons': 203, 'dropout_rate': 5.210855289515477e-05, 'weight_decay': 3.896084650947436e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 13:36:25,089] Trial 491 pruned. 
[I 2025-11-04 13:36:34,953] Trial 492 pruned. 
2025-11-04 13:39:21,556 - INFO - Trial 493: Early stopping at epoch 111.
[I 2025-11-04 13:39:21,647] Trial 493 finished with value: 0.0030550057293908714 and parameters: {'batch_size': 64, 'learning_rate': 0.006553922518798213, 'nr_hidden_layers': 1, 'nr_neurons': 189, 'dropout_rate': 0.00022182111280085303, 'weight_decay': 3.880357612808135e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 13:39:43,825] Trial 494 pruned. 
2025-11-04 13:41:33,870 - INFO - Trial 495: Early stopping at epoch 71.
[I 2025-11-04 13:41:33,960] Trial 495 finished with value: 0.007504467740568355 and parameters: {'batch_size': 64, 'learning_rate': 0.00711894667103038, 'nr_hidden_layers': 1, 'nr_neurons': 183, 'dropout_rate': 0.016369894396224566, 'weight_decay': 2.026568938220981e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 13:43:51,487 - INFO - Trial 496: Early stopping at epoch 91.
[I 2025-11-04 13:43:51,581] Trial 496 finished with value: 0.005442815419165835 and parameters: {'batch_size': 64, 'learning_rate': 0.005624590257190302, 'nr_hidden_layers': 1, 'nr_neurons': 176, 'dropout_rate': 0.00020501406875000715, 'weight_decay': 4.2311998880582884e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 13:43:58,044] Trial 497 pruned. 
[I 2025-11-04 13:44:28,257] Trial 498 pruned. 
2025-11-04 13:48:39,118 - INFO - Trial 499: Early stopping at epoch 166.
[I 2025-11-04 13:48:39,209] Trial 499 finished with value: 0.0017871857961697364 and parameters: {'batch_size': 64, 'learning_rate': 0.006442208375934627, 'nr_hidden_layers': 1, 'nr_neurons': 218, 'dropout_rate': 7.269356020038828e-05, 'weight_decay': 4.0524329040821994e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 13:49:26,526] Trial 500 pruned. 
[I 2025-11-04 13:49:42,756] Trial 501 pruned. 
[I 2025-11-04 13:49:59,030] Trial 502 pruned. 
[I 2025-11-04 13:50:06,819] Trial 503 pruned. 
[I 2025-11-04 13:50:23,119] Trial 504 pruned. 
2025-11-04 13:53:55,399 - INFO - Trial 505: Early stopping at epoch 139.
[I 2025-11-04 13:53:55,490] Trial 505 finished with value: 0.002437887132809257 and parameters: {'batch_size': 64, 'learning_rate': 0.005339909787536266, 'nr_hidden_layers': 1, 'nr_neurons': 167, 'dropout_rate': 0.00015879765437892325, 'weight_decay': 3.7766149001918e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 13:55:09,396 - INFO - Trial 506: Early stopping at epoch 44.
[I 2025-11-04 13:55:09,491] Trial 506 finished with value: 0.007937924886381008 and parameters: {'batch_size': 64, 'learning_rate': 0.0054148733429762565, 'nr_hidden_layers': 2, 'nr_neurons': 170, 'dropout_rate': 0.009415653602984603, 'weight_decay': 2.5243320526216953e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 13:57:44,043 - INFO - Trial 507: Early stopping at epoch 103.
[I 2025-11-04 13:57:44,133] Trial 507 finished with value: 0.006018503438718856 and parameters: {'batch_size': 64, 'learning_rate': 0.006440673720348107, 'nr_hidden_layers': 1, 'nr_neurons': 183, 'dropout_rate': 0.016529666933475972, 'weight_decay': 0.0010771637295168743, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 13:57:55,376] Trial 508 pruned. 
2025-11-04 14:02:38,948 - INFO - Trial 509: Early stopping at epoch 189.
[I 2025-11-04 14:02:39,040] Trial 509 finished with value: 0.0022204466918250634 and parameters: {'batch_size': 64, 'learning_rate': 0.005150175017962237, 'nr_hidden_layers': 1, 'nr_neurons': 174, 'dropout_rate': 0.0004798060386925511, 'weight_decay': 3.13465844550845e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 14:06:43,505 - INFO - Trial 510: Early stopping at epoch 145.
[I 2025-11-04 14:06:43,600] Trial 510 finished with value: 0.002391485008161875 and parameters: {'batch_size': 64, 'learning_rate': 0.005314975299077778, 'nr_hidden_layers': 1, 'nr_neurons': 171, 'dropout_rate': 3.246043707642193e-05, 'weight_decay': 2.060034829121151e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 14:07:47,690 - INFO - Trial 511: Early stopping at epoch 43.
[I 2025-11-04 14:07:47,781] Trial 511 finished with value: 0.009474738542901652 and parameters: {'batch_size': 64, 'learning_rate': 0.0049698561903764584, 'nr_hidden_layers': 1, 'nr_neurons': 174, 'dropout_rate': 0.034383977360628, 'weight_decay': 1.6259603510380425e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 14:07:54,425] Trial 512 pruned. 
2025-11-04 14:09:42,945 - INFO - Trial 513: Early stopping at epoch 75.
[I 2025-11-04 14:09:43,036] Trial 513 finished with value: 0.007429745541535389 and parameters: {'batch_size': 64, 'learning_rate': 0.007173229379748005, 'nr_hidden_layers': 1, 'nr_neurons': 161, 'dropout_rate': 0.023637277154639966, 'weight_decay': 2.166424831141012e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 14:10:59,091 - INFO - Trial 514: Early stopping at epoch 53.
[I 2025-11-04 14:10:59,180] Trial 514 finished with value: 0.007884634588983313 and parameters: {'batch_size': 64, 'learning_rate': 0.005296722665170603, 'nr_hidden_layers': 1, 'nr_neurons': 178, 'dropout_rate': 0.01682410033644213, 'weight_decay': 1.4737182717169289e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 14:13:36,335 - INFO - Trial 515: Early stopping at epoch 110.
[I 2025-11-04 14:13:36,430] Trial 515 finished with value: 0.003235606426447412 and parameters: {'batch_size': 64, 'learning_rate': 0.00595378969212908, 'nr_hidden_layers': 1, 'nr_neurons': 237, 'dropout_rate': 0.00020469425124085332, 'weight_decay': 2.284270268318826e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 14:14:42,103 - INFO - Trial 516: Early stopping at epoch 46.
[I 2025-11-04 14:14:42,196] Trial 516 finished with value: 0.00837840354615733 and parameters: {'batch_size': 64, 'learning_rate': 0.004865939157965259, 'nr_hidden_layers': 1, 'nr_neurons': 170, 'dropout_rate': 0.00830811268611358, 'weight_decay': 2.737301229657844e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 14:15:46,629 - INFO - Trial 517: Early stopping at epoch 45.
[I 2025-11-04 14:15:46,718] Trial 517 finished with value: 0.008481036795005455 and parameters: {'batch_size': 64, 'learning_rate': 0.005066116440660105, 'nr_hidden_layers': 1, 'nr_neurons': 185, 'dropout_rate': 0.016016173281986183, 'weight_decay': 2.8887199727762388e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 14:15:52,225] Trial 518 pruned. 
2025-11-04 14:18:23,243 - INFO - Trial 519: Early stopping at epoch 107.
[I 2025-11-04 14:18:23,333] Trial 519 finished with value: 0.003409072221337862 and parameters: {'batch_size': 64, 'learning_rate': 0.006340874878451249, 'nr_hidden_layers': 1, 'nr_neurons': 174, 'dropout_rate': 0.00015766145309182694, 'weight_decay': 2.776860960959373e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 14:18:41,666] Trial 520 pruned. 
2025-11-04 14:21:05,744 - INFO - Trial 521: Early stopping at epoch 100.
[I 2025-11-04 14:21:05,835] Trial 521 finished with value: 0.005833371895725791 and parameters: {'batch_size': 64, 'learning_rate': 0.006865907987852272, 'nr_hidden_layers': 1, 'nr_neurons': 202, 'dropout_rate': 0.01724524763029543, 'weight_decay': 1.2805388303887957e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 14:21:12,113] Trial 522 pruned. 
[I 2025-11-04 14:22:01,595] Trial 523 pruned. 
[I 2025-11-04 14:22:15,265] Trial 524 pruned. 
2025-11-04 14:26:46,671 - INFO - Trial 525: Early stopping at epoch 187.
[I 2025-11-04 14:26:46,762] Trial 525 finished with value: 0.0017690659211973606 and parameters: {'batch_size': 64, 'learning_rate': 0.004787357873374585, 'nr_hidden_layers': 1, 'nr_neurons': 171, 'dropout_rate': 0.00011664214235276162, 'weight_decay': 2.0231825470027866e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 14:30:00,049 - INFO - Trial 526: Early stopping at epoch 135.
[I 2025-11-04 14:30:00,140] Trial 526 finished with value: 0.0026293368189866046 and parameters: {'batch_size': 64, 'learning_rate': 0.005544578142844692, 'nr_hidden_layers': 1, 'nr_neurons': 184, 'dropout_rate': 2.626991671877816e-05, 'weight_decay': 1.9696702110377232e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 14:30:15,606] Trial 527 pruned. 
2025-11-04 14:34:00,136 - INFO - Trial 528: Early stopping at epoch 135.
[I 2025-11-04 14:34:00,227] Trial 528 finished with value: 0.004314718775951099 and parameters: {'batch_size': 64, 'learning_rate': 0.006106641223265137, 'nr_hidden_layers': 2, 'nr_neurons': 209, 'dropout_rate': 0.008275125999931063, 'weight_decay': 1.4066626987341517e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 14:34:17,517] Trial 529 pruned. 
2025-11-04 14:36:07,137 - INFO - Trial 530: Early stopping at epoch 72.
[I 2025-11-04 14:36:07,226] Trial 530 finished with value: 0.007204453707555739 and parameters: {'batch_size': 64, 'learning_rate': 0.004743263851573249, 'nr_hidden_layers': 1, 'nr_neurons': 178, 'dropout_rate': 0.025997448466660057, 'weight_decay': 1.7231181468509e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 14:36:22,870] Trial 531 pruned. 
2025-11-04 14:38:35,840 - INFO - Trial 532: Early stopping at epoch 93.
[I 2025-11-04 14:38:35,929] Trial 532 finished with value: 0.00483631593475014 and parameters: {'batch_size': 64, 'learning_rate': 0.006045093774343499, 'nr_hidden_layers': 1, 'nr_neurons': 230, 'dropout_rate': 0.008861505926013076, 'weight_decay': 2.402647805014118e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 14:43:25,595 - INFO - Trial 533: Early stopping at epoch 199.
[I 2025-11-04 14:43:25,689] Trial 533 finished with value: 0.0023505084948709874 and parameters: {'batch_size': 64, 'learning_rate': 0.005718411207200146, 'nr_hidden_layers': 1, 'nr_neurons': 169, 'dropout_rate': 0.0002686463404120939, 'weight_decay': 1.6538889611664194e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
2025-11-04 14:45:41,850 - INFO - Trial 537: Early stopping at epoch 89.
[I 2025-11-04 14:45:41,956] Trial 537 finished with value: 0.006188892823990942 and parameters: {'batch_size': 64, 'learning_rate': 0.006714863108204043, 'nr_hidden_layers': 1, 'nr_neurons': 181, 'dropout_rate': 0.00030411311130190834, 'weight_decay': 1.2665867164233486e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.
[I 2025-11-04 14:49:21,732] Trial 540 pruned. 
2025-11-04 14:53:48,147 - INFO - Trial 544: Early stopping at epoch 179.
[I 2025-11-04 14:53:48,243] Trial 544 finished with value: 0.0023688912005030414 and parameters: {'batch_size': 64, 'learning_rate': 0.005903093017678991, 'nr_hidden_layers': 1, 'nr_neurons': 175, 'dropout_rate': 1.109190962006847e-05, 'weight_decay': 2.0966821644469248e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 192 with value: 0.0016149684023931267.

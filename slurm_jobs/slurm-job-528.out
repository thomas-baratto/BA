Job started on argon-gtx
Job ID: 528
Working directory: /home/barattts/lavoltabuona/BA
---
Starting Python script...
Running: python run_optuna.py --target Iso_width --skip-optuna
2025-11-06 16:54:08,725 - INFO - Using device: cuda
2025-11-06 16:54:08,726 - INFO - Target labels for this run: ['Iso_width']
2025-11-06 16:54:08,726 - INFO - Skip Optuna: True
2025-11-06 16:54:08,727 - INFO - Skipping Optuna. Loading best parameters from study: nn_study_['Iso_width']...
2025-11-06 16:54:09,562 - INFO - Loaded best parameters from trial 1616:
2025-11-06 16:54:09,584 - INFO - Best value (RMSE): 0.0011460189707577229
2025-11-06 16:54:09,584 - INFO - Parameters: {'batch_size': 64, 'learning_rate': 0.003384871040990215, 'nr_hidden_layers': 1, 'nr_neurons': 112, 'dropout_rate': 0.00014697292771531992, 'weight_decay': 4.3897138187438567e-05, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}
2025-11-06 16:54:09,584 - INFO - Training final model with parameters...
2025-11-06 16:54:09,584 - INFO - Starting main training for labels ['Iso_width']...
2025-11-06 16:54:10,636 - INFO - Final training: 47896 train samples, 11975 val samples, 25660 test samples.
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
2025-11-06 16:54:10,978 - INFO - Using SmoothL1Loss (Huber Loss)
2025-11-06 16:54:12,947 - INFO - Using CosineAnnealingLR with T_max=1000
2025-11-06 16:54:13,009 - INFO - Starting final training loop for max 1000 epochs (Patience=25)...
2025-11-06 16:54:14,544 - INFO - Epoch [1/1000], Train Loss: 0.004145, Val Loss: 0.002677, LR: 0.003385
2025-11-06 16:54:14,545 - INFO - New best model found at epoch 1 with val_loss: 0.002677
2025-11-06 16:54:15,957 - INFO - New best model found at epoch 2 with val_loss: 0.000895
2025-11-06 16:54:17,378 - INFO - New best model found at epoch 3 with val_loss: 0.000561
2025-11-06 16:54:18,791 - INFO - New best model found at epoch 4 with val_loss: 0.000349
2025-11-06 16:54:20,201 - INFO - New best model found at epoch 5 with val_loss: 0.000277
2025-11-06 16:54:21,610 - INFO - New best model found at epoch 6 with val_loss: 0.000193
2025-11-06 16:54:24,443 - INFO - New best model found at epoch 8 with val_loss: 0.000149
2025-11-06 16:54:25,854 - INFO - New best model found at epoch 9 with val_loss: 0.000107
2025-11-06 16:54:27,267 - INFO - New best model found at epoch 10 with val_loss: 0.000093
2025-11-06 16:54:31,496 - INFO - New best model found at epoch 13 with val_loss: 0.000076
2025-11-06 16:54:32,904 - INFO - New best model found at epoch 14 with val_loss: 0.000062
2025-11-06 16:54:34,318 - INFO - New best model found at epoch 15 with val_loss: 0.000053
2025-11-06 16:54:38,537 - INFO - New best model found at epoch 18 with val_loss: 0.000053
2025-11-06 16:54:41,360 - INFO - New best model found at epoch 20 with val_loss: 0.000052
2025-11-06 16:54:42,766 - INFO - New best model found at epoch 21 with val_loss: 0.000031
2025-11-06 16:54:44,181 - INFO - New best model found at epoch 22 with val_loss: 0.000026
2025-11-06 16:54:52,624 - INFO - New best model found at epoch 28 with val_loss: 0.000025
2025-11-06 16:55:02,504 - INFO - New best model found at epoch 35 with val_loss: 0.000023
2025-11-06 16:55:08,160 - INFO - New best model found at epoch 39 with val_loss: 0.000022
2025-11-06 16:55:12,391 - INFO - New best model found at epoch 42 with val_loss: 0.000016
2025-11-06 16:55:23,607 - INFO - Epoch [50/1000], Train Loss: 0.000043, Val Loss: 0.000081, LR: 0.003364
2025-11-06 16:55:47,553 - INFO - Early stopping at epoch 67.
2025-11-06 16:55:47,554 - INFO - Training complete. Evaluating on test set...
2025-11-06 16:55:47,843 - INFO - Final Test Loss (SmoothL1): 0.000017
2025-11-06 16:55:47,843 - INFO - Inverting transforms and generating plots...
2025-11-06 16:55:47,845 - INFO - Calculating final metrics...
2025-11-06 16:55:47,852 - INFO - Final Test MAE (unscaled): 0.745057
2025-11-06 16:55:47,852 - INFO - Final Test RMSE (unscaled): 1.537926
2025-11-06 16:55:47,853 - INFO - Final Test R2 (unscaled): 0.998433
2025-11-06 16:55:47,853 - INFO - Final Test MEDAE (unscaled): 0.330624
2025-11-06 16:55:47,853 - INFO - Final Test MAPE (unscaled): 0.021417
2025-11-06 16:55:47,853 - INFO - Final Test REL_ERR_STD (unscaled): 0.055590
2025-11-06 16:55:47,853 - INFO - Final Test REL_ERR_MEAN_ABS (unscaled): 0.021417
2025-11-06 16:55:48,744 - INFO - Logging scatter plots to tensorboard...
2025-11-06 16:55:48,908 - INFO - Main training function finished.
2025-11-06 16:55:48,911 - INFO - Final model saved to runs/run_20251106-165408_['Iso_width']/final_model/best_model.pt
2025-11-06 16:55:48,911 - INFO - --- Run complete ---
2025-11-06 16:55:48,911 - INFO - To view Optuna results: optuna-dashboard sqlite:///runs/optuna_study.db
2025-11-06 16:55:48,911 - INFO - To view TensorBoard logs: tensorboard --logdir runs/run_20251106-165408_['Iso_width']/
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [64, 1]                   --
├─ModuleList: 1-5                        --                        (recursive)
│    └─Linear: 2-1                       [64, 112]                 1,120
│    └─GELU: 2-2                         [64, 112]                 --
├─Dropout: 1-2                           [64, 112]                 --
├─ModuleList: 1-5                        --                        (recursive)
│    └─Linear: 2-3                       [64, 112]                 12,656
│    └─GELU: 2-4                         [64, 112]                 --
├─Dropout: 1-4                           [64, 112]                 --
├─ModuleList: 1-5                        --                        (recursive)
│    └─Linear: 2-5                       [64, 1]                   113
==========================================================================================
Total params: 13,889
Trainable params: 13,889
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 0.89
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.12
Params size (MB): 0.06
Estimated Total Size (MB): 0.17
==========================================================================================
Job finished.

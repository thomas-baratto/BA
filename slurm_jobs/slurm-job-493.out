Job started on argon-gtx
Job ID: 493
Working directory: /home/barattts/lavoltabuona/BA
---
Starting Python script...
Running: python run_optuna.py --target Area
2025-11-04 00:09:53,684 - INFO - Using device: cuda
2025-11-04 00:09:53,685 - INFO - Target labels for this run: ['Area']
2025-11-04 00:09:53,686 - INFO - Loading data for Optuna study (Labels: ['Area'])...
2025-11-04 00:09:53,860 - INFO - Starting Optuna study: nn_study_['Area']...
[I 2025-11-04 00:09:54,591] A new study created in RDB with name: nn_study_['Area']
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
2025-11-04 00:10:53,127 - INFO - Trial 0: Early stopping at epoch 75.
[I 2025-11-04 00:10:53,202] Trial 0 finished with value: 0.035749769969930394 and parameters: {'batch_size': 256, 'learning_rate': 0.009016125163078821, 'nr_hidden_layers': 1, 'nr_neurons': 60, 'dropout_rate': 0.23807797919397783, 'weight_decay': 7.755637407349951e-05, 'activation_name': 'ReLU', 'loss_criterion': 'L1'}. Best is trial 0 with value: 0.035749769969930394.
2025-11-04 00:14:05,820 - INFO - Trial 1: Early stopping at epoch 85.
[I 2025-11-04 00:14:05,883] Trial 1 finished with value: 0.031294745954180865 and parameters: {'batch_size': 64, 'learning_rate': 0.003300155395325728, 'nr_hidden_layers': 4, 'nr_neurons': 27, 'dropout_rate': 0.19008484461865144, 'weight_decay': 0.0012381884749605603, 'activation_name': 'ELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1 with value: 0.031294745954180865.
2025-11-04 00:14:29,379 - INFO - Trial 2: Early stopping at epoch 46.
[I 2025-11-04 00:14:29,442] Trial 2 finished with value: 0.07667727188215345 and parameters: {'batch_size': 1024, 'learning_rate': 0.0050030733342068005, 'nr_hidden_layers': 2, 'nr_neurons': 85, 'dropout_rate': 0.44157495008421754, 'weight_decay': 1.2913128306788412e-06, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 1 with value: 0.031294745954180865.
2025-11-04 00:16:58,074 - INFO - Trial 3: Early stopping at epoch 248.
[I 2025-11-04 00:16:58,139] Trial 3 finished with value: 0.019337290809214716 and parameters: {'batch_size': 4096, 'learning_rate': 0.0018977630217570473, 'nr_hidden_layers': 2, 'nr_neurons': 45, 'dropout_rate': 0.021164876517663467, 'weight_decay': 9.960120880667705e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 3 with value: 0.019337290809214716.
2025-11-04 00:18:29,523 - INFO - Trial 4: Early stopping at epoch 149.
[I 2025-11-04 00:18:29,587] Trial 4 finished with value: 0.06635411754630789 and parameters: {'batch_size': 4096, 'learning_rate': 0.0009899520939574385, 'nr_hidden_layers': 5, 'nr_neurons': 115, 'dropout_rate': 0.480019316264429, 'weight_decay': 0.0010503317864734923, 'activation_name': 'LeakyReLU', 'loss_criterion': 'L1'}. Best is trial 3 with value: 0.019337290809214716.
[I 2025-11-04 00:18:51,253] Trial 5 pruned. 
[I 2025-11-04 00:19:11,954] Trial 6 pruned. 
[I 2025-11-04 00:19:19,620] Trial 7 pruned. 
[I 2025-11-04 00:19:34,028] Trial 8 pruned. 
[I 2025-11-04 00:19:40,983] Trial 9 pruned. 
2025-11-04 00:22:33,249 - INFO - Trial 10: Early stopping at epoch 289.
[I 2025-11-04 00:22:33,315] Trial 10 finished with value: 0.004689004131791803 and parameters: {'batch_size': 512, 'learning_rate': 0.0003576479862300152, 'nr_hidden_layers': 3, 'nr_neurons': 252, 'dropout_rate': 0.0034279678304202574, 'weight_decay': 1.6731065005342427e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:25:02,958] Trial 11 pruned. 
[I 2025-11-04 00:27:31,919] Trial 12 pruned. 
[I 2025-11-04 00:27:39,056] Trial 13 pruned. 
[I 2025-11-04 00:27:45,759] Trial 14 pruned. 
[I 2025-11-04 00:27:57,740] Trial 15 pruned. 
[I 2025-11-04 00:28:04,293] Trial 16 pruned. 
2025-11-04 00:28:31,989 - INFO - Trial 17: Early stopping at epoch 44.
[I 2025-11-04 00:28:32,053] Trial 17 finished with value: 0.02668837998253483 and parameters: {'batch_size': 512, 'learning_rate': 0.00200574202675297, 'nr_hidden_layers': 4, 'nr_neurons': 137, 'dropout_rate': 0.1643321822085001, 'weight_decay': 3.2244655313163954e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:28:38,549] Trial 18 pruned. 
[I 2025-11-04 00:28:45,337] Trial 19 pruned. 
2025-11-04 00:30:05,296 - INFO - Trial 20: Early stopping at epoch 39.
[I 2025-11-04 00:30:05,360] Trial 20 finished with value: 0.02055037076093636 and parameters: {'batch_size': 64, 'learning_rate': 0.002822734795569483, 'nr_hidden_layers': 4, 'nr_neurons': 24, 'dropout_rate': 0.038521364959144426, 'weight_decay': 9.656260003010475e-06, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 00:32:13,246 - INFO - Trial 21: Early stopping at epoch 64.
[I 2025-11-04 00:32:13,311] Trial 21 finished with value: 0.03290500635949219 and parameters: {'batch_size': 64, 'learning_rate': 0.0027017770947404657, 'nr_hidden_layers': 4, 'nr_neurons': 25, 'dropout_rate': 0.04006587901320264, 'weight_decay': 9.997177738598509e-06, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:32:35,121] Trial 22 pruned. 
2025-11-04 00:33:54,975 - INFO - Trial 23: Early stopping at epoch 43.
[I 2025-11-04 00:33:55,039] Trial 23 finished with value: 0.01815448294955144 and parameters: {'batch_size': 64, 'learning_rate': 0.0032413442452322435, 'nr_hidden_layers': 3, 'nr_neurons': 36, 'dropout_rate': 0.03223890326310175, 'weight_decay': 8.048639940165234e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:34:00,702] Trial 24 pruned. 
2025-11-04 00:34:35,999 - INFO - Trial 25: Early stopping at epoch 34.
[I 2025-11-04 00:34:36,063] Trial 25 finished with value: 0.032181580173324294 and parameters: {'batch_size': 128, 'learning_rate': 0.005250603906484106, 'nr_hidden_layers': 2, 'nr_neurons': 65, 'dropout_rate': 0.12483833757244049, 'weight_decay': 0.0002334607806841194, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:34:44,605] Trial 26 pruned. 
[I 2025-11-04 00:34:51,299] Trial 27 pruned. 
[I 2025-11-04 00:34:57,910] Trial 28 pruned. 
[I 2025-11-04 00:35:06,477] Trial 29 pruned. 
2025-11-04 00:36:33,217 - INFO - Trial 30: Early stopping at epoch 56.
[I 2025-11-04 00:36:33,282] Trial 30 finished with value: 0.024375665988749254 and parameters: {'batch_size': 64, 'learning_rate': 0.0013042096043300885, 'nr_hidden_layers': 1, 'nr_neurons': 42, 'dropout_rate': 0.09937690200626542, 'weight_decay': 0.00011829851906110353, 'activation_name': 'LeakyReLU', 'loss_criterion': 'L1'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 00:37:45,906 - INFO - Trial 31: Early stopping at epoch 36.
[I 2025-11-04 00:37:45,970] Trial 31 finished with value: 0.037499791196897454 and parameters: {'batch_size': 64, 'learning_rate': 0.002581499772944735, 'nr_hidden_layers': 4, 'nr_neurons': 25, 'dropout_rate': 0.03503317760722291, 'weight_decay': 1.3870877416127663e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 00:39:00,768 - INFO - Trial 32: Early stopping at epoch 37.
[I 2025-11-04 00:39:00,833] Trial 32 finished with value: 0.02105497404489175 and parameters: {'batch_size': 64, 'learning_rate': 0.0035871952442170707, 'nr_hidden_layers': 4, 'nr_neurons': 30, 'dropout_rate': 0.039719664220714324, 'weight_decay': 5.342399097430212e-06, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 00:39:58,610 - INFO - Trial 33: Early stopping at epoch 31.
[I 2025-11-04 00:39:58,676] Trial 33 finished with value: 0.030991650502062824 and parameters: {'batch_size': 64, 'learning_rate': 0.006558055365412014, 'nr_hidden_layers': 3, 'nr_neurons': 21, 'dropout_rate': 0.06471093401759384, 'weight_decay': 3.2639562988860565e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 00:41:53,207 - INFO - Trial 34: Early stopping at epoch 65.
[I 2025-11-04 00:41:53,272] Trial 34 finished with value: 0.012222118590791886 and parameters: {'batch_size': 64, 'learning_rate': 0.004020115108666063, 'nr_hidden_layers': 2, 'nr_neurons': 36, 'dropout_rate': 0.02080395902183351, 'weight_decay': 0.00033740902582556754, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 00:44:58,471 - INFO - Trial 35: Early stopping at epoch 108.
[I 2025-11-04 00:44:58,538] Trial 35 finished with value: 0.004979796530784249 and parameters: {'batch_size': 64, 'learning_rate': 0.0041734612545766235, 'nr_hidden_layers': 2, 'nr_neurons': 35, 'dropout_rate': 0.0005827800451096723, 'weight_decay': 0.0004432949008140396, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:45:14,945] Trial 36 pruned. 
2025-11-04 00:47:39,282 - INFO - Trial 37: Early stopping at epoch 81.
[I 2025-11-04 00:47:39,349] Trial 37 finished with value: 0.008764194948981825 and parameters: {'batch_size': 64, 'learning_rate': 0.006278046770594711, 'nr_hidden_layers': 2, 'nr_neurons': 74, 'dropout_rate': 0.0029553317684507955, 'weight_decay': 0.0006196207726527797, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 00:51:09,201 - INFO - Trial 38: Early stopping at epoch 124.
[I 2025-11-04 00:51:09,269] Trial 38 finished with value: 0.010495615624966158 and parameters: {'batch_size': 64, 'learning_rate': 0.0072093089065830744, 'nr_hidden_layers': 2, 'nr_neurons': 85, 'dropout_rate': 0.015284386004772083, 'weight_decay': 0.0005713597158153313, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:51:14,900] Trial 39 pruned. 
[I 2025-11-04 00:51:33,466] Trial 40 pruned. 
2025-11-04 00:53:11,232 - INFO - Trial 41: Early stopping at epoch 55.
[I 2025-11-04 00:53:11,299] Trial 41 finished with value: 0.011212591267769018 and parameters: {'batch_size': 64, 'learning_rate': 0.005166373080197459, 'nr_hidden_layers': 2, 'nr_neurons': 74, 'dropout_rate': 0.01690519596901954, 'weight_decay': 0.0004027445141342534, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:53:30,831] Trial 42 pruned. 
2025-11-04 00:55:48,890 - INFO - Trial 43: Early stopping at epoch 75.
[I 2025-11-04 00:55:48,958] Trial 43 finished with value: 0.007167822506400849 and parameters: {'batch_size': 64, 'learning_rate': 0.0053833509595159505, 'nr_hidden_layers': 2, 'nr_neurons': 58, 'dropout_rate': 0.0006870053084942606, 'weight_decay': 0.0018844739879813478, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:56:05,321] Trial 44 pruned. 
[I 2025-11-04 00:56:11,848] Trial 45 pruned. 
2025-11-04 00:57:22,846 - INFO - Trial 46: Early stopping at epoch 74.
[I 2025-11-04 00:57:22,914] Trial 46 finished with value: 0.01126259634609033 and parameters: {'batch_size': 128, 'learning_rate': 0.004822128963247764, 'nr_hidden_layers': 1, 'nr_neurons': 147, 'dropout_rate': 0.004293888509268175, 'weight_decay': 0.0016533641225604414, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:57:31,056] Trial 47 pruned. 
[I 2025-11-04 00:57:49,245] Trial 48 pruned. 
[I 2025-11-04 00:57:54,927] Trial 49 pruned. 
[I 2025-11-04 00:58:01,127] Trial 50 pruned. 
2025-11-04 00:59:49,303 - INFO - Trial 51: Early stopping at epoch 64.
[I 2025-11-04 00:59:49,372] Trial 51 finished with value: 0.011265501807272699 and parameters: {'batch_size': 64, 'learning_rate': 0.004443239710541873, 'nr_hidden_layers': 2, 'nr_neurons': 76, 'dropout_rate': 0.02444743918879138, 'weight_decay': 0.0005862722202639245, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:02:22,849 - INFO - Trial 52: Early stopping at epoch 91.
[I 2025-11-04 01:02:22,930] Trial 52 finished with value: 0.00741173664851813 and parameters: {'batch_size': 64, 'learning_rate': 0.00565444403411108, 'nr_hidden_layers': 2, 'nr_neurons': 73, 'dropout_rate': 0.002583495732458004, 'weight_decay': 0.00029818744136979493, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:03:22,901 - INFO - Trial 53: Early stopping at epoch 35.
[I 2025-11-04 01:03:22,967] Trial 53 finished with value: 0.01632947366765145 and parameters: {'batch_size': 64, 'learning_rate': 0.00800972041593068, 'nr_hidden_layers': 2, 'nr_neurons': 189, 'dropout_rate': 0.0019068058792489169, 'weight_decay': 0.00026845202205454886, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 01:03:41,299] Trial 54 pruned. 
[I 2025-11-04 01:04:01,672] Trial 55 pruned. 
[I 2025-11-04 01:04:08,978] Trial 56 pruned. 
[I 2025-11-04 01:04:27,833] Trial 57 pruned. 
[I 2025-11-04 01:05:09,378] Trial 58 pruned. 
[I 2025-11-04 01:05:27,512] Trial 59 pruned. 
[I 2025-11-04 01:05:34,300] Trial 60 pruned. 
2025-11-04 01:07:21,503 - INFO - Trial 61: Early stopping at epoch 63.
[I 2025-11-04 01:07:21,570] Trial 61 finished with value: 0.012677507454716467 and parameters: {'batch_size': 64, 'learning_rate': 0.005071284568358476, 'nr_hidden_layers': 2, 'nr_neurons': 72, 'dropout_rate': 0.02167105066474505, 'weight_decay': 0.0004261216115083767, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:08:39,418 - INFO - Trial 62: Early stopping at epoch 45.
[I 2025-11-04 01:08:39,492] Trial 62 finished with value: 0.014164474359181441 and parameters: {'batch_size': 64, 'learning_rate': 0.005449309688452028, 'nr_hidden_layers': 2, 'nr_neurons': 128, 'dropout_rate': 0.01751448122552368, 'weight_decay': 0.0003448711822496446, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 01:09:00,587] Trial 63 pruned. 
[I 2025-11-04 01:10:34,199] Trial 64 pruned. 
[I 2025-11-04 01:10:41,147] Trial 65 pruned. 
2025-11-04 01:13:24,692 - INFO - Trial 66: Early stopping at epoch 85.
[I 2025-11-04 01:13:24,790] Trial 66 finished with value: 0.010218125383404783 and parameters: {'batch_size': 64, 'learning_rate': 0.004609042108051847, 'nr_hidden_layers': 3, 'nr_neurons': 86, 'dropout_rate': 0.0145289810428243, 'weight_decay': 0.00047523220523546937, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 01:13:33,451] Trial 67 pruned. 
[I 2025-11-04 01:13:39,263] Trial 68 pruned. 
2025-11-04 01:16:16,143 - INFO - Trial 69: Early stopping at epoch 84.
[I 2025-11-04 01:16:16,232] Trial 69 finished with value: 0.01086981736942098 and parameters: {'batch_size': 64, 'learning_rate': 0.006145976804819801, 'nr_hidden_layers': 3, 'nr_neurons': 29, 'dropout_rate': 0.013106638463449038, 'weight_decay': 0.000293333093129812, 'activation_name': 'ELU', 'loss_criterion': 'L1'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 01:16:36,514] Trial 70 pruned. 
[I 2025-11-04 01:16:57,026] Trial 71 pruned. 
[I 2025-11-04 01:17:17,525] Trial 72 pruned. 
[I 2025-11-04 01:17:38,057] Trial 73 pruned. 
[I 2025-11-04 01:17:58,989] Trial 74 pruned. 
[I 2025-11-04 01:18:05,953] Trial 75 pruned. 
[I 2025-11-04 01:18:25,954] Trial 76 pruned. 
[I 2025-11-04 01:18:38,889] Trial 77 pruned. 
[I 2025-11-04 01:18:57,210] Trial 78 pruned. 
[I 2025-11-04 01:19:03,810] Trial 79 pruned. 
[I 2025-11-04 01:19:47,834] Trial 80 pruned. 
2025-11-04 01:22:08,914 - INFO - Trial 81: Early stopping at epoch 77.
[I 2025-11-04 01:22:08,983] Trial 81 finished with value: 0.009502350398498614 and parameters: {'batch_size': 64, 'learning_rate': 0.005204308661719575, 'nr_hidden_layers': 2, 'nr_neurons': 75, 'dropout_rate': 0.013476961249045369, 'weight_decay': 0.00022024634885837974, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 01:24:27,365] Trial 82 pruned. 
2025-11-04 01:26:43,788 - INFO - Trial 83: Early stopping at epoch 79.
[I 2025-11-04 01:26:43,857] Trial 83 finished with value: 0.009364126121722029 and parameters: {'batch_size': 64, 'learning_rate': 0.004948751975995237, 'nr_hidden_layers': 2, 'nr_neurons': 81, 'dropout_rate': 0.010021850737912794, 'weight_decay': 0.0002208055350192952, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:29:19,625 - INFO - Trial 84: Early stopping at epoch 90.
[I 2025-11-04 01:29:19,693] Trial 84 finished with value: 0.006162903761611697 and parameters: {'batch_size': 64, 'learning_rate': 0.00452326204663678, 'nr_hidden_layers': 2, 'nr_neurons': 66, 'dropout_rate': 0.0014938747048781557, 'weight_decay': 0.0002277747889153851, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:30:17,084 - INFO - Trial 85: Early stopping at epoch 78.
[I 2025-11-04 01:30:17,154] Trial 85 finished with value: 0.01054564417505071 and parameters: {'batch_size': 256, 'learning_rate': 0.0039842014659445335, 'nr_hidden_layers': 2, 'nr_neurons': 64, 'dropout_rate': 0.034230853451379904, 'weight_decay': 0.0002325499738374975, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:33:46,354 - INFO - Trial 86: Early stopping at epoch 119.
[I 2025-11-04 01:33:46,435] Trial 86 finished with value: 0.004845462943705086 and parameters: {'batch_size': 64, 'learning_rate': 0.004718388264689828, 'nr_hidden_layers': 2, 'nr_neurons': 58, 'dropout_rate': 0.0009107920547347915, 'weight_decay': 0.00020579632563979226, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 01:33:52,932] Trial 87 pruned. 
2025-11-04 01:34:49,165 - INFO - Trial 88: Early stopping at epoch 33.
[I 2025-11-04 01:34:49,233] Trial 88 finished with value: 0.02276487449364223 and parameters: {'batch_size': 64, 'learning_rate': 0.005102392309293798, 'nr_hidden_layers': 2, 'nr_neurons': 57, 'dropout_rate': 0.05798156601761428, 'weight_decay': 8.798667178708091e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 01:34:54,826] Trial 89 pruned. 
2025-11-04 01:36:48,225 - INFO - Trial 90: Early stopping at epoch 67.
[I 2025-11-04 01:36:48,293] Trial 90 finished with value: 0.0047237867722510745 and parameters: {'batch_size': 64, 'learning_rate': 0.0029799526063421264, 'nr_hidden_layers': 2, 'nr_neurons': 77, 'dropout_rate': 0.00043522626244629336, 'weight_decay': 0.00013174370535188885, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:40:08,621 - INFO - Trial 91: Early stopping at epoch 116.
[I 2025-11-04 01:40:08,691] Trial 91 finished with value: 0.008514206894257722 and parameters: {'batch_size': 64, 'learning_rate': 0.004033332060203114, 'nr_hidden_layers': 2, 'nr_neurons': 72, 'dropout_rate': 0.04613337286495889, 'weight_decay': 0.0001569439380893175, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:41:39,044 - INFO - Trial 92: Early stopping at epoch 53.
[I 2025-11-04 01:41:39,111] Trial 92 finished with value: 0.005924951578776709 and parameters: {'batch_size': 64, 'learning_rate': 0.0029499672961390663, 'nr_hidden_layers': 2, 'nr_neurons': 59, 'dropout_rate': 0.002620971376684228, 'weight_decay': 0.00013720696108329746, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:43:44,967 - INFO - Trial 93: Early stopping at epoch 61.
[I 2025-11-04 01:43:45,036] Trial 93 finished with value: 0.005402659190637144 and parameters: {'batch_size': 64, 'learning_rate': 0.002616623111956819, 'nr_hidden_layers': 2, 'nr_neurons': 52, 'dropout_rate': 0.0010237460157118965, 'weight_decay': 0.00014066384833106655, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:46:02,630 - INFO - Trial 94: Early stopping at epoch 80.
[I 2025-11-04 01:46:02,698] Trial 94 finished with value: 0.009382244241166637 and parameters: {'batch_size': 64, 'learning_rate': 0.0026363317532335073, 'nr_hidden_layers': 2, 'nr_neurons': 50, 'dropout_rate': 0.04561385987865024, 'weight_decay': 3.923282149056476e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:48:35,986 - INFO - Trial 95: Early stopping at epoch 92.
[I 2025-11-04 01:48:36,057] Trial 95 finished with value: 0.006775442522869566 and parameters: {'batch_size': 64, 'learning_rate': 0.0023991170362209556, 'nr_hidden_layers': 2, 'nr_neurons': 61, 'dropout_rate': 0.024957501440953954, 'weight_decay': 0.00012917593254634606, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:51:02,866 - INFO - Trial 96: Early stopping at epoch 88.
[I 2025-11-04 01:51:02,934] Trial 96 finished with value: 0.009067207205309073 and parameters: {'batch_size': 64, 'learning_rate': 0.0029393353712905035, 'nr_hidden_layers': 2, 'nr_neurons': 59, 'dropout_rate': 0.025939048896244668, 'weight_decay': 9.90263549973223e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 01:51:09,496] Trial 97 pruned. 
[I 2025-11-04 01:51:29,327] Trial 98 pruned. 
[I 2025-11-04 01:51:41,574] Trial 99 pruned. 
2025-11-04 01:56:19,491 - INFO - Trial 100: Early stopping at epoch 163.
[I 2025-11-04 01:56:19,560] Trial 100 finished with value: 0.0032998721685287497 and parameters: {'batch_size': 64, 'learning_rate': 0.0023312005069114692, 'nr_hidden_layers': 2, 'nr_neurons': 55, 'dropout_rate': 0.0017446243680497653, 'weight_decay': 0.00010501615088689511, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 100 with value: 0.0032998721685287497.
2025-11-04 02:01:50,254 - INFO - Trial 101: Early stopping at epoch 190.
[I 2025-11-04 02:01:50,324] Trial 101 finished with value: 0.0023265188406348886 and parameters: {'batch_size': 64, 'learning_rate': 0.0023390828789765024, 'nr_hidden_layers': 2, 'nr_neurons': 54, 'dropout_rate': 0.00044278800831537985, 'weight_decay': 0.00012825891380511265, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:04:26,098 - INFO - Trial 102: Early stopping at epoch 89.
[I 2025-11-04 02:04:26,167] Trial 102 finished with value: 0.006917551973994787 and parameters: {'batch_size': 64, 'learning_rate': 0.00235941647201057, 'nr_hidden_layers': 2, 'nr_neurons': 55, 'dropout_rate': 0.025302043722443428, 'weight_decay': 0.00010547308369133812, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:06:18,369 - INFO - Trial 103: Early stopping at epoch 67.
[I 2025-11-04 02:06:18,439] Trial 103 finished with value: 0.008046679136319559 and parameters: {'batch_size': 64, 'learning_rate': 0.0023213419206991304, 'nr_hidden_layers': 2, 'nr_neurons': 54, 'dropout_rate': 0.02527769111992276, 'weight_decay': 9.802508701670548e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
[I 2025-11-04 02:06:37,680] Trial 104 pruned. 
2025-11-04 02:11:10,947 - INFO - Trial 105: Early stopping at epoch 153.
[I 2025-11-04 02:11:11,028] Trial 105 finished with value: 0.004636311204876732 and parameters: {'batch_size': 64, 'learning_rate': 0.0025420203497147995, 'nr_hidden_layers': 2, 'nr_neurons': 51, 'dropout_rate': 0.010421381319345387, 'weight_decay': 0.00013844467086820484, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
[I 2025-11-04 02:11:17,832] Trial 106 pruned. 
[I 2025-11-04 02:11:36,063] Trial 107 pruned. 
2025-11-04 02:13:15,106 - INFO - Trial 108: Early stopping at epoch 58.
[I 2025-11-04 02:13:15,175] Trial 108 finished with value: 0.0071875664013731555 and parameters: {'batch_size': 64, 'learning_rate': 0.0031969230139682584, 'nr_hidden_layers': 2, 'nr_neurons': 46, 'dropout_rate': 0.008851171412884126, 'weight_decay': 7.254474246020022e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
[I 2025-11-04 02:13:23,322] Trial 109 pruned. 
2025-11-04 02:16:43,732 - INFO - Trial 110: Early stopping at epoch 117.
[I 2025-11-04 02:16:43,816] Trial 110 finished with value: 0.006477506476317011 and parameters: {'batch_size': 64, 'learning_rate': 0.0024709181971400494, 'nr_hidden_layers': 2, 'nr_neurons': 43, 'dropout_rate': 0.0207301813388809, 'weight_decay': 0.00018178374474970654, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:19:49,518 - INFO - Trial 111: Early stopping at epoch 110.
[I 2025-11-04 02:19:49,588] Trial 111 finished with value: 0.005051724567874063 and parameters: {'batch_size': 64, 'learning_rate': 0.002493087534468591, 'nr_hidden_layers': 2, 'nr_neurons': 43, 'dropout_rate': 0.009074417042007973, 'weight_decay': 0.00014032216950454526, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:23:57,128 - INFO - Trial 112: Early stopping at epoch 133.
[I 2025-11-04 02:23:57,200] Trial 112 finished with value: 0.004997883094544792 and parameters: {'batch_size': 64, 'learning_rate': 0.0030233010826053943, 'nr_hidden_layers': 2, 'nr_neurons': 32, 'dropout_rate': 0.009661431808602359, 'weight_decay': 0.00017456806655071999, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
[I 2025-11-04 02:24:15,459] Trial 113 pruned. 
2025-11-04 02:26:17,414 - INFO - Trial 114: Early stopping at epoch 73.
[I 2025-11-04 02:26:17,485] Trial 114 finished with value: 0.007030236606618 and parameters: {'batch_size': 64, 'learning_rate': 0.00334377630052309, 'nr_hidden_layers': 2, 'nr_neurons': 39, 'dropout_rate': 0.00862227983213973, 'weight_decay': 0.00015932522868261477, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:29:13,739 - INFO - Trial 115: Early stopping at epoch 101.
[I 2025-11-04 02:29:13,811] Trial 115 finished with value: 0.004782343992639545 and parameters: {'batch_size': 64, 'learning_rate': 0.0017568861322056792, 'nr_hidden_layers': 2, 'nr_neurons': 34, 'dropout_rate': 0.00013025372621462336, 'weight_decay': 0.00024845125648620457, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
[I 2025-11-04 02:29:20,382] Trial 116 pruned. 
[I 2025-11-04 02:29:26,115] Trial 117 pruned. 
[I 2025-11-04 02:29:44,392] Trial 118 pruned. 
[I 2025-11-04 02:30:07,736] Trial 119 pruned. 
[I 2025-11-04 02:30:27,501] Trial 120 pruned. 
2025-11-04 02:33:59,982 - INFO - Trial 121: Early stopping at epoch 127.
[I 2025-11-04 02:34:00,053] Trial 121 finished with value: 0.005390370554777885 and parameters: {'batch_size': 64, 'learning_rate': 0.003085721892881456, 'nr_hidden_layers': 2, 'nr_neurons': 31, 'dropout_rate': 0.006924210984187683, 'weight_decay': 0.000183957560260274, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:36:16,320 - INFO - Trial 122: Early stopping at epoch 72.
[I 2025-11-04 02:36:16,402] Trial 122 finished with value: 0.006455042939678133 and parameters: {'batch_size': 64, 'learning_rate': 0.003745324126369997, 'nr_hidden_layers': 2, 'nr_neurons': 31, 'dropout_rate': 0.009022137196809742, 'weight_decay': 0.00018433894018609297, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:40:05,324 - INFO - Trial 123: Early stopping at epoch 136.
[I 2025-11-04 02:40:05,396] Trial 123 finished with value: 0.002832973630190867 and parameters: {'batch_size': 64, 'learning_rate': 0.0030307269209414994, 'nr_hidden_layers': 2, 'nr_neurons': 44, 'dropout_rate': 0.00023200087517106892, 'weight_decay': 0.00011705061132780218, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:42:51,955 - INFO - Trial 124: Early stopping at epoch 100.
[I 2025-11-04 02:42:52,026] Trial 124 finished with value: 0.0036322685470643375 and parameters: {'batch_size': 64, 'learning_rate': 0.0031208093216095185, 'nr_hidden_layers': 2, 'nr_neurons': 44, 'dropout_rate': 0.00015756472139532337, 'weight_decay': 0.00017767597524348454, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:44:47,776 - INFO - Trial 125: Early stopping at epoch 69.
[I 2025-11-04 02:44:47,855] Trial 125 finished with value: 0.008954958971467402 and parameters: {'batch_size': 64, 'learning_rate': 0.0031991747554740665, 'nr_hidden_layers': 2, 'nr_neurons': 44, 'dropout_rate': 0.021442051596666806, 'weight_decay': 0.0003115451560796026, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
[I 2025-11-04 02:45:06,077] Trial 126 pruned. 
[I 2025-11-04 02:45:24,370] Trial 127 pruned. 
[I 2025-11-04 02:45:42,623] Trial 128 pruned. 
[I 2025-11-04 02:45:49,088] Trial 129 pruned. 
[I 2025-11-04 02:46:00,285] Trial 130 pruned. 
2025-11-04 02:49:03,440 - INFO - Trial 131: Early stopping at epoch 110.
[I 2025-11-04 02:49:03,514] Trial 131 finished with value: 0.004735585412863713 and parameters: {'batch_size': 64, 'learning_rate': 0.002712957151973114, 'nr_hidden_layers': 2, 'nr_neurons': 49, 'dropout_rate': 0.00020284456430861493, 'weight_decay': 0.0001602279322502635, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:52:32,752 - INFO - Trial 132: Early stopping at epoch 121.
[I 2025-11-04 02:52:32,835] Trial 132 finished with value: 0.003406261933758593 and parameters: {'batch_size': 64, 'learning_rate': 0.0027143463249642286, 'nr_hidden_layers': 2, 'nr_neurons': 36, 'dropout_rate': 0.0007400721318561829, 'weight_decay': 0.00017493996803253202, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:56:45,060 - INFO - Trial 133: Early stopping at epoch 145.
[I 2025-11-04 02:56:45,133] Trial 133 finished with value: 0.0024301168259304334 and parameters: {'batch_size': 64, 'learning_rate': 0.002809663079435974, 'nr_hidden_layers': 2, 'nr_neurons': 37, 'dropout_rate': 3.4093130862110794e-05, 'weight_decay': 8.823906705905348e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
[I 2025-11-04 02:57:03,421] Trial 134 pruned. 
[I 2025-11-04 02:59:06,568] Trial 135 pruned. 
[I 2025-11-04 02:59:13,403] Trial 136 pruned. 
[I 2025-11-04 02:59:34,458] Trial 137 pruned. 
[I 2025-11-04 02:59:52,693] Trial 138 pruned. 
2025-11-04 03:02:31,818 - INFO - Trial 139: Early stopping at epoch 95.
[I 2025-11-04 03:02:31,889] Trial 139 finished with value: 0.0033336222858054957 and parameters: {'batch_size': 64, 'learning_rate': 0.0028256302138549593, 'nr_hidden_layers': 2, 'nr_neurons': 207, 'dropout_rate': 0.0008171167017167884, 'weight_decay': 0.00024560734609220514, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:03:20,879 - INFO - Trial 140: Early stopping at epoch 63.
[I 2025-11-04 03:03:20,948] Trial 140 finished with value: 0.007911324837837738 and parameters: {'batch_size': 256, 'learning_rate': 0.0026593138571000454, 'nr_hidden_layers': 2, 'nr_neurons': 221, 'dropout_rate': 0.021730733696228893, 'weight_decay': 0.0004530499423552516, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:06:10,175 - INFO - Trial 141: Early stopping at epoch 101.
[I 2025-11-04 03:06:10,246] Trial 141 finished with value: 0.003092897696422202 and parameters: {'batch_size': 64, 'learning_rate': 0.002830237931382506, 'nr_hidden_layers': 2, 'nr_neurons': 236, 'dropout_rate': 0.001179061912249361, 'weight_decay': 0.00031802577904209824, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:09:07,501 - INFO - Trial 142: Early stopping at epoch 99.
[I 2025-11-04 03:09:07,574] Trial 142 finished with value: 0.003583351262533121 and parameters: {'batch_size': 64, 'learning_rate': 0.0022800195881401523, 'nr_hidden_layers': 2, 'nr_neurons': 249, 'dropout_rate': 0.000833082671600073, 'weight_decay': 0.000367149742934199, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:14:53,509 - INFO - Trial 143: Early stopping at epoch 199.
[I 2025-11-04 03:14:53,593] Trial 143 finished with value: 0.00238691621835406 and parameters: {'batch_size': 64, 'learning_rate': 0.0020877594897380836, 'nr_hidden_layers': 2, 'nr_neurons': 203, 'dropout_rate': 0.0014627982751344822, 'weight_decay': 0.00033093444303507554, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:16:29,482 - INFO - Trial 144: Early stopping at epoch 56.
[I 2025-11-04 03:16:29,551] Trial 144 finished with value: 0.006859497412948242 and parameters: {'batch_size': 64, 'learning_rate': 0.0017818423993148987, 'nr_hidden_layers': 2, 'nr_neurons': 251, 'dropout_rate': 0.016240937934129795, 'weight_decay': 0.00030976222140347703, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:19:33,602 - INFO - Trial 145: Early stopping at epoch 109.
[I 2025-11-04 03:19:33,675] Trial 145 finished with value: 0.004035731563910439 and parameters: {'batch_size': 64, 'learning_rate': 0.0021306514285948383, 'nr_hidden_layers': 2, 'nr_neurons': 204, 'dropout_rate': 0.002025913629556762, 'weight_decay': 0.00027753539930650017, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:21:37,568 - INFO - Trial 146: Early stopping at epoch 72.
[I 2025-11-04 03:21:37,639] Trial 146 finished with value: 0.006182637568357223 and parameters: {'batch_size': 64, 'learning_rate': 0.0021610142004061584, 'nr_hidden_layers': 2, 'nr_neurons': 202, 'dropout_rate': 0.02922826953534735, 'weight_decay': 0.00038206290874449617, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:24:43,315 - INFO - Trial 147: Early stopping at epoch 108.
[I 2025-11-04 03:24:43,386] Trial 147 finished with value: 0.0027100493596822236 and parameters: {'batch_size': 64, 'learning_rate': 0.002372963284932545, 'nr_hidden_layers': 2, 'nr_neurons': 202, 'dropout_rate': 0.00012114713156833114, 'weight_decay': 0.0003110925218803501, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
[I 2025-11-04 03:24:49,921] Trial 148 pruned. 
2025-11-04 03:27:02,780 - INFO - Trial 149: Early stopping at epoch 79.
[I 2025-11-04 03:27:02,851] Trial 149 finished with value: 0.005551116934362596 and parameters: {'batch_size': 64, 'learning_rate': 0.0020330502317160966, 'nr_hidden_layers': 2, 'nr_neurons': 238, 'dropout_rate': 0.010799477725801605, 'weight_decay': 0.00034438975183580115, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
[I 2025-11-04 03:27:08,602] Trial 150 pruned. 
2025-11-04 03:28:40,042 - INFO - Trial 151: Early stopping at epoch 53.
[I 2025-11-04 03:28:40,115] Trial 151 finished with value: 0.007213702218660594 and parameters: {'batch_size': 64, 'learning_rate': 0.0028220760776232817, 'nr_hidden_layers': 2, 'nr_neurons': 208, 'dropout_rate': 0.01175371183252955, 'weight_decay': 0.00025516196656191135, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:31:24,433 - INFO - Trial 152: Early stopping at epoch 82.
[I 2025-11-04 03:31:24,505] Trial 152 finished with value: 0.0043153753333327795 and parameters: {'batch_size': 64, 'learning_rate': 0.0021576078355718684, 'nr_hidden_layers': 2, 'nr_neurons': 178, 'dropout_rate': 0.0010956121670966559, 'weight_decay': 0.0003259576622922677, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:37:40,008 - INFO - Trial 153: Early stopping at epoch 223.
[I 2025-11-04 03:37:40,082] Trial 153 finished with value: 0.0017232450908056518 and parameters: {'batch_size': 64, 'learning_rate': 0.00155813825910047, 'nr_hidden_layers': 2, 'nr_neurons': 179, 'dropout_rate': 0.00011304352476430943, 'weight_decay': 0.0003412592283104479, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 153 with value: 0.0017232450908056518.
[I 2025-11-04 03:37:58,551] Trial 154 pruned. 
2025-11-04 03:40:53,035 - INFO - Trial 155: Early stopping at epoch 95.
[I 2025-11-04 03:40:53,107] Trial 155 finished with value: 0.0050686222565355325 and parameters: {'batch_size': 64, 'learning_rate': 0.0015718098187667195, 'nr_hidden_layers': 2, 'nr_neurons': 175, 'dropout_rate': 0.010139525583702387, 'weight_decay': 0.00031644077702867255, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 153 with value: 0.0017232450908056518.
2025-11-04 03:46:26,482 - INFO - Trial 156: Early stopping at epoch 195.
[I 2025-11-04 03:46:26,555] Trial 156 finished with value: 0.001703693990911879 and parameters: {'batch_size': 64, 'learning_rate': 0.00196258307677906, 'nr_hidden_layers': 2, 'nr_neurons': 240, 'dropout_rate': 0.00011397177303976765, 'weight_decay': 0.0005146727726270247, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 03:49:38,191 - INFO - Trial 157: Early stopping at epoch 111.
[I 2025-11-04 03:49:38,263] Trial 157 finished with value: 0.0031992184399321105 and parameters: {'batch_size': 64, 'learning_rate': 0.0020511009644638995, 'nr_hidden_layers': 2, 'nr_neurons': 235, 'dropout_rate': 0.0006210535885154249, 'weight_decay': 0.0006304073622846829, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 03:54:13,089] Trial 158 pruned. 
2025-11-04 03:57:33,330 - INFO - Trial 159: Early stopping at epoch 114.
[I 2025-11-04 03:57:33,402] Trial 159 finished with value: 0.003166019049682109 and parameters: {'batch_size': 64, 'learning_rate': 0.001940698898758376, 'nr_hidden_layers': 2, 'nr_neurons': 210, 'dropout_rate': 0.0004893032945299006, 'weight_decay': 0.00048777467502667096, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 03:57:56,895] Trial 160 pruned. 
2025-11-04 04:01:16,522 - INFO - Trial 161: Early stopping at epoch 118.
[I 2025-11-04 04:01:16,613] Trial 161 finished with value: 0.002950986106544083 and parameters: {'batch_size': 64, 'learning_rate': 0.001603027820126278, 'nr_hidden_layers': 2, 'nr_neurons': 211, 'dropout_rate': 0.002153330745210171, 'weight_decay': 0.0004908837180209471, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 04:05:41,443 - INFO - Trial 162: Early stopping at epoch 148.
[I 2025-11-04 04:05:41,518] Trial 162 finished with value: 0.0024778737285700444 and parameters: {'batch_size': 64, 'learning_rate': 0.0015132310132768328, 'nr_hidden_layers': 2, 'nr_neurons': 213, 'dropout_rate': 0.0004459337206613683, 'weight_decay': 0.0006243208402091219, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 04:07:29,412 - INFO - Trial 163: Early stopping at epoch 62.
[I 2025-11-04 04:07:29,486] Trial 163 finished with value: 0.006839146084585311 and parameters: {'batch_size': 64, 'learning_rate': 0.0015790664992168834, 'nr_hidden_layers': 2, 'nr_neurons': 213, 'dropout_rate': 0.018218637408468293, 'weight_decay': 0.0007549155556533404, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 04:13:42,336 - INFO - Trial 164: Early stopping at epoch 223.
[I 2025-11-04 04:13:42,411] Trial 164 finished with value: 0.0018375076887480418 and parameters: {'batch_size': 64, 'learning_rate': 0.0013007368740094705, 'nr_hidden_layers': 2, 'nr_neurons': 227, 'dropout_rate': 0.0005055490932731704, 'weight_decay': 0.0006223600050677631, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 04:16:13,578 - INFO - Trial 165: Early stopping at epoch 90.
[I 2025-11-04 04:16:13,650] Trial 165 finished with value: 0.005502092370785997 and parameters: {'batch_size': 64, 'learning_rate': 0.0015536291717713018, 'nr_hidden_layers': 2, 'nr_neurons': 230, 'dropout_rate': 0.030041455311321748, 'weight_decay': 0.0006055462268947308, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 04:16:32,072] Trial 166 pruned. 
[I 2025-11-04 04:16:50,513] Trial 167 pruned. 
2025-11-04 04:20:13,254 - INFO - Trial 168: Early stopping at epoch 120.
[I 2025-11-04 04:20:13,327] Trial 168 finished with value: 0.004063426870787914 and parameters: {'batch_size': 64, 'learning_rate': 0.0018723229538061433, 'nr_hidden_layers': 2, 'nr_neurons': 237, 'dropout_rate': 0.01095835758912041, 'weight_decay': 0.0009412391007810916, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 04:23:41,677 - INFO - Trial 169: Early stopping at epoch 116.
[I 2025-11-04 04:23:41,751] Trial 169 finished with value: 0.004810453688696731 and parameters: {'batch_size': 64, 'learning_rate': 0.0011664071752203744, 'nr_hidden_layers': 2, 'nr_neurons': 163, 'dropout_rate': 0.020793372603409025, 'weight_decay': 0.0004390671200042368, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 04:24:00,289] Trial 170 pruned. 
2025-11-04 04:27:04,594 - INFO - Trial 171: Early stopping at epoch 108.
[I 2025-11-04 04:27:04,670] Trial 171 finished with value: 0.0028878806247821668 and parameters: {'batch_size': 64, 'learning_rate': 0.0016949649472788228, 'nr_hidden_layers': 2, 'nr_neurons': 226, 'dropout_rate': 0.0009197729793027875, 'weight_decay': 0.000526217931592782, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 04:29:56,498 - INFO - Trial 172: Early stopping at epoch 92.
[I 2025-11-04 04:29:56,572] Trial 172 finished with value: 0.0029332181894752736 and parameters: {'batch_size': 64, 'learning_rate': 0.0016818441023689961, 'nr_hidden_layers': 2, 'nr_neurons': 225, 'dropout_rate': 0.0005080443755686155, 'weight_decay': 0.0005499397788998313, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 04:34:21,360] Trial 173 pruned. 
2025-11-04 04:37:01,861 - INFO - Trial 174: Early stopping at epoch 93.
[I 2025-11-04 04:37:01,935] Trial 174 finished with value: 0.0030639633833171205 and parameters: {'batch_size': 64, 'learning_rate': 0.0016470341299268075, 'nr_hidden_layers': 2, 'nr_neurons': 210, 'dropout_rate': 0.0002978199773784132, 'weight_decay': 0.0009597950447819424, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 04:39:17,854 - INFO - Trial 175: Early stopping at epoch 70.
[I 2025-11-04 04:39:17,928] Trial 175 finished with value: 0.005995878983046708 and parameters: {'batch_size': 64, 'learning_rate': 0.0016658214257595856, 'nr_hidden_layers': 2, 'nr_neurons': 210, 'dropout_rate': 0.021528992145449403, 'weight_decay': 0.0011680581096143359, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 04:39:29,307] Trial 176 pruned. 
2025-11-04 04:42:13,869 - INFO - Trial 177: Early stopping at epoch 97.
[I 2025-11-04 04:42:13,944] Trial 177 finished with value: 0.004793028596090157 and parameters: {'batch_size': 64, 'learning_rate': 0.0012688138131294485, 'nr_hidden_layers': 2, 'nr_neurons': 190, 'dropout_rate': 0.01951262932596887, 'weight_decay': 0.001355522229670154, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 04:46:18,787 - INFO - Trial 178: Early stopping at epoch 141.
[I 2025-11-04 04:46:18,864] Trial 178 finished with value: 0.0019218407461842576 and parameters: {'batch_size': 64, 'learning_rate': 0.0018522922492381303, 'nr_hidden_layers': 2, 'nr_neurons': 220, 'dropout_rate': 9.441605779113077e-06, 'weight_decay': 0.0006208902890618567, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 04:46:25,564] Trial 179 pruned. 
2025-11-04 04:50:08,476 - INFO - Trial 180: Early stopping at epoch 131.
[I 2025-11-04 04:50:08,561] Trial 180 finished with value: 0.002382251527082925 and parameters: {'batch_size': 64, 'learning_rate': 0.0015225190050177178, 'nr_hidden_layers': 2, 'nr_neurons': 223, 'dropout_rate': 5.082351686300527e-06, 'weight_decay': 0.0008459538831013483, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 04:52:55,617] Trial 181 pruned. 
[I 2025-11-04 04:56:00,338] Trial 182 pruned. 
[I 2025-11-04 04:58:24,212] Trial 183 pruned. 
2025-11-04 05:01:19,606 - INFO - Trial 184: Early stopping at epoch 102.
[I 2025-11-04 05:01:19,685] Trial 184 finished with value: 0.004135804148069693 and parameters: {'batch_size': 64, 'learning_rate': 0.0013551877298336066, 'nr_hidden_layers': 2, 'nr_neurons': 199, 'dropout_rate': 0.00079614135354137, 'weight_decay': 0.0006286670838915534, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 05:01:38,222] Trial 185 pruned. 
2025-11-04 05:06:28,678 - INFO - Trial 186: Early stopping at epoch 171.
[I 2025-11-04 05:06:28,766] Trial 186 finished with value: 0.002144483182101648 and parameters: {'batch_size': 64, 'learning_rate': 0.0020353078499482933, 'nr_hidden_layers': 2, 'nr_neurons': 186, 'dropout_rate': 0.0002871801606311408, 'weight_decay': 0.0004499185687485009, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 05:08:52,360] Trial 187 pruned. 
2025-11-04 05:13:37,865 - INFO - Trial 188: Early stopping at epoch 152.
[I 2025-11-04 05:13:37,945] Trial 188 finished with value: 0.0019672053204514146 and parameters: {'batch_size': 64, 'learning_rate': 0.0019846762972843845, 'nr_hidden_layers': 2, 'nr_neurons': 174, 'dropout_rate': 0.00021015973754471044, 'weight_decay': 0.0005035921945080893, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 05:13:56,498] Trial 189 pruned. 
[I 2025-11-04 05:14:04,893] Trial 190 pruned. 
2025-11-04 05:16:48,538 - INFO - Trial 191: Early stopping at epoch 97.
[I 2025-11-04 05:16:48,612] Trial 191 finished with value: 0.004004495602067035 and parameters: {'batch_size': 64, 'learning_rate': 0.002053275057763007, 'nr_hidden_layers': 2, 'nr_neurons': 207, 'dropout_rate': 0.006681709161118788, 'weight_decay': 0.0006723414186946356, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 05:20:35,640 - INFO - Trial 192: Early stopping at epoch 131.
[I 2025-11-04 05:20:35,715] Trial 192 finished with value: 0.0026781699816892943 and parameters: {'batch_size': 64, 'learning_rate': 0.0016434368376432203, 'nr_hidden_layers': 2, 'nr_neurons': 217, 'dropout_rate': 0.0016187148267935117, 'weight_decay': 0.0005617184894856109, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 05:23:30,619 - INFO - Trial 193: Early stopping at epoch 103.
[I 2025-11-04 05:23:30,735] Trial 193 finished with value: 0.005272857274811596 and parameters: {'batch_size': 64, 'learning_rate': 0.0016268613422992417, 'nr_hidden_layers': 2, 'nr_neurons': 184, 'dropout_rate': 0.018310412969621558, 'weight_decay': 0.00040773407864280514, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 05:28:33,439 - INFO - Trial 194: Early stopping at epoch 172.
[I 2025-11-04 05:28:33,515] Trial 194 finished with value: 0.0017897426411018452 and parameters: {'batch_size': 64, 'learning_rate': 0.0011572557976751129, 'nr_hidden_layers': 2, 'nr_neurons': 220, 'dropout_rate': 4.0768083449835367e-05, 'weight_decay': 0.0008169274724774148, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 05:28:52,029] Trial 195 pruned. 
[I 2025-11-04 05:29:10,527] Trial 196 pruned. 
[I 2025-11-04 05:29:16,342] Trial 197 pruned. 
[I 2025-11-04 05:29:45,277] Trial 198 pruned. 
2025-11-04 05:33:18,229 - INFO - Trial 199: Early stopping at epoch 122.
[I 2025-11-04 05:33:18,306] Trial 199 finished with value: 0.002323318970192309 and parameters: {'batch_size': 64, 'learning_rate': 0.0017500595302689785, 'nr_hidden_layers': 2, 'nr_neurons': 244, 'dropout_rate': 0.00020815364592747046, 'weight_decay': 0.00036293944392730025, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 05:36:29,571] Trial 200 pruned. 
2025-11-04 05:39:23,208 - INFO - Trial 201: Early stopping at epoch 102.
[I 2025-11-04 05:39:23,285] Trial 201 finished with value: 0.003134758232204909 and parameters: {'batch_size': 64, 'learning_rate': 0.001555008212387015, 'nr_hidden_layers': 2, 'nr_neurons': 215, 'dropout_rate': 0.0004018925457473, 'weight_decay': 0.0005631066314056518, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 05:44:37,159 - INFO - Trial 202: Early stopping at epoch 183.
[I 2025-11-04 05:44:37,237] Trial 202 finished with value: 0.0022608223012242413 and parameters: {'batch_size': 64, 'learning_rate': 0.0018055981123317258, 'nr_hidden_layers': 2, 'nr_neurons': 242, 'dropout_rate': 0.0004777948293977172, 'weight_decay': 0.00036874416125972726, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 05:47:43,163 - INFO - Trial 203: Early stopping at epoch 109.
[I 2025-11-04 05:47:43,239] Trial 203 finished with value: 0.004327050220387058 and parameters: {'batch_size': 64, 'learning_rate': 0.0016885657491153346, 'nr_hidden_layers': 2, 'nr_neurons': 199, 'dropout_rate': 0.010937374357714667, 'weight_decay': 0.0007449744777475171, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 05:50:28,110 - INFO - Trial 204: Early stopping at epoch 92.
[I 2025-11-04 05:50:28,187] Trial 204 finished with value: 0.005223900776732692 and parameters: {'batch_size': 64, 'learning_rate': 0.0018262752645400934, 'nr_hidden_layers': 2, 'nr_neurons': 242, 'dropout_rate': 0.009752294282155915, 'weight_decay': 0.00043492342101297165, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 05:50:48,349] Trial 205 pruned. 
[I 2025-11-04 05:51:06,845] Trial 206 pruned. 
[I 2025-11-04 05:54:10,415] Trial 207 pruned. 
2025-11-04 05:58:16,951 - INFO - Trial 208: Early stopping at epoch 144.
[I 2025-11-04 05:58:17,028] Trial 208 finished with value: 0.002450723304253892 and parameters: {'batch_size': 64, 'learning_rate': 0.0016449255288424334, 'nr_hidden_layers': 2, 'nr_neurons': 158, 'dropout_rate': 0.0009370261143665355, 'weight_decay': 0.0008969113557074593, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:02:32,043 - INFO - Trial 209: Early stopping at epoch 144.
[I 2025-11-04 06:02:32,130] Trial 209 finished with value: 0.002144540011959881 and parameters: {'batch_size': 64, 'learning_rate': 0.002003996483706191, 'nr_hidden_layers': 2, 'nr_neurons': 192, 'dropout_rate': 6.218669962836229e-05, 'weight_decay': 0.0005803002930645313, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:07:00,248 - INFO - Trial 210: Early stopping at epoch 157.
[I 2025-11-04 06:07:00,325] Trial 210 finished with value: 0.0019556789956991947 and parameters: {'batch_size': 64, 'learning_rate': 0.002218021724735613, 'nr_hidden_layers': 2, 'nr_neurons': 166, 'dropout_rate': 5.3122278756485014e-05, 'weight_decay': 0.0006087090019984425, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:10:46,174 - INFO - Trial 211: Early stopping at epoch 132.
[I 2025-11-04 06:10:46,251] Trial 211 finished with value: 0.004049947734640692 and parameters: {'batch_size': 64, 'learning_rate': 0.0022189310289409663, 'nr_hidden_layers': 2, 'nr_neurons': 166, 'dropout_rate': 0.009675607063200455, 'weight_decay': 0.0006006467054195102, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:14:55,229 - INFO - Trial 212: Early stopping at epoch 145.
[I 2025-11-04 06:14:55,314] Trial 212 finished with value: 0.002564592576199526 and parameters: {'batch_size': 64, 'learning_rate': 0.001965883830961385, 'nr_hidden_layers': 2, 'nr_neurons': 155, 'dropout_rate': 0.0011195557042287252, 'weight_decay': 0.000823646948228683, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:18:44,848 - INFO - Trial 213: Early stopping at epoch 136.
[I 2025-11-04 06:18:44,926] Trial 213 finished with value: 0.0024064227695382444 and parameters: {'batch_size': 64, 'learning_rate': 0.0020223303047922775, 'nr_hidden_layers': 2, 'nr_neurons': 166, 'dropout_rate': 0.00012039052706208663, 'weight_decay': 0.0007927013610682116, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 06:21:01,074] Trial 214 pruned. 
2025-11-04 06:23:22,633 - INFO - Trial 215: Early stopping at epoch 84.
[I 2025-11-04 06:23:22,708] Trial 215 finished with value: 0.005483768295466217 and parameters: {'batch_size': 64, 'learning_rate': 0.0023455672327879298, 'nr_hidden_layers': 2, 'nr_neurons': 157, 'dropout_rate': 0.01114680879626126, 'weight_decay': 0.0008359868139199343, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:24:49,658 - INFO - Trial 216: Early stopping at epoch 50.
[I 2025-11-04 06:24:49,736] Trial 216 finished with value: 0.007808778014049641 and parameters: {'batch_size': 64, 'learning_rate': 0.0021081254030867087, 'nr_hidden_layers': 2, 'nr_neurons': 152, 'dropout_rate': 0.018232411477998256, 'weight_decay': 0.0011060929548208987, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:28:09,845 - INFO - Trial 217: Early stopping at epoch 117.
[I 2025-11-04 06:28:09,929] Trial 217 finished with value: 0.004226907274941152 and parameters: {'batch_size': 64, 'learning_rate': 0.0020093610846059614, 'nr_hidden_layers': 2, 'nr_neurons': 156, 'dropout_rate': 0.010219991905123973, 'weight_decay': 0.0007358781788357956, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 06:28:21,309] Trial 218 pruned. 
[I 2025-11-04 06:29:56,551] Trial 219 pruned. 
[I 2025-11-04 06:30:03,250] Trial 220 pruned. 
2025-11-04 06:34:17,885 - INFO - Trial 221: Early stopping at epoch 150.
[I 2025-11-04 06:34:17,962] Trial 221 finished with value: 0.0018320893429119897 and parameters: {'batch_size': 64, 'learning_rate': 0.0018509124512151292, 'nr_hidden_layers': 2, 'nr_neurons': 181, 'dropout_rate': 0.0002968597198542962, 'weight_decay': 0.00036754151370859545, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:36:03,447 - INFO - Trial 222: Early stopping at epoch 54.
[I 2025-11-04 06:36:03,522] Trial 222 finished with value: 0.005846593869442664 and parameters: {'batch_size': 64, 'learning_rate': 0.0019663286834806534, 'nr_hidden_layers': 2, 'nr_neurons': 181, 'dropout_rate': 0.010057436658193347, 'weight_decay': 0.00036497128389446925, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:39:40,004 - INFO - Trial 223: Early stopping at epoch 124.
[I 2025-11-04 06:39:40,082] Trial 223 finished with value: 0.002275562444250195 and parameters: {'batch_size': 64, 'learning_rate': 0.0018619016392431049, 'nr_hidden_layers': 2, 'nr_neurons': 166, 'dropout_rate': 0.00017275977697411263, 'weight_decay': 0.00038812680892398707, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:42:15,319 - INFO - Trial 224: Early stopping at epoch 89.
[I 2025-11-04 06:42:15,395] Trial 224 finished with value: 0.005753996023100448 and parameters: {'batch_size': 64, 'learning_rate': 0.001848946648849795, 'nr_hidden_layers': 2, 'nr_neurons': 169, 'dropout_rate': 0.019250257001766576, 'weight_decay': 0.00041325522318857636, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:44:56,549 - INFO - Trial 225: Early stopping at epoch 96.
[I 2025-11-04 06:44:56,627] Trial 225 finished with value: 0.0027884505826481177 and parameters: {'batch_size': 64, 'learning_rate': 0.002221149005279816, 'nr_hidden_layers': 2, 'nr_neurons': 160, 'dropout_rate': 0.00022227330928375013, 'weight_decay': 0.00041849569335792556, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:48:55,387 - INFO - Trial 226: Early stopping at epoch 141.
[I 2025-11-04 06:48:55,465] Trial 226 finished with value: 0.003988809151790671 and parameters: {'batch_size': 64, 'learning_rate': 0.0018983033957719344, 'nr_hidden_layers': 2, 'nr_neurons': 190, 'dropout_rate': 0.010621880973833927, 'weight_decay': 0.0003083894239348409, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 06:51:54,295] Trial 227 pruned. 
[I 2025-11-04 06:52:12,960] Trial 228 pruned. 
[I 2025-11-04 06:52:31,778] Trial 229 pruned. 
[I 2025-11-04 06:52:40,235] Trial 230 pruned. 
2025-11-04 06:56:38,409 - INFO - Trial 231: Early stopping at epoch 125.
[I 2025-11-04 06:56:38,487] Trial 231 finished with value: 0.0025770020020284327 and parameters: {'batch_size': 64, 'learning_rate': 0.0022218793258580614, 'nr_hidden_layers': 2, 'nr_neurons': 159, 'dropout_rate': 0.0003855183565834302, 'weight_decay': 0.00044042802595940545, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:01:16,773 - INFO - Trial 232: Early stopping at epoch 165.
[I 2025-11-04 07:01:16,864] Trial 232 finished with value: 0.0022830482109757982 and parameters: {'batch_size': 64, 'learning_rate': 0.0022438284395842607, 'nr_hidden_layers': 2, 'nr_neurons': 140, 'dropout_rate': 0.00011483407663706802, 'weight_decay': 0.00046008047870959304, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:03:32,837 - INFO - Trial 233: Early stopping at epoch 81.
[I 2025-11-04 07:03:32,913] Trial 233 finished with value: 0.005972894753457939 and parameters: {'batch_size': 64, 'learning_rate': 0.002237534544150058, 'nr_hidden_layers': 2, 'nr_neurons': 139, 'dropout_rate': 0.0097193473642961, 'weight_decay': 0.00046193458788506767, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:06:09,202 - INFO - Trial 234: Early stopping at epoch 92.
[I 2025-11-04 07:06:09,280] Trial 234 finished with value: 0.004739058805165488 and parameters: {'batch_size': 64, 'learning_rate': 0.0020348794053248803, 'nr_hidden_layers': 2, 'nr_neurons': 151, 'dropout_rate': 0.008365110204145055, 'weight_decay': 0.0006080606711065252, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:10:24,594 - INFO - Trial 235: Early stopping at epoch 144.
[I 2025-11-04 07:10:24,672] Trial 235 finished with value: 0.002580405151756864 and parameters: {'batch_size': 64, 'learning_rate': 0.0018242026244798823, 'nr_hidden_layers': 2, 'nr_neurons': 162, 'dropout_rate': 0.00047328232053574763, 'weight_decay': 0.0004628671708659736, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 07:10:43,223] Trial 236 pruned. 
[I 2025-11-04 07:13:06,270] Trial 237 pruned. 
2025-11-04 07:17:35,509 - INFO - Trial 238: Early stopping at epoch 158.
[I 2025-11-04 07:17:35,589] Trial 238 finished with value: 0.002320502444288576 and parameters: {'batch_size': 64, 'learning_rate': 0.0017762651132925639, 'nr_hidden_layers': 2, 'nr_neurons': 167, 'dropout_rate': 8.905606941106032e-05, 'weight_decay': 0.0009997237093289668, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 07:21:37,175] Trial 239 pruned. 
[I 2025-11-04 07:21:42,871] Trial 240 pruned. 
2025-11-04 07:24:08,920 - INFO - Trial 241: Early stopping at epoch 85.
[I 2025-11-04 07:24:08,999] Trial 241 finished with value: 0.004068725372304262 and parameters: {'batch_size': 64, 'learning_rate': 0.0018224213175828258, 'nr_hidden_layers': 2, 'nr_neurons': 156, 'dropout_rate': 0.0007596566313449247, 'weight_decay': 0.0013553662984965725, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:27:57,919 - INFO - Trial 242: Early stopping at epoch 129.
[I 2025-11-04 07:27:57,999] Trial 242 finished with value: 0.003351524177780395 and parameters: {'batch_size': 64, 'learning_rate': 0.0019949388237217123, 'nr_hidden_layers': 2, 'nr_neurons': 167, 'dropout_rate': 0.0005928342376525594, 'weight_decay': 0.0009462894263151227, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:31:08,316 - INFO - Trial 243: Early stopping at epoch 110.
[I 2025-11-04 07:31:08,406] Trial 243 finished with value: 0.00266032796656622 and parameters: {'batch_size': 64, 'learning_rate': 0.0022291618792607496, 'nr_hidden_layers': 2, 'nr_neurons': 161, 'dropout_rate': 0.00011334542240336255, 'weight_decay': 0.00036157655702255233, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 07:35:09,096] Trial 244 pruned. 
[I 2025-11-04 07:37:54,576] Trial 245 pruned. 
2025-11-04 07:40:09,622 - INFO - Trial 246: Early stopping at epoch 76.
[I 2025-11-04 07:40:09,702] Trial 246 finished with value: 0.0063530295696310355 and parameters: {'batch_size': 64, 'learning_rate': 0.0015456150960395274, 'nr_hidden_layers': 2, 'nr_neurons': 141, 'dropout_rate': 0.009749988460213535, 'weight_decay': 0.0007619285740841879, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:42:54,704 - INFO - Trial 247: Early stopping at epoch 98.
[I 2025-11-04 07:42:54,783] Trial 247 finished with value: 0.005193062537705916 and parameters: {'batch_size': 64, 'learning_rate': 0.002455692951019067, 'nr_hidden_layers': 2, 'nr_neurons': 164, 'dropout_rate': 0.019349624703812275, 'weight_decay': 0.0003912514025482102, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:46:21,897 - INFO - Trial 248: Early stopping at epoch 118.
[I 2025-11-04 07:46:21,978] Trial 248 finished with value: 0.002937104322742584 and parameters: {'batch_size': 64, 'learning_rate': 0.0011018166270380565, 'nr_hidden_layers': 2, 'nr_neurons': 192, 'dropout_rate': 0.0003166967781870037, 'weight_decay': 0.00028015765781405416, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:49:06,949 - INFO - Trial 249: Early stopping at epoch 98.
[I 2025-11-04 07:49:07,036] Trial 249 finished with value: 0.004460835036272863 and parameters: {'batch_size': 64, 'learning_rate': 0.0018661182381393463, 'nr_hidden_layers': 2, 'nr_neurons': 176, 'dropout_rate': 0.008366227572726766, 'weight_decay': 0.0005283787108815382, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 07:49:28,330] Trial 250 pruned. 
[I 2025-11-04 07:50:48,232] Trial 251 pruned. 
2025-11-04 07:56:05,834 - INFO - Trial 252: Early stopping at epoch 186.
[I 2025-11-04 07:56:05,916] Trial 252 finished with value: 0.0017696543509006426 and parameters: {'batch_size': 64, 'learning_rate': 0.0016345125017416119, 'nr_hidden_layers': 2, 'nr_neurons': 242, 'dropout_rate': 2.9027010752291715e-05, 'weight_decay': 0.0004365846103098413, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:57:21,045 - INFO - Trial 253: Early stopping at epoch 44.
[I 2025-11-04 07:57:21,124] Trial 253 finished with value: 0.0077720393911317265 and parameters: {'batch_size': 64, 'learning_rate': 0.0015680652300904406, 'nr_hidden_layers': 2, 'nr_neurons': 254, 'dropout_rate': 0.01719257117796154, 'weight_decay': 0.0003391326006402832, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 08:01:43,487 - INFO - Trial 254: Early stopping at epoch 148.
[I 2025-11-04 08:01:43,569] Trial 254 finished with value: 0.0036362456156857756 and parameters: {'batch_size': 64, 'learning_rate': 0.0012649809358949104, 'nr_hidden_layers': 2, 'nr_neurons': 241, 'dropout_rate': 0.009926397014030211, 'weight_decay': 0.0008637716124238994, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 08:04:32,176 - INFO - Trial 255: Early stopping at epoch 100.
[I 2025-11-04 08:04:32,257] Trial 255 finished with value: 0.004443996656876153 and parameters: {'batch_size': 64, 'learning_rate': 0.0017071578951238773, 'nr_hidden_layers': 2, 'nr_neurons': 199, 'dropout_rate': 0.025900203493343033, 'weight_decay': 0.0005904362619236189, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 08:04:50,664] Trial 256 pruned. 
[I 2025-11-04 08:05:02,025] Trial 257 pruned. 
2025-11-04 08:06:57,367 - INFO - Trial 258: Early stopping at epoch 67.
[I 2025-11-04 08:06:57,446] Trial 258 finished with value: 0.006233907495399644 and parameters: {'batch_size': 64, 'learning_rate': 0.002462084147022242, 'nr_hidden_layers': 2, 'nr_neurons': 245, 'dropout_rate': 0.014893311890203775, 'weight_decay': 0.0005227434635271796, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 08:09:07,037] Trial 259 pruned. 
[I 2025-11-04 08:09:13,945] Trial 260 pruned. 
[I 2025-11-04 08:09:32,793] Trial 261 pruned. 
[I 2025-11-04 08:09:59,279] Trial 262 pruned. 
[I 2025-11-04 08:10:17,742] Trial 263 pruned. 
2025-11-04 08:13:02,871 - INFO - Trial 264: Early stopping at epoch 96.
[I 2025-11-04 08:13:02,952] Trial 264 finished with value: 0.005115749579626213 and parameters: {'batch_size': 64, 'learning_rate': 0.001772027826165768, 'nr_hidden_layers': 2, 'nr_neurons': 231, 'dropout_rate': 0.009683074566583263, 'weight_decay': 0.0010492832836326014, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 08:13:33,972] Trial 265 pruned. 
[I 2025-11-04 08:13:42,477] Trial 266 pruned. 
2025-11-04 08:16:09,467 - INFO - Trial 267: Early stopping at epoch 84.
[I 2025-11-04 08:16:09,547] Trial 267 finished with value: 0.005902790428077017 and parameters: {'batch_size': 64, 'learning_rate': 0.002606076499361336, 'nr_hidden_layers': 2, 'nr_neurons': 132, 'dropout_rate': 0.011164921505798054, 'weight_decay': 0.0012470692119409623, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 08:16:27,844] Trial 268 pruned. 
2025-11-04 08:20:37,659 - INFO - Trial 269: Early stopping at epoch 149.
[I 2025-11-04 08:20:37,739] Trial 269 finished with value: 0.0021331730105428976 and parameters: {'batch_size': 64, 'learning_rate': 0.0017290638885753718, 'nr_hidden_layers': 2, 'nr_neurons': 170, 'dropout_rate': 8.090095682626499e-05, 'weight_decay': 0.0004587391664055132, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 08:24:17,432] Trial 270 pruned. 
[I 2025-11-04 08:27:10,524] Trial 271 pruned. 
[I 2025-11-04 08:27:28,817] Trial 272 pruned. 
[I 2025-11-04 08:27:34,449] Trial 273 pruned. 
2025-11-04 08:30:52,989 - INFO - Trial 274: Early stopping at epoch 111.
[I 2025-11-04 08:30:53,071] Trial 274 finished with value: 0.003641759439106371 and parameters: {'batch_size': 64, 'learning_rate': 0.0016227039798803564, 'nr_hidden_layers': 2, 'nr_neurons': 208, 'dropout_rate': 0.008807158546717524, 'weight_decay': 0.0002957458089378418, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 08:30:59,654] Trial 275 pruned. 
2025-11-04 08:34:44,689 - INFO - Trial 276: Early stopping at epoch 134.
[I 2025-11-04 08:34:44,772] Trial 276 finished with value: 0.003007004081015141 and parameters: {'batch_size': 64, 'learning_rate': 0.0017977213755297253, 'nr_hidden_layers': 2, 'nr_neurons': 171, 'dropout_rate': 0.0005139620133413702, 'weight_decay': 0.0005187878364126482, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 08:35:03,229] Trial 277 pruned. 
2025-11-04 08:38:00,984 - INFO - Trial 278: Early stopping at epoch 106.
[I 2025-11-04 08:38:01,073] Trial 278 finished with value: 0.0043909220311847885 and parameters: {'batch_size': 64, 'learning_rate': 0.001503340838125165, 'nr_hidden_layers': 2, 'nr_neurons': 224, 'dropout_rate': 0.010012822423044434, 'weight_decay': 0.0006339422602865467, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 08:40:50,205 - INFO - Trial 279: Early stopping at epoch 100.
[I 2025-11-04 08:40:50,287] Trial 279 finished with value: 0.005384148573669635 and parameters: {'batch_size': 64, 'learning_rate': 0.0020525125741293407, 'nr_hidden_layers': 2, 'nr_neurons': 195, 'dropout_rate': 0.01979362004649466, 'weight_decay': 0.000447275096528369, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 08:43:45,846 - INFO - Trial 280: Early stopping at epoch 100.
[I 2025-11-04 08:43:45,927] Trial 280 finished with value: 0.002853109223178146 and parameters: {'batch_size': 64, 'learning_rate': 0.0017837401450900138, 'nr_hidden_layers': 2, 'nr_neurons': 179, 'dropout_rate': 0.00020050195374939344, 'weight_decay': 0.0007088212256507952, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 08:49:11,259 - INFO - Trial 281: Early stopping at epoch 182.
[I 2025-11-04 08:49:11,342] Trial 281 finished with value: 0.0020103415004177317 and parameters: {'batch_size': 64, 'learning_rate': 0.001582512630663724, 'nr_hidden_layers': 2, 'nr_neurons': 215, 'dropout_rate': 0.00023298559951897817, 'weight_decay': 0.0003903859185876924, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 08:50:49,846 - INFO - Trial 282: Early stopping at epoch 45.
[I 2025-11-04 08:50:49,925] Trial 282 finished with value: 0.007297961036516207 and parameters: {'batch_size': 64, 'learning_rate': 0.0013184284771514123, 'nr_hidden_layers': 5, 'nr_neurons': 215, 'dropout_rate': 0.010029019148589833, 'weight_decay': 0.000397138160030218, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 08:51:08,844] Trial 283 pruned. 
2025-11-04 08:53:02,388 - INFO - Trial 284: Early stopping at epoch 67.
[I 2025-11-04 08:53:02,487] Trial 284 finished with value: 0.006228112778513175 and parameters: {'batch_size': 64, 'learning_rate': 0.0014415873784218737, 'nr_hidden_layers': 2, 'nr_neurons': 204, 'dropout_rate': 0.023307630503042277, 'weight_decay': 0.0003188312704479658, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 08:56:11,457] Trial 285 pruned. 
[I 2025-11-04 08:59:15,684] Trial 286 pruned. 
[I 2025-11-04 08:59:22,758] Trial 287 pruned. 
2025-11-04 09:02:49,786 - INFO - Trial 288: Early stopping at epoch 100.
[I 2025-11-04 09:02:49,869] Trial 288 finished with value: 0.004739657349088244 and parameters: {'batch_size': 64, 'learning_rate': 0.002380498926751574, 'nr_hidden_layers': 4, 'nr_neurons': 191, 'dropout_rate': 0.0008517024025449063, 'weight_decay': 0.0003343878911228494, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 09:03:01,214] Trial 289 pruned. 
[I 2025-11-04 09:03:21,389] Trial 290 pruned. 
[I 2025-11-04 09:06:11,373] Trial 291 pruned. 
2025-11-04 09:09:34,493 - INFO - Trial 292: Early stopping at epoch 119.
[I 2025-11-04 09:09:34,574] Trial 292 finished with value: 0.00455003943051893 and parameters: {'batch_size': 64, 'learning_rate': 0.0016280541627021374, 'nr_hidden_layers': 2, 'nr_neurons': 218, 'dropout_rate': 0.007771285198309058, 'weight_decay': 6.250440662786251e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 09:15:20,680 - INFO - Trial 293: Early stopping at epoch 201.
[I 2025-11-04 09:15:20,761] Trial 293 finished with value: 0.0016160019030080897 and parameters: {'batch_size': 64, 'learning_rate': 0.0013769697512055082, 'nr_hidden_layers': 2, 'nr_neurons': 169, 'dropout_rate': 7.770529593864131e-05, 'weight_decay': 0.0004262642792345516, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 09:15:29,483] Trial 294 pruned. 
[I 2025-11-04 09:15:47,956] Trial 295 pruned. 
[I 2025-11-04 09:16:06,378] Trial 296 pruned. 
2025-11-04 09:19:44,496 - INFO - Trial 297: Early stopping at epoch 128.
[I 2025-11-04 09:19:44,577] Trial 297 finished with value: 0.0042024413796440535 and parameters: {'batch_size': 64, 'learning_rate': 0.001215277400414682, 'nr_hidden_layers': 2, 'nr_neurons': 246, 'dropout_rate': 0.018148677705624422, 'weight_decay': 0.00027860622982492665, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 293 with value: 0.0016160019030080897.
2025-11-04 09:22:33,553 - INFO - Trial 298: Early stopping at epoch 99.
[I 2025-11-04 09:22:33,635] Trial 298 finished with value: 0.0033398070787816793 and parameters: {'batch_size': 64, 'learning_rate': 0.002435382356115228, 'nr_hidden_layers': 2, 'nr_neurons': 185, 'dropout_rate': 1.834340077863498e-05, 'weight_decay': 0.0005067943683591132, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 293 with value: 0.0016160019030080897.
2025-11-04 09:24:32,456 - INFO - Trial 299: Early stopping at epoch 78.
[I 2025-11-04 09:24:32,535] Trial 299 finished with value: 0.006197777576175181 and parameters: {'batch_size': 64, 'learning_rate': 0.001872019276743626, 'nr_hidden_layers': 1, 'nr_neurons': 176, 'dropout_rate': 0.009311067161890318, 'weight_decay': 0.0003734061876060071, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 09:24:38,375] Trial 300 pruned. 
[I 2025-11-04 09:25:06,546] Trial 301 pruned. 
2025-11-04 09:27:17,621 - INFO - Trial 302: Early stopping at epoch 76.
[I 2025-11-04 09:27:17,700] Trial 302 finished with value: 0.006173316464315369 and parameters: {'batch_size': 64, 'learning_rate': 0.0017457577342493745, 'nr_hidden_layers': 2, 'nr_neurons': 149, 'dropout_rate': 0.03763461311767657, 'weight_decay': 0.0002986371998675829, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 09:27:24,308] Trial 303 pruned. 
2025-11-04 09:29:25,717 - INFO - Trial 304: Early stopping at epoch 72.
[I 2025-11-04 09:29:25,799] Trial 304 finished with value: 0.00479045845273963 and parameters: {'batch_size': 64, 'learning_rate': 0.0025717828268789246, 'nr_hidden_layers': 2, 'nr_neurons': 253, 'dropout_rate': 0.0002268159084933072, 'weight_decay': 0.0006880090733434275, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 09:29:44,155] Trial 305 pruned. 
[I 2025-11-04 09:30:02,556] Trial 306 pruned. 
[I 2025-11-04 09:30:21,452] Trial 307 pruned. 
[I 2025-11-04 09:30:39,935] Trial 308 pruned. 
[I 2025-11-04 09:34:14,878] Trial 309 pruned. 
2025-11-04 09:37:57,447 - INFO - Trial 310: Early stopping at epoch 128.
[I 2025-11-04 09:37:57,529] Trial 310 finished with value: 0.00232116178747211 and parameters: {'batch_size': 64, 'learning_rate': 0.0018762228258440198, 'nr_hidden_layers': 2, 'nr_neurons': 224, 'dropout_rate': 0.00016692277866589428, 'weight_decay': 0.0004250407087350204, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 293 with value: 0.0016160019030080897.
2025-11-04 09:42:20,728 - INFO - Trial 311: Early stopping at epoch 152.
[I 2025-11-04 09:42:20,812] Trial 311 finished with value: 0.0019349332733101731 and parameters: {'batch_size': 64, 'learning_rate': 0.0022678275022202, 'nr_hidden_layers': 2, 'nr_neurons': 229, 'dropout_rate': 3.963331392435156e-05, 'weight_decay': 0.00041658982938379984, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 09:43:06,724] Trial 312 pruned. 
2025-11-04 09:46:24,340 - INFO - Trial 313: Early stopping at epoch 114.
[I 2025-11-04 09:46:24,420] Trial 313 finished with value: 0.00451870052757414 and parameters: {'batch_size': 64, 'learning_rate': 0.0019182445757690387, 'nr_hidden_layers': 2, 'nr_neurons': 231, 'dropout_rate': 0.008846674337355337, 'weight_decay': 0.0002912427334526761, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 09:46:35,767] Trial 314 pruned. 
[I 2025-11-04 09:46:54,213] Trial 315 pruned. 
2025-11-04 09:48:59,307 - INFO - Trial 316: Early stopping at epoch 66.
[I 2025-11-04 09:48:59,399] Trial 316 finished with value: 0.0047404196683064346 and parameters: {'batch_size': 64, 'learning_rate': 0.0018182584751236484, 'nr_hidden_layers': 2, 'nr_neurons': 239, 'dropout_rate': 0.00010036178913385564, 'weight_decay': 0.00025058990423895445, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 09:49:06,133] Trial 317 pruned. 
[I 2025-11-04 09:49:24,454] Trial 318 pruned. 
2025-11-04 09:52:14,936 - INFO - Trial 319: Early stopping at epoch 95.
[I 2025-11-04 09:52:15,017] Trial 319 finished with value: 0.0022531111271382 and parameters: {'batch_size': 64, 'learning_rate': 0.0022295943650694756, 'nr_hidden_layers': 2, 'nr_neurons': 203, 'dropout_rate': 1.1264057388117945e-05, 'weight_decay': 0.0003184460538646115, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 293 with value: 0.0016160019030080897.
2025-11-04 09:54:34,726 - INFO - Trial 320: Early stopping at epoch 81.
[I 2025-11-04 09:54:34,808] Trial 320 finished with value: 0.00582598945203883 and parameters: {'batch_size': 64, 'learning_rate': 0.002559687838658227, 'nr_hidden_layers': 2, 'nr_neurons': 203, 'dropout_rate': 0.010417276392548505, 'weight_decay': 0.0003224480545005248, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 09:55:13,332] Trial 321 pruned. 
[I 2025-11-04 09:55:31,914] Trial 322 pruned. 
[I 2025-11-04 09:55:40,475] Trial 323 pruned. 
[I 2025-11-04 09:56:17,414] Trial 324 pruned. 
2025-11-04 09:57:44,126 - INFO - Trial 325: Early stopping at epoch 51.
[I 2025-11-04 09:57:44,207] Trial 325 finished with value: 0.006830143814968225 and parameters: {'batch_size': 64, 'learning_rate': 0.0021346396452303867, 'nr_hidden_layers': 2, 'nr_neurons': 216, 'dropout_rate': 0.017140337266572426, 'weight_decay': 0.00030643326912608004, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 10:00:01,576] Trial 326 pruned. 
[I 2025-11-04 10:00:25,843] Trial 327 pruned. 
2025-11-04 10:03:54,198 - INFO - Trial 328: Early stopping at epoch 124.
[I 2025-11-04 10:03:54,281] Trial 328 finished with value: 0.002109759526669034 and parameters: {'batch_size': 64, 'learning_rate': 0.002419632804768115, 'nr_hidden_layers': 2, 'nr_neurons': 231, 'dropout_rate': 2.9314428170695904e-05, 'weight_decay': 0.0002891503033826793, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 10:04:00,179] Trial 329 pruned. 
[I 2025-11-04 10:06:07,766] Trial 330 pruned. 
[I 2025-11-04 10:06:26,792] Trial 331 pruned. 
[I 2025-11-04 10:06:33,402] Trial 332 pruned. 
2025-11-04 10:16:06,910 - INFO - Trial 333: Early stopping at epoch 330.
[I 2025-11-04 10:16:06,997] Trial 333 finished with value: 0.0009757127058634517 and parameters: {'batch_size': 64, 'learning_rate': 0.001372335074817238, 'nr_hidden_layers': 2, 'nr_neurons': 230, 'dropout_rate': 8.943741579532514e-05, 'weight_decay': 0.00021732207759797098, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 10:16:25,461] Trial 334 pruned. 
2025-11-04 10:19:39,122 - INFO - Trial 335: Early stopping at epoch 113.
[I 2025-11-04 10:19:39,207] Trial 335 finished with value: 0.0043223303934993105 and parameters: {'batch_size': 64, 'learning_rate': 0.002402131934288198, 'nr_hidden_layers': 2, 'nr_neurons': 235, 'dropout_rate': 0.010946621811213775, 'weight_decay': 0.0002517767638606494, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 10:20:56,692] Trial 336 pruned. 
[I 2025-11-04 10:21:15,752] Trial 337 pruned. 
2025-11-04 10:25:15,678 - INFO - Trial 338: Early stopping at epoch 142.
[I 2025-11-04 10:25:15,764] Trial 338 finished with value: 0.002011523069248419 and parameters: {'batch_size': 64, 'learning_rate': 0.0021174683221867894, 'nr_hidden_layers': 2, 'nr_neurons': 248, 'dropout_rate': 4.5017386704143445e-05, 'weight_decay': 0.00028053722293121795, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 10:25:37,607] Trial 339 pruned. 
2025-11-04 10:27:47,298 - INFO - Trial 340: Early stopping at epoch 74.
[I 2025-11-04 10:27:47,383] Trial 340 finished with value: 0.0058992131758177175 and parameters: {'batch_size': 64, 'learning_rate': 0.0020872412418210915, 'nr_hidden_layers': 2, 'nr_neurons': 248, 'dropout_rate': 0.017254408839888706, 'weight_decay': 0.0002901791386525701, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 10:28:05,890] Trial 341 pruned. 
2025-11-04 10:30:53,796 - INFO - Trial 342: Early stopping at epoch 98.
[I 2025-11-04 10:30:53,881] Trial 342 finished with value: 0.002740589532005382 and parameters: {'batch_size': 64, 'learning_rate': 0.0014070566170241382, 'nr_hidden_layers': 2, 'nr_neurons': 256, 'dropout_rate': 0.00015846963686887136, 'weight_decay': 0.00044874587400134115, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 10:31:17,441] Trial 343 pruned. 
[I 2025-11-04 10:31:28,789] Trial 344 pruned. 
[I 2025-11-04 10:31:47,275] Trial 345 pruned. 
[I 2025-11-04 10:31:54,033] Trial 346 pruned. 
[I 2025-11-04 10:34:12,773] Trial 347 pruned. 
[I 2025-11-04 10:34:31,322] Trial 348 pruned. 
2025-11-04 10:36:58,916 - INFO - Trial 349: Early stopping at epoch 87.
[I 2025-11-04 10:36:59,002] Trial 349 finished with value: 0.00446660673595446 and parameters: {'batch_size': 64, 'learning_rate': 0.0018264671061693526, 'nr_hidden_layers': 2, 'nr_neurons': 245, 'dropout_rate': 0.009857689210513491, 'weight_decay': 0.00033149371701487963, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 10:40:08,618 - INFO - Trial 350: Early stopping at epoch 113.
[I 2025-11-04 10:40:08,708] Trial 350 finished with value: 0.0025208241595821067 and parameters: {'batch_size': 64, 'learning_rate': 0.0019984111477091356, 'nr_hidden_layers': 2, 'nr_neurons': 221, 'dropout_rate': 0.00019499995429297833, 'weight_decay': 0.0005808003625708594, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 10:42:32,773 - INFO - Trial 351: Early stopping at epoch 85.
[I 2025-11-04 10:42:32,861] Trial 351 finished with value: 0.0039409183089343935 and parameters: {'batch_size': 64, 'learning_rate': 0.002251962204078734, 'nr_hidden_layers': 2, 'nr_neurons': 207, 'dropout_rate': 7.498033871574088e-05, 'weight_decay': 0.0005155961750653994, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 10:42:41,420] Trial 352 pruned. 
[I 2025-11-04 10:43:04,084] Trial 353 pruned. 
[I 2025-11-04 10:45:10,883] Trial 354 pruned. 
[I 2025-11-04 10:45:36,300] Trial 355 pruned. 
2025-11-04 10:49:26,835 - INFO - Trial 356: Early stopping at epoch 134.
[I 2025-11-04 10:49:26,925] Trial 356 finished with value: 0.0017484676464697452 and parameters: {'batch_size': 64, 'learning_rate': 0.0015122217626678625, 'nr_hidden_layers': 2, 'nr_neurons': 204, 'dropout_rate': 4.984125999520355e-05, 'weight_decay': 0.0006231849078169501, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 10:49:45,467] Trial 357 pruned. 
[I 2025-11-04 10:49:51,175] Trial 358 pruned. 
2025-11-04 10:51:42,969 - INFO - Trial 359: Early stopping at epoch 64.
[I 2025-11-04 10:51:43,058] Trial 359 finished with value: 0.006823196842367235 and parameters: {'batch_size': 64, 'learning_rate': 0.0015856268319538846, 'nr_hidden_layers': 2, 'nr_neurons': 209, 'dropout_rate': 0.016693159627415945, 'weight_decay': 0.0005345726876352571, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 10:52:06,614] Trial 360 pruned. 
[I 2025-11-04 10:52:13,250] Trial 361 pruned. 
2025-11-04 10:55:06,581 - INFO - Trial 362: Early stopping at epoch 100.
[I 2025-11-04 10:55:06,669] Trial 362 finished with value: 0.005067976783151517 and parameters: {'batch_size': 64, 'learning_rate': 0.0019856966381637878, 'nr_hidden_layers': 2, 'nr_neurons': 201, 'dropout_rate': 0.019434331568871793, 'weight_decay': 0.0005751420512750043, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 10:55:25,236] Trial 363 pruned. 
[I 2025-11-04 10:55:43,813] Trial 364 pruned. 
[I 2025-11-04 10:56:02,311] Trial 365 pruned. 
[I 2025-11-04 10:59:05,532] Trial 366 pruned. 
[I 2025-11-04 11:00:00,470] Trial 367 pruned. 
2025-11-04 11:02:18,908 - INFO - Trial 368: Early stopping at epoch 82.
[I 2025-11-04 11:02:18,995] Trial 368 finished with value: 0.004397683577608602 and parameters: {'batch_size': 64, 'learning_rate': 0.0017297821537482518, 'nr_hidden_layers': 2, 'nr_neurons': 208, 'dropout_rate': 0.009222539487297308, 'weight_decay': 0.0002953562548127958, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 11:05:30,992 - INFO - Trial 369: Early stopping at epoch 113.
[I 2025-11-04 11:05:31,082] Trial 369 finished with value: 0.0046159241788938255 and parameters: {'batch_size': 64, 'learning_rate': 0.0019525550944959078, 'nr_hidden_layers': 2, 'nr_neurons': 185, 'dropout_rate': 0.009141198452401949, 'weight_decay': 0.0005091217113158041, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 11:08:01,736 - INFO - Trial 370: Early stopping at epoch 87.
[I 2025-11-04 11:08:01,834] Trial 370 finished with value: 0.005863966483964138 and parameters: {'batch_size': 64, 'learning_rate': 0.0012633759290010976, 'nr_hidden_layers': 2, 'nr_neurons': 200, 'dropout_rate': 0.01927639753579207, 'weight_decay': 0.0006011528629349891, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 11:08:13,192] Trial 371 pruned. 
2025-11-04 11:10:05,880 - INFO - Trial 372: Early stopping at epoch 65.
[I 2025-11-04 11:10:05,968] Trial 372 finished with value: 0.006087969412269355 and parameters: {'batch_size': 64, 'learning_rate': 0.001825983215652881, 'nr_hidden_layers': 2, 'nr_neurons': 175, 'dropout_rate': 0.009006015434754568, 'weight_decay': 0.0002516261202959776, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 11:12:49,331 - INFO - Trial 373: Early stopping at epoch 97.
[I 2025-11-04 11:12:49,418] Trial 373 finished with value: 0.0032205664973762624 and parameters: {'batch_size': 64, 'learning_rate': 0.0015497257430497704, 'nr_hidden_layers': 2, 'nr_neurons': 217, 'dropout_rate': 0.0002327112966286834, 'weight_decay': 0.000750712059600627, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 11:15:39,592] Trial 374 pruned. 
[I 2025-11-04 11:18:43,797] Trial 375 pruned. 
[I 2025-11-04 11:19:12,133] Trial 376 pruned. 
[I 2025-11-04 11:19:18,960] Trial 377 pruned. 
[I 2025-11-04 11:20:27,407] Trial 378 pruned. 
[I 2025-11-04 11:20:45,971] Trial 379 pruned. 
[I 2025-11-04 11:21:04,516] Trial 380 pruned. 
[I 2025-11-04 11:21:12,980] Trial 381 pruned. 
2025-11-04 11:23:50,983 - INFO - Trial 382: Early stopping at epoch 91.
[I 2025-11-04 11:23:51,074] Trial 382 finished with value: 0.004871097495925831 and parameters: {'batch_size': 64, 'learning_rate': 0.0022146684238568094, 'nr_hidden_layers': 2, 'nr_neurons': 194, 'dropout_rate': 0.008916931606744527, 'weight_decay': 0.0003893377203350007, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 11:25:35,886 - INFO - Trial 383: Early stopping at epoch 60.
[I 2025-11-04 11:25:35,972] Trial 383 finished with value: 0.006007982887537119 and parameters: {'batch_size': 64, 'learning_rate': 0.0013386959407578171, 'nr_hidden_layers': 2, 'nr_neurons': 235, 'dropout_rate': 0.020935713386707366, 'weight_decay': 0.0035905883908630767, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 11:29:25,872 - INFO - Trial 384: Early stopping at epoch 136.
[I 2025-11-04 11:29:25,962] Trial 384 finished with value: 0.0030459137929765216 and parameters: {'batch_size': 64, 'learning_rate': 0.0018200099774211978, 'nr_hidden_layers': 2, 'nr_neurons': 179, 'dropout_rate': 0.0006489270783442017, 'weight_decay': 0.000280132949431581, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 11:29:44,448] Trial 385 pruned. 
[I 2025-11-04 11:29:50,291] Trial 386 pruned. 
[I 2025-11-04 11:30:08,774] Trial 387 pruned. 
[I 2025-11-04 11:30:27,235] Trial 388 pruned. 
2025-11-04 11:35:08,159 - INFO - Trial 389: Early stopping at epoch 159.
[I 2025-11-04 11:35:08,252] Trial 389 finished with value: 0.002180925452259323 and parameters: {'batch_size': 64, 'learning_rate': 0.0017570426595925834, 'nr_hidden_layers': 2, 'nr_neurons': 219, 'dropout_rate': 0.00044299957274945715, 'weight_decay': 0.0005581138526603317, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 11:35:14,918] Trial 390 pruned. 
[I 2025-11-04 11:35:36,833] Trial 391 pruned. 
[I 2025-11-04 11:35:55,376] Trial 392 pruned. 
[I 2025-11-04 11:36:13,885] Trial 393 pruned. 
[I 2025-11-04 11:36:37,663] Trial 394 pruned. 
[I 2025-11-04 11:36:54,306] Trial 395 pruned. 
[I 2025-11-04 11:37:12,856] Trial 396 pruned. 
[I 2025-11-04 11:37:57,928] Trial 397 pruned. 
[I 2025-11-04 11:41:07,306] Trial 398 pruned. 
[I 2025-11-04 11:41:18,697] Trial 399 pruned. 
[I 2025-11-04 11:44:07,560] Trial 400 pruned. 
2025-11-04 11:46:32,986 - INFO - Trial 401: Early stopping at epoch 85.
[I 2025-11-04 11:46:33,073] Trial 401 finished with value: 0.003133489516929033 and parameters: {'batch_size': 64, 'learning_rate': 0.0013977733494515675, 'nr_hidden_layers': 2, 'nr_neurons': 225, 'dropout_rate': 0.0005591512184678577, 'weight_decay': 0.000287794668191489, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 11:46:51,494] Trial 402 pruned. 
[I 2025-11-04 11:46:58,235] Trial 403 pruned. 
[I 2025-11-04 11:47:21,731] Trial 404 pruned. 
2025-11-04 11:50:19,929 - INFO - Trial 405: Early stopping at epoch 106.
[I 2025-11-04 11:50:20,018] Trial 405 finished with value: 0.004836623207301094 and parameters: {'batch_size': 64, 'learning_rate': 0.0016070556397429123, 'nr_hidden_layers': 2, 'nr_neurons': 191, 'dropout_rate': 0.011148301318412199, 'weight_decay': 0.0002374449887516488, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 11:50:38,965] Trial 406 pruned. 
2025-11-04 11:53:19,323 - INFO - Trial 407: Early stopping at epoch 85.
[I 2025-11-04 11:53:19,412] Trial 407 finished with value: 0.005209056940110113 and parameters: {'batch_size': 64, 'learning_rate': 0.002859556538678598, 'nr_hidden_layers': 2, 'nr_neurons': 231, 'dropout_rate': 0.0096379304766681, 'weight_decay': 0.00047568150167726076, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 11:56:02,346 - INFO - Trial 408: Early stopping at epoch 96.
[I 2025-11-04 11:56:02,449] Trial 408 finished with value: 0.0028716436981756355 and parameters: {'batch_size': 64, 'learning_rate': 0.0017624059868485155, 'nr_hidden_layers': 2, 'nr_neurons': 161, 'dropout_rate': 0.00015532995337484977, 'weight_decay': 0.0007974122860284961, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 11:56:10,836] Trial 409 pruned. 
[I 2025-11-04 11:56:30,748] Trial 410 pruned. 
[I 2025-11-04 11:57:25,597] Trial 411 pruned. 
[I 2025-11-04 11:57:48,406] Trial 412 pruned. 
2025-11-04 12:01:25,196 - INFO - Trial 413: Early stopping at epoch 129.
[I 2025-11-04 12:01:25,290] Trial 413 finished with value: 0.004258214452495819 and parameters: {'batch_size': 64, 'learning_rate': 0.0019551966769060427, 'nr_hidden_layers': 2, 'nr_neurons': 198, 'dropout_rate': 0.008669155412066093, 'weight_decay': 0.00029615225664327347, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 12:01:31,232] Trial 414 pruned. 
[I 2025-11-04 12:01:54,051] Trial 415 pruned. 
[I 2025-11-04 12:02:12,547] Trial 416 pruned. 
[I 2025-11-04 12:04:51,151] Trial 417 pruned. 
[I 2025-11-04 12:04:57,802] Trial 418 pruned. 
2025-11-04 12:08:45,263 - INFO - Trial 419: Early stopping at epoch 129.
[I 2025-11-04 12:08:45,354] Trial 419 finished with value: 0.003257365198262515 and parameters: {'batch_size': 64, 'learning_rate': 0.0013539678384768537, 'nr_hidden_layers': 2, 'nr_neurons': 194, 'dropout_rate': 0.0006161943545438333, 'weight_decay': 0.00041783316807070687, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 12:09:03,853] Trial 420 pruned. 
2025-11-04 12:11:14,166 - INFO - Trial 421: Early stopping at epoch 77.
[I 2025-11-04 12:11:14,255] Trial 421 finished with value: 0.003902818664708414 and parameters: {'batch_size': 64, 'learning_rate': 0.0018060209116534634, 'nr_hidden_layers': 2, 'nr_neurons': 244, 'dropout_rate': 0.00015524104145909898, 'weight_decay': 0.0002545911362713726, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 12:14:05,399 - INFO - Trial 422: Early stopping at epoch 86.
[I 2025-11-04 12:14:05,491] Trial 422 finished with value: 0.005329308203133148 and parameters: {'batch_size': 64, 'learning_rate': 0.002409601023300003, 'nr_hidden_layers': 2, 'nr_neurons': 209, 'dropout_rate': 0.009911316642527614, 'weight_decay': 2.911753512239618e-06, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 12:14:24,108] Trial 423 pruned. 
[I 2025-11-04 12:14:50,309] Trial 424 pruned. 
2025-11-04 12:17:13,635 - INFO - Trial 425: Early stopping at epoch 79.
[I 2025-11-04 12:17:13,737] Trial 425 finished with value: 0.00554836767461686 and parameters: {'batch_size': 64, 'learning_rate': 0.0027693218476793425, 'nr_hidden_layers': 2, 'nr_neurons': 173, 'dropout_rate': 0.00937281656872684, 'weight_decay': 0.0003619824188573191, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 12:19:30,443 - INFO - Trial 426: Early stopping at epoch 80.
[I 2025-11-04 12:19:30,533] Trial 426 finished with value: 0.004906206787130345 and parameters: {'batch_size': 64, 'learning_rate': 0.0015262789614517399, 'nr_hidden_layers': 2, 'nr_neurons': 185, 'dropout_rate': 0.00839150823290553, 'weight_decay': 0.0005509463435276564, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 12:19:41,896] Trial 427 pruned. 
2025-11-04 12:24:02,000 - INFO - Trial 428: Early stopping at epoch 149.
[I 2025-11-04 12:24:02,092] Trial 428 finished with value: 0.002046364983938102 and parameters: {'batch_size': 64, 'learning_rate': 0.0018817560802475485, 'nr_hidden_layers': 2, 'nr_neurons': 166, 'dropout_rate': 1.5760411049011992e-05, 'weight_decay': 0.00030490900306669123, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 12:29:16,218 - INFO - Trial 429: Early stopping at epoch 183.
[I 2025-11-04 12:29:16,313] Trial 429 finished with value: 0.0016910017859367065 and parameters: {'batch_size': 64, 'learning_rate': 0.0019310804975492927, 'nr_hidden_layers': 2, 'nr_neurons': 229, 'dropout_rate': 3.1050632738490755e-05, 'weight_decay': 0.0002613094671420462, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 12:29:53,171] Trial 430 pruned. 
[I 2025-11-04 12:29:59,982] Trial 431 pruned. 
2025-11-04 12:34:16,209 - INFO - Trial 432: Early stopping at epoch 145.
[I 2025-11-04 12:34:16,299] Trial 432 finished with value: 0.0025640028387790403 and parameters: {'batch_size': 64, 'learning_rate': 0.001843516699896894, 'nr_hidden_layers': 2, 'nr_neurons': 222, 'dropout_rate': 0.0005470251686930418, 'weight_decay': 0.0002532621514772608, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 12:36:35,712 - INFO - Trial 433: Early stopping at epoch 81.
[I 2025-11-04 12:36:35,803] Trial 433 finished with value: 0.004880614456518074 and parameters: {'batch_size': 64, 'learning_rate': 0.0016717574017039213, 'nr_hidden_layers': 2, 'nr_neurons': 232, 'dropout_rate': 0.008199046129233726, 'weight_decay': 0.0002830887682708292, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 12:41:11,227 - INFO - Trial 434: Early stopping at epoch 164.
[I 2025-11-04 12:41:11,319] Trial 434 finished with value: 0.0022598933350774404 and parameters: {'batch_size': 64, 'learning_rate': 0.0014601521957529177, 'nr_hidden_layers': 2, 'nr_neurons': 213, 'dropout_rate': 0.00038048636647273625, 'weight_decay': 0.0003054117821041585, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 12:41:29,864] Trial 435 pruned. 
[I 2025-11-04 12:42:38,350] Trial 436 pruned. 
[I 2025-11-04 12:42:56,847] Trial 437 pruned. 
[I 2025-11-04 12:43:05,188] Trial 438 pruned. 
[I 2025-11-04 12:43:23,689] Trial 439 pruned. 
[I 2025-11-04 12:43:45,527] Trial 440 pruned. 
[I 2025-11-04 12:47:09,936] Trial 441 pruned. 
[I 2025-11-04 12:47:28,506] Trial 442 pruned. 
[I 2025-11-04 12:47:47,530] Trial 443 pruned. 
[I 2025-11-04 12:47:54,163] Trial 444 pruned. 
[I 2025-11-04 12:47:59,992] Trial 445 pruned. 
[I 2025-11-04 12:48:18,909] Trial 446 pruned. 
2025-11-04 12:50:44,101 - INFO - Trial 447: Early stopping at epoch 86.
[I 2025-11-04 12:50:44,202] Trial 447 finished with value: 0.005114327827014515 and parameters: {'batch_size': 64, 'learning_rate': 0.0018402259312253512, 'nr_hidden_layers': 2, 'nr_neurons': 243, 'dropout_rate': 0.017079825426333527, 'weight_decay': 0.00029545382955098275, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 12:53:41,128] Trial 448 pruned. 
[I 2025-11-04 12:55:03,559] Trial 449 pruned. 
[I 2025-11-04 12:58:56,047] Trial 450 pruned. 
[I 2025-11-04 13:01:06,635] Trial 451 pruned. 
[I 2025-11-04 13:01:25,175] Trial 452 pruned. 
[I 2025-11-04 13:01:43,532] Trial 453 pruned. 
[I 2025-11-04 13:05:37,759] Trial 454 pruned. 
[I 2025-11-04 13:05:56,298] Trial 455 pruned. 
[I 2025-11-04 13:09:01,831] Trial 456 pruned. 
[I 2025-11-04 13:09:13,238] Trial 457 pruned. 
[I 2025-11-04 13:09:31,906] Trial 458 pruned. 
[I 2025-11-04 13:09:38,807] Trial 459 pruned. 
[I 2025-11-04 13:10:35,404] Trial 460 pruned. 
[I 2025-11-04 13:10:53,929] Trial 461 pruned. 
[I 2025-11-04 13:11:12,472] Trial 462 pruned. 
2025-11-04 13:15:12,344 - INFO - Trial 463: Early stopping at epoch 95.
[I 2025-11-04 13:15:12,437] Trial 463 finished with value: 0.00519595586205447 and parameters: {'batch_size': 64, 'learning_rate': 0.0022349405215632513, 'nr_hidden_layers': 2, 'nr_neurons': 224, 'dropout_rate': 0.01661406319431538, 'weight_decay': 0.00047130885056648707, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 13:15:39,063] Trial 464 pruned. 
[I 2025-11-04 13:15:49,840] Trial 465 pruned. 
[I 2025-11-04 13:16:20,350] Trial 466 pruned. 
[I 2025-11-04 13:16:48,161] Trial 467 pruned. 
2025-11-04 13:19:05,305 - INFO - Trial 468: Early stopping at epoch 81.
[I 2025-11-04 13:19:05,396] Trial 468 finished with value: 0.004889315878723458 and parameters: {'batch_size': 64, 'learning_rate': 0.0013999417764830077, 'nr_hidden_layers': 2, 'nr_neurons': 244, 'dropout_rate': 0.017475734794303744, 'weight_decay': 0.0007545901268301911, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 13:19:23,953] Trial 469 pruned. 
[I 2025-11-04 13:19:46,419] Trial 470 pruned. 
[I 2025-11-04 13:19:52,123] Trial 471 pruned. 
2025-11-04 13:22:38,955 - INFO - Trial 472: Early stopping at epoch 97.
[I 2025-11-04 13:22:39,046] Trial 472 finished with value: 0.004667152906530755 and parameters: {'batch_size': 64, 'learning_rate': 0.0019702466277214735, 'nr_hidden_layers': 2, 'nr_neurons': 182, 'dropout_rate': 0.011850292336711867, 'weight_decay': 0.000616346328923362, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 13:25:45,743 - INFO - Trial 473: Early stopping at epoch 107.
[I 2025-11-04 13:25:45,835] Trial 473 finished with value: 0.0023718113202100257 and parameters: {'batch_size': 64, 'learning_rate': 0.001758418803937761, 'nr_hidden_layers': 2, 'nr_neurons': 236, 'dropout_rate': 2.7931631298907715e-05, 'weight_decay': 0.0004704569182149895, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 13:25:52,472] Trial 474 pruned. 
[I 2025-11-04 13:26:21,726] Trial 475 pruned. 
2025-11-04 13:29:06,646 - INFO - Trial 476: Early stopping at epoch 94.
[I 2025-11-04 13:29:06,738] Trial 476 finished with value: 0.0046615776180304975 and parameters: {'batch_size': 64, 'learning_rate': 0.0013710803413219872, 'nr_hidden_layers': 2, 'nr_neurons': 232, 'dropout_rate': 0.01583832967062213, 'weight_decay': 0.0005452686095003152, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 13:33:20,296 - INFO - Trial 477: Early stopping at epoch 137.
[I 2025-11-04 13:33:20,389] Trial 477 finished with value: 0.0037348546731184235 and parameters: {'batch_size': 64, 'learning_rate': 0.0018195786814012335, 'nr_hidden_layers': 2, 'nr_neurons': 188, 'dropout_rate': 0.010205539361793506, 'weight_decay': 0.0003090756055158872, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 13:33:39,030] Trial 478 pruned. 
2025-11-04 13:35:57,455 - INFO - Trial 479: Early stopping at epoch 80.
[I 2025-11-04 13:35:57,546] Trial 479 finished with value: 0.005956979572060261 and parameters: {'batch_size': 64, 'learning_rate': 0.0022917509805352888, 'nr_hidden_layers': 2, 'nr_neurons': 169, 'dropout_rate': 0.017771250743627204, 'weight_decay': 0.006084517040848361, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 13:39:44,406] Trial 480 pruned. 
[I 2025-11-04 13:42:18,637] Trial 481 pruned. 
2025-11-04 13:45:38,145 - INFO - Trial 482: Early stopping at epoch 118.
[I 2025-11-04 13:45:38,238] Trial 482 finished with value: 0.004029574975503621 and parameters: {'batch_size': 64, 'learning_rate': 0.0019412602392354142, 'nr_hidden_layers': 2, 'nr_neurons': 232, 'dropout_rate': 0.00908366195946101, 'weight_decay': 0.00048044727912865444, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 13:45:56,828] Trial 483 pruned. 
2025-11-04 13:49:27,498 - INFO - Trial 484: Early stopping at epoch 122.
[I 2025-11-04 13:49:27,598] Trial 484 finished with value: 0.004529660265649216 and parameters: {'batch_size': 64, 'learning_rate': 0.0014886605676941121, 'nr_hidden_layers': 2, 'nr_neurons': 221, 'dropout_rate': 0.008745317740127106, 'weight_decay': 0.00034927770230574725, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 13:51:43,515 - INFO - Trial 485: Early stopping at epoch 80.
[I 2025-11-04 13:51:43,607] Trial 485 finished with value: 0.003862525325008864 and parameters: {'batch_size': 64, 'learning_rate': 0.0017323485100535457, 'nr_hidden_layers': 2, 'nr_neurons': 193, 'dropout_rate': 0.0003512210749143747, 'weight_decay': 0.0004373437259006573, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 13:52:02,141] Trial 486 pruned. 
[I 2025-11-04 13:52:13,516] Trial 487 pruned. 
[I 2025-11-04 13:52:20,662] Trial 488 pruned. 
[I 2025-11-04 13:52:39,569] Trial 489 pruned. 
[I 2025-11-04 13:56:10,846] Trial 490 pruned. 
2025-11-04 14:00:01,421 - INFO - Trial 491: Early stopping at epoch 135.
[I 2025-11-04 14:00:01,523] Trial 491 finished with value: 0.0028304803081132873 and parameters: {'batch_size': 64, 'learning_rate': 0.00208870283587487, 'nr_hidden_layers': 2, 'nr_neurons': 244, 'dropout_rate': 0.0006678822141792372, 'weight_decay': 0.0006543720002055773, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 14:00:18,313] Trial 492 pruned. 
[I 2025-11-04 14:01:14,035] Trial 493 pruned. 
[I 2025-11-04 14:01:22,430] Trial 494 pruned. 
2025-11-04 14:02:55,575 - INFO - Trial 495: Early stopping at epoch 53.
[I 2025-11-04 14:02:55,666] Trial 495 finished with value: 0.0055501977161551 and parameters: {'batch_size': 64, 'learning_rate': 0.0029446573982688405, 'nr_hidden_layers': 2, 'nr_neurons': 235, 'dropout_rate': 0.00011513204892588007, 'weight_decay': 0.0004279810155554498, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 14:06:07,756 - INFO - Trial 496: Early stopping at epoch 114.
[I 2025-11-04 14:06:07,850] Trial 496 finished with value: 0.004750173556976875 and parameters: {'batch_size': 64, 'learning_rate': 0.00196605844259028, 'nr_hidden_layers': 2, 'nr_neurons': 218, 'dropout_rate': 0.009788955269490791, 'weight_decay': 0.00027717895011103785, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 14:06:26,647] Trial 497 pruned. 
[I 2025-11-04 14:06:45,008] Trial 498 pruned. 
2025-11-04 14:12:44,622 - INFO - Trial 499: Early stopping at epoch 222.
[I 2025-11-04 14:12:44,715] Trial 499 finished with value: 0.0017358147134199145 and parameters: {'batch_size': 64, 'learning_rate': 0.0012216002435068549, 'nr_hidden_layers': 2, 'nr_neurons': 228, 'dropout_rate': 0.0001839658239502202, 'weight_decay': 0.0005727512441006393, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 14:12:50,298] Trial 500 pruned. 
[I 2025-11-04 14:12:56,562] Trial 501 pruned. 
[I 2025-11-04 14:13:14,239] Trial 502 pruned. 
[I 2025-11-04 14:13:31,925] Trial 503 pruned. 
[I 2025-11-04 14:17:20,630] Trial 504 pruned. 
[I 2025-11-04 14:17:38,393] Trial 505 pruned. 
[I 2025-11-04 14:17:58,180] Trial 506 pruned. 
2025-11-04 14:21:40,752 - INFO - Trial 507: Early stopping at epoch 120.
[I 2025-11-04 14:21:40,849] Trial 507 finished with value: 0.0044851811061596926 and parameters: {'batch_size': 64, 'learning_rate': 0.0011317408267841047, 'nr_hidden_layers': 3, 'nr_neurons': 212, 'dropout_rate': 0.009211752963061872, 'weight_decay': 0.0009623611494851579, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 14:21:59,185] Trial 508 pruned. 
2025-11-04 14:27:08,113 - INFO - Trial 509: Early stopping at epoch 186.
[I 2025-11-04 14:27:08,205] Trial 509 finished with value: 0.0026206561568459926 and parameters: {'batch_size': 64, 'learning_rate': 0.001089283813878618, 'nr_hidden_layers': 2, 'nr_neurons': 176, 'dropout_rate': 0.0001736791699090103, 'weight_decay': 0.0006463372673665282, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 14:27:25,930] Trial 510 pruned. 
2025-11-04 14:29:54,234 - INFO - Trial 511: Early stopping at epoch 92.
[I 2025-11-04 14:29:54,328] Trial 511 finished with value: 0.005410918640016638 and parameters: {'batch_size': 64, 'learning_rate': 0.0022886948143492182, 'nr_hidden_layers': 2, 'nr_neurons': 203, 'dropout_rate': 0.02413865174308535, 'weight_decay': 0.00041489375020038136, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 14:30:12,467] Trial 512 pruned. 
[I 2025-11-04 14:30:30,147] Trial 513 pruned. 
[I 2025-11-04 14:30:36,817] Trial 514 pruned. 
[I 2025-11-04 14:30:47,669] Trial 515 pruned. 
[I 2025-11-04 14:31:10,607] Trial 516 pruned. 
[I 2025-11-04 14:32:15,581] Trial 517 pruned. 
2025-11-04 14:33:48,496 - INFO - Trial 518: Early stopping at epoch 55.
[I 2025-11-04 14:33:48,587] Trial 518 finished with value: 0.007893282039745776 and parameters: {'batch_size': 64, 'learning_rate': 0.001969269458501978, 'nr_hidden_layers': 2, 'nr_neurons': 219, 'dropout_rate': 0.00887708971411239, 'weight_decay': 0.0004908622568266822, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 14:34:07,013] Trial 519 pruned. 
[I 2025-11-04 14:34:25,388] Trial 520 pruned. 
[I 2025-11-04 14:34:33,579] Trial 521 pruned. 
[I 2025-11-04 14:34:51,923] Trial 522 pruned. 
[I 2025-11-04 14:36:55,610] Trial 523 pruned. 
[I 2025-11-04 14:40:14,658] Trial 524 pruned. 
[I 2025-11-04 14:40:32,270] Trial 525 pruned. 
2025-11-04 14:42:35,133 - INFO - Trial 526: Early stopping at epoch 70.
[I 2025-11-04 14:42:35,238] Trial 526 finished with value: 0.005805654053523015 and parameters: {'batch_size': 64, 'learning_rate': 0.0018400540395428853, 'nr_hidden_layers': 2, 'nr_neurons': 227, 'dropout_rate': 0.017014204152341894, 'weight_decay': 0.0003852142582841768, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 14:42:54,303] Trial 528 pruned. 
[I 2025-11-04 14:43:01,113] Trial 529 pruned. 
[I 2025-11-04 14:43:06,956] Trial 530 pruned. 
[I 2025-11-04 14:43:30,821] Trial 532 pruned. 
[I 2025-11-04 14:43:58,535] Trial 535 pruned. 
[I 2025-11-04 14:44:17,555] Trial 537 pruned. 
[I 2025-11-04 14:44:36,203] Trial 539 pruned. 
[I 2025-11-04 14:45:03,365] Trial 541 pruned. 
[I 2025-11-04 14:45:22,012] Trial 543 pruned. 
[I 2025-11-04 14:45:33,503] Trial 545 pruned. 
[I 2025-11-04 14:45:40,678] Trial 546 pruned. 
[I 2025-11-04 14:46:18,132] Trial 547 pruned. 
[I 2025-11-04 14:46:36,795] Trial 548 pruned. 
[I 2025-11-04 14:46:55,515] Trial 549 pruned. 
2025-11-04 14:49:48,421 - INFO - Trial 550: Early stopping at epoch 100.
[I 2025-11-04 14:49:48,534] Trial 550 finished with value: 0.004546849911675232 and parameters: {'batch_size': 64, 'learning_rate': 0.001764158145753545, 'nr_hidden_layers': 2, 'nr_neurons': 223, 'dropout_rate': 0.008327789654407804, 'weight_decay': 0.00015620911297378227, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 14:50:07,282] Trial 557 pruned. 
[I 2025-11-04 14:50:14,211] Trial 559 pruned. 
[I 2025-11-04 14:50:32,883] Trial 561 pruned. 
2025-11-04 14:53:42,812 - INFO - Trial 562: Early stopping at epoch 112.
[I 2025-11-04 14:53:42,907] Trial 562 finished with value: 0.003310855893517774 and parameters: {'batch_size': 64, 'learning_rate': 0.0016458879117734024, 'nr_hidden_layers': 2, 'nr_neurons': 228, 'dropout_rate': 0.0004852594592591309, 'weight_decay': 0.0002448429143239357, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.

Job started on argon-gtx
Job ID: 493
Working directory: /home/barattts/lavoltabuona/BA
---
Starting Python script...
Running: python run_optuna.py --target Area
2025-11-04 00:09:53,684 - INFO - Using device: cuda
2025-11-04 00:09:53,685 - INFO - Target labels for this run: ['Area']
2025-11-04 00:09:53,686 - INFO - Loading data for Optuna study (Labels: ['Area'])...
2025-11-04 00:09:53,860 - INFO - Starting Optuna study: nn_study_['Area']...
[I 2025-11-04 00:09:54,591] A new study created in RDB with name: nn_study_['Area']
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
2025-11-04 00:10:53,127 - INFO - Trial 0: Early stopping at epoch 75.
[I 2025-11-04 00:10:53,202] Trial 0 finished with value: 0.035749769969930394 and parameters: {'batch_size': 256, 'learning_rate': 0.009016125163078821, 'nr_hidden_layers': 1, 'nr_neurons': 60, 'dropout_rate': 0.23807797919397783, 'weight_decay': 7.755637407349951e-05, 'activation_name': 'ReLU', 'loss_criterion': 'L1'}. Best is trial 0 with value: 0.035749769969930394.
2025-11-04 00:14:05,820 - INFO - Trial 1: Early stopping at epoch 85.
[I 2025-11-04 00:14:05,883] Trial 1 finished with value: 0.031294745954180865 and parameters: {'batch_size': 64, 'learning_rate': 0.003300155395325728, 'nr_hidden_layers': 4, 'nr_neurons': 27, 'dropout_rate': 0.19008484461865144, 'weight_decay': 0.0012381884749605603, 'activation_name': 'ELU', 'loss_criterion': 'SmoothL1'}. Best is trial 1 with value: 0.031294745954180865.
2025-11-04 00:14:29,379 - INFO - Trial 2: Early stopping at epoch 46.
[I 2025-11-04 00:14:29,442] Trial 2 finished with value: 0.07667727188215345 and parameters: {'batch_size': 1024, 'learning_rate': 0.0050030733342068005, 'nr_hidden_layers': 2, 'nr_neurons': 85, 'dropout_rate': 0.44157495008421754, 'weight_decay': 1.2913128306788412e-06, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 1 with value: 0.031294745954180865.
2025-11-04 00:16:58,074 - INFO - Trial 3: Early stopping at epoch 248.
[I 2025-11-04 00:16:58,139] Trial 3 finished with value: 0.019337290809214716 and parameters: {'batch_size': 4096, 'learning_rate': 0.0018977630217570473, 'nr_hidden_layers': 2, 'nr_neurons': 45, 'dropout_rate': 0.021164876517663467, 'weight_decay': 9.960120880667705e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 3 with value: 0.019337290809214716.
2025-11-04 00:18:29,523 - INFO - Trial 4: Early stopping at epoch 149.
[I 2025-11-04 00:18:29,587] Trial 4 finished with value: 0.06635411754630789 and parameters: {'batch_size': 4096, 'learning_rate': 0.0009899520939574385, 'nr_hidden_layers': 5, 'nr_neurons': 115, 'dropout_rate': 0.480019316264429, 'weight_decay': 0.0010503317864734923, 'activation_name': 'LeakyReLU', 'loss_criterion': 'L1'}. Best is trial 3 with value: 0.019337290809214716.
[I 2025-11-04 00:18:51,253] Trial 5 pruned. 
[I 2025-11-04 00:19:11,954] Trial 6 pruned. 
[I 2025-11-04 00:19:19,620] Trial 7 pruned. 
[I 2025-11-04 00:19:34,028] Trial 8 pruned. 
[I 2025-11-04 00:19:40,983] Trial 9 pruned. 
2025-11-04 00:22:33,249 - INFO - Trial 10: Early stopping at epoch 289.
[I 2025-11-04 00:22:33,315] Trial 10 finished with value: 0.004689004131791803 and parameters: {'batch_size': 512, 'learning_rate': 0.0003576479862300152, 'nr_hidden_layers': 3, 'nr_neurons': 252, 'dropout_rate': 0.0034279678304202574, 'weight_decay': 1.6731065005342427e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:25:02,958] Trial 11 pruned. 
[I 2025-11-04 00:27:31,919] Trial 12 pruned. 
[I 2025-11-04 00:27:39,056] Trial 13 pruned. 
[I 2025-11-04 00:27:45,759] Trial 14 pruned. 
[I 2025-11-04 00:27:57,740] Trial 15 pruned. 
[I 2025-11-04 00:28:04,293] Trial 16 pruned. 
2025-11-04 00:28:31,989 - INFO - Trial 17: Early stopping at epoch 44.
[I 2025-11-04 00:28:32,053] Trial 17 finished with value: 0.02668837998253483 and parameters: {'batch_size': 512, 'learning_rate': 0.00200574202675297, 'nr_hidden_layers': 4, 'nr_neurons': 137, 'dropout_rate': 0.1643321822085001, 'weight_decay': 3.2244655313163954e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:28:38,549] Trial 18 pruned. 
[I 2025-11-04 00:28:45,337] Trial 19 pruned. 
2025-11-04 00:30:05,296 - INFO - Trial 20: Early stopping at epoch 39.
[I 2025-11-04 00:30:05,360] Trial 20 finished with value: 0.02055037076093636 and parameters: {'batch_size': 64, 'learning_rate': 0.002822734795569483, 'nr_hidden_layers': 4, 'nr_neurons': 24, 'dropout_rate': 0.038521364959144426, 'weight_decay': 9.656260003010475e-06, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 00:32:13,246 - INFO - Trial 21: Early stopping at epoch 64.
[I 2025-11-04 00:32:13,311] Trial 21 finished with value: 0.03290500635949219 and parameters: {'batch_size': 64, 'learning_rate': 0.0027017770947404657, 'nr_hidden_layers': 4, 'nr_neurons': 25, 'dropout_rate': 0.04006587901320264, 'weight_decay': 9.997177738598509e-06, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:32:35,121] Trial 22 pruned. 
2025-11-04 00:33:54,975 - INFO - Trial 23: Early stopping at epoch 43.
[I 2025-11-04 00:33:55,039] Trial 23 finished with value: 0.01815448294955144 and parameters: {'batch_size': 64, 'learning_rate': 0.0032413442452322435, 'nr_hidden_layers': 3, 'nr_neurons': 36, 'dropout_rate': 0.03223890326310175, 'weight_decay': 8.048639940165234e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:34:00,702] Trial 24 pruned. 
2025-11-04 00:34:35,999 - INFO - Trial 25: Early stopping at epoch 34.
[I 2025-11-04 00:34:36,063] Trial 25 finished with value: 0.032181580173324294 and parameters: {'batch_size': 128, 'learning_rate': 0.005250603906484106, 'nr_hidden_layers': 2, 'nr_neurons': 65, 'dropout_rate': 0.12483833757244049, 'weight_decay': 0.0002334607806841194, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:34:44,605] Trial 26 pruned. 
[I 2025-11-04 00:34:51,299] Trial 27 pruned. 
[I 2025-11-04 00:34:57,910] Trial 28 pruned. 
[I 2025-11-04 00:35:06,477] Trial 29 pruned. 
2025-11-04 00:36:33,217 - INFO - Trial 30: Early stopping at epoch 56.
[I 2025-11-04 00:36:33,282] Trial 30 finished with value: 0.024375665988749254 and parameters: {'batch_size': 64, 'learning_rate': 0.0013042096043300885, 'nr_hidden_layers': 1, 'nr_neurons': 42, 'dropout_rate': 0.09937690200626542, 'weight_decay': 0.00011829851906110353, 'activation_name': 'LeakyReLU', 'loss_criterion': 'L1'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 00:37:45,906 - INFO - Trial 31: Early stopping at epoch 36.
[I 2025-11-04 00:37:45,970] Trial 31 finished with value: 0.037499791196897454 and parameters: {'batch_size': 64, 'learning_rate': 0.002581499772944735, 'nr_hidden_layers': 4, 'nr_neurons': 25, 'dropout_rate': 0.03503317760722291, 'weight_decay': 1.3870877416127663e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 00:39:00,768 - INFO - Trial 32: Early stopping at epoch 37.
[I 2025-11-04 00:39:00,833] Trial 32 finished with value: 0.02105497404489175 and parameters: {'batch_size': 64, 'learning_rate': 0.0035871952442170707, 'nr_hidden_layers': 4, 'nr_neurons': 30, 'dropout_rate': 0.039719664220714324, 'weight_decay': 5.342399097430212e-06, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 00:39:58,610 - INFO - Trial 33: Early stopping at epoch 31.
[I 2025-11-04 00:39:58,676] Trial 33 finished with value: 0.030991650502062824 and parameters: {'batch_size': 64, 'learning_rate': 0.006558055365412014, 'nr_hidden_layers': 3, 'nr_neurons': 21, 'dropout_rate': 0.06471093401759384, 'weight_decay': 3.2639562988860565e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 00:41:53,207 - INFO - Trial 34: Early stopping at epoch 65.
[I 2025-11-04 00:41:53,272] Trial 34 finished with value: 0.012222118590791886 and parameters: {'batch_size': 64, 'learning_rate': 0.004020115108666063, 'nr_hidden_layers': 2, 'nr_neurons': 36, 'dropout_rate': 0.02080395902183351, 'weight_decay': 0.00033740902582556754, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 00:44:58,471 - INFO - Trial 35: Early stopping at epoch 108.
[I 2025-11-04 00:44:58,538] Trial 35 finished with value: 0.004979796530784249 and parameters: {'batch_size': 64, 'learning_rate': 0.0041734612545766235, 'nr_hidden_layers': 2, 'nr_neurons': 35, 'dropout_rate': 0.0005827800451096723, 'weight_decay': 0.0004432949008140396, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:45:14,945] Trial 36 pruned. 
2025-11-04 00:47:39,282 - INFO - Trial 37: Early stopping at epoch 81.
[I 2025-11-04 00:47:39,349] Trial 37 finished with value: 0.008764194948981825 and parameters: {'batch_size': 64, 'learning_rate': 0.006278046770594711, 'nr_hidden_layers': 2, 'nr_neurons': 74, 'dropout_rate': 0.0029553317684507955, 'weight_decay': 0.0006196207726527797, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 00:51:09,201 - INFO - Trial 38: Early stopping at epoch 124.
[I 2025-11-04 00:51:09,269] Trial 38 finished with value: 0.010495615624966158 and parameters: {'batch_size': 64, 'learning_rate': 0.0072093089065830744, 'nr_hidden_layers': 2, 'nr_neurons': 85, 'dropout_rate': 0.015284386004772083, 'weight_decay': 0.0005713597158153313, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:51:14,900] Trial 39 pruned. 
[I 2025-11-04 00:51:33,466] Trial 40 pruned. 
2025-11-04 00:53:11,232 - INFO - Trial 41: Early stopping at epoch 55.
[I 2025-11-04 00:53:11,299] Trial 41 finished with value: 0.011212591267769018 and parameters: {'batch_size': 64, 'learning_rate': 0.005166373080197459, 'nr_hidden_layers': 2, 'nr_neurons': 74, 'dropout_rate': 0.01690519596901954, 'weight_decay': 0.0004027445141342534, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:53:30,831] Trial 42 pruned. 
2025-11-04 00:55:48,890 - INFO - Trial 43: Early stopping at epoch 75.
[I 2025-11-04 00:55:48,958] Trial 43 finished with value: 0.007167822506400849 and parameters: {'batch_size': 64, 'learning_rate': 0.0053833509595159505, 'nr_hidden_layers': 2, 'nr_neurons': 58, 'dropout_rate': 0.0006870053084942606, 'weight_decay': 0.0018844739879813478, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:56:05,321] Trial 44 pruned. 
[I 2025-11-04 00:56:11,848] Trial 45 pruned. 
2025-11-04 00:57:22,846 - INFO - Trial 46: Early stopping at epoch 74.
[I 2025-11-04 00:57:22,914] Trial 46 finished with value: 0.01126259634609033 and parameters: {'batch_size': 128, 'learning_rate': 0.004822128963247764, 'nr_hidden_layers': 1, 'nr_neurons': 147, 'dropout_rate': 0.004293888509268175, 'weight_decay': 0.0016533641225604414, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 00:57:31,056] Trial 47 pruned. 
[I 2025-11-04 00:57:49,245] Trial 48 pruned. 
[I 2025-11-04 00:57:54,927] Trial 49 pruned. 
[I 2025-11-04 00:58:01,127] Trial 50 pruned. 
2025-11-04 00:59:49,303 - INFO - Trial 51: Early stopping at epoch 64.
[I 2025-11-04 00:59:49,372] Trial 51 finished with value: 0.011265501807272699 and parameters: {'batch_size': 64, 'learning_rate': 0.004443239710541873, 'nr_hidden_layers': 2, 'nr_neurons': 76, 'dropout_rate': 0.02444743918879138, 'weight_decay': 0.0005862722202639245, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:02:22,849 - INFO - Trial 52: Early stopping at epoch 91.
[I 2025-11-04 01:02:22,930] Trial 52 finished with value: 0.00741173664851813 and parameters: {'batch_size': 64, 'learning_rate': 0.00565444403411108, 'nr_hidden_layers': 2, 'nr_neurons': 73, 'dropout_rate': 0.002583495732458004, 'weight_decay': 0.00029818744136979493, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:03:22,901 - INFO - Trial 53: Early stopping at epoch 35.
[I 2025-11-04 01:03:22,967] Trial 53 finished with value: 0.01632947366765145 and parameters: {'batch_size': 64, 'learning_rate': 0.00800972041593068, 'nr_hidden_layers': 2, 'nr_neurons': 189, 'dropout_rate': 0.0019068058792489169, 'weight_decay': 0.00026845202205454886, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 01:03:41,299] Trial 54 pruned. 
[I 2025-11-04 01:04:01,672] Trial 55 pruned. 
[I 2025-11-04 01:04:08,978] Trial 56 pruned. 
[I 2025-11-04 01:04:27,833] Trial 57 pruned. 
[I 2025-11-04 01:05:09,378] Trial 58 pruned. 
[I 2025-11-04 01:05:27,512] Trial 59 pruned. 
[I 2025-11-04 01:05:34,300] Trial 60 pruned. 
2025-11-04 01:07:21,503 - INFO - Trial 61: Early stopping at epoch 63.
[I 2025-11-04 01:07:21,570] Trial 61 finished with value: 0.012677507454716467 and parameters: {'batch_size': 64, 'learning_rate': 0.005071284568358476, 'nr_hidden_layers': 2, 'nr_neurons': 72, 'dropout_rate': 0.02167105066474505, 'weight_decay': 0.0004261216115083767, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:08:39,418 - INFO - Trial 62: Early stopping at epoch 45.
[I 2025-11-04 01:08:39,492] Trial 62 finished with value: 0.014164474359181441 and parameters: {'batch_size': 64, 'learning_rate': 0.005449309688452028, 'nr_hidden_layers': 2, 'nr_neurons': 128, 'dropout_rate': 0.01751448122552368, 'weight_decay': 0.0003448711822496446, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 01:09:00,587] Trial 63 pruned. 
[I 2025-11-04 01:10:34,199] Trial 64 pruned. 
[I 2025-11-04 01:10:41,147] Trial 65 pruned. 
2025-11-04 01:13:24,692 - INFO - Trial 66: Early stopping at epoch 85.
[I 2025-11-04 01:13:24,790] Trial 66 finished with value: 0.010218125383404783 and parameters: {'batch_size': 64, 'learning_rate': 0.004609042108051847, 'nr_hidden_layers': 3, 'nr_neurons': 86, 'dropout_rate': 0.0145289810428243, 'weight_decay': 0.00047523220523546937, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 01:13:33,451] Trial 67 pruned. 
[I 2025-11-04 01:13:39,263] Trial 68 pruned. 
2025-11-04 01:16:16,143 - INFO - Trial 69: Early stopping at epoch 84.
[I 2025-11-04 01:16:16,232] Trial 69 finished with value: 0.01086981736942098 and parameters: {'batch_size': 64, 'learning_rate': 0.006145976804819801, 'nr_hidden_layers': 3, 'nr_neurons': 29, 'dropout_rate': 0.013106638463449038, 'weight_decay': 0.000293333093129812, 'activation_name': 'ELU', 'loss_criterion': 'L1'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 01:16:36,514] Trial 70 pruned. 
[I 2025-11-04 01:16:57,026] Trial 71 pruned. 
[I 2025-11-04 01:17:17,525] Trial 72 pruned. 
[I 2025-11-04 01:17:38,057] Trial 73 pruned. 
[I 2025-11-04 01:17:58,989] Trial 74 pruned. 
[I 2025-11-04 01:18:05,953] Trial 75 pruned. 
[I 2025-11-04 01:18:25,954] Trial 76 pruned. 
[I 2025-11-04 01:18:38,889] Trial 77 pruned. 
[I 2025-11-04 01:18:57,210] Trial 78 pruned. 
[I 2025-11-04 01:19:03,810] Trial 79 pruned. 
[I 2025-11-04 01:19:47,834] Trial 80 pruned. 
2025-11-04 01:22:08,914 - INFO - Trial 81: Early stopping at epoch 77.
[I 2025-11-04 01:22:08,983] Trial 81 finished with value: 0.009502350398498614 and parameters: {'batch_size': 64, 'learning_rate': 0.005204308661719575, 'nr_hidden_layers': 2, 'nr_neurons': 75, 'dropout_rate': 0.013476961249045369, 'weight_decay': 0.00022024634885837974, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 01:24:27,365] Trial 82 pruned. 
2025-11-04 01:26:43,788 - INFO - Trial 83: Early stopping at epoch 79.
[I 2025-11-04 01:26:43,857] Trial 83 finished with value: 0.009364126121722029 and parameters: {'batch_size': 64, 'learning_rate': 0.004948751975995237, 'nr_hidden_layers': 2, 'nr_neurons': 81, 'dropout_rate': 0.010021850737912794, 'weight_decay': 0.0002208055350192952, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:29:19,625 - INFO - Trial 84: Early stopping at epoch 90.
[I 2025-11-04 01:29:19,693] Trial 84 finished with value: 0.006162903761611697 and parameters: {'batch_size': 64, 'learning_rate': 0.00452326204663678, 'nr_hidden_layers': 2, 'nr_neurons': 66, 'dropout_rate': 0.0014938747048781557, 'weight_decay': 0.0002277747889153851, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:30:17,084 - INFO - Trial 85: Early stopping at epoch 78.
[I 2025-11-04 01:30:17,154] Trial 85 finished with value: 0.01054564417505071 and parameters: {'batch_size': 256, 'learning_rate': 0.0039842014659445335, 'nr_hidden_layers': 2, 'nr_neurons': 64, 'dropout_rate': 0.034230853451379904, 'weight_decay': 0.0002325499738374975, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:33:46,354 - INFO - Trial 86: Early stopping at epoch 119.
[I 2025-11-04 01:33:46,435] Trial 86 finished with value: 0.004845462943705086 and parameters: {'batch_size': 64, 'learning_rate': 0.004718388264689828, 'nr_hidden_layers': 2, 'nr_neurons': 58, 'dropout_rate': 0.0009107920547347915, 'weight_decay': 0.00020579632563979226, 'activation_name': 'ELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 01:33:52,932] Trial 87 pruned. 
2025-11-04 01:34:49,165 - INFO - Trial 88: Early stopping at epoch 33.
[I 2025-11-04 01:34:49,233] Trial 88 finished with value: 0.02276487449364223 and parameters: {'batch_size': 64, 'learning_rate': 0.005102392309293798, 'nr_hidden_layers': 2, 'nr_neurons': 57, 'dropout_rate': 0.05798156601761428, 'weight_decay': 8.798667178708091e-05, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 01:34:54,826] Trial 89 pruned. 
2025-11-04 01:36:48,225 - INFO - Trial 90: Early stopping at epoch 67.
[I 2025-11-04 01:36:48,293] Trial 90 finished with value: 0.0047237867722510745 and parameters: {'batch_size': 64, 'learning_rate': 0.0029799526063421264, 'nr_hidden_layers': 2, 'nr_neurons': 77, 'dropout_rate': 0.00043522626244629336, 'weight_decay': 0.00013174370535188885, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:40:08,621 - INFO - Trial 91: Early stopping at epoch 116.
[I 2025-11-04 01:40:08,691] Trial 91 finished with value: 0.008514206894257722 and parameters: {'batch_size': 64, 'learning_rate': 0.004033332060203114, 'nr_hidden_layers': 2, 'nr_neurons': 72, 'dropout_rate': 0.04613337286495889, 'weight_decay': 0.0001569439380893175, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:41:39,044 - INFO - Trial 92: Early stopping at epoch 53.
[I 2025-11-04 01:41:39,111] Trial 92 finished with value: 0.005924951578776709 and parameters: {'batch_size': 64, 'learning_rate': 0.0029499672961390663, 'nr_hidden_layers': 2, 'nr_neurons': 59, 'dropout_rate': 0.002620971376684228, 'weight_decay': 0.00013720696108329746, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:43:44,967 - INFO - Trial 93: Early stopping at epoch 61.
[I 2025-11-04 01:43:45,036] Trial 93 finished with value: 0.005402659190637144 and parameters: {'batch_size': 64, 'learning_rate': 0.002616623111956819, 'nr_hidden_layers': 2, 'nr_neurons': 52, 'dropout_rate': 0.0010237460157118965, 'weight_decay': 0.00014066384833106655, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:46:02,630 - INFO - Trial 94: Early stopping at epoch 80.
[I 2025-11-04 01:46:02,698] Trial 94 finished with value: 0.009382244241166637 and parameters: {'batch_size': 64, 'learning_rate': 0.0026363317532335073, 'nr_hidden_layers': 2, 'nr_neurons': 50, 'dropout_rate': 0.04561385987865024, 'weight_decay': 3.923282149056476e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:48:35,986 - INFO - Trial 95: Early stopping at epoch 92.
[I 2025-11-04 01:48:36,057] Trial 95 finished with value: 0.006775442522869566 and parameters: {'batch_size': 64, 'learning_rate': 0.0023991170362209556, 'nr_hidden_layers': 2, 'nr_neurons': 61, 'dropout_rate': 0.024957501440953954, 'weight_decay': 0.00012917593254634606, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
2025-11-04 01:51:02,866 - INFO - Trial 96: Early stopping at epoch 88.
[I 2025-11-04 01:51:02,934] Trial 96 finished with value: 0.009067207205309073 and parameters: {'batch_size': 64, 'learning_rate': 0.0029393353712905035, 'nr_hidden_layers': 2, 'nr_neurons': 59, 'dropout_rate': 0.025939048896244668, 'weight_decay': 9.90263549973223e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 10 with value: 0.004689004131791803.
[I 2025-11-04 01:51:09,496] Trial 97 pruned. 
[I 2025-11-04 01:51:29,327] Trial 98 pruned. 
[I 2025-11-04 01:51:41,574] Trial 99 pruned. 
2025-11-04 01:56:19,491 - INFO - Trial 100: Early stopping at epoch 163.
[I 2025-11-04 01:56:19,560] Trial 100 finished with value: 0.0032998721685287497 and parameters: {'batch_size': 64, 'learning_rate': 0.0023312005069114692, 'nr_hidden_layers': 2, 'nr_neurons': 55, 'dropout_rate': 0.0017446243680497653, 'weight_decay': 0.00010501615088689511, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 100 with value: 0.0032998721685287497.
2025-11-04 02:01:50,254 - INFO - Trial 101: Early stopping at epoch 190.
[I 2025-11-04 02:01:50,324] Trial 101 finished with value: 0.0023265188406348886 and parameters: {'batch_size': 64, 'learning_rate': 0.0023390828789765024, 'nr_hidden_layers': 2, 'nr_neurons': 54, 'dropout_rate': 0.00044278800831537985, 'weight_decay': 0.00012825891380511265, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:04:26,098 - INFO - Trial 102: Early stopping at epoch 89.
[I 2025-11-04 02:04:26,167] Trial 102 finished with value: 0.006917551973994787 and parameters: {'batch_size': 64, 'learning_rate': 0.00235941647201057, 'nr_hidden_layers': 2, 'nr_neurons': 55, 'dropout_rate': 0.025302043722443428, 'weight_decay': 0.00010547308369133812, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:06:18,369 - INFO - Trial 103: Early stopping at epoch 67.
[I 2025-11-04 02:06:18,439] Trial 103 finished with value: 0.008046679136319559 and parameters: {'batch_size': 64, 'learning_rate': 0.0023213419206991304, 'nr_hidden_layers': 2, 'nr_neurons': 54, 'dropout_rate': 0.02527769111992276, 'weight_decay': 9.802508701670548e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
[I 2025-11-04 02:06:37,680] Trial 104 pruned. 
2025-11-04 02:11:10,947 - INFO - Trial 105: Early stopping at epoch 153.
[I 2025-11-04 02:11:11,028] Trial 105 finished with value: 0.004636311204876732 and parameters: {'batch_size': 64, 'learning_rate': 0.0025420203497147995, 'nr_hidden_layers': 2, 'nr_neurons': 51, 'dropout_rate': 0.010421381319345387, 'weight_decay': 0.00013844467086820484, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
[I 2025-11-04 02:11:17,832] Trial 106 pruned. 
[I 2025-11-04 02:11:36,063] Trial 107 pruned. 
2025-11-04 02:13:15,106 - INFO - Trial 108: Early stopping at epoch 58.
[I 2025-11-04 02:13:15,175] Trial 108 finished with value: 0.0071875664013731555 and parameters: {'batch_size': 64, 'learning_rate': 0.0031969230139682584, 'nr_hidden_layers': 2, 'nr_neurons': 46, 'dropout_rate': 0.008851171412884126, 'weight_decay': 7.254474246020022e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
[I 2025-11-04 02:13:23,322] Trial 109 pruned. 
2025-11-04 02:16:43,732 - INFO - Trial 110: Early stopping at epoch 117.
[I 2025-11-04 02:16:43,816] Trial 110 finished with value: 0.006477506476317011 and parameters: {'batch_size': 64, 'learning_rate': 0.0024709181971400494, 'nr_hidden_layers': 2, 'nr_neurons': 43, 'dropout_rate': 0.0207301813388809, 'weight_decay': 0.00018178374474970654, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:19:49,518 - INFO - Trial 111: Early stopping at epoch 110.
[I 2025-11-04 02:19:49,588] Trial 111 finished with value: 0.005051724567874063 and parameters: {'batch_size': 64, 'learning_rate': 0.002493087534468591, 'nr_hidden_layers': 2, 'nr_neurons': 43, 'dropout_rate': 0.009074417042007973, 'weight_decay': 0.00014032216950454526, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:23:57,128 - INFO - Trial 112: Early stopping at epoch 133.
[I 2025-11-04 02:23:57,200] Trial 112 finished with value: 0.004997883094544792 and parameters: {'batch_size': 64, 'learning_rate': 0.0030233010826053943, 'nr_hidden_layers': 2, 'nr_neurons': 32, 'dropout_rate': 0.009661431808602359, 'weight_decay': 0.00017456806655071999, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
[I 2025-11-04 02:24:15,459] Trial 113 pruned. 
2025-11-04 02:26:17,414 - INFO - Trial 114: Early stopping at epoch 73.
[I 2025-11-04 02:26:17,485] Trial 114 finished with value: 0.007030236606618 and parameters: {'batch_size': 64, 'learning_rate': 0.00334377630052309, 'nr_hidden_layers': 2, 'nr_neurons': 39, 'dropout_rate': 0.00862227983213973, 'weight_decay': 0.00015932522868261477, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:29:13,739 - INFO - Trial 115: Early stopping at epoch 101.
[I 2025-11-04 02:29:13,811] Trial 115 finished with value: 0.004782343992639545 and parameters: {'batch_size': 64, 'learning_rate': 0.0017568861322056792, 'nr_hidden_layers': 2, 'nr_neurons': 34, 'dropout_rate': 0.00013025372621462336, 'weight_decay': 0.00024845125648620457, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
[I 2025-11-04 02:29:20,382] Trial 116 pruned. 
[I 2025-11-04 02:29:26,115] Trial 117 pruned. 
[I 2025-11-04 02:29:44,392] Trial 118 pruned. 
[I 2025-11-04 02:30:07,736] Trial 119 pruned. 
[I 2025-11-04 02:30:27,501] Trial 120 pruned. 
2025-11-04 02:33:59,982 - INFO - Trial 121: Early stopping at epoch 127.
[I 2025-11-04 02:34:00,053] Trial 121 finished with value: 0.005390370554777885 and parameters: {'batch_size': 64, 'learning_rate': 0.003085721892881456, 'nr_hidden_layers': 2, 'nr_neurons': 31, 'dropout_rate': 0.006924210984187683, 'weight_decay': 0.000183957560260274, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:36:16,320 - INFO - Trial 122: Early stopping at epoch 72.
[I 2025-11-04 02:36:16,402] Trial 122 finished with value: 0.006455042939678133 and parameters: {'batch_size': 64, 'learning_rate': 0.003745324126369997, 'nr_hidden_layers': 2, 'nr_neurons': 31, 'dropout_rate': 0.009022137196809742, 'weight_decay': 0.00018433894018609297, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:40:05,324 - INFO - Trial 123: Early stopping at epoch 136.
[I 2025-11-04 02:40:05,396] Trial 123 finished with value: 0.002832973630190867 and parameters: {'batch_size': 64, 'learning_rate': 0.0030307269209414994, 'nr_hidden_layers': 2, 'nr_neurons': 44, 'dropout_rate': 0.00023200087517106892, 'weight_decay': 0.00011705061132780218, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:42:51,955 - INFO - Trial 124: Early stopping at epoch 100.
[I 2025-11-04 02:42:52,026] Trial 124 finished with value: 0.0036322685470643375 and parameters: {'batch_size': 64, 'learning_rate': 0.0031208093216095185, 'nr_hidden_layers': 2, 'nr_neurons': 44, 'dropout_rate': 0.00015756472139532337, 'weight_decay': 0.00017767597524348454, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:44:47,776 - INFO - Trial 125: Early stopping at epoch 69.
[I 2025-11-04 02:44:47,855] Trial 125 finished with value: 0.008954958971467402 and parameters: {'batch_size': 64, 'learning_rate': 0.0031991747554740665, 'nr_hidden_layers': 2, 'nr_neurons': 44, 'dropout_rate': 0.021442051596666806, 'weight_decay': 0.0003115451560796026, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
[I 2025-11-04 02:45:06,077] Trial 126 pruned. 
[I 2025-11-04 02:45:24,370] Trial 127 pruned. 
[I 2025-11-04 02:45:42,623] Trial 128 pruned. 
[I 2025-11-04 02:45:49,088] Trial 129 pruned. 
[I 2025-11-04 02:46:00,285] Trial 130 pruned. 
2025-11-04 02:49:03,440 - INFO - Trial 131: Early stopping at epoch 110.
[I 2025-11-04 02:49:03,514] Trial 131 finished with value: 0.004735585412863713 and parameters: {'batch_size': 64, 'learning_rate': 0.002712957151973114, 'nr_hidden_layers': 2, 'nr_neurons': 49, 'dropout_rate': 0.00020284456430861493, 'weight_decay': 0.0001602279322502635, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:52:32,752 - INFO - Trial 132: Early stopping at epoch 121.
[I 2025-11-04 02:52:32,835] Trial 132 finished with value: 0.003406261933758593 and parameters: {'batch_size': 64, 'learning_rate': 0.0027143463249642286, 'nr_hidden_layers': 2, 'nr_neurons': 36, 'dropout_rate': 0.0007400721318561829, 'weight_decay': 0.00017493996803253202, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 02:56:45,060 - INFO - Trial 133: Early stopping at epoch 145.
[I 2025-11-04 02:56:45,133] Trial 133 finished with value: 0.0024301168259304334 and parameters: {'batch_size': 64, 'learning_rate': 0.002809663079435974, 'nr_hidden_layers': 2, 'nr_neurons': 37, 'dropout_rate': 3.4093130862110794e-05, 'weight_decay': 8.823906705905348e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
[I 2025-11-04 02:57:03,421] Trial 134 pruned. 
[I 2025-11-04 02:59:06,568] Trial 135 pruned. 
[I 2025-11-04 02:59:13,403] Trial 136 pruned. 
[I 2025-11-04 02:59:34,458] Trial 137 pruned. 
[I 2025-11-04 02:59:52,693] Trial 138 pruned. 
2025-11-04 03:02:31,818 - INFO - Trial 139: Early stopping at epoch 95.
[I 2025-11-04 03:02:31,889] Trial 139 finished with value: 0.0033336222858054957 and parameters: {'batch_size': 64, 'learning_rate': 0.0028256302138549593, 'nr_hidden_layers': 2, 'nr_neurons': 207, 'dropout_rate': 0.0008171167017167884, 'weight_decay': 0.00024560734609220514, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:03:20,879 - INFO - Trial 140: Early stopping at epoch 63.
[I 2025-11-04 03:03:20,948] Trial 140 finished with value: 0.007911324837837738 and parameters: {'batch_size': 256, 'learning_rate': 0.0026593138571000454, 'nr_hidden_layers': 2, 'nr_neurons': 221, 'dropout_rate': 0.021730733696228893, 'weight_decay': 0.0004530499423552516, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:06:10,175 - INFO - Trial 141: Early stopping at epoch 101.
[I 2025-11-04 03:06:10,246] Trial 141 finished with value: 0.003092897696422202 and parameters: {'batch_size': 64, 'learning_rate': 0.002830237931382506, 'nr_hidden_layers': 2, 'nr_neurons': 236, 'dropout_rate': 0.001179061912249361, 'weight_decay': 0.00031802577904209824, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:09:07,501 - INFO - Trial 142: Early stopping at epoch 99.
[I 2025-11-04 03:09:07,574] Trial 142 finished with value: 0.003583351262533121 and parameters: {'batch_size': 64, 'learning_rate': 0.0022800195881401523, 'nr_hidden_layers': 2, 'nr_neurons': 249, 'dropout_rate': 0.000833082671600073, 'weight_decay': 0.000367149742934199, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:14:53,509 - INFO - Trial 143: Early stopping at epoch 199.
[I 2025-11-04 03:14:53,593] Trial 143 finished with value: 0.00238691621835406 and parameters: {'batch_size': 64, 'learning_rate': 0.0020877594897380836, 'nr_hidden_layers': 2, 'nr_neurons': 203, 'dropout_rate': 0.0014627982751344822, 'weight_decay': 0.00033093444303507554, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:16:29,482 - INFO - Trial 144: Early stopping at epoch 56.
[I 2025-11-04 03:16:29,551] Trial 144 finished with value: 0.006859497412948242 and parameters: {'batch_size': 64, 'learning_rate': 0.0017818423993148987, 'nr_hidden_layers': 2, 'nr_neurons': 251, 'dropout_rate': 0.016240937934129795, 'weight_decay': 0.00030976222140347703, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:19:33,602 - INFO - Trial 145: Early stopping at epoch 109.
[I 2025-11-04 03:19:33,675] Trial 145 finished with value: 0.004035731563910439 and parameters: {'batch_size': 64, 'learning_rate': 0.0021306514285948383, 'nr_hidden_layers': 2, 'nr_neurons': 204, 'dropout_rate': 0.002025913629556762, 'weight_decay': 0.00027753539930650017, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:21:37,568 - INFO - Trial 146: Early stopping at epoch 72.
[I 2025-11-04 03:21:37,639] Trial 146 finished with value: 0.006182637568357223 and parameters: {'batch_size': 64, 'learning_rate': 0.0021610142004061584, 'nr_hidden_layers': 2, 'nr_neurons': 202, 'dropout_rate': 0.02922826953534735, 'weight_decay': 0.00038206290874449617, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:24:43,315 - INFO - Trial 147: Early stopping at epoch 108.
[I 2025-11-04 03:24:43,386] Trial 147 finished with value: 0.0027100493596822236 and parameters: {'batch_size': 64, 'learning_rate': 0.002372963284932545, 'nr_hidden_layers': 2, 'nr_neurons': 202, 'dropout_rate': 0.00012114713156833114, 'weight_decay': 0.0003110925218803501, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
[I 2025-11-04 03:24:49,921] Trial 148 pruned. 
2025-11-04 03:27:02,780 - INFO - Trial 149: Early stopping at epoch 79.
[I 2025-11-04 03:27:02,851] Trial 149 finished with value: 0.005551116934362596 and parameters: {'batch_size': 64, 'learning_rate': 0.0020330502317160966, 'nr_hidden_layers': 2, 'nr_neurons': 238, 'dropout_rate': 0.010799477725801605, 'weight_decay': 0.00034438975183580115, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
[I 2025-11-04 03:27:08,602] Trial 150 pruned. 
2025-11-04 03:28:40,042 - INFO - Trial 151: Early stopping at epoch 53.
[I 2025-11-04 03:28:40,115] Trial 151 finished with value: 0.007213702218660594 and parameters: {'batch_size': 64, 'learning_rate': 0.0028220760776232817, 'nr_hidden_layers': 2, 'nr_neurons': 208, 'dropout_rate': 0.01175371183252955, 'weight_decay': 0.00025516196656191135, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:31:24,433 - INFO - Trial 152: Early stopping at epoch 82.
[I 2025-11-04 03:31:24,505] Trial 152 finished with value: 0.0043153753333327795 and parameters: {'batch_size': 64, 'learning_rate': 0.0021576078355718684, 'nr_hidden_layers': 2, 'nr_neurons': 178, 'dropout_rate': 0.0010956121670966559, 'weight_decay': 0.0003259576622922677, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 101 with value: 0.0023265188406348886.
2025-11-04 03:37:40,008 - INFO - Trial 153: Early stopping at epoch 223.
[I 2025-11-04 03:37:40,082] Trial 153 finished with value: 0.0017232450908056518 and parameters: {'batch_size': 64, 'learning_rate': 0.00155813825910047, 'nr_hidden_layers': 2, 'nr_neurons': 179, 'dropout_rate': 0.00011304352476430943, 'weight_decay': 0.0003412592283104479, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 153 with value: 0.0017232450908056518.
[I 2025-11-04 03:37:58,551] Trial 154 pruned. 
2025-11-04 03:40:53,035 - INFO - Trial 155: Early stopping at epoch 95.
[I 2025-11-04 03:40:53,107] Trial 155 finished with value: 0.0050686222565355325 and parameters: {'batch_size': 64, 'learning_rate': 0.0015718098187667195, 'nr_hidden_layers': 2, 'nr_neurons': 175, 'dropout_rate': 0.010139525583702387, 'weight_decay': 0.00031644077702867255, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 153 with value: 0.0017232450908056518.
2025-11-04 03:46:26,482 - INFO - Trial 156: Early stopping at epoch 195.
[I 2025-11-04 03:46:26,555] Trial 156 finished with value: 0.001703693990911879 and parameters: {'batch_size': 64, 'learning_rate': 0.00196258307677906, 'nr_hidden_layers': 2, 'nr_neurons': 240, 'dropout_rate': 0.00011397177303976765, 'weight_decay': 0.0005146727726270247, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 03:49:38,191 - INFO - Trial 157: Early stopping at epoch 111.
[I 2025-11-04 03:49:38,263] Trial 157 finished with value: 0.0031992184399321105 and parameters: {'batch_size': 64, 'learning_rate': 0.0020511009644638995, 'nr_hidden_layers': 2, 'nr_neurons': 235, 'dropout_rate': 0.0006210535885154249, 'weight_decay': 0.0006304073622846829, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 03:54:13,089] Trial 158 pruned. 
2025-11-04 03:57:33,330 - INFO - Trial 159: Early stopping at epoch 114.
[I 2025-11-04 03:57:33,402] Trial 159 finished with value: 0.003166019049682109 and parameters: {'batch_size': 64, 'learning_rate': 0.001940698898758376, 'nr_hidden_layers': 2, 'nr_neurons': 210, 'dropout_rate': 0.0004893032945299006, 'weight_decay': 0.00048777467502667096, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 03:57:56,895] Trial 160 pruned. 
2025-11-04 04:01:16,522 - INFO - Trial 161: Early stopping at epoch 118.
[I 2025-11-04 04:01:16,613] Trial 161 finished with value: 0.002950986106544083 and parameters: {'batch_size': 64, 'learning_rate': 0.001603027820126278, 'nr_hidden_layers': 2, 'nr_neurons': 211, 'dropout_rate': 0.002153330745210171, 'weight_decay': 0.0004908837180209471, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 04:05:41,443 - INFO - Trial 162: Early stopping at epoch 148.
[I 2025-11-04 04:05:41,518] Trial 162 finished with value: 0.0024778737285700444 and parameters: {'batch_size': 64, 'learning_rate': 0.0015132310132768328, 'nr_hidden_layers': 2, 'nr_neurons': 213, 'dropout_rate': 0.0004459337206613683, 'weight_decay': 0.0006243208402091219, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 04:07:29,412 - INFO - Trial 163: Early stopping at epoch 62.
[I 2025-11-04 04:07:29,486] Trial 163 finished with value: 0.006839146084585311 and parameters: {'batch_size': 64, 'learning_rate': 0.0015790664992168834, 'nr_hidden_layers': 2, 'nr_neurons': 213, 'dropout_rate': 0.018218637408468293, 'weight_decay': 0.0007549155556533404, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 04:13:42,336 - INFO - Trial 164: Early stopping at epoch 223.
[I 2025-11-04 04:13:42,411] Trial 164 finished with value: 0.0018375076887480418 and parameters: {'batch_size': 64, 'learning_rate': 0.0013007368740094705, 'nr_hidden_layers': 2, 'nr_neurons': 227, 'dropout_rate': 0.0005055490932731704, 'weight_decay': 0.0006223600050677631, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 04:16:13,578 - INFO - Trial 165: Early stopping at epoch 90.
[I 2025-11-04 04:16:13,650] Trial 165 finished with value: 0.005502092370785997 and parameters: {'batch_size': 64, 'learning_rate': 0.0015536291717713018, 'nr_hidden_layers': 2, 'nr_neurons': 230, 'dropout_rate': 0.030041455311321748, 'weight_decay': 0.0006055462268947308, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 04:16:32,072] Trial 166 pruned. 
[I 2025-11-04 04:16:50,513] Trial 167 pruned. 
2025-11-04 04:20:13,254 - INFO - Trial 168: Early stopping at epoch 120.
[I 2025-11-04 04:20:13,327] Trial 168 finished with value: 0.004063426870787914 and parameters: {'batch_size': 64, 'learning_rate': 0.0018723229538061433, 'nr_hidden_layers': 2, 'nr_neurons': 237, 'dropout_rate': 0.01095835758912041, 'weight_decay': 0.0009412391007810916, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 04:23:41,677 - INFO - Trial 169: Early stopping at epoch 116.
[I 2025-11-04 04:23:41,751] Trial 169 finished with value: 0.004810453688696731 and parameters: {'batch_size': 64, 'learning_rate': 0.0011664071752203744, 'nr_hidden_layers': 2, 'nr_neurons': 163, 'dropout_rate': 0.020793372603409025, 'weight_decay': 0.0004390671200042368, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 04:24:00,289] Trial 170 pruned. 
2025-11-04 04:27:04,594 - INFO - Trial 171: Early stopping at epoch 108.
[I 2025-11-04 04:27:04,670] Trial 171 finished with value: 0.0028878806247821668 and parameters: {'batch_size': 64, 'learning_rate': 0.0016949649472788228, 'nr_hidden_layers': 2, 'nr_neurons': 226, 'dropout_rate': 0.0009197729793027875, 'weight_decay': 0.000526217931592782, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 04:29:56,498 - INFO - Trial 172: Early stopping at epoch 92.
[I 2025-11-04 04:29:56,572] Trial 172 finished with value: 0.0029332181894752736 and parameters: {'batch_size': 64, 'learning_rate': 0.0016818441023689961, 'nr_hidden_layers': 2, 'nr_neurons': 225, 'dropout_rate': 0.0005080443755686155, 'weight_decay': 0.0005499397788998313, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 04:34:21,360] Trial 173 pruned. 
2025-11-04 04:37:01,861 - INFO - Trial 174: Early stopping at epoch 93.
[I 2025-11-04 04:37:01,935] Trial 174 finished with value: 0.0030639633833171205 and parameters: {'batch_size': 64, 'learning_rate': 0.0016470341299268075, 'nr_hidden_layers': 2, 'nr_neurons': 210, 'dropout_rate': 0.0002978199773784132, 'weight_decay': 0.0009597950447819424, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 04:39:17,854 - INFO - Trial 175: Early stopping at epoch 70.
[I 2025-11-04 04:39:17,928] Trial 175 finished with value: 0.005995878983046708 and parameters: {'batch_size': 64, 'learning_rate': 0.0016658214257595856, 'nr_hidden_layers': 2, 'nr_neurons': 210, 'dropout_rate': 0.021528992145449403, 'weight_decay': 0.0011680581096143359, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 04:39:29,307] Trial 176 pruned. 
2025-11-04 04:42:13,869 - INFO - Trial 177: Early stopping at epoch 97.
[I 2025-11-04 04:42:13,944] Trial 177 finished with value: 0.004793028596090157 and parameters: {'batch_size': 64, 'learning_rate': 0.0012688138131294485, 'nr_hidden_layers': 2, 'nr_neurons': 190, 'dropout_rate': 0.01951262932596887, 'weight_decay': 0.001355522229670154, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 04:46:18,787 - INFO - Trial 178: Early stopping at epoch 141.
[I 2025-11-04 04:46:18,864] Trial 178 finished with value: 0.0019218407461842576 and parameters: {'batch_size': 64, 'learning_rate': 0.0018522922492381303, 'nr_hidden_layers': 2, 'nr_neurons': 220, 'dropout_rate': 9.441605779113077e-06, 'weight_decay': 0.0006208902890618567, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 04:46:25,564] Trial 179 pruned. 
2025-11-04 04:50:08,476 - INFO - Trial 180: Early stopping at epoch 131.
[I 2025-11-04 04:50:08,561] Trial 180 finished with value: 0.002382251527082925 and parameters: {'batch_size': 64, 'learning_rate': 0.0015225190050177178, 'nr_hidden_layers': 2, 'nr_neurons': 223, 'dropout_rate': 5.082351686300527e-06, 'weight_decay': 0.0008459538831013483, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 04:52:55,617] Trial 181 pruned. 
[I 2025-11-04 04:56:00,338] Trial 182 pruned. 
[I 2025-11-04 04:58:24,212] Trial 183 pruned. 
2025-11-04 05:01:19,606 - INFO - Trial 184: Early stopping at epoch 102.
[I 2025-11-04 05:01:19,685] Trial 184 finished with value: 0.004135804148069693 and parameters: {'batch_size': 64, 'learning_rate': 0.0013551877298336066, 'nr_hidden_layers': 2, 'nr_neurons': 199, 'dropout_rate': 0.00079614135354137, 'weight_decay': 0.0006286670838915534, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 05:01:38,222] Trial 185 pruned. 
2025-11-04 05:06:28,678 - INFO - Trial 186: Early stopping at epoch 171.
[I 2025-11-04 05:06:28,766] Trial 186 finished with value: 0.002144483182101648 and parameters: {'batch_size': 64, 'learning_rate': 0.0020353078499482933, 'nr_hidden_layers': 2, 'nr_neurons': 186, 'dropout_rate': 0.0002871801606311408, 'weight_decay': 0.0004499185687485009, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 05:08:52,360] Trial 187 pruned. 
2025-11-04 05:13:37,865 - INFO - Trial 188: Early stopping at epoch 152.
[I 2025-11-04 05:13:37,945] Trial 188 finished with value: 0.0019672053204514146 and parameters: {'batch_size': 64, 'learning_rate': 0.0019846762972843845, 'nr_hidden_layers': 2, 'nr_neurons': 174, 'dropout_rate': 0.00021015973754471044, 'weight_decay': 0.0005035921945080893, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 05:13:56,498] Trial 189 pruned. 
[I 2025-11-04 05:14:04,893] Trial 190 pruned. 
2025-11-04 05:16:48,538 - INFO - Trial 191: Early stopping at epoch 97.
[I 2025-11-04 05:16:48,612] Trial 191 finished with value: 0.004004495602067035 and parameters: {'batch_size': 64, 'learning_rate': 0.002053275057763007, 'nr_hidden_layers': 2, 'nr_neurons': 207, 'dropout_rate': 0.006681709161118788, 'weight_decay': 0.0006723414186946356, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 05:20:35,640 - INFO - Trial 192: Early stopping at epoch 131.
[I 2025-11-04 05:20:35,715] Trial 192 finished with value: 0.0026781699816892943 and parameters: {'batch_size': 64, 'learning_rate': 0.0016434368376432203, 'nr_hidden_layers': 2, 'nr_neurons': 217, 'dropout_rate': 0.0016187148267935117, 'weight_decay': 0.0005617184894856109, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 05:23:30,619 - INFO - Trial 193: Early stopping at epoch 103.
[I 2025-11-04 05:23:30,735] Trial 193 finished with value: 0.005272857274811596 and parameters: {'batch_size': 64, 'learning_rate': 0.0016268613422992417, 'nr_hidden_layers': 2, 'nr_neurons': 184, 'dropout_rate': 0.018310412969621558, 'weight_decay': 0.00040773407864280514, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 05:28:33,439 - INFO - Trial 194: Early stopping at epoch 172.
[I 2025-11-04 05:28:33,515] Trial 194 finished with value: 0.0017897426411018452 and parameters: {'batch_size': 64, 'learning_rate': 0.0011572557976751129, 'nr_hidden_layers': 2, 'nr_neurons': 220, 'dropout_rate': 4.0768083449835367e-05, 'weight_decay': 0.0008169274724774148, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 05:28:52,029] Trial 195 pruned. 
[I 2025-11-04 05:29:10,527] Trial 196 pruned. 
[I 2025-11-04 05:29:16,342] Trial 197 pruned. 
[I 2025-11-04 05:29:45,277] Trial 198 pruned. 
2025-11-04 05:33:18,229 - INFO - Trial 199: Early stopping at epoch 122.
[I 2025-11-04 05:33:18,306] Trial 199 finished with value: 0.002323318970192309 and parameters: {'batch_size': 64, 'learning_rate': 0.0017500595302689785, 'nr_hidden_layers': 2, 'nr_neurons': 244, 'dropout_rate': 0.00020815364592747046, 'weight_decay': 0.00036293944392730025, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 05:36:29,571] Trial 200 pruned. 
2025-11-04 05:39:23,208 - INFO - Trial 201: Early stopping at epoch 102.
[I 2025-11-04 05:39:23,285] Trial 201 finished with value: 0.003134758232204909 and parameters: {'batch_size': 64, 'learning_rate': 0.001555008212387015, 'nr_hidden_layers': 2, 'nr_neurons': 215, 'dropout_rate': 0.0004018925457473, 'weight_decay': 0.0005631066314056518, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 05:44:37,159 - INFO - Trial 202: Early stopping at epoch 183.
[I 2025-11-04 05:44:37,237] Trial 202 finished with value: 0.0022608223012242413 and parameters: {'batch_size': 64, 'learning_rate': 0.0018055981123317258, 'nr_hidden_layers': 2, 'nr_neurons': 242, 'dropout_rate': 0.0004777948293977172, 'weight_decay': 0.00036874416125972726, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 05:47:43,163 - INFO - Trial 203: Early stopping at epoch 109.
[I 2025-11-04 05:47:43,239] Trial 203 finished with value: 0.004327050220387058 and parameters: {'batch_size': 64, 'learning_rate': 0.0016885657491153346, 'nr_hidden_layers': 2, 'nr_neurons': 199, 'dropout_rate': 0.010937374357714667, 'weight_decay': 0.0007449744777475171, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 05:50:28,110 - INFO - Trial 204: Early stopping at epoch 92.
[I 2025-11-04 05:50:28,187] Trial 204 finished with value: 0.005223900776732692 and parameters: {'batch_size': 64, 'learning_rate': 0.0018262752645400934, 'nr_hidden_layers': 2, 'nr_neurons': 242, 'dropout_rate': 0.009752294282155915, 'weight_decay': 0.00043492342101297165, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 05:50:48,349] Trial 205 pruned. 
[I 2025-11-04 05:51:06,845] Trial 206 pruned. 
[I 2025-11-04 05:54:10,415] Trial 207 pruned. 
2025-11-04 05:58:16,951 - INFO - Trial 208: Early stopping at epoch 144.
[I 2025-11-04 05:58:17,028] Trial 208 finished with value: 0.002450723304253892 and parameters: {'batch_size': 64, 'learning_rate': 0.0016449255288424334, 'nr_hidden_layers': 2, 'nr_neurons': 158, 'dropout_rate': 0.0009370261143665355, 'weight_decay': 0.0008969113557074593, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:02:32,043 - INFO - Trial 209: Early stopping at epoch 144.
[I 2025-11-04 06:02:32,130] Trial 209 finished with value: 0.002144540011959881 and parameters: {'batch_size': 64, 'learning_rate': 0.002003996483706191, 'nr_hidden_layers': 2, 'nr_neurons': 192, 'dropout_rate': 6.218669962836229e-05, 'weight_decay': 0.0005803002930645313, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:07:00,248 - INFO - Trial 210: Early stopping at epoch 157.
[I 2025-11-04 06:07:00,325] Trial 210 finished with value: 0.0019556789956991947 and parameters: {'batch_size': 64, 'learning_rate': 0.002218021724735613, 'nr_hidden_layers': 2, 'nr_neurons': 166, 'dropout_rate': 5.3122278756485014e-05, 'weight_decay': 0.0006087090019984425, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:10:46,174 - INFO - Trial 211: Early stopping at epoch 132.
[I 2025-11-04 06:10:46,251] Trial 211 finished with value: 0.004049947734640692 and parameters: {'batch_size': 64, 'learning_rate': 0.0022189310289409663, 'nr_hidden_layers': 2, 'nr_neurons': 166, 'dropout_rate': 0.009675607063200455, 'weight_decay': 0.0006006467054195102, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:14:55,229 - INFO - Trial 212: Early stopping at epoch 145.
[I 2025-11-04 06:14:55,314] Trial 212 finished with value: 0.002564592576199526 and parameters: {'batch_size': 64, 'learning_rate': 0.001965883830961385, 'nr_hidden_layers': 2, 'nr_neurons': 155, 'dropout_rate': 0.0011195557042287252, 'weight_decay': 0.000823646948228683, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:18:44,848 - INFO - Trial 213: Early stopping at epoch 136.
[I 2025-11-04 06:18:44,926] Trial 213 finished with value: 0.0024064227695382444 and parameters: {'batch_size': 64, 'learning_rate': 0.0020223303047922775, 'nr_hidden_layers': 2, 'nr_neurons': 166, 'dropout_rate': 0.00012039052706208663, 'weight_decay': 0.0007927013610682116, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 06:21:01,074] Trial 214 pruned. 
2025-11-04 06:23:22,633 - INFO - Trial 215: Early stopping at epoch 84.
[I 2025-11-04 06:23:22,708] Trial 215 finished with value: 0.005483768295466217 and parameters: {'batch_size': 64, 'learning_rate': 0.0023455672327879298, 'nr_hidden_layers': 2, 'nr_neurons': 157, 'dropout_rate': 0.01114680879626126, 'weight_decay': 0.0008359868139199343, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:24:49,658 - INFO - Trial 216: Early stopping at epoch 50.
[I 2025-11-04 06:24:49,736] Trial 216 finished with value: 0.007808778014049641 and parameters: {'batch_size': 64, 'learning_rate': 0.0021081254030867087, 'nr_hidden_layers': 2, 'nr_neurons': 152, 'dropout_rate': 0.018232411477998256, 'weight_decay': 0.0011060929548208987, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:28:09,845 - INFO - Trial 217: Early stopping at epoch 117.
[I 2025-11-04 06:28:09,929] Trial 217 finished with value: 0.004226907274941152 and parameters: {'batch_size': 64, 'learning_rate': 0.0020093610846059614, 'nr_hidden_layers': 2, 'nr_neurons': 156, 'dropout_rate': 0.010219991905123973, 'weight_decay': 0.0007358781788357956, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 06:28:21,309] Trial 218 pruned. 
[I 2025-11-04 06:29:56,551] Trial 219 pruned. 
[I 2025-11-04 06:30:03,250] Trial 220 pruned. 
2025-11-04 06:34:17,885 - INFO - Trial 221: Early stopping at epoch 150.
[I 2025-11-04 06:34:17,962] Trial 221 finished with value: 0.0018320893429119897 and parameters: {'batch_size': 64, 'learning_rate': 0.0018509124512151292, 'nr_hidden_layers': 2, 'nr_neurons': 181, 'dropout_rate': 0.0002968597198542962, 'weight_decay': 0.00036754151370859545, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:36:03,447 - INFO - Trial 222: Early stopping at epoch 54.
[I 2025-11-04 06:36:03,522] Trial 222 finished with value: 0.005846593869442664 and parameters: {'batch_size': 64, 'learning_rate': 0.0019663286834806534, 'nr_hidden_layers': 2, 'nr_neurons': 181, 'dropout_rate': 0.010057436658193347, 'weight_decay': 0.00036497128389446925, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:39:40,004 - INFO - Trial 223: Early stopping at epoch 124.
[I 2025-11-04 06:39:40,082] Trial 223 finished with value: 0.002275562444250195 and parameters: {'batch_size': 64, 'learning_rate': 0.0018619016392431049, 'nr_hidden_layers': 2, 'nr_neurons': 166, 'dropout_rate': 0.00017275977697411263, 'weight_decay': 0.00038812680892398707, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:42:15,319 - INFO - Trial 224: Early stopping at epoch 89.
[I 2025-11-04 06:42:15,395] Trial 224 finished with value: 0.005753996023100448 and parameters: {'batch_size': 64, 'learning_rate': 0.001848946648849795, 'nr_hidden_layers': 2, 'nr_neurons': 169, 'dropout_rate': 0.019250257001766576, 'weight_decay': 0.00041325522318857636, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:44:56,549 - INFO - Trial 225: Early stopping at epoch 96.
[I 2025-11-04 06:44:56,627] Trial 225 finished with value: 0.0027884505826481177 and parameters: {'batch_size': 64, 'learning_rate': 0.002221149005279816, 'nr_hidden_layers': 2, 'nr_neurons': 160, 'dropout_rate': 0.00022227330928375013, 'weight_decay': 0.00041849569335792556, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 06:48:55,387 - INFO - Trial 226: Early stopping at epoch 141.
[I 2025-11-04 06:48:55,465] Trial 226 finished with value: 0.003988809151790671 and parameters: {'batch_size': 64, 'learning_rate': 0.0018983033957719344, 'nr_hidden_layers': 2, 'nr_neurons': 190, 'dropout_rate': 0.010621880973833927, 'weight_decay': 0.0003083894239348409, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 06:51:54,295] Trial 227 pruned. 
[I 2025-11-04 06:52:12,960] Trial 228 pruned. 
[I 2025-11-04 06:52:31,778] Trial 229 pruned. 
[I 2025-11-04 06:52:40,235] Trial 230 pruned. 
2025-11-04 06:56:38,409 - INFO - Trial 231: Early stopping at epoch 125.
[I 2025-11-04 06:56:38,487] Trial 231 finished with value: 0.0025770020020284327 and parameters: {'batch_size': 64, 'learning_rate': 0.0022218793258580614, 'nr_hidden_layers': 2, 'nr_neurons': 159, 'dropout_rate': 0.0003855183565834302, 'weight_decay': 0.00044042802595940545, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:01:16,773 - INFO - Trial 232: Early stopping at epoch 165.
[I 2025-11-04 07:01:16,864] Trial 232 finished with value: 0.0022830482109757982 and parameters: {'batch_size': 64, 'learning_rate': 0.0022438284395842607, 'nr_hidden_layers': 2, 'nr_neurons': 140, 'dropout_rate': 0.00011483407663706802, 'weight_decay': 0.00046008047870959304, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:03:32,837 - INFO - Trial 233: Early stopping at epoch 81.
[I 2025-11-04 07:03:32,913] Trial 233 finished with value: 0.005972894753457939 and parameters: {'batch_size': 64, 'learning_rate': 0.002237534544150058, 'nr_hidden_layers': 2, 'nr_neurons': 139, 'dropout_rate': 0.0097193473642961, 'weight_decay': 0.00046193458788506767, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:06:09,202 - INFO - Trial 234: Early stopping at epoch 92.
[I 2025-11-04 07:06:09,280] Trial 234 finished with value: 0.004739058805165488 and parameters: {'batch_size': 64, 'learning_rate': 0.0020348794053248803, 'nr_hidden_layers': 2, 'nr_neurons': 151, 'dropout_rate': 0.008365110204145055, 'weight_decay': 0.0006080606711065252, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:10:24,594 - INFO - Trial 235: Early stopping at epoch 144.
[I 2025-11-04 07:10:24,672] Trial 235 finished with value: 0.002580405151756864 and parameters: {'batch_size': 64, 'learning_rate': 0.0018242026244798823, 'nr_hidden_layers': 2, 'nr_neurons': 162, 'dropout_rate': 0.00047328232053574763, 'weight_decay': 0.0004628671708659736, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 07:10:43,223] Trial 236 pruned. 
[I 2025-11-04 07:13:06,270] Trial 237 pruned. 
2025-11-04 07:17:35,509 - INFO - Trial 238: Early stopping at epoch 158.
[I 2025-11-04 07:17:35,589] Trial 238 finished with value: 0.002320502444288576 and parameters: {'batch_size': 64, 'learning_rate': 0.0017762651132925639, 'nr_hidden_layers': 2, 'nr_neurons': 167, 'dropout_rate': 8.905606941106032e-05, 'weight_decay': 0.0009997237093289668, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 07:21:37,175] Trial 239 pruned. 
[I 2025-11-04 07:21:42,871] Trial 240 pruned. 
2025-11-04 07:24:08,920 - INFO - Trial 241: Early stopping at epoch 85.
[I 2025-11-04 07:24:08,999] Trial 241 finished with value: 0.004068725372304262 and parameters: {'batch_size': 64, 'learning_rate': 0.0018224213175828258, 'nr_hidden_layers': 2, 'nr_neurons': 156, 'dropout_rate': 0.0007596566313449247, 'weight_decay': 0.0013553662984965725, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:27:57,919 - INFO - Trial 242: Early stopping at epoch 129.
[I 2025-11-04 07:27:57,999] Trial 242 finished with value: 0.003351524177780395 and parameters: {'batch_size': 64, 'learning_rate': 0.0019949388237217123, 'nr_hidden_layers': 2, 'nr_neurons': 167, 'dropout_rate': 0.0005928342376525594, 'weight_decay': 0.0009462894263151227, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:31:08,316 - INFO - Trial 243: Early stopping at epoch 110.
[I 2025-11-04 07:31:08,406] Trial 243 finished with value: 0.00266032796656622 and parameters: {'batch_size': 64, 'learning_rate': 0.0022291618792607496, 'nr_hidden_layers': 2, 'nr_neurons': 161, 'dropout_rate': 0.00011334542240336255, 'weight_decay': 0.00036157655702255233, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 07:35:09,096] Trial 244 pruned. 
[I 2025-11-04 07:37:54,576] Trial 245 pruned. 
2025-11-04 07:40:09,622 - INFO - Trial 246: Early stopping at epoch 76.
[I 2025-11-04 07:40:09,702] Trial 246 finished with value: 0.0063530295696310355 and parameters: {'batch_size': 64, 'learning_rate': 0.0015456150960395274, 'nr_hidden_layers': 2, 'nr_neurons': 141, 'dropout_rate': 0.009749988460213535, 'weight_decay': 0.0007619285740841879, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:42:54,704 - INFO - Trial 247: Early stopping at epoch 98.
[I 2025-11-04 07:42:54,783] Trial 247 finished with value: 0.005193062537705916 and parameters: {'batch_size': 64, 'learning_rate': 0.002455692951019067, 'nr_hidden_layers': 2, 'nr_neurons': 164, 'dropout_rate': 0.019349624703812275, 'weight_decay': 0.0003912514025482102, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:46:21,897 - INFO - Trial 248: Early stopping at epoch 118.
[I 2025-11-04 07:46:21,978] Trial 248 finished with value: 0.002937104322742584 and parameters: {'batch_size': 64, 'learning_rate': 0.0011018166270380565, 'nr_hidden_layers': 2, 'nr_neurons': 192, 'dropout_rate': 0.0003166967781870037, 'weight_decay': 0.00028015765781405416, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:49:06,949 - INFO - Trial 249: Early stopping at epoch 98.
[I 2025-11-04 07:49:07,036] Trial 249 finished with value: 0.004460835036272863 and parameters: {'batch_size': 64, 'learning_rate': 0.0018661182381393463, 'nr_hidden_layers': 2, 'nr_neurons': 176, 'dropout_rate': 0.008366227572726766, 'weight_decay': 0.0005283787108815382, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 07:49:28,330] Trial 250 pruned. 
[I 2025-11-04 07:50:48,232] Trial 251 pruned. 
2025-11-04 07:56:05,834 - INFO - Trial 252: Early stopping at epoch 186.
[I 2025-11-04 07:56:05,916] Trial 252 finished with value: 0.0017696543509006426 and parameters: {'batch_size': 64, 'learning_rate': 0.0016345125017416119, 'nr_hidden_layers': 2, 'nr_neurons': 242, 'dropout_rate': 2.9027010752291715e-05, 'weight_decay': 0.0004365846103098413, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 07:57:21,045 - INFO - Trial 253: Early stopping at epoch 44.
[I 2025-11-04 07:57:21,124] Trial 253 finished with value: 0.0077720393911317265 and parameters: {'batch_size': 64, 'learning_rate': 0.0015680652300904406, 'nr_hidden_layers': 2, 'nr_neurons': 254, 'dropout_rate': 0.01719257117796154, 'weight_decay': 0.0003391326006402832, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 08:01:43,487 - INFO - Trial 254: Early stopping at epoch 148.
[I 2025-11-04 08:01:43,569] Trial 254 finished with value: 0.0036362456156857756 and parameters: {'batch_size': 64, 'learning_rate': 0.0012649809358949104, 'nr_hidden_layers': 2, 'nr_neurons': 241, 'dropout_rate': 0.009926397014030211, 'weight_decay': 0.0008637716124238994, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 08:04:32,176 - INFO - Trial 255: Early stopping at epoch 100.
[I 2025-11-04 08:04:32,257] Trial 255 finished with value: 0.004443996656876153 and parameters: {'batch_size': 64, 'learning_rate': 0.0017071578951238773, 'nr_hidden_layers': 2, 'nr_neurons': 199, 'dropout_rate': 0.025900203493343033, 'weight_decay': 0.0005904362619236189, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 08:04:50,664] Trial 256 pruned. 
[I 2025-11-04 08:05:02,025] Trial 257 pruned. 
2025-11-04 08:06:57,367 - INFO - Trial 258: Early stopping at epoch 67.
[I 2025-11-04 08:06:57,446] Trial 258 finished with value: 0.006233907495399644 and parameters: {'batch_size': 64, 'learning_rate': 0.002462084147022242, 'nr_hidden_layers': 2, 'nr_neurons': 245, 'dropout_rate': 0.014893311890203775, 'weight_decay': 0.0005227434635271796, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 08:09:07,037] Trial 259 pruned. 
[I 2025-11-04 08:09:13,945] Trial 260 pruned. 
[I 2025-11-04 08:09:32,793] Trial 261 pruned. 
[I 2025-11-04 08:09:59,279] Trial 262 pruned. 
[I 2025-11-04 08:10:17,742] Trial 263 pruned. 
2025-11-04 08:13:02,871 - INFO - Trial 264: Early stopping at epoch 96.
[I 2025-11-04 08:13:02,952] Trial 264 finished with value: 0.005115749579626213 and parameters: {'batch_size': 64, 'learning_rate': 0.001772027826165768, 'nr_hidden_layers': 2, 'nr_neurons': 231, 'dropout_rate': 0.009683074566583263, 'weight_decay': 0.0010492832836326014, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 08:13:33,972] Trial 265 pruned. 
[I 2025-11-04 08:13:42,477] Trial 266 pruned. 
2025-11-04 08:16:09,467 - INFO - Trial 267: Early stopping at epoch 84.
[I 2025-11-04 08:16:09,547] Trial 267 finished with value: 0.005902790428077017 and parameters: {'batch_size': 64, 'learning_rate': 0.002606076499361336, 'nr_hidden_layers': 2, 'nr_neurons': 132, 'dropout_rate': 0.011164921505798054, 'weight_decay': 0.0012470692119409623, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 08:16:27,844] Trial 268 pruned. 
2025-11-04 08:20:37,659 - INFO - Trial 269: Early stopping at epoch 149.
[I 2025-11-04 08:20:37,739] Trial 269 finished with value: 0.0021331730105428976 and parameters: {'batch_size': 64, 'learning_rate': 0.0017290638885753718, 'nr_hidden_layers': 2, 'nr_neurons': 170, 'dropout_rate': 8.090095682626499e-05, 'weight_decay': 0.0004587391664055132, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 08:24:17,432] Trial 270 pruned. 
[I 2025-11-04 08:27:10,524] Trial 271 pruned. 
[I 2025-11-04 08:27:28,817] Trial 272 pruned. 
[I 2025-11-04 08:27:34,449] Trial 273 pruned. 
2025-11-04 08:30:52,989 - INFO - Trial 274: Early stopping at epoch 111.
[I 2025-11-04 08:30:53,071] Trial 274 finished with value: 0.003641759439106371 and parameters: {'batch_size': 64, 'learning_rate': 0.0016227039798803564, 'nr_hidden_layers': 2, 'nr_neurons': 208, 'dropout_rate': 0.008807158546717524, 'weight_decay': 0.0002957458089378418, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 08:30:59,654] Trial 275 pruned. 
2025-11-04 08:34:44,689 - INFO - Trial 276: Early stopping at epoch 134.
[I 2025-11-04 08:34:44,772] Trial 276 finished with value: 0.003007004081015141 and parameters: {'batch_size': 64, 'learning_rate': 0.0017977213755297253, 'nr_hidden_layers': 2, 'nr_neurons': 171, 'dropout_rate': 0.0005139620133413702, 'weight_decay': 0.0005187878364126482, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 08:35:03,229] Trial 277 pruned. 
2025-11-04 08:38:00,984 - INFO - Trial 278: Early stopping at epoch 106.
[I 2025-11-04 08:38:01,073] Trial 278 finished with value: 0.0043909220311847885 and parameters: {'batch_size': 64, 'learning_rate': 0.001503340838125165, 'nr_hidden_layers': 2, 'nr_neurons': 224, 'dropout_rate': 0.010012822423044434, 'weight_decay': 0.0006339422602865467, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 08:40:50,205 - INFO - Trial 279: Early stopping at epoch 100.
[I 2025-11-04 08:40:50,287] Trial 279 finished with value: 0.005384148573669635 and parameters: {'batch_size': 64, 'learning_rate': 0.0020525125741293407, 'nr_hidden_layers': 2, 'nr_neurons': 195, 'dropout_rate': 0.01979362004649466, 'weight_decay': 0.000447275096528369, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 08:43:45,846 - INFO - Trial 280: Early stopping at epoch 100.
[I 2025-11-04 08:43:45,927] Trial 280 finished with value: 0.002853109223178146 and parameters: {'batch_size': 64, 'learning_rate': 0.0017837401450900138, 'nr_hidden_layers': 2, 'nr_neurons': 179, 'dropout_rate': 0.00020050195374939344, 'weight_decay': 0.0007088212256507952, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 08:49:11,259 - INFO - Trial 281: Early stopping at epoch 182.
[I 2025-11-04 08:49:11,342] Trial 281 finished with value: 0.0020103415004177317 and parameters: {'batch_size': 64, 'learning_rate': 0.001582512630663724, 'nr_hidden_layers': 2, 'nr_neurons': 215, 'dropout_rate': 0.00023298559951897817, 'weight_decay': 0.0003903859185876924, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 08:50:49,846 - INFO - Trial 282: Early stopping at epoch 45.
[I 2025-11-04 08:50:49,925] Trial 282 finished with value: 0.007297961036516207 and parameters: {'batch_size': 64, 'learning_rate': 0.0013184284771514123, 'nr_hidden_layers': 5, 'nr_neurons': 215, 'dropout_rate': 0.010029019148589833, 'weight_decay': 0.000397138160030218, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 08:51:08,844] Trial 283 pruned. 
2025-11-04 08:53:02,388 - INFO - Trial 284: Early stopping at epoch 67.
[I 2025-11-04 08:53:02,487] Trial 284 finished with value: 0.006228112778513175 and parameters: {'batch_size': 64, 'learning_rate': 0.0014415873784218737, 'nr_hidden_layers': 2, 'nr_neurons': 204, 'dropout_rate': 0.023307630503042277, 'weight_decay': 0.0003188312704479658, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 08:56:11,457] Trial 285 pruned. 
[I 2025-11-04 08:59:15,684] Trial 286 pruned. 
[I 2025-11-04 08:59:22,758] Trial 287 pruned. 
2025-11-04 09:02:49,786 - INFO - Trial 288: Early stopping at epoch 100.
[I 2025-11-04 09:02:49,869] Trial 288 finished with value: 0.004739657349088244 and parameters: {'batch_size': 64, 'learning_rate': 0.002380498926751574, 'nr_hidden_layers': 4, 'nr_neurons': 191, 'dropout_rate': 0.0008517024025449063, 'weight_decay': 0.0003343878911228494, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
[I 2025-11-04 09:03:01,214] Trial 289 pruned. 
[I 2025-11-04 09:03:21,389] Trial 290 pruned. 
[I 2025-11-04 09:06:11,373] Trial 291 pruned. 
2025-11-04 09:09:34,493 - INFO - Trial 292: Early stopping at epoch 119.
[I 2025-11-04 09:09:34,574] Trial 292 finished with value: 0.00455003943051893 and parameters: {'batch_size': 64, 'learning_rate': 0.0016280541627021374, 'nr_hidden_layers': 2, 'nr_neurons': 218, 'dropout_rate': 0.007771285198309058, 'weight_decay': 6.250440662786251e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 156 with value: 0.001703693990911879.
2025-11-04 09:15:20,680 - INFO - Trial 293: Early stopping at epoch 201.
[I 2025-11-04 09:15:20,761] Trial 293 finished with value: 0.0016160019030080897 and parameters: {'batch_size': 64, 'learning_rate': 0.0013769697512055082, 'nr_hidden_layers': 2, 'nr_neurons': 169, 'dropout_rate': 7.770529593864131e-05, 'weight_decay': 0.0004262642792345516, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 09:15:29,483] Trial 294 pruned. 
[I 2025-11-04 09:15:47,956] Trial 295 pruned. 
[I 2025-11-04 09:16:06,378] Trial 296 pruned. 
2025-11-04 09:19:44,496 - INFO - Trial 297: Early stopping at epoch 128.
[I 2025-11-04 09:19:44,577] Trial 297 finished with value: 0.0042024413796440535 and parameters: {'batch_size': 64, 'learning_rate': 0.001215277400414682, 'nr_hidden_layers': 2, 'nr_neurons': 246, 'dropout_rate': 0.018148677705624422, 'weight_decay': 0.00027860622982492665, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 293 with value: 0.0016160019030080897.
2025-11-04 09:22:33,553 - INFO - Trial 298: Early stopping at epoch 99.
[I 2025-11-04 09:22:33,635] Trial 298 finished with value: 0.0033398070787816793 and parameters: {'batch_size': 64, 'learning_rate': 0.002435382356115228, 'nr_hidden_layers': 2, 'nr_neurons': 185, 'dropout_rate': 1.834340077863498e-05, 'weight_decay': 0.0005067943683591132, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 293 with value: 0.0016160019030080897.
2025-11-04 09:24:32,456 - INFO - Trial 299: Early stopping at epoch 78.
[I 2025-11-04 09:24:32,535] Trial 299 finished with value: 0.006197777576175181 and parameters: {'batch_size': 64, 'learning_rate': 0.001872019276743626, 'nr_hidden_layers': 1, 'nr_neurons': 176, 'dropout_rate': 0.009311067161890318, 'weight_decay': 0.0003734061876060071, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 09:24:38,375] Trial 300 pruned. 
[I 2025-11-04 09:25:06,546] Trial 301 pruned. 
2025-11-04 09:27:17,621 - INFO - Trial 302: Early stopping at epoch 76.
[I 2025-11-04 09:27:17,700] Trial 302 finished with value: 0.006173316464315369 and parameters: {'batch_size': 64, 'learning_rate': 0.0017457577342493745, 'nr_hidden_layers': 2, 'nr_neurons': 149, 'dropout_rate': 0.03763461311767657, 'weight_decay': 0.0002986371998675829, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 09:27:24,308] Trial 303 pruned. 
2025-11-04 09:29:25,717 - INFO - Trial 304: Early stopping at epoch 72.
[I 2025-11-04 09:29:25,799] Trial 304 finished with value: 0.00479045845273963 and parameters: {'batch_size': 64, 'learning_rate': 0.0025717828268789246, 'nr_hidden_layers': 2, 'nr_neurons': 253, 'dropout_rate': 0.0002268159084933072, 'weight_decay': 0.0006880090733434275, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 09:29:44,155] Trial 305 pruned. 
[I 2025-11-04 09:30:02,556] Trial 306 pruned. 
[I 2025-11-04 09:30:21,452] Trial 307 pruned. 
[I 2025-11-04 09:30:39,935] Trial 308 pruned. 
[I 2025-11-04 09:34:14,878] Trial 309 pruned. 
2025-11-04 09:37:57,447 - INFO - Trial 310: Early stopping at epoch 128.
[I 2025-11-04 09:37:57,529] Trial 310 finished with value: 0.00232116178747211 and parameters: {'batch_size': 64, 'learning_rate': 0.0018762228258440198, 'nr_hidden_layers': 2, 'nr_neurons': 224, 'dropout_rate': 0.00016692277866589428, 'weight_decay': 0.0004250407087350204, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 293 with value: 0.0016160019030080897.
2025-11-04 09:42:20,728 - INFO - Trial 311: Early stopping at epoch 152.
[I 2025-11-04 09:42:20,812] Trial 311 finished with value: 0.0019349332733101731 and parameters: {'batch_size': 64, 'learning_rate': 0.0022678275022202, 'nr_hidden_layers': 2, 'nr_neurons': 229, 'dropout_rate': 3.963331392435156e-05, 'weight_decay': 0.00041658982938379984, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 09:43:06,724] Trial 312 pruned. 
2025-11-04 09:46:24,340 - INFO - Trial 313: Early stopping at epoch 114.
[I 2025-11-04 09:46:24,420] Trial 313 finished with value: 0.00451870052757414 and parameters: {'batch_size': 64, 'learning_rate': 0.0019182445757690387, 'nr_hidden_layers': 2, 'nr_neurons': 231, 'dropout_rate': 0.008846674337355337, 'weight_decay': 0.0002912427334526761, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 09:46:35,767] Trial 314 pruned. 
[I 2025-11-04 09:46:54,213] Trial 315 pruned. 
2025-11-04 09:48:59,307 - INFO - Trial 316: Early stopping at epoch 66.
[I 2025-11-04 09:48:59,399] Trial 316 finished with value: 0.0047404196683064346 and parameters: {'batch_size': 64, 'learning_rate': 0.0018182584751236484, 'nr_hidden_layers': 2, 'nr_neurons': 239, 'dropout_rate': 0.00010036178913385564, 'weight_decay': 0.00025058990423895445, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 09:49:06,133] Trial 317 pruned. 
[I 2025-11-04 09:49:24,454] Trial 318 pruned. 
2025-11-04 09:52:14,936 - INFO - Trial 319: Early stopping at epoch 95.
[I 2025-11-04 09:52:15,017] Trial 319 finished with value: 0.0022531111271382 and parameters: {'batch_size': 64, 'learning_rate': 0.0022295943650694756, 'nr_hidden_layers': 2, 'nr_neurons': 203, 'dropout_rate': 1.1264057388117945e-05, 'weight_decay': 0.0003184460538646115, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 293 with value: 0.0016160019030080897.
2025-11-04 09:54:34,726 - INFO - Trial 320: Early stopping at epoch 81.
[I 2025-11-04 09:54:34,808] Trial 320 finished with value: 0.00582598945203883 and parameters: {'batch_size': 64, 'learning_rate': 0.002559687838658227, 'nr_hidden_layers': 2, 'nr_neurons': 203, 'dropout_rate': 0.010417276392548505, 'weight_decay': 0.0003224480545005248, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 09:55:13,332] Trial 321 pruned. 
[I 2025-11-04 09:55:31,914] Trial 322 pruned. 
[I 2025-11-04 09:55:40,475] Trial 323 pruned. 
[I 2025-11-04 09:56:17,414] Trial 324 pruned. 
2025-11-04 09:57:44,126 - INFO - Trial 325: Early stopping at epoch 51.
[I 2025-11-04 09:57:44,207] Trial 325 finished with value: 0.006830143814968225 and parameters: {'batch_size': 64, 'learning_rate': 0.0021346396452303867, 'nr_hidden_layers': 2, 'nr_neurons': 216, 'dropout_rate': 0.017140337266572426, 'weight_decay': 0.00030643326912608004, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 10:00:01,576] Trial 326 pruned. 
[I 2025-11-04 10:00:25,843] Trial 327 pruned. 
2025-11-04 10:03:54,198 - INFO - Trial 328: Early stopping at epoch 124.
[I 2025-11-04 10:03:54,281] Trial 328 finished with value: 0.002109759526669034 and parameters: {'batch_size': 64, 'learning_rate': 0.002419632804768115, 'nr_hidden_layers': 2, 'nr_neurons': 231, 'dropout_rate': 2.9314428170695904e-05, 'weight_decay': 0.0002891503033826793, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 293 with value: 0.0016160019030080897.
[I 2025-11-04 10:04:00,179] Trial 329 pruned. 
[I 2025-11-04 10:06:07,766] Trial 330 pruned. 
[I 2025-11-04 10:06:26,792] Trial 331 pruned. 
[I 2025-11-04 10:06:33,402] Trial 332 pruned. 
2025-11-04 10:16:06,910 - INFO - Trial 333: Early stopping at epoch 330.
[I 2025-11-04 10:16:06,997] Trial 333 finished with value: 0.0009757127058634517 and parameters: {'batch_size': 64, 'learning_rate': 0.001372335074817238, 'nr_hidden_layers': 2, 'nr_neurons': 230, 'dropout_rate': 8.943741579532514e-05, 'weight_decay': 0.00021732207759797098, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 10:16:25,461] Trial 334 pruned. 
2025-11-04 10:19:39,122 - INFO - Trial 335: Early stopping at epoch 113.
[I 2025-11-04 10:19:39,207] Trial 335 finished with value: 0.0043223303934993105 and parameters: {'batch_size': 64, 'learning_rate': 0.002402131934288198, 'nr_hidden_layers': 2, 'nr_neurons': 235, 'dropout_rate': 0.010946621811213775, 'weight_decay': 0.0002517767638606494, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 10:20:56,692] Trial 336 pruned. 
[I 2025-11-04 10:21:15,752] Trial 337 pruned. 
2025-11-04 10:25:15,678 - INFO - Trial 338: Early stopping at epoch 142.
[I 2025-11-04 10:25:15,764] Trial 338 finished with value: 0.002011523069248419 and parameters: {'batch_size': 64, 'learning_rate': 0.0021174683221867894, 'nr_hidden_layers': 2, 'nr_neurons': 248, 'dropout_rate': 4.5017386704143445e-05, 'weight_decay': 0.00028053722293121795, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 10:25:37,607] Trial 339 pruned. 
2025-11-04 10:27:47,298 - INFO - Trial 340: Early stopping at epoch 74.
[I 2025-11-04 10:27:47,383] Trial 340 finished with value: 0.0058992131758177175 and parameters: {'batch_size': 64, 'learning_rate': 0.0020872412418210915, 'nr_hidden_layers': 2, 'nr_neurons': 248, 'dropout_rate': 0.017254408839888706, 'weight_decay': 0.0002901791386525701, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 10:28:05,890] Trial 341 pruned. 
2025-11-04 10:30:53,796 - INFO - Trial 342: Early stopping at epoch 98.
[I 2025-11-04 10:30:53,881] Trial 342 finished with value: 0.002740589532005382 and parameters: {'batch_size': 64, 'learning_rate': 0.0014070566170241382, 'nr_hidden_layers': 2, 'nr_neurons': 256, 'dropout_rate': 0.00015846963686887136, 'weight_decay': 0.00044874587400134115, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 10:31:17,441] Trial 343 pruned. 
[I 2025-11-04 10:31:28,789] Trial 344 pruned. 
[I 2025-11-04 10:31:47,275] Trial 345 pruned. 
[I 2025-11-04 10:31:54,033] Trial 346 pruned. 
[I 2025-11-04 10:34:12,773] Trial 347 pruned. 
[I 2025-11-04 10:34:31,322] Trial 348 pruned. 
2025-11-04 10:36:58,916 - INFO - Trial 349: Early stopping at epoch 87.
[I 2025-11-04 10:36:59,002] Trial 349 finished with value: 0.00446660673595446 and parameters: {'batch_size': 64, 'learning_rate': 0.0018264671061693526, 'nr_hidden_layers': 2, 'nr_neurons': 245, 'dropout_rate': 0.009857689210513491, 'weight_decay': 0.00033149371701487963, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 10:40:08,618 - INFO - Trial 350: Early stopping at epoch 113.
[I 2025-11-04 10:40:08,708] Trial 350 finished with value: 0.0025208241595821067 and parameters: {'batch_size': 64, 'learning_rate': 0.0019984111477091356, 'nr_hidden_layers': 2, 'nr_neurons': 221, 'dropout_rate': 0.00019499995429297833, 'weight_decay': 0.0005808003625708594, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 10:42:32,773 - INFO - Trial 351: Early stopping at epoch 85.
[I 2025-11-04 10:42:32,861] Trial 351 finished with value: 0.0039409183089343935 and parameters: {'batch_size': 64, 'learning_rate': 0.002251962204078734, 'nr_hidden_layers': 2, 'nr_neurons': 207, 'dropout_rate': 7.498033871574088e-05, 'weight_decay': 0.0005155961750653994, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 10:42:41,420] Trial 352 pruned. 
[I 2025-11-04 10:43:04,084] Trial 353 pruned. 
[I 2025-11-04 10:45:10,883] Trial 354 pruned. 
[I 2025-11-04 10:45:36,300] Trial 355 pruned. 
2025-11-04 10:49:26,835 - INFO - Trial 356: Early stopping at epoch 134.
[I 2025-11-04 10:49:26,925] Trial 356 finished with value: 0.0017484676464697452 and parameters: {'batch_size': 64, 'learning_rate': 0.0015122217626678625, 'nr_hidden_layers': 2, 'nr_neurons': 204, 'dropout_rate': 4.984125999520355e-05, 'weight_decay': 0.0006231849078169501, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 10:49:45,467] Trial 357 pruned. 
[I 2025-11-04 10:49:51,175] Trial 358 pruned. 
2025-11-04 10:51:42,969 - INFO - Trial 359: Early stopping at epoch 64.
[I 2025-11-04 10:51:43,058] Trial 359 finished with value: 0.006823196842367235 and parameters: {'batch_size': 64, 'learning_rate': 0.0015856268319538846, 'nr_hidden_layers': 2, 'nr_neurons': 209, 'dropout_rate': 0.016693159627415945, 'weight_decay': 0.0005345726876352571, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 10:52:06,614] Trial 360 pruned. 
[I 2025-11-04 10:52:13,250] Trial 361 pruned. 
2025-11-04 10:55:06,581 - INFO - Trial 362: Early stopping at epoch 100.
[I 2025-11-04 10:55:06,669] Trial 362 finished with value: 0.005067976783151517 and parameters: {'batch_size': 64, 'learning_rate': 0.0019856966381637878, 'nr_hidden_layers': 2, 'nr_neurons': 201, 'dropout_rate': 0.019434331568871793, 'weight_decay': 0.0005751420512750043, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 10:55:25,236] Trial 363 pruned. 
[I 2025-11-04 10:55:43,813] Trial 364 pruned. 
[I 2025-11-04 10:56:02,311] Trial 365 pruned. 
[I 2025-11-04 10:59:05,532] Trial 366 pruned. 
[I 2025-11-04 11:00:00,470] Trial 367 pruned. 
2025-11-04 11:02:18,908 - INFO - Trial 368: Early stopping at epoch 82.
[I 2025-11-04 11:02:18,995] Trial 368 finished with value: 0.004397683577608602 and parameters: {'batch_size': 64, 'learning_rate': 0.0017297821537482518, 'nr_hidden_layers': 2, 'nr_neurons': 208, 'dropout_rate': 0.009222539487297308, 'weight_decay': 0.0002953562548127958, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 11:05:30,992 - INFO - Trial 369: Early stopping at epoch 113.
[I 2025-11-04 11:05:31,082] Trial 369 finished with value: 0.0046159241788938255 and parameters: {'batch_size': 64, 'learning_rate': 0.0019525550944959078, 'nr_hidden_layers': 2, 'nr_neurons': 185, 'dropout_rate': 0.009141198452401949, 'weight_decay': 0.0005091217113158041, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 11:08:01,736 - INFO - Trial 370: Early stopping at epoch 87.
[I 2025-11-04 11:08:01,834] Trial 370 finished with value: 0.005863966483964138 and parameters: {'batch_size': 64, 'learning_rate': 0.0012633759290010976, 'nr_hidden_layers': 2, 'nr_neurons': 200, 'dropout_rate': 0.01927639753579207, 'weight_decay': 0.0006011528629349891, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 11:08:13,192] Trial 371 pruned. 
2025-11-04 11:10:05,880 - INFO - Trial 372: Early stopping at epoch 65.
[I 2025-11-04 11:10:05,968] Trial 372 finished with value: 0.006087969412269355 and parameters: {'batch_size': 64, 'learning_rate': 0.001825983215652881, 'nr_hidden_layers': 2, 'nr_neurons': 175, 'dropout_rate': 0.009006015434754568, 'weight_decay': 0.0002516261202959776, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 11:12:49,331 - INFO - Trial 373: Early stopping at epoch 97.
[I 2025-11-04 11:12:49,418] Trial 373 finished with value: 0.0032205664973762624 and parameters: {'batch_size': 64, 'learning_rate': 0.0015497257430497704, 'nr_hidden_layers': 2, 'nr_neurons': 217, 'dropout_rate': 0.0002327112966286834, 'weight_decay': 0.000750712059600627, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 11:15:39,592] Trial 374 pruned. 
[I 2025-11-04 11:18:43,797] Trial 375 pruned. 
[I 2025-11-04 11:19:12,133] Trial 376 pruned. 
[I 2025-11-04 11:19:18,960] Trial 377 pruned. 
[I 2025-11-04 11:20:27,407] Trial 378 pruned. 
[I 2025-11-04 11:20:45,971] Trial 379 pruned. 
[I 2025-11-04 11:21:04,516] Trial 380 pruned. 
[I 2025-11-04 11:21:12,980] Trial 381 pruned. 
2025-11-04 11:23:50,983 - INFO - Trial 382: Early stopping at epoch 91.
[I 2025-11-04 11:23:51,074] Trial 382 finished with value: 0.004871097495925831 and parameters: {'batch_size': 64, 'learning_rate': 0.0022146684238568094, 'nr_hidden_layers': 2, 'nr_neurons': 194, 'dropout_rate': 0.008916931606744527, 'weight_decay': 0.0003893377203350007, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 11:25:35,886 - INFO - Trial 383: Early stopping at epoch 60.
[I 2025-11-04 11:25:35,972] Trial 383 finished with value: 0.006007982887537119 and parameters: {'batch_size': 64, 'learning_rate': 0.0013386959407578171, 'nr_hidden_layers': 2, 'nr_neurons': 235, 'dropout_rate': 0.020935713386707366, 'weight_decay': 0.0035905883908630767, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 11:29:25,872 - INFO - Trial 384: Early stopping at epoch 136.
[I 2025-11-04 11:29:25,962] Trial 384 finished with value: 0.0030459137929765216 and parameters: {'batch_size': 64, 'learning_rate': 0.0018200099774211978, 'nr_hidden_layers': 2, 'nr_neurons': 179, 'dropout_rate': 0.0006489270783442017, 'weight_decay': 0.000280132949431581, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 11:29:44,448] Trial 385 pruned. 
[I 2025-11-04 11:29:50,291] Trial 386 pruned. 
[I 2025-11-04 11:30:08,774] Trial 387 pruned. 
[I 2025-11-04 11:30:27,235] Trial 388 pruned. 
2025-11-04 11:35:08,159 - INFO - Trial 389: Early stopping at epoch 159.
[I 2025-11-04 11:35:08,252] Trial 389 finished with value: 0.002180925452259323 and parameters: {'batch_size': 64, 'learning_rate': 0.0017570426595925834, 'nr_hidden_layers': 2, 'nr_neurons': 219, 'dropout_rate': 0.00044299957274945715, 'weight_decay': 0.0005581138526603317, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 11:35:14,918] Trial 390 pruned. 
[I 2025-11-04 11:35:36,833] Trial 391 pruned. 
[I 2025-11-04 11:35:55,376] Trial 392 pruned. 
[I 2025-11-04 11:36:13,885] Trial 393 pruned. 
[I 2025-11-04 11:36:37,663] Trial 394 pruned. 
[I 2025-11-04 11:36:54,306] Trial 395 pruned. 
[I 2025-11-04 11:37:12,856] Trial 396 pruned. 
[I 2025-11-04 11:37:57,928] Trial 397 pruned. 
[I 2025-11-04 11:41:07,306] Trial 398 pruned. 
[I 2025-11-04 11:41:18,697] Trial 399 pruned. 
[I 2025-11-04 11:44:07,560] Trial 400 pruned. 
2025-11-04 11:46:32,986 - INFO - Trial 401: Early stopping at epoch 85.
[I 2025-11-04 11:46:33,073] Trial 401 finished with value: 0.003133489516929033 and parameters: {'batch_size': 64, 'learning_rate': 0.0013977733494515675, 'nr_hidden_layers': 2, 'nr_neurons': 225, 'dropout_rate': 0.0005591512184678577, 'weight_decay': 0.000287794668191489, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 11:46:51,494] Trial 402 pruned. 
[I 2025-11-04 11:46:58,235] Trial 403 pruned. 
[I 2025-11-04 11:47:21,731] Trial 404 pruned. 
2025-11-04 11:50:19,929 - INFO - Trial 405: Early stopping at epoch 106.
[I 2025-11-04 11:50:20,018] Trial 405 finished with value: 0.004836623207301094 and parameters: {'batch_size': 64, 'learning_rate': 0.0016070556397429123, 'nr_hidden_layers': 2, 'nr_neurons': 191, 'dropout_rate': 0.011148301318412199, 'weight_decay': 0.0002374449887516488, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 11:50:38,965] Trial 406 pruned. 
2025-11-04 11:53:19,323 - INFO - Trial 407: Early stopping at epoch 85.
[I 2025-11-04 11:53:19,412] Trial 407 finished with value: 0.005209056940110113 and parameters: {'batch_size': 64, 'learning_rate': 0.002859556538678598, 'nr_hidden_layers': 2, 'nr_neurons': 231, 'dropout_rate': 0.0096379304766681, 'weight_decay': 0.00047568150167726076, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 11:56:02,346 - INFO - Trial 408: Early stopping at epoch 96.
[I 2025-11-04 11:56:02,449] Trial 408 finished with value: 0.0028716436981756355 and parameters: {'batch_size': 64, 'learning_rate': 0.0017624059868485155, 'nr_hidden_layers': 2, 'nr_neurons': 161, 'dropout_rate': 0.00015532995337484977, 'weight_decay': 0.0007974122860284961, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 11:56:10,836] Trial 409 pruned. 
[I 2025-11-04 11:56:30,748] Trial 410 pruned. 
[I 2025-11-04 11:57:25,597] Trial 411 pruned. 
[I 2025-11-04 11:57:48,406] Trial 412 pruned. 
2025-11-04 12:01:25,196 - INFO - Trial 413: Early stopping at epoch 129.
[I 2025-11-04 12:01:25,290] Trial 413 finished with value: 0.004258214452495819 and parameters: {'batch_size': 64, 'learning_rate': 0.0019551966769060427, 'nr_hidden_layers': 2, 'nr_neurons': 198, 'dropout_rate': 0.008669155412066093, 'weight_decay': 0.00029615225664327347, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 12:01:31,232] Trial 414 pruned. 
[I 2025-11-04 12:01:54,051] Trial 415 pruned. 
[I 2025-11-04 12:02:12,547] Trial 416 pruned. 
[I 2025-11-04 12:04:51,151] Trial 417 pruned. 
[I 2025-11-04 12:04:57,802] Trial 418 pruned. 
2025-11-04 12:08:45,263 - INFO - Trial 419: Early stopping at epoch 129.
[I 2025-11-04 12:08:45,354] Trial 419 finished with value: 0.003257365198262515 and parameters: {'batch_size': 64, 'learning_rate': 0.0013539678384768537, 'nr_hidden_layers': 2, 'nr_neurons': 194, 'dropout_rate': 0.0006161943545438333, 'weight_decay': 0.00041783316807070687, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 12:09:03,853] Trial 420 pruned. 
2025-11-04 12:11:14,166 - INFO - Trial 421: Early stopping at epoch 77.
[I 2025-11-04 12:11:14,255] Trial 421 finished with value: 0.003902818664708414 and parameters: {'batch_size': 64, 'learning_rate': 0.0018060209116534634, 'nr_hidden_layers': 2, 'nr_neurons': 244, 'dropout_rate': 0.00015524104145909898, 'weight_decay': 0.0002545911362713726, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 12:14:05,399 - INFO - Trial 422: Early stopping at epoch 86.
[I 2025-11-04 12:14:05,491] Trial 422 finished with value: 0.005329308203133148 and parameters: {'batch_size': 64, 'learning_rate': 0.002409601023300003, 'nr_hidden_layers': 2, 'nr_neurons': 209, 'dropout_rate': 0.009911316642527614, 'weight_decay': 2.911753512239618e-06, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 12:14:24,108] Trial 423 pruned. 
[I 2025-11-04 12:14:50,309] Trial 424 pruned. 
2025-11-04 12:17:13,635 - INFO - Trial 425: Early stopping at epoch 79.
[I 2025-11-04 12:17:13,737] Trial 425 finished with value: 0.00554836767461686 and parameters: {'batch_size': 64, 'learning_rate': 0.0027693218476793425, 'nr_hidden_layers': 2, 'nr_neurons': 173, 'dropout_rate': 0.00937281656872684, 'weight_decay': 0.0003619824188573191, 'activation_name': 'GELU', 'loss_criterion': 'L1'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 12:19:30,443 - INFO - Trial 426: Early stopping at epoch 80.
[I 2025-11-04 12:19:30,533] Trial 426 finished with value: 0.004906206787130345 and parameters: {'batch_size': 64, 'learning_rate': 0.0015262789614517399, 'nr_hidden_layers': 2, 'nr_neurons': 185, 'dropout_rate': 0.00839150823290553, 'weight_decay': 0.0005509463435276564, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 12:19:41,896] Trial 427 pruned. 
2025-11-04 12:24:02,000 - INFO - Trial 428: Early stopping at epoch 149.
[I 2025-11-04 12:24:02,092] Trial 428 finished with value: 0.002046364983938102 and parameters: {'batch_size': 64, 'learning_rate': 0.0018817560802475485, 'nr_hidden_layers': 2, 'nr_neurons': 166, 'dropout_rate': 1.5760411049011992e-05, 'weight_decay': 0.00030490900306669123, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 12:29:16,218 - INFO - Trial 429: Early stopping at epoch 183.
[I 2025-11-04 12:29:16,313] Trial 429 finished with value: 0.0016910017859367065 and parameters: {'batch_size': 64, 'learning_rate': 0.0019310804975492927, 'nr_hidden_layers': 2, 'nr_neurons': 229, 'dropout_rate': 3.1050632738490755e-05, 'weight_decay': 0.0002613094671420462, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 12:29:53,171] Trial 430 pruned. 
[I 2025-11-04 12:29:59,982] Trial 431 pruned. 
2025-11-04 12:34:16,209 - INFO - Trial 432: Early stopping at epoch 145.
[I 2025-11-04 12:34:16,299] Trial 432 finished with value: 0.0025640028387790403 and parameters: {'batch_size': 64, 'learning_rate': 0.001843516699896894, 'nr_hidden_layers': 2, 'nr_neurons': 222, 'dropout_rate': 0.0005470251686930418, 'weight_decay': 0.0002532621514772608, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 12:36:35,712 - INFO - Trial 433: Early stopping at epoch 81.
[I 2025-11-04 12:36:35,803] Trial 433 finished with value: 0.004880614456518074 and parameters: {'batch_size': 64, 'learning_rate': 0.0016717574017039213, 'nr_hidden_layers': 2, 'nr_neurons': 232, 'dropout_rate': 0.008199046129233726, 'weight_decay': 0.0002830887682708292, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 12:41:11,227 - INFO - Trial 434: Early stopping at epoch 164.
[I 2025-11-04 12:41:11,319] Trial 434 finished with value: 0.0022598933350774404 and parameters: {'batch_size': 64, 'learning_rate': 0.0014601521957529177, 'nr_hidden_layers': 2, 'nr_neurons': 213, 'dropout_rate': 0.00038048636647273625, 'weight_decay': 0.0003054117821041585, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 12:41:29,864] Trial 435 pruned. 
[I 2025-11-04 12:42:38,350] Trial 436 pruned. 
[I 2025-11-04 12:42:56,847] Trial 437 pruned. 
[I 2025-11-04 12:43:05,188] Trial 438 pruned. 
[I 2025-11-04 12:43:23,689] Trial 439 pruned. 
[I 2025-11-04 12:43:45,527] Trial 440 pruned. 
[I 2025-11-04 12:47:09,936] Trial 441 pruned. 
[I 2025-11-04 12:47:28,506] Trial 442 pruned. 
[I 2025-11-04 12:47:47,530] Trial 443 pruned. 
[I 2025-11-04 12:47:54,163] Trial 444 pruned. 
[I 2025-11-04 12:47:59,992] Trial 445 pruned. 
[I 2025-11-04 12:48:18,909] Trial 446 pruned. 
2025-11-04 12:50:44,101 - INFO - Trial 447: Early stopping at epoch 86.
[I 2025-11-04 12:50:44,202] Trial 447 finished with value: 0.005114327827014515 and parameters: {'batch_size': 64, 'learning_rate': 0.0018402259312253512, 'nr_hidden_layers': 2, 'nr_neurons': 243, 'dropout_rate': 0.017079825426333527, 'weight_decay': 0.00029545382955098275, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 12:53:41,128] Trial 448 pruned. 
[I 2025-11-04 12:55:03,559] Trial 449 pruned. 
[I 2025-11-04 12:58:56,047] Trial 450 pruned. 
[I 2025-11-04 13:01:06,635] Trial 451 pruned. 
[I 2025-11-04 13:01:25,175] Trial 452 pruned. 
[I 2025-11-04 13:01:43,532] Trial 453 pruned. 
[I 2025-11-04 13:05:37,759] Trial 454 pruned. 
[I 2025-11-04 13:05:56,298] Trial 455 pruned. 
[I 2025-11-04 13:09:01,831] Trial 456 pruned. 
[I 2025-11-04 13:09:13,238] Trial 457 pruned. 
[I 2025-11-04 13:09:31,906] Trial 458 pruned. 
[I 2025-11-04 13:09:38,807] Trial 459 pruned. 
[I 2025-11-04 13:10:35,404] Trial 460 pruned. 
[I 2025-11-04 13:10:53,929] Trial 461 pruned. 
[I 2025-11-04 13:11:12,472] Trial 462 pruned. 
2025-11-04 13:15:12,344 - INFO - Trial 463: Early stopping at epoch 95.
[I 2025-11-04 13:15:12,437] Trial 463 finished with value: 0.00519595586205447 and parameters: {'batch_size': 64, 'learning_rate': 0.0022349405215632513, 'nr_hidden_layers': 2, 'nr_neurons': 224, 'dropout_rate': 0.01661406319431538, 'weight_decay': 0.00047130885056648707, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 13:15:39,063] Trial 464 pruned. 
[I 2025-11-04 13:15:49,840] Trial 465 pruned. 
[I 2025-11-04 13:16:20,350] Trial 466 pruned. 
[I 2025-11-04 13:16:48,161] Trial 467 pruned. 
2025-11-04 13:19:05,305 - INFO - Trial 468: Early stopping at epoch 81.
[I 2025-11-04 13:19:05,396] Trial 468 finished with value: 0.004889315878723458 and parameters: {'batch_size': 64, 'learning_rate': 0.0013999417764830077, 'nr_hidden_layers': 2, 'nr_neurons': 244, 'dropout_rate': 0.017475734794303744, 'weight_decay': 0.0007545901268301911, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 13:19:23,953] Trial 469 pruned. 
[I 2025-11-04 13:19:46,419] Trial 470 pruned. 
[I 2025-11-04 13:19:52,123] Trial 471 pruned. 
2025-11-04 13:22:38,955 - INFO - Trial 472: Early stopping at epoch 97.
[I 2025-11-04 13:22:39,046] Trial 472 finished with value: 0.004667152906530755 and parameters: {'batch_size': 64, 'learning_rate': 0.0019702466277214735, 'nr_hidden_layers': 2, 'nr_neurons': 182, 'dropout_rate': 0.011850292336711867, 'weight_decay': 0.000616346328923362, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 13:25:45,743 - INFO - Trial 473: Early stopping at epoch 107.
[I 2025-11-04 13:25:45,835] Trial 473 finished with value: 0.0023718113202100257 and parameters: {'batch_size': 64, 'learning_rate': 0.001758418803937761, 'nr_hidden_layers': 2, 'nr_neurons': 236, 'dropout_rate': 2.7931631298907715e-05, 'weight_decay': 0.0004704569182149895, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 13:25:52,472] Trial 474 pruned. 
[I 2025-11-04 13:26:21,726] Trial 475 pruned. 
2025-11-04 13:29:06,646 - INFO - Trial 476: Early stopping at epoch 94.
[I 2025-11-04 13:29:06,738] Trial 476 finished with value: 0.0046615776180304975 and parameters: {'batch_size': 64, 'learning_rate': 0.0013710803413219872, 'nr_hidden_layers': 2, 'nr_neurons': 232, 'dropout_rate': 0.01583832967062213, 'weight_decay': 0.0005452686095003152, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 13:33:20,296 - INFO - Trial 477: Early stopping at epoch 137.
[I 2025-11-04 13:33:20,389] Trial 477 finished with value: 0.0037348546731184235 and parameters: {'batch_size': 64, 'learning_rate': 0.0018195786814012335, 'nr_hidden_layers': 2, 'nr_neurons': 188, 'dropout_rate': 0.010205539361793506, 'weight_decay': 0.0003090756055158872, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 13:33:39,030] Trial 478 pruned. 
2025-11-04 13:35:57,455 - INFO - Trial 479: Early stopping at epoch 80.
[I 2025-11-04 13:35:57,546] Trial 479 finished with value: 0.005956979572060261 and parameters: {'batch_size': 64, 'learning_rate': 0.0022917509805352888, 'nr_hidden_layers': 2, 'nr_neurons': 169, 'dropout_rate': 0.017771250743627204, 'weight_decay': 0.006084517040848361, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 13:39:44,406] Trial 480 pruned. 
[I 2025-11-04 13:42:18,637] Trial 481 pruned. 
2025-11-04 13:45:38,145 - INFO - Trial 482: Early stopping at epoch 118.
[I 2025-11-04 13:45:38,238] Trial 482 finished with value: 0.004029574975503621 and parameters: {'batch_size': 64, 'learning_rate': 0.0019412602392354142, 'nr_hidden_layers': 2, 'nr_neurons': 232, 'dropout_rate': 0.00908366195946101, 'weight_decay': 0.00048044727912865444, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 13:45:56,828] Trial 483 pruned. 
2025-11-04 13:49:27,498 - INFO - Trial 484: Early stopping at epoch 122.
[I 2025-11-04 13:49:27,598] Trial 484 finished with value: 0.004529660265649216 and parameters: {'batch_size': 64, 'learning_rate': 0.0014886605676941121, 'nr_hidden_layers': 2, 'nr_neurons': 221, 'dropout_rate': 0.008745317740127106, 'weight_decay': 0.00034927770230574725, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 13:51:43,515 - INFO - Trial 485: Early stopping at epoch 80.
[I 2025-11-04 13:51:43,607] Trial 485 finished with value: 0.003862525325008864 and parameters: {'batch_size': 64, 'learning_rate': 0.0017323485100535457, 'nr_hidden_layers': 2, 'nr_neurons': 193, 'dropout_rate': 0.0003512210749143747, 'weight_decay': 0.0004373437259006573, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 13:52:02,141] Trial 486 pruned. 
[I 2025-11-04 13:52:13,516] Trial 487 pruned. 
[I 2025-11-04 13:52:20,662] Trial 488 pruned. 
[I 2025-11-04 13:52:39,569] Trial 489 pruned. 
[I 2025-11-04 13:56:10,846] Trial 490 pruned. 
2025-11-04 14:00:01,421 - INFO - Trial 491: Early stopping at epoch 135.
[I 2025-11-04 14:00:01,523] Trial 491 finished with value: 0.0028304803081132873 and parameters: {'batch_size': 64, 'learning_rate': 0.00208870283587487, 'nr_hidden_layers': 2, 'nr_neurons': 244, 'dropout_rate': 0.0006678822141792372, 'weight_decay': 0.0006543720002055773, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 14:00:18,313] Trial 492 pruned. 
[I 2025-11-04 14:01:14,035] Trial 493 pruned. 
[I 2025-11-04 14:01:22,430] Trial 494 pruned. 
2025-11-04 14:02:55,575 - INFO - Trial 495: Early stopping at epoch 53.
[I 2025-11-04 14:02:55,666] Trial 495 finished with value: 0.0055501977161551 and parameters: {'batch_size': 64, 'learning_rate': 0.0029446573982688405, 'nr_hidden_layers': 2, 'nr_neurons': 235, 'dropout_rate': 0.00011513204892588007, 'weight_decay': 0.0004279810155554498, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 14:06:07,756 - INFO - Trial 496: Early stopping at epoch 114.
[I 2025-11-04 14:06:07,850] Trial 496 finished with value: 0.004750173556976875 and parameters: {'batch_size': 64, 'learning_rate': 0.00196605844259028, 'nr_hidden_layers': 2, 'nr_neurons': 218, 'dropout_rate': 0.009788955269490791, 'weight_decay': 0.00027717895011103785, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 14:06:26,647] Trial 497 pruned. 
[I 2025-11-04 14:06:45,008] Trial 498 pruned. 
2025-11-04 14:12:44,622 - INFO - Trial 499: Early stopping at epoch 222.
[I 2025-11-04 14:12:44,715] Trial 499 finished with value: 0.0017358147134199145 and parameters: {'batch_size': 64, 'learning_rate': 0.0012216002435068549, 'nr_hidden_layers': 2, 'nr_neurons': 228, 'dropout_rate': 0.0001839658239502202, 'weight_decay': 0.0005727512441006393, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 14:12:50,298] Trial 500 pruned. 
[I 2025-11-04 14:12:56,562] Trial 501 pruned. 
[I 2025-11-04 14:13:14,239] Trial 502 pruned. 
[I 2025-11-04 14:13:31,925] Trial 503 pruned. 
[I 2025-11-04 14:17:20,630] Trial 504 pruned. 
[I 2025-11-04 14:17:38,393] Trial 505 pruned. 
[I 2025-11-04 14:17:58,180] Trial 506 pruned. 
2025-11-04 14:21:40,752 - INFO - Trial 507: Early stopping at epoch 120.
[I 2025-11-04 14:21:40,849] Trial 507 finished with value: 0.0044851811061596926 and parameters: {'batch_size': 64, 'learning_rate': 0.0011317408267841047, 'nr_hidden_layers': 3, 'nr_neurons': 212, 'dropout_rate': 0.009211752963061872, 'weight_decay': 0.0009623611494851579, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 14:21:59,185] Trial 508 pruned. 
2025-11-04 14:27:08,113 - INFO - Trial 509: Early stopping at epoch 186.
[I 2025-11-04 14:27:08,205] Trial 509 finished with value: 0.0026206561568459926 and parameters: {'batch_size': 64, 'learning_rate': 0.001089283813878618, 'nr_hidden_layers': 2, 'nr_neurons': 176, 'dropout_rate': 0.0001736791699090103, 'weight_decay': 0.0006463372673665282, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 14:27:25,930] Trial 510 pruned. 
2025-11-04 14:29:54,234 - INFO - Trial 511: Early stopping at epoch 92.
[I 2025-11-04 14:29:54,328] Trial 511 finished with value: 0.005410918640016638 and parameters: {'batch_size': 64, 'learning_rate': 0.0022886948143492182, 'nr_hidden_layers': 2, 'nr_neurons': 203, 'dropout_rate': 0.02413865174308535, 'weight_decay': 0.00041489375020038136, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 14:30:12,467] Trial 512 pruned. 
[I 2025-11-04 14:30:30,147] Trial 513 pruned. 
[I 2025-11-04 14:30:36,817] Trial 514 pruned. 
[I 2025-11-04 14:30:47,669] Trial 515 pruned. 
[I 2025-11-04 14:31:10,607] Trial 516 pruned. 
[I 2025-11-04 14:32:15,581] Trial 517 pruned. 
2025-11-04 14:33:48,496 - INFO - Trial 518: Early stopping at epoch 55.
[I 2025-11-04 14:33:48,587] Trial 518 finished with value: 0.007893282039745776 and parameters: {'batch_size': 64, 'learning_rate': 0.001969269458501978, 'nr_hidden_layers': 2, 'nr_neurons': 219, 'dropout_rate': 0.00887708971411239, 'weight_decay': 0.0004908622568266822, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 14:34:07,013] Trial 519 pruned. 
[I 2025-11-04 14:34:25,388] Trial 520 pruned. 
[I 2025-11-04 14:34:33,579] Trial 521 pruned. 
[I 2025-11-04 14:34:51,923] Trial 522 pruned. 
[I 2025-11-04 14:36:55,610] Trial 523 pruned. 
[I 2025-11-04 14:40:14,658] Trial 524 pruned. 
[I 2025-11-04 14:40:32,270] Trial 525 pruned. 
2025-11-04 14:42:35,133 - INFO - Trial 526: Early stopping at epoch 70.
[I 2025-11-04 14:42:35,238] Trial 526 finished with value: 0.005805654053523015 and parameters: {'batch_size': 64, 'learning_rate': 0.0018400540395428853, 'nr_hidden_layers': 2, 'nr_neurons': 227, 'dropout_rate': 0.017014204152341894, 'weight_decay': 0.0003852142582841768, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 14:42:54,303] Trial 528 pruned. 
[I 2025-11-04 14:43:01,113] Trial 529 pruned. 
[I 2025-11-04 14:43:06,956] Trial 530 pruned. 
[I 2025-11-04 14:43:30,821] Trial 532 pruned. 
[I 2025-11-04 14:43:58,535] Trial 535 pruned. 
[I 2025-11-04 14:44:17,555] Trial 537 pruned. 
[I 2025-11-04 14:44:36,203] Trial 539 pruned. 
[I 2025-11-04 14:45:03,365] Trial 541 pruned. 
[I 2025-11-04 14:45:22,012] Trial 543 pruned. 
[I 2025-11-04 14:45:33,503] Trial 545 pruned. 
[I 2025-11-04 14:45:40,678] Trial 546 pruned. 
[I 2025-11-04 14:46:18,132] Trial 547 pruned. 
[I 2025-11-04 14:46:36,795] Trial 548 pruned. 
[I 2025-11-04 14:46:55,515] Trial 549 pruned. 
2025-11-04 14:49:48,421 - INFO - Trial 550: Early stopping at epoch 100.
[I 2025-11-04 14:49:48,534] Trial 550 finished with value: 0.004546849911675232 and parameters: {'batch_size': 64, 'learning_rate': 0.001764158145753545, 'nr_hidden_layers': 2, 'nr_neurons': 223, 'dropout_rate': 0.008327789654407804, 'weight_decay': 0.00015620911297378227, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 14:50:07,282] Trial 557 pruned. 
[I 2025-11-04 14:50:14,211] Trial 559 pruned. 
[I 2025-11-04 14:50:32,883] Trial 561 pruned. 
2025-11-04 14:53:42,812 - INFO - Trial 562: Early stopping at epoch 112.
[I 2025-11-04 14:53:42,907] Trial 562 finished with value: 0.003310855893517774 and parameters: {'batch_size': 64, 'learning_rate': 0.0016458879117734024, 'nr_hidden_layers': 2, 'nr_neurons': 228, 'dropout_rate': 0.0004852594592591309, 'weight_decay': 0.0002448429143239357, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 14:57:08,245 - INFO - Trial 565: Early stopping at epoch 118.
[I 2025-11-04 14:57:08,341] Trial 565 finished with value: 0.0032375210626602647 and parameters: {'batch_size': 64, 'learning_rate': 0.0022995277264815962, 'nr_hidden_layers': 2, 'nr_neurons': 180, 'dropout_rate': 0.00042526760409478093, 'weight_decay': 0.00048846350869058, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 14:59:47,966 - INFO - Trial 569: Early stopping at epoch 91.
[I 2025-11-04 14:59:48,062] Trial 569 finished with value: 0.003268706581154398 and parameters: {'batch_size': 64, 'learning_rate': 0.0016324614468457694, 'nr_hidden_layers': 2, 'nr_neurons': 256, 'dropout_rate': 1.8335407618488435e-05, 'weight_decay': 0.00037074971132266827, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 15:00:10,161] Trial 571 pruned. 
[I 2025-11-04 15:00:17,275] Trial 572 pruned. 
[I 2025-11-04 15:00:28,775] Trial 573 pruned. 
[I 2025-11-04 15:00:47,413] Trial 574 pruned. 
2025-11-04 15:03:39,749 - INFO - Trial 576: Early stopping at epoch 96.
[I 2025-11-04 15:03:39,843] Trial 576 finished with value: 0.005190234714689941 and parameters: {'batch_size': 64, 'learning_rate': 0.0028023385964882634, 'nr_hidden_layers': 2, 'nr_neurons': 168, 'dropout_rate': 0.008914838269541342, 'weight_decay': 0.0005561685919160045, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 15:05:33,238 - INFO - Trial 577: Early stopping at epoch 65.
[I 2025-11-04 15:05:33,332] Trial 577 finished with value: 0.007321565614416975 and parameters: {'batch_size': 64, 'learning_rate': 0.0024694567825826745, 'nr_hidden_layers': 2, 'nr_neurons': 230, 'dropout_rate': 0.024653215954837236, 'weight_decay': 0.0008059822957151712, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 15:07:39,575 - INFO - Trial 580: Early stopping at epoch 73.
[I 2025-11-04 15:07:39,670] Trial 580 finished with value: 0.00548522544461478 and parameters: {'batch_size': 64, 'learning_rate': 0.0020828343054578105, 'nr_hidden_layers': 2, 'nr_neurons': 186, 'dropout_rate': 0.010208489991277568, 'weight_decay': 0.000596827139745663, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 15:07:58,482] Trial 581 pruned. 
[I 2025-11-04 15:10:08,990] Trial 582 pruned. 
[I 2025-11-04 15:10:14,982] Trial 587 pruned. 
[I 2025-11-04 15:10:42,112] Trial 588 pruned. 
[I 2025-11-04 15:11:00,926] Trial 591 pruned. 
2025-11-04 15:15:19,919 - INFO - Trial 592: Early stopping at epoch 139.
[I 2025-11-04 15:15:20,026] Trial 592 finished with value: 0.0029476224951809943 and parameters: {'batch_size': 64, 'learning_rate': 0.0011110187791063947, 'nr_hidden_layers': 2, 'nr_neurons': 220, 'dropout_rate': 0.0004425864944648179, 'weight_decay': 0.0002786995434745175, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 15:15:31,540] Trial 596 pruned. 
2025-11-04 15:20:28,258 - INFO - Trial 597: Early stopping at epoch 172.
[I 2025-11-04 15:20:28,354] Trial 597 finished with value: 0.002587815158655708 and parameters: {'batch_size': 64, 'learning_rate': 0.0012828034009046783, 'nr_hidden_layers': 2, 'nr_neurons': 196, 'dropout_rate': 0.0006426634678839466, 'weight_decay': 0.000961513093777741, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 15:23:50,524 - INFO - Trial 602: Early stopping at epoch 104.
[I 2025-11-04 15:23:50,639] Trial 602 finished with value: 0.0023502572637033635 and parameters: {'batch_size': 64, 'learning_rate': 0.0029291819241346905, 'nr_hidden_layers': 2, 'nr_neurons': 182, 'dropout_rate': 1.5108877948701855e-05, 'weight_decay': 0.0004908599944076725, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 15:23:59,073] Trial 606 pruned. 
2025-11-04 15:26:19,708 - INFO - Trial 607: Early stopping at epoch 80.
[I 2025-11-04 15:26:19,803] Trial 607 finished with value: 0.004626273027623195 and parameters: {'batch_size': 64, 'learning_rate': 0.001483087495066114, 'nr_hidden_layers': 2, 'nr_neurons': 228, 'dropout_rate': 0.007853525162059415, 'weight_decay': 0.00023437834850518121, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 15:27:07,329] Trial 608 pruned. 
[I 2025-11-04 15:27:14,573] Trial 611 pruned. 
2025-11-04 15:30:28,316 - INFO - Trial 613: Early stopping at epoch 109.
[I 2025-11-04 15:30:28,438] Trial 613 finished with value: 0.0028726528938423698 and parameters: {'batch_size': 64, 'learning_rate': 0.0013745016780924329, 'nr_hidden_layers': 2, 'nr_neurons': 206, 'dropout_rate': 0.0005654639013971203, 'weight_decay': 0.00020990213683416052, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 15:30:47,938] Trial 616 pruned. 
[I 2025-11-04 15:31:07,350] Trial 618 pruned. 
[I 2025-11-04 15:31:51,314] Trial 619 pruned. 
[I 2025-11-04 15:32:08,713] Trial 620 pruned. 
2025-11-04 15:33:40,149 - INFO - Trial 622: Early stopping at epoch 51.
[I 2025-11-04 15:33:40,244] Trial 622 finished with value: 0.006787223394726048 and parameters: {'batch_size': 64, 'learning_rate': 0.002686763969628089, 'nr_hidden_layers': 2, 'nr_neurons': 158, 'dropout_rate': 0.009252928626696444, 'weight_decay': 0.0003291787431388958, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 15:33:59,563] Trial 625 pruned. 
[I 2025-11-04 15:34:18,894] Trial 626 pruned. 
[I 2025-11-04 15:34:38,094] Trial 627 pruned. 
[I 2025-11-04 15:34:49,891] Trial 628 pruned. 
[I 2025-11-04 15:34:58,272] Trial 629 pruned. 
[I 2025-11-04 15:35:44,004] Trial 630 pruned. 
[I 2025-11-04 15:36:03,279] Trial 631 pruned. 
[I 2025-11-04 15:36:22,513] Trial 632 pruned. 
[I 2025-11-04 15:36:31,315] Trial 634 pruned. 
2025-11-04 15:38:20,424 - INFO - Trial 635: Early stopping at epoch 62.
[I 2025-11-04 15:38:20,529] Trial 635 finished with value: 0.006001116861658013 and parameters: {'batch_size': 64, 'learning_rate': 0.0023202739563335526, 'nr_hidden_layers': 2, 'nr_neurons': 243, 'dropout_rate': 0.00842831759215956, 'weight_decay': 0.0004891811036051703, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 15:38:39,782] Trial 638 pruned. 
[I 2025-11-04 15:38:45,977] Trial 639 pruned. 
[I 2025-11-04 15:39:15,346] Trial 640 pruned. 
2025-11-04 15:41:58,807 - INFO - Trial 641: Early stopping at epoch 93.
[I 2025-11-04 15:41:58,944] Trial 641 finished with value: 0.005796884366617353 and parameters: {'batch_size': 64, 'learning_rate': 0.0024656289596374174, 'nr_hidden_layers': 2, 'nr_neurons': 232, 'dropout_rate': 0.01666610708875723, 'weight_decay': 0.0006806173533573529, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 15:44:33,357 - INFO - Trial 643: Early stopping at epoch 87.
[I 2025-11-04 15:44:33,457] Trial 643 finished with value: 0.0053532157916711814 and parameters: {'batch_size': 64, 'learning_rate': 0.0018572204276053232, 'nr_hidden_layers': 2, 'nr_neurons': 171, 'dropout_rate': 0.010633328887564136, 'weight_decay': 0.0007938573622965539, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 15:47:18,201] Trial 647 pruned. 
2025-11-04 15:50:35,556 - INFO - Trial 649: Early stopping at epoch 112.
[I 2025-11-04 15:50:35,654] Trial 649 finished with value: 0.004687767840720337 and parameters: {'batch_size': 64, 'learning_rate': 0.0017121449095869362, 'nr_hidden_layers': 2, 'nr_neurons': 214, 'dropout_rate': 0.015593817329401804, 'weight_decay': 2.3884840279718978e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 15:51:25,113] Trial 654 pruned. 
2025-11-04 15:55:06,122 - INFO - Trial 655: Early stopping at epoch 125.
[I 2025-11-04 15:55:06,220] Trial 655 finished with value: 0.004163135653908534 and parameters: {'batch_size': 64, 'learning_rate': 0.0018947220276401783, 'nr_hidden_layers': 2, 'nr_neurons': 199, 'dropout_rate': 0.0100227874659184, 'weight_decay': 0.0006121581924552751, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 15:55:14,538] Trial 657 pruned. 
[I 2025-11-04 15:55:37,379] Trial 658 pruned. 
[I 2025-11-04 15:55:56,488] Trial 659 pruned. 
[I 2025-11-04 15:57:24,741] Trial 660 pruned. 
[I 2025-11-04 15:57:31,118] Trial 665 pruned. 
2025-11-04 16:04:10,266 - INFO - Trial 666: Early stopping at epoch 229.
[I 2025-11-04 16:04:10,368] Trial 666 finished with value: 0.0017550366511290124 and parameters: {'batch_size': 64, 'learning_rate': 0.001492533378964447, 'nr_hidden_layers': 2, 'nr_neurons': 209, 'dropout_rate': 0.0004025145468820016, 'weight_decay': 0.0009442416771033175, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 16:06:30,606 - INFO - Trial 672: Early stopping at epoch 79.
[I 2025-11-04 16:06:30,712] Trial 672 finished with value: 0.0034050086408263323 and parameters: {'batch_size': 64, 'learning_rate': 0.0013756371256878053, 'nr_hidden_layers': 2, 'nr_neurons': 244, 'dropout_rate': 0.000755513190595943, 'weight_decay': 0.0006206797343858028, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 16:06:50,205] Trial 675 pruned. 
[I 2025-11-04 16:07:09,597] Trial 676 pruned. 
2025-11-04 16:12:03,076 - INFO - Trial 677: Early stopping at epoch 168.
[I 2025-11-04 16:12:03,175] Trial 677 finished with value: 0.0014988042465075315 and parameters: {'batch_size': 64, 'learning_rate': 0.001578296367442209, 'nr_hidden_layers': 2, 'nr_neurons': 253, 'dropout_rate': 8.980192244878201e-06, 'weight_decay': 0.001012854798930279, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 16:12:41,643] Trial 683 pruned. 
[I 2025-11-04 16:13:00,972] Trial 684 pruned. 
[I 2025-11-04 16:13:09,127] Trial 685 pruned. 
[I 2025-11-04 16:13:28,467] Trial 686 pruned. 
[I 2025-11-04 16:15:56,021] Trial 687 pruned. 
[I 2025-11-04 16:16:15,217] Trial 694 pruned. 
[I 2025-11-04 16:16:22,333] Trial 696 pruned. 
[I 2025-11-04 16:16:41,558] Trial 698 pruned. 
[I 2025-11-04 16:17:00,956] Trial 699 pruned. 
2025-11-04 16:19:30,113 - INFO - Trial 700: Early stopping at epoch 85.
[I 2025-11-04 16:19:30,216] Trial 700 finished with value: 0.0035924705168574834 and parameters: {'batch_size': 64, 'learning_rate': 0.0017380575872814076, 'nr_hidden_layers': 2, 'nr_neurons': 239, 'dropout_rate': 0.0006473408752199776, 'weight_decay': 0.00039673669892667274, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 16:24:20,550 - INFO - Trial 704: Early stopping at epoch 165.
[I 2025-11-04 16:24:20,653] Trial 704 finished with value: 0.001854360240591908 and parameters: {'batch_size': 64, 'learning_rate': 0.0013390051524984927, 'nr_hidden_layers': 2, 'nr_neurons': 210, 'dropout_rate': 1.9775704123969437e-05, 'weight_decay': 0.00021117780492168665, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 16:24:40,221] Trial 706 pruned. 
2025-11-04 16:30:05,833 - INFO - Trial 707: Early stopping at epoch 154.
[I 2025-11-04 16:30:05,937] Trial 707 finished with value: 0.0020880228195402166 and parameters: {'batch_size': 64, 'learning_rate': 0.00134116978277855, 'nr_hidden_layers': 4, 'nr_neurons': 210, 'dropout_rate': 0.00011159084508626478, 'weight_decay': 0.00016058900093153655, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 16:30:30,792] Trial 717 pruned. 
[I 2025-11-04 16:30:56,117] Trial 718 pruned. 
[I 2025-11-04 16:31:15,439] Trial 719 pruned. 
[I 2025-11-04 16:31:25,079] Trial 720 pruned. 
[I 2025-11-04 16:31:48,041] Trial 721 pruned. 
[I 2025-11-04 16:32:13,413] Trial 722 pruned. 
2025-11-04 16:34:33,608 - INFO - Trial 723: Early stopping at epoch 66.
[I 2025-11-04 16:34:33,710] Trial 723 finished with value: 0.004367530596048822 and parameters: {'batch_size': 64, 'learning_rate': 0.0011888183536729081, 'nr_hidden_layers': 4, 'nr_neurons': 207, 'dropout_rate': 0.000524013443031982, 'weight_decay': 0.00020815677188035366, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 16:34:51,034] Trial 727 pruned. 
2025-11-04 16:38:32,293 - INFO - Trial 728: Early stopping at epoch 115.
[I 2025-11-04 16:38:32,403] Trial 728 finished with value: 0.004683348242311527 and parameters: {'batch_size': 64, 'learning_rate': 0.0012968509462304887, 'nr_hidden_layers': 3, 'nr_neurons': 237, 'dropout_rate': 0.009282309005587634, 'weight_decay': 0.00011590319497240154, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 16:38:53,922] Trial 731 pruned. 
[I 2025-11-04 16:39:16,915] Trial 732 pruned. 
[I 2025-11-04 16:39:36,374] Trial 733 pruned. 
[I 2025-11-04 16:39:56,245] Trial 735 pruned. 
[I 2025-11-04 16:40:25,669] Trial 737 pruned. 
[I 2025-11-04 16:40:33,197] Trial 740 pruned. 
[I 2025-11-04 16:40:52,643] Trial 742 pruned. 
[I 2025-11-04 16:41:11,940] Trial 744 pruned. 
[I 2025-11-04 16:41:31,275] Trial 746 pruned. 
[I 2025-11-04 16:45:10,098] Trial 748 pruned. 
[I 2025-11-04 16:45:19,012] Trial 752 pruned. 
[I 2025-11-04 16:45:25,991] Trial 754 pruned. 
[I 2025-11-04 16:45:32,081] Trial 756 pruned. 
2025-11-04 16:51:54,794 - INFO - Trial 757: Early stopping at epoch 217.
[I 2025-11-04 16:51:54,898] Trial 757 finished with value: 0.0012898413398971592 and parameters: {'batch_size': 64, 'learning_rate': 0.001626691068212618, 'nr_hidden_layers': 2, 'nr_neurons': 194, 'dropout_rate': 7.028725470725432e-05, 'weight_decay': 0.0002823742173422716, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 16:52:15,692] Trial 765 pruned. 
[I 2025-11-04 16:52:42,096] Trial 766 pruned. 
[I 2025-11-04 16:56:04,704] Trial 768 pruned. 
[I 2025-11-04 16:56:24,183] Trial 771 pruned. 
2025-11-04 17:01:23,491 - INFO - Trial 772: Early stopping at epoch 132.
[I 2025-11-04 17:01:23,600] Trial 772 finished with value: 0.004148544442613798 and parameters: {'batch_size': 64, 'learning_rate': 0.0015014690417253821, 'nr_hidden_layers': 5, 'nr_neurons': 177, 'dropout_rate': 0.008723878729241161, 'weight_decay': 0.0003403207832084018, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 17:01:43,169] Trial 776 pruned. 
[I 2025-11-04 17:02:03,159] Trial 777 pruned. 
2025-11-04 17:06:48,916 - INFO - Trial 778: Early stopping at epoch 159.
[I 2025-11-04 17:06:49,038] Trial 778 finished with value: 0.002173632569470603 and parameters: {'batch_size': 64, 'learning_rate': 0.0018263280217285548, 'nr_hidden_layers': 2, 'nr_neurons': 207, 'dropout_rate': 0.00013304503736869677, 'weight_decay': 0.0013908525782143273, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 17:09:42,688] Trial 784 pruned. 
[I 2025-11-04 17:10:02,145] Trial 788 pruned. 
[I 2025-11-04 17:10:21,724] Trial 790 pruned. 
[I 2025-11-04 17:13:13,183] Trial 792 pruned. 
[I 2025-11-04 17:13:25,093] Trial 794 pruned. 
[I 2025-11-04 17:13:44,621] Trial 795 pruned. 
[I 2025-11-04 17:13:52,119] Trial 796 pruned. 
[I 2025-11-04 17:14:11,568] Trial 798 pruned. 
[I 2025-11-04 17:14:32,689] Trial 800 pruned. 
[I 2025-11-04 17:14:41,537] Trial 802 pruned. 
[I 2025-11-04 17:15:00,965] Trial 803 pruned. 
[I 2025-11-04 17:16:01,814] Trial 805 pruned. 
[I 2025-11-04 17:16:08,876] Trial 807 pruned. 
[I 2025-11-04 17:16:15,024] Trial 808 pruned. 
2025-11-04 17:19:54,820 - INFO - Trial 809: Early stopping at epoch 123.
[I 2025-11-04 17:19:54,942] Trial 809 finished with value: 0.0024427127322644185 and parameters: {'batch_size': 64, 'learning_rate': 0.0017034575811015317, 'nr_hidden_layers': 2, 'nr_neurons': 148, 'dropout_rate': 0.00022469462533868448, 'weight_decay': 0.00026586046244630643, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 17:20:16,721] Trial 814 pruned. 
[I 2025-11-04 17:20:36,440] Trial 815 pruned. 
[I 2025-11-04 17:20:59,588] Trial 817 pruned. 
[I 2025-11-04 17:21:18,913] Trial 819 pruned. 
[I 2025-11-04 17:21:30,650] Trial 821 pruned. 
[I 2025-11-04 17:21:55,016] Trial 822 pruned. 
[I 2025-11-04 17:22:02,141] Trial 823 pruned. 
[I 2025-11-04 17:22:21,794] Trial 825 pruned. 
2025-11-04 17:24:58,071 - INFO - Trial 827: Early stopping at epoch 86.
[I 2025-11-04 17:24:58,184] Trial 827 finished with value: 0.0033308679368676828 and parameters: {'batch_size': 64, 'learning_rate': 0.0018023711392384564, 'nr_hidden_layers': 2, 'nr_neurons': 233, 'dropout_rate': 0.00026644562331864537, 'weight_decay': 0.0005163199435412331, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 17:25:17,674] Trial 830 pruned. 
[I 2025-11-04 17:25:26,492] Trial 831 pruned. 
[I 2025-11-04 17:25:45,972] Trial 832 pruned. 
[I 2025-11-04 17:26:05,645] Trial 833 pruned. 
[I 2025-11-04 17:26:27,281] Trial 834 pruned. 
[I 2025-11-04 17:26:50,336] Trial 837 pruned. 
[I 2025-11-04 17:27:09,841] Trial 840 pruned. 
2025-11-04 17:30:00,949 - INFO - Trial 842: Early stopping at epoch 93.
[I 2025-11-04 17:30:01,058] Trial 842 finished with value: 0.0026274533095009974 and parameters: {'batch_size': 64, 'learning_rate': 0.0021936254017762714, 'nr_hidden_layers': 2, 'nr_neurons': 197, 'dropout_rate': 0.00012524415174476467, 'weight_decay': 0.00019036669822037765, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 17:30:20,609] Trial 844 pruned. 
[I 2025-11-04 17:30:45,395] Trial 845 pruned. 
2025-11-04 17:32:49,923 - INFO - Trial 847: Early stopping at epoch 70.
[I 2025-11-04 17:32:50,026] Trial 847 finished with value: 0.00514878915705641 and parameters: {'batch_size': 64, 'learning_rate': 0.0014280747433847913, 'nr_hidden_layers': 2, 'nr_neurons': 255, 'dropout_rate': 0.008839776148524018, 'weight_decay': 0.0003138390676174853, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 17:33:02,219] Trial 851 pruned. 
[I 2025-11-04 17:33:21,715] Trial 852 pruned. 
[I 2025-11-04 17:33:40,927] Trial 853 pruned. 
[I 2025-11-04 17:34:00,203] Trial 854 pruned. 
[I 2025-11-04 17:34:19,790] Trial 855 pruned. 
2025-11-04 17:36:36,592 - INFO - Trial 856: Early stopping at epoch 77.
[I 2025-11-04 17:36:36,695] Trial 856 finished with value: 0.004125898202809437 and parameters: {'batch_size': 64, 'learning_rate': 0.002139782602255902, 'nr_hidden_layers': 2, 'nr_neurons': 139, 'dropout_rate': 0.00019752519975512075, 'weight_decay': 0.0004823805571130634, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 17:36:56,187] Trial 860 pruned. 
[I 2025-11-04 17:37:15,674] Trial 861 pruned. 
[I 2025-11-04 17:37:22,574] Trial 863 pruned. 
[I 2025-11-04 17:37:42,014] Trial 864 pruned. 
[I 2025-11-04 17:37:47,999] Trial 865 pruned. 
2025-11-04 17:40:26,213 - INFO - Trial 866: Early stopping at epoch 89.
[I 2025-11-04 17:40:26,321] Trial 866 finished with value: 0.003473140979739824 and parameters: {'batch_size': 64, 'learning_rate': 0.0015539749980977425, 'nr_hidden_layers': 2, 'nr_neurons': 207, 'dropout_rate': 0.0005094094551238859, 'weight_decay': 0.0001439769620014314, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 17:40:48,025] Trial 868 pruned. 
[I 2025-11-04 17:43:01,228] Trial 869 pruned. 
[I 2025-11-04 17:43:20,362] Trial 870 pruned. 
2025-11-04 17:46:02,350 - INFO - Trial 871: Early stopping at epoch 93.
[I 2025-11-04 17:46:02,454] Trial 871 finished with value: 0.0034625798735706753 and parameters: {'batch_size': 64, 'learning_rate': 0.0015242841656172232, 'nr_hidden_layers': 2, 'nr_neurons': 222, 'dropout_rate': 0.0002439883802653556, 'weight_decay': 0.0003114304133467956, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 17:46:32,324] Trial 872 pruned. 
2025-11-04 17:49:23,832 - INFO - Trial 875: Early stopping at epoch 96.
[I 2025-11-04 17:49:23,966] Trial 875 finished with value: 0.00362276145209698 and parameters: {'batch_size': 64, 'learning_rate': 0.0016345689024209395, 'nr_hidden_layers': 2, 'nr_neurons': 192, 'dropout_rate': 9.345809665153482e-05, 'weight_decay': 6.586365045062202e-06, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 17:49:31,336] Trial 878 pruned. 
[I 2025-11-04 17:49:52,622] Trial 880 pruned. 
[I 2025-11-04 17:50:12,125] Trial 883 pruned. 
[I 2025-11-04 17:50:31,682] Trial 884 pruned. 
2025-11-04 17:52:26,531 - INFO - Trial 886: Early stopping at epoch 64.
[I 2025-11-04 17:52:26,649] Trial 886 finished with value: 0.0070867524976732914 and parameters: {'batch_size': 64, 'learning_rate': 0.0020987328884754532, 'nr_hidden_layers': 2, 'nr_neurons': 215, 'dropout_rate': 0.008053377481430153, 'weight_decay': 0.0007955254779963882, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 17:52:46,287] Trial 895 pruned. 
[I 2025-11-04 17:53:07,626] Trial 897 pruned. 
[I 2025-11-04 17:53:25,124] Trial 899 pruned. 
2025-11-04 17:57:00,736 - INFO - Trial 900: Early stopping at epoch 122.
[I 2025-11-04 17:57:00,842] Trial 900 finished with value: 0.0022429512655957164 and parameters: {'batch_size': 64, 'learning_rate': 0.001625600796069949, 'nr_hidden_layers': 2, 'nr_neurons': 245, 'dropout_rate': 5.463524747396107e-05, 'weight_decay': 0.0005635908652685073, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 17:57:25,652] Trial 903 pruned. 
[I 2025-11-04 17:57:37,613] Trial 905 pruned. 
[I 2025-11-04 17:58:00,035] Trial 907 pruned. 
[I 2025-11-04 17:58:19,594] Trial 909 pruned. 
[I 2025-11-04 17:58:39,128] Trial 911 pruned. 
[I 2025-11-04 17:58:48,131] Trial 912 pruned. 
[I 2025-11-04 17:59:07,579] Trial 913 pruned. 
[I 2025-11-04 17:59:32,860] Trial 914 pruned. 
[I 2025-11-04 17:59:52,447] Trial 915 pruned. 
[I 2025-11-04 18:00:22,624] Trial 916 pruned. 
[I 2025-11-04 18:00:29,666] Trial 917 pruned. 
[I 2025-11-04 18:00:52,554] Trial 918 pruned. 
[I 2025-11-04 18:00:58,763] Trial 920 pruned. 
[I 2025-11-04 18:01:51,558] Trial 921 pruned. 
[I 2025-11-04 18:02:11,245] Trial 923 pruned. 
[I 2025-11-04 18:02:32,553] Trial 924 pruned. 
[I 2025-11-04 18:02:52,144] Trial 925 pruned. 
[I 2025-11-04 18:05:45,478] Trial 926 pruned. 
[I 2025-11-04 18:07:57,028] Trial 928 pruned. 
[I 2025-11-04 18:08:17,901] Trial 937 pruned. 
[I 2025-11-04 18:08:37,349] Trial 939 pruned. 
2025-11-04 18:12:40,824 - INFO - Trial 940: Early stopping at epoch 137.
[I 2025-11-04 18:12:40,930] Trial 940 finished with value: 0.001908189230699491 and parameters: {'batch_size': 64, 'learning_rate': 0.0016147921068798306, 'nr_hidden_layers': 2, 'nr_neurons': 215, 'dropout_rate': 5.7194205788988594e-05, 'weight_decay': 0.0007996530347411042, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 18:13:00,497] Trial 942 pruned. 
[I 2025-11-04 18:13:09,314] Trial 943 pruned. 
[I 2025-11-04 18:13:28,954] Trial 944 pruned. 
2025-11-04 18:17:03,319 - INFO - Trial 945: Early stopping at epoch 121.
[I 2025-11-04 18:17:03,428] Trial 945 finished with value: 0.0021836566981484683 and parameters: {'batch_size': 64, 'learning_rate': 0.0015515669465357665, 'nr_hidden_layers': 2, 'nr_neurons': 221, 'dropout_rate': 2.4681781844911065e-05, 'weight_decay': 0.0007253948926474298, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 18:17:22,948] Trial 951 pruned. 
[I 2025-11-04 18:17:45,477] Trial 952 pruned. 
[I 2025-11-04 18:18:04,976] Trial 953 pruned. 
[I 2025-11-04 18:18:24,543] Trial 954 pruned. 
[I 2025-11-04 18:18:44,388] Trial 955 pruned. 
[I 2025-11-04 18:19:04,373] Trial 956 pruned. 
[I 2025-11-04 18:19:23,892] Trial 957 pruned. 
[I 2025-11-04 18:19:57,566] Trial 958 pruned. 
[I 2025-11-04 18:20:04,810] Trial 959 pruned. 
2025-11-04 18:23:02,348 - INFO - Trial 960: Early stopping at epoch 99.
[I 2025-11-04 18:23:02,453] Trial 960 finished with value: 0.004967963855013237 and parameters: {'batch_size': 64, 'learning_rate': 0.0018510543749132781, 'nr_hidden_layers': 2, 'nr_neurons': 228, 'dropout_rate': 0.014603045198195544, 'weight_decay': 0.0009538824196913005, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 18:23:27,945] Trial 968 pruned. 
[I 2025-11-04 18:23:36,686] Trial 969 pruned. 
[I 2025-11-04 18:25:53,524] Trial 970 pruned. 
[I 2025-11-04 18:26:13,030] Trial 973 pruned. 
[I 2025-11-04 18:26:19,201] Trial 974 pruned. 
[I 2025-11-04 18:26:38,558] Trial 975 pruned. 
[I 2025-11-04 18:26:45,730] Trial 976 pruned. 
[I 2025-11-04 18:27:05,189] Trial 977 pruned. 
[I 2025-11-04 18:27:24,476] Trial 978 pruned. 
[I 2025-11-04 18:27:44,015] Trial 979 pruned. 
[I 2025-11-04 18:28:03,637] Trial 980 pruned. 
[I 2025-11-04 18:28:23,630] Trial 981 pruned. 
[I 2025-11-04 18:28:47,779] Trial 982 pruned. 
[I 2025-11-04 18:29:07,285] Trial 983 pruned. 
2025-11-04 18:33:40,521 - INFO - Trial 984: Early stopping at epoch 154.
[I 2025-11-04 18:33:40,626] Trial 984 finished with value: 0.0020831675692677596 and parameters: {'batch_size': 64, 'learning_rate': 0.001698512513001183, 'nr_hidden_layers': 2, 'nr_neurons': 256, 'dropout_rate': 3.9673070218835735e-05, 'weight_decay': 0.00042851188162297256, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 18:33:47,751] Trial 988 pruned. 
[I 2025-11-04 18:33:59,813] Trial 990 pruned. 
[I 2025-11-04 18:34:23,320] Trial 992 pruned. 
2025-11-04 18:36:12,374 - INFO - Trial 994: Early stopping at epoch 60.
[I 2025-11-04 18:36:12,503] Trial 994 finished with value: 0.00570829328254698 and parameters: {'batch_size': 64, 'learning_rate': 0.002335431955571331, 'nr_hidden_layers': 2, 'nr_neurons': 215, 'dropout_rate': 0.00897290672866184, 'weight_decay': 0.00015410903669422295, 'activation_name': 'GELU', 'loss_criterion': 'SmoothL1'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 18:36:21,371] Trial 998 pruned. 
[I 2025-11-04 18:36:41,040] Trial 999 pruned. 
[I 2025-11-04 18:37:03,992] Trial 1000 pruned. 
[I 2025-11-04 18:37:23,969] Trial 1001 pruned. 
[I 2025-11-04 18:37:30,990] Trial 1002 pruned. 
[I 2025-11-04 18:37:50,618] Trial 1003 pruned. 
[I 2025-11-04 18:37:56,845] Trial 1004 pruned. 
2025-11-04 18:41:01,845 - INFO - Trial 1005: Early stopping at epoch 103.
[I 2025-11-04 18:41:01,959] Trial 1005 finished with value: 0.0034376048951661213 and parameters: {'batch_size': 64, 'learning_rate': 0.0013665008108663915, 'nr_hidden_layers': 2, 'nr_neurons': 243, 'dropout_rate': 0.00022479723508872035, 'weight_decay': 0.005521589677909635, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 18:41:21,609] Trial 1007 pruned. 
[I 2025-11-04 18:41:41,210] Trial 1008 pruned. 
[I 2025-11-04 18:42:00,842] Trial 1009 pruned. 
2025-11-04 18:44:15,290 - INFO - Trial 1010: Early stopping at epoch 75.
[I 2025-11-04 18:44:15,396] Trial 1010 finished with value: 0.005363069915918603 and parameters: {'batch_size': 64, 'learning_rate': 0.002810682387955759, 'nr_hidden_layers': 2, 'nr_neurons': 223, 'dropout_rate': 0.00950891084522252, 'weight_decay': 0.00035237383402145217, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 18:44:34,932] Trial 1014 pruned. 
[I 2025-11-04 18:44:54,628] Trial 1015 pruned. 
[I 2025-11-04 18:45:16,007] Trial 1016 pruned. 
[I 2025-11-04 18:45:37,334] Trial 1017 pruned. 
[I 2025-11-04 18:45:56,864] Trial 1018 pruned. 
[I 2025-11-04 18:47:09,387] Trial 1019 pruned. 
[I 2025-11-04 18:47:28,992] Trial 1020 pruned. 
[I 2025-11-04 18:47:48,686] Trial 1021 pruned. 
[I 2025-11-04 18:48:08,828] Trial 1022 pruned. 
[I 2025-11-04 18:48:28,576] Trial 1023 pruned. 
[I 2025-11-04 18:48:37,528] Trial 1024 pruned. 
[I 2025-11-04 18:48:57,209] Trial 1025 pruned. 
[I 2025-11-04 18:49:16,983] Trial 1027 pruned. 
[I 2025-11-04 18:49:36,539] Trial 1029 pruned. 
[I 2025-11-04 18:49:56,258] Trial 1031 pruned. 
[I 2025-11-04 18:50:03,274] Trial 1034 pruned. 
[I 2025-11-04 18:50:22,863] Trial 1035 pruned. 
[I 2025-11-04 18:50:42,484] Trial 1036 pruned. 
[I 2025-11-04 18:51:00,018] Trial 1037 pruned. 
[I 2025-11-04 18:51:38,469] Trial 1038 pruned. 
[I 2025-11-04 18:51:57,889] Trial 1039 pruned. 
[I 2025-11-04 18:52:17,617] Trial 1040 pruned. 
[I 2025-11-04 18:52:37,230] Trial 1041 pruned. 
[I 2025-11-04 18:52:56,908] Trial 1042 pruned. 
[I 2025-11-04 18:53:16,500] Trial 1043 pruned. 
[I 2025-11-04 18:53:23,902] Trial 1044 pruned. 
[I 2025-11-04 18:53:36,191] Trial 1045 pruned. 
[I 2025-11-04 18:53:55,725] Trial 1047 pruned. 
[I 2025-11-04 18:54:15,216] Trial 1049 pruned. 
[I 2025-11-04 18:54:34,793] Trial 1051 pruned. 
[I 2025-11-04 18:54:54,331] Trial 1052 pruned. 
[I 2025-11-04 18:55:03,083] Trial 1053 pruned. 
[I 2025-11-04 18:55:22,664] Trial 1054 pruned. 
[I 2025-11-04 18:59:18,405] Trial 1055 pruned. 
[I 2025-11-04 18:59:38,119] Trial 1062 pruned. 
[I 2025-11-04 18:59:57,662] Trial 1063 pruned. 
[I 2025-11-04 19:00:15,220] Trial 1064 pruned. 
[I 2025-11-04 19:00:34,644] Trial 1065 pruned. 
[I 2025-11-04 19:00:54,279] Trial 1066 pruned. 
[I 2025-11-04 19:01:15,712] Trial 1067 pruned. 
[I 2025-11-04 19:01:35,823] Trial 1068 pruned. 
2025-11-04 19:06:05,470 - INFO - Trial 1070: Early stopping at epoch 152.
[I 2025-11-04 19:06:05,580] Trial 1070 finished with value: 0.0019589155291032992 and parameters: {'batch_size': 64, 'learning_rate': 0.001913042277678353, 'nr_hidden_layers': 2, 'nr_neurons': 220, 'dropout_rate': 0.0001129719075298442, 'weight_decay': 0.0001296363627281343, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 19:07:26,777] Trial 1075 pruned. 
[I 2025-11-04 19:07:46,376] Trial 1076 pruned. 
[I 2025-11-04 19:08:06,087] Trial 1077 pruned. 
[I 2025-11-04 19:08:25,678] Trial 1078 pruned. 
[I 2025-11-04 19:09:41,268] Trial 1079 pruned. 
[I 2025-11-04 19:10:00,865] Trial 1082 pruned. 
2025-11-04 19:12:41,600 - INFO - Trial 1083: Early stopping at epoch 86.
[I 2025-11-04 19:12:41,707] Trial 1083 finished with value: 0.005532675607668566 and parameters: {'batch_size': 64, 'learning_rate': 0.0018113150190201507, 'nr_hidden_layers': 2, 'nr_neurons': 256, 'dropout_rate': 0.018345056969660795, 'weight_decay': 8.640047640232678e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 19:12:48,796] Trial 1085 pruned. 
[I 2025-11-04 19:15:19,319] Trial 1086 pruned. 
2025-11-04 19:16:50,864 - INFO - Trial 1090: Early stopping at epoch 51.
[I 2025-11-04 19:16:50,974] Trial 1090 finished with value: 0.007560048616350116 and parameters: {'batch_size': 64, 'learning_rate': 0.0018814311554150765, 'nr_hidden_layers': 2, 'nr_neurons': 245, 'dropout_rate': 0.026039389362273253, 'weight_decay': 2.4367811974769308e-05, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 19:17:10,412] Trial 1095 pruned. 
[I 2025-11-04 19:17:30,013] Trial 1096 pruned. 
2025-11-04 19:20:45,434 - INFO - Trial 1097: Early stopping at epoch 109.
[I 2025-11-04 19:20:45,551] Trial 1097 finished with value: 0.004826747054939556 and parameters: {'batch_size': 64, 'learning_rate': 0.0018194455699925228, 'nr_hidden_layers': 2, 'nr_neurons': 200, 'dropout_rate': 0.017243477564532126, 'weight_decay': 0.0008772155455678112, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 19:21:05,111] Trial 1102 pruned. 
[I 2025-11-04 19:23:03,430] Trial 1103 pruned. 
[I 2025-11-04 19:23:31,631] Trial 1108 pruned. 
[I 2025-11-04 19:23:40,991] Trial 1109 pruned. 
[I 2025-11-04 19:24:00,519] Trial 1110 pruned. 
[I 2025-11-04 19:24:20,176] Trial 1111 pruned. 
2025-11-04 19:28:10,755 - INFO - Trial 1112: Early stopping at epoch 130.
[I 2025-11-04 19:28:10,867] Trial 1112 finished with value: 0.002407109302618185 and parameters: {'batch_size': 64, 'learning_rate': 0.001699846052752952, 'nr_hidden_layers': 2, 'nr_neurons': 224, 'dropout_rate': 5.247306267860681e-05, 'weight_decay': 0.0006913364509362199, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 19:28:55,408] Trial 1117 pruned. 
2025-11-04 19:34:16,961 - INFO - Trial 1118: Early stopping at epoch 181.
[I 2025-11-04 19:34:17,073] Trial 1118 finished with value: 0.0018459491010585063 and parameters: {'batch_size': 64, 'learning_rate': 0.0015369831535971973, 'nr_hidden_layers': 2, 'nr_neurons': 243, 'dropout_rate': 0.00016904174034656393, 'weight_decay': 0.0005438073995216721, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 19:34:36,633] Trial 1123 pruned. 
[I 2025-11-04 19:34:56,158] Trial 1125 pruned. 
[I 2025-11-04 19:35:08,309] Trial 1127 pruned. 
[I 2025-11-04 19:35:15,563] Trial 1129 pruned. 
[I 2025-11-04 19:35:35,225] Trial 1130 pruned. 
[I 2025-11-04 19:36:47,813] Trial 1132 pruned. 
[I 2025-11-04 19:37:07,826] Trial 1133 pruned. 
[I 2025-11-04 19:37:27,396] Trial 1134 pruned. 
[I 2025-11-04 19:37:46,920] Trial 1135 pruned. 
[I 2025-11-04 19:38:06,562] Trial 1136 pruned. 
[I 2025-11-04 19:38:15,390] Trial 1137 pruned. 
[I 2025-11-04 19:38:41,009] Trial 1138 pruned. 
2025-11-04 19:41:59,204 - INFO - Trial 1139: Early stopping at epoch 110.
[I 2025-11-04 19:41:59,320] Trial 1139 finished with value: 0.0030114360700262775 and parameters: {'batch_size': 64, 'learning_rate': 0.0012953580053603202, 'nr_hidden_layers': 2, 'nr_neurons': 233, 'dropout_rate': 5.287678338879193e-05, 'weight_decay': 0.0005679606559402486, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 19:42:27,679] Trial 1149 pruned. 
[I 2025-11-04 19:42:47,266] Trial 1151 pruned. 
[I 2025-11-04 19:45:33,229] Trial 1152 pruned. 
[I 2025-11-04 19:45:52,952] Trial 1154 pruned. 
[I 2025-11-04 19:46:00,450] Trial 1155 pruned. 
[I 2025-11-04 19:46:20,431] Trial 1156 pruned. 
[I 2025-11-04 19:46:41,604] Trial 1157 pruned. 
[I 2025-11-04 19:47:01,088] Trial 1159 pruned. 
[I 2025-11-04 19:47:20,636] Trial 1160 pruned. 
[I 2025-11-04 19:47:43,802] Trial 1161 pruned. 
[I 2025-11-04 19:48:01,438] Trial 1162 pruned. 
[I 2025-11-04 19:48:21,029] Trial 1163 pruned. 
[I 2025-11-04 19:48:40,611] Trial 1164 pruned. 
[I 2025-11-04 19:48:49,937] Trial 1165 pruned. 
2025-11-04 19:56:09,885 - INFO - Trial 1166: Early stopping at epoch 249.
[I 2025-11-04 19:56:09,999] Trial 1166 finished with value: 0.0015204331704500144 and parameters: {'batch_size': 64, 'learning_rate': 0.0015470981210942323, 'nr_hidden_layers': 2, 'nr_neurons': 217, 'dropout_rate': 0.00028668109167446804, 'weight_decay': 0.0014841257090078487, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 19:56:29,559] Trial 1175 pruned. 
[I 2025-11-04 19:56:49,165] Trial 1176 pruned. 
[I 2025-11-04 19:57:15,290] Trial 1177 pruned. 
[I 2025-11-04 19:57:35,283] Trial 1179 pruned. 
2025-11-04 20:01:24,283 - INFO - Trial 1180: Early stopping at epoch 129.
[I 2025-11-04 20:01:24,404] Trial 1180 finished with value: 0.0027517227568792384 and parameters: {'batch_size': 64, 'learning_rate': 0.0012237148018508582, 'nr_hidden_layers': 2, 'nr_neurons': 220, 'dropout_rate': 0.0001510875945871797, 'weight_decay': 0.0017666588452494303, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 20:01:31,868] Trial 1184 pruned. 
[I 2025-11-04 20:01:51,368] Trial 1185 pruned. 
[I 2025-11-04 20:02:10,924] Trial 1186 pruned. 
[I 2025-11-04 20:02:32,260] Trial 1187 pruned. 
2025-11-04 20:04:54,785 - INFO - Trial 1188: Early stopping at epoch 80.
[I 2025-11-04 20:04:54,899] Trial 1188 finished with value: 0.005411935459220754 and parameters: {'batch_size': 64, 'learning_rate': 0.001735396372738753, 'nr_hidden_layers': 2, 'nr_neurons': 235, 'dropout_rate': 0.01648496170064494, 'weight_decay': 0.001156264053684973, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 20:05:14,459] Trial 1191 pruned. 
[I 2025-11-04 20:05:34,095] Trial 1192 pruned. 
[I 2025-11-04 20:05:57,345] Trial 1193 pruned. 
[I 2025-11-04 20:06:16,906] Trial 1195 pruned. 
[I 2025-11-04 20:06:23,227] Trial 1198 pruned. 
[I 2025-11-04 20:07:14,481] Trial 1200 pruned. 
[I 2025-11-04 20:07:34,078] Trial 1202 pruned. 
2025-11-04 20:10:05,358 - INFO - Trial 1203: Early stopping at epoch 85.
[I 2025-11-04 20:10:05,504] Trial 1203 finished with value: 0.003299794306335492 and parameters: {'batch_size': 64, 'learning_rate': 0.0016029288591285855, 'nr_hidden_layers': 2, 'nr_neurons': 246, 'dropout_rate': 0.00012660076611909897, 'weight_decay': 0.00040985088812062453, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 20:10:23,002] Trial 1207 pruned. 
2025-11-04 20:14:07,505 - INFO - Trial 1209: Early stopping at epoch 125.
[I 2025-11-04 20:14:07,620] Trial 1209 finished with value: 0.004190838855604804 and parameters: {'batch_size': 64, 'learning_rate': 0.0018377220188890474, 'nr_hidden_layers': 2, 'nr_neurons': 211, 'dropout_rate': 0.009642181682883609, 'weight_decay': 0.0005075079638409393, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 20:14:27,133] Trial 1215 pruned. 
2025-11-04 20:20:33,644 - INFO - Trial 1216: Early stopping at epoch 207.
[I 2025-11-04 20:20:33,764] Trial 1216 finished with value: 0.0016246641120928084 and parameters: {'batch_size': 64, 'learning_rate': 0.0016375938091452507, 'nr_hidden_layers': 2, 'nr_neurons': 192, 'dropout_rate': 5.665442256355467e-05, 'weight_decay': 0.0007544236335096081, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 20:20:40,802] Trial 1228 pruned. 
[I 2025-11-04 20:21:00,306] Trial 1230 pruned. 
2025-11-04 20:23:55,677 - INFO - Trial 1232: Early stopping at epoch 97.
[I 2025-11-04 20:23:55,790] Trial 1232 finished with value: 0.005071554115087298 and parameters: {'batch_size': 64, 'learning_rate': 0.0015813113757502772, 'nr_hidden_layers': 2, 'nr_neurons': 191, 'dropout_rate': 0.008905925347662413, 'weight_decay': 0.0011492448148509166, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 20:24:15,650] Trial 1233 pruned. 
[I 2025-11-04 20:24:37,109] Trial 1235 pruned. 
[I 2025-11-04 20:24:56,719] Trial 1237 pruned. 
[I 2025-11-04 20:25:08,786] Trial 1239 pruned. 
[I 2025-11-04 20:26:00,153] Trial 1240 pruned. 
[I 2025-11-04 20:26:07,379] Trial 1242 pruned. 
[I 2025-11-04 20:26:26,868] Trial 1243 pruned. 
[I 2025-11-04 20:26:46,870] Trial 1244 pruned. 
[I 2025-11-04 20:27:07,939] Trial 1245 pruned. 
[I 2025-11-04 20:27:27,631] Trial 1246 pruned. 
[I 2025-11-04 20:28:18,780] Trial 1247 pruned. 
[I 2025-11-04 20:28:38,409] Trial 1249 pruned. 
[I 2025-11-04 20:28:57,977] Trial 1252 pruned. 
[I 2025-11-04 20:29:17,392] Trial 1254 pruned. 
[I 2025-11-04 20:29:36,871] Trial 1257 pruned. 
[I 2025-11-04 20:29:56,422] Trial 1259 pruned. 
[I 2025-11-04 20:30:15,964] Trial 1261 pruned. 
[I 2025-11-04 20:30:35,539] Trial 1263 pruned. 
[I 2025-11-04 20:30:56,999] Trial 1265 pruned. 
[I 2025-11-04 20:31:04,206] Trial 1267 pruned. 
[I 2025-11-04 20:31:24,142] Trial 1268 pruned. 
[I 2025-11-04 20:31:43,683] Trial 1270 pruned. 
[I 2025-11-04 20:32:03,165] Trial 1272 pruned. 
[I 2025-11-04 20:32:22,572] Trial 1274 pruned. 
[I 2025-11-04 20:32:47,414] Trial 1277 pruned. 
[I 2025-11-04 20:32:56,150] Trial 1279 pruned. 
[I 2025-11-04 20:33:03,145] Trial 1280 pruned. 
[I 2025-11-04 20:33:22,651] Trial 1281 pruned. 
[I 2025-11-04 20:33:28,954] Trial 1283 pruned. 
[I 2025-11-04 20:33:49,088] Trial 1285 pruned. 
[I 2025-11-04 20:34:08,646] Trial 1287 pruned. 
[I 2025-11-04 20:36:15,889] Trial 1289 pruned. 
2025-11-04 20:39:11,502 - INFO - Trial 1292: Early stopping at epoch 99.
[I 2025-11-04 20:39:11,614] Trial 1292 finished with value: 0.005244030213170456 and parameters: {'batch_size': 64, 'learning_rate': 0.0014812992260357413, 'nr_hidden_layers': 2, 'nr_neurons': 187, 'dropout_rate': 0.02362923889136364, 'weight_decay': 0.0002467373470946424, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 20:39:31,265] Trial 1301 pruned. 
[I 2025-11-04 20:39:50,936] Trial 1302 pruned. 
2025-11-04 20:42:25,439 - INFO - Trial 1305: Early stopping at epoch 87.
[I 2025-11-04 20:42:25,553] Trial 1305 finished with value: 0.004596376604819823 and parameters: {'batch_size': 64, 'learning_rate': 0.001632356110371381, 'nr_hidden_layers': 2, 'nr_neurons': 208, 'dropout_rate': 0.009490139034497474, 'weight_decay': 0.0005653299726671616, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 20:42:33,958] Trial 1306 pruned. 
[I 2025-11-04 20:46:09,062] Trial 1307 pruned. 
[I 2025-11-04 20:46:28,565] Trial 1314 pruned. 
[I 2025-11-04 20:46:48,095] Trial 1315 pruned. 
2025-11-04 20:49:36,248 - INFO - Trial 1316: Early stopping at epoch 94.
[I 2025-11-04 20:49:36,364] Trial 1316 finished with value: 0.003028691260132828 and parameters: {'batch_size': 64, 'learning_rate': 0.001900809797093128, 'nr_hidden_layers': 2, 'nr_neurons': 236, 'dropout_rate': 8.47881046781529e-05, 'weight_decay': 0.0007019861230022273, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 20:49:55,958] Trial 1320 pruned. 
[I 2025-11-04 20:50:15,679] Trial 1321 pruned. 
[I 2025-11-04 20:50:29,032] Trial 1322 pruned. 
[I 2025-11-04 20:50:48,687] Trial 1323 pruned. 
[I 2025-11-04 20:51:08,232] Trial 1324 pruned. 
[I 2025-11-04 20:51:15,731] Trial 1326 pruned. 
[I 2025-11-04 20:51:35,730] Trial 1328 pruned. 
[I 2025-11-04 20:51:55,276] Trial 1330 pruned. 
[I 2025-11-04 20:52:04,098] Trial 1332 pruned. 
[I 2025-11-04 20:52:23,469] Trial 1334 pruned. 
[I 2025-11-04 20:53:22,688] Trial 1336 pruned. 
[I 2025-11-04 20:53:28,731] Trial 1339 pruned. 
2025-11-04 20:56:27,129 - INFO - Trial 1340: Early stopping at epoch 89.
[I 2025-11-04 20:56:27,246] Trial 1340 finished with value: 0.004629331206580758 and parameters: {'batch_size': 64, 'learning_rate': 0.0014587727212543307, 'nr_hidden_layers': 3, 'nr_neurons': 256, 'dropout_rate': 0.010224409132465659, 'weight_decay': 0.0005091257110263816, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 20:57:04,434] Trial 1343 pruned. 
2025-11-04 20:59:56,026 - INFO - Trial 1345: Early stopping at epoch 86.
[I 2025-11-04 20:59:56,140] Trial 1345 finished with value: 0.004946289555871097 and parameters: {'batch_size': 64, 'learning_rate': 0.0019123850952101062, 'nr_hidden_layers': 2, 'nr_neurons': 236, 'dropout_rate': 0.009377345166595948, 'weight_decay': 0.0006217229600303353, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 21:00:15,779] Trial 1348 pruned. 
2025-11-04 21:03:04,275 - INFO - Trial 1349: Early stopping at epoch 71.
[I 2025-11-04 21:03:04,389] Trial 1349 finished with value: 0.004441840891895801 and parameters: {'batch_size': 64, 'learning_rate': 0.0012970482892165197, 'nr_hidden_layers': 5, 'nr_neurons': 243, 'dropout_rate': 0.00032010549973382794, 'weight_decay': 0.0012573505009613102, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 21:05:16,703 - INFO - Trial 1353: Early stopping at epoch 74.
[I 2025-11-04 21:05:16,817] Trial 1353 finished with value: 0.005581458762118273 and parameters: {'batch_size': 64, 'learning_rate': 0.001680169534622805, 'nr_hidden_layers': 2, 'nr_neurons': 225, 'dropout_rate': 0.024008431694481077, 'weight_decay': 0.0002926252567643385, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 21:05:38,098] Trial 1357 pruned. 
2025-11-04 21:09:26,422 - INFO - Trial 1358: Early stopping at epoch 129.
[I 2025-11-04 21:09:26,540] Trial 1358 finished with value: 0.0022722166690967785 and parameters: {'batch_size': 64, 'learning_rate': 0.0015649352459614352, 'nr_hidden_layers': 2, 'nr_neurons': 209, 'dropout_rate': 0.0001078248868425877, 'weight_decay': 0.0004159448872693578, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 21:09:48,496] Trial 1362 pruned. 
[I 2025-11-04 21:09:55,619] Trial 1363 pruned. 
[I 2025-11-04 21:10:20,623] Trial 1364 pruned. 
[I 2025-11-04 21:10:26,956] Trial 1365 pruned. 
2025-11-04 21:15:10,054 - INFO - Trial 1366: Early stopping at epoch 160.
[I 2025-11-04 21:15:10,170] Trial 1366 finished with value: 0.0018897082448860307 and parameters: {'batch_size': 64, 'learning_rate': 0.0015272051026377683, 'nr_hidden_layers': 2, 'nr_neurons': 243, 'dropout_rate': 4.541727059613922e-05, 'weight_decay': 0.000500513533407575, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
2025-11-04 21:18:47,792 - INFO - Trial 1375: Early stopping at epoch 118.
[I 2025-11-04 21:18:47,908] Trial 1375 finished with value: 0.00265924922353538 and parameters: {'batch_size': 64, 'learning_rate': 0.0019382257775959761, 'nr_hidden_layers': 2, 'nr_neurons': 255, 'dropout_rate': 0.00022517895835570662, 'weight_decay': 0.0006843160053745139, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 21:19:23,068] Trial 1380 pruned. 
[I 2025-11-04 21:19:42,592] Trial 1381 pruned. 
[I 2025-11-04 21:20:05,165] Trial 1382 pruned. 
[I 2025-11-04 21:23:39,443] Trial 1383 pruned. 
[I 2025-11-04 21:24:16,968] Trial 1385 pruned. 
[I 2025-11-04 21:24:25,765] Trial 1386 pruned. 
[I 2025-11-04 21:24:45,259] Trial 1387 pruned. 
2025-11-04 21:27:37,812 - INFO - Trial 1388: Early stopping at epoch 97.
[I 2025-11-04 21:27:37,957] Trial 1388 finished with value: 0.002651287239095021 and parameters: {'batch_size': 64, 'learning_rate': 0.0018170258001216466, 'nr_hidden_layers': 2, 'nr_neurons': 240, 'dropout_rate': 0.00019413662448090755, 'weight_decay': 0.0002173967046300302, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 21:27:45,015] Trial 1391 pruned. 
2025-11-04 21:29:04,112 - INFO - Trial 1392: Early stopping at epoch 44.
[I 2025-11-04 21:29:04,226] Trial 1392 finished with value: 0.008322838532875567 and parameters: {'batch_size': 64, 'learning_rate': 0.0020389817851063216, 'nr_hidden_layers': 2, 'nr_neurons': 224, 'dropout_rate': 0.017237657315533825, 'weight_decay': 0.0012290083172596155, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 21:29:10,504] Trial 1393 pruned. 
2025-11-04 21:32:16,538 - INFO - Trial 1394: Early stopping at epoch 105.
[I 2025-11-04 21:32:16,665] Trial 1394 finished with value: 0.0028791227020949772 and parameters: {'batch_size': 64, 'learning_rate': 0.0014419786690238142, 'nr_hidden_layers': 2, 'nr_neurons': 228, 'dropout_rate': 4.054003638678306e-05, 'weight_decay': 0.0004029071268298824, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 21:32:37,980] Trial 1401 pruned. 
[I 2025-11-04 21:32:57,601] Trial 1402 pruned. 
2025-11-04 21:35:50,525 - INFO - Trial 1403: Early stopping at epoch 97.
[I 2025-11-04 21:35:50,651] Trial 1403 finished with value: 0.0032803226195783197 and parameters: {'batch_size': 64, 'learning_rate': 0.001376991462663426, 'nr_hidden_layers': 2, 'nr_neurons': 243, 'dropout_rate': 3.964868792884561e-05, 'weight_decay': 0.0004901588162940025, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 21:36:10,296] Trial 1410 pruned. 
[I 2025-11-04 21:36:30,412] Trial 1412 pruned. 
[I 2025-11-04 21:36:39,335] Trial 1413 pruned. 
[I 2025-11-04 21:36:58,988] Trial 1415 pruned. 
[I 2025-11-04 21:37:18,601] Trial 1417 pruned. 
[I 2025-11-04 21:37:38,206] Trial 1419 pruned. 
[I 2025-11-04 21:37:45,085] Trial 1420 pruned. 
[I 2025-11-04 21:38:06,235] Trial 1421 pruned. 
[I 2025-11-04 21:38:12,469] Trial 1422 pruned. 
[I 2025-11-04 21:38:36,605] Trial 1423 pruned. 
[I 2025-11-04 21:38:56,225] Trial 1424 pruned. 
[I 2025-11-04 21:39:40,429] Trial 1426 pruned. 
[I 2025-11-04 21:43:26,974] Trial 1429 pruned. 
2025-11-04 21:45:24,824 - INFO - Trial 1438: Early stopping at epoch 66.
[I 2025-11-04 21:45:25,152] Trial 1438 finished with value: 0.006037909351332825 and parameters: {'batch_size': 64, 'learning_rate': 0.0015142243906712928, 'nr_hidden_layers': 2, 'nr_neurons': 215, 'dropout_rate': 0.023453258753960683, 'weight_decay': 0.0010165167055142723, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 21:45:44,848] Trial 1442 pruned. 
[I 2025-11-04 21:46:04,537] Trial 1443 pruned. 
[I 2025-11-04 21:46:24,173] Trial 1444 pruned. 
2025-11-04 21:49:37,468 - INFO - Trial 1445: Early stopping at epoch 109.
[I 2025-11-04 21:49:37,593] Trial 1445 finished with value: 0.004332842492122679 and parameters: {'batch_size': 64, 'learning_rate': 0.0018607340978354949, 'nr_hidden_layers': 2, 'nr_neurons': 256, 'dropout_rate': 0.009319091907046773, 'weight_decay': 0.00016142115975072095, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 21:49:45,098] Trial 1447 pruned. 
[I 2025-11-04 21:50:10,052] Trial 1448 pruned. 
[I 2025-11-04 21:50:30,206] Trial 1451 pruned. 
[I 2025-11-04 21:50:49,857] Trial 1453 pruned. 
2025-11-04 21:52:44,160 - INFO - Trial 1455: Early stopping at epoch 64.
[I 2025-11-04 21:52:44,278] Trial 1455 finished with value: 0.006432413010996666 and parameters: {'batch_size': 64, 'learning_rate': 0.0017414462900427815, 'nr_hidden_layers': 2, 'nr_neurons': 224, 'dropout_rate': 0.015648264679799826, 'weight_decay': 0.00032193257517520627, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}. Best is trial 333 with value: 0.0009757127058634517.
[I 2025-11-04 21:54:58,579] Trial 1457 pruned. 
[I 2025-11-04 21:55:10,625] Trial 1459 pruned. 
2025-11-04 21:55:10,700 - INFO - Optuna study complete. Best trial: 333
2025-11-04 21:55:10,775 - INFO - Best Loss: 0.0009757127058634517
2025-11-04 21:55:10,799 - INFO - Best Params: {'batch_size': 64, 'learning_rate': 0.001372335074817238, 'nr_hidden_layers': 2, 'nr_neurons': 230, 'dropout_rate': 8.943741579532514e-05, 'weight_decay': 0.00021732207759797098, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}
2025-11-04 21:55:10,799 - INFO - Training final model with best parameters...
2025-11-04 21:55:10,822 - INFO - Starting main training for labels ['Area']...
2025-11-04 21:55:11,971 - INFO - Final training: 47896 train samples, 11975 val samples, 25660 test samples.
2025-11-04 21:55:11,975 - INFO - Using MSELoss
2025-11-04 21:55:11,975 - INFO - Using CosineAnnealingLR with T_max=1000
2025-11-04 21:55:11,982 - INFO - Starting final training loop for max 1000 epochs (Patience=25)...
2025-11-04 21:55:13,671 - INFO - Epoch [1/1000], Train Loss: 0.011331, Val Loss: 0.007501, LR: 0.001372
2025-11-04 21:55:13,673 - INFO - New best model found at epoch 1 with val_loss: 0.007501
2025-11-04 21:55:15,355 - INFO - New best model found at epoch 2 with val_loss: 0.003841
2025-11-04 21:55:18,741 - INFO - New best model found at epoch 4 with val_loss: 0.001327
2025-11-04 21:55:22,126 - INFO - New best model found at epoch 6 with val_loss: 0.000922
2025-11-04 21:55:23,806 - INFO - New best model found at epoch 7 with val_loss: 0.000505
2025-11-04 21:55:27,176 - INFO - New best model found at epoch 9 with val_loss: 0.000213
2025-11-04 21:55:32,262 - INFO - New best model found at epoch 12 with val_loss: 0.000197
2025-11-04 21:55:37,347 - INFO - New best model found at epoch 15 with val_loss: 0.000117
2025-11-04 21:55:40,749 - INFO - New best model found at epoch 17 with val_loss: 0.000092
2025-11-04 21:55:44,138 - INFO - New best model found at epoch 19 with val_loss: 0.000072
2025-11-04 21:55:50,947 - INFO - New best model found at epoch 23 with val_loss: 0.000071
2025-11-04 21:55:52,650 - INFO - New best model found at epoch 24 with val_loss: 0.000055
2025-11-04 21:56:02,885 - INFO - New best model found at epoch 30 with val_loss: 0.000049
2025-11-04 21:56:08,006 - INFO - New best model found at epoch 33 with val_loss: 0.000042
2025-11-04 21:56:13,066 - INFO - New best model found at epoch 36 with val_loss: 0.000032
2025-11-04 21:56:14,756 - INFO - New best model found at epoch 37 with val_loss: 0.000023
2025-11-04 21:56:33,381 - INFO - New best model found at epoch 48 with val_loss: 0.000015
2025-11-04 21:56:36,742 - INFO - Epoch [50/1000], Train Loss: 0.000046, Val Loss: 0.000073, LR: 0.001364
2025-11-04 21:57:12,184 - INFO - New best model found at epoch 71 with val_loss: 0.000009
2025-11-04 21:57:35,775 - INFO - New best model found at epoch 85 with val_loss: 0.000008
2025-11-04 21:58:01,094 - INFO - Epoch [100/1000], Train Loss: 0.000044, Val Loss: 0.000017, LR: 0.001339
2025-11-04 21:58:18,009 - INFO - Early stopping at epoch 110.
2025-11-04 21:58:18,009 - INFO - Training complete. Evaluating on test set...
2025-11-04 21:58:18,347 - INFO - Final Test Loss (MSE): 0.000008
2025-11-04 21:58:18,347 - INFO - Inverting transforms and generating plots...
2025-11-04 21:58:18,348 - INFO - Calculating final metrics...
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [64, 1]                   --
ModuleList: 1-7                        --                        (recursive)
    Linear: 2-1                       [64, 230]                 2,300
    GELU: 2-2                         [64, 230]                 --
Dropout: 1-2                           [64, 230]                 --
ModuleList: 1-7                        --                        (recursive)
    Linear: 2-3                       [64, 230]                 53,130
    GELU: 2-4                         [64, 230]                 --
Dropout: 1-4                           [64, 230]                 --
ModuleList: 1-7                        --                        (recursive)
    Linear: 2-5                       [64, 230]                 53,130
    GELU: 2-6                         [64, 230]                 --
Dropout: 1-6                           [64, 230]                 --
ModuleList: 1-7                        --                        (recursive)
    Linear: 2-7                       [64, 1]                   231
==========================================================================================
Total params: 108,791
Trainable params: 108,791
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 6.96
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.35
Params size (MB): 0.44
Estimated Total Size (MB): 0.79
==========================================================================================
Traceback (most recent call last):
  File "/home/barattts/lavoltabuona/BA/run_optuna.py", line 238, in <module>
    final_model = main_train(
                  ^^^^^^^^^^^
  File "/home/barattts/lavoltabuona/BA/trainer.py", line 202, in main_train
    final_metrics = compute_regression_metrics(inverted_true_values, inverted_predictions)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/barattts/lavoltabuona/BA/utils.py", line 44, in compute_regression_metrics
    metrics["rmse"] = root_mean_squared_error(y_true, y_pred)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/sklearn/utils/_param_validation.py", line 196, in wrapper
    params = func_sig.bind(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/inspect.py", line 3242, in bind
    return self._bind(args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/inspect.py", line 3231, in _bind
    raise TypeError(
TypeError: got an unexpected keyword argument 'squared'
Job finished.

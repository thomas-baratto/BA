Job started on argon-gtx
Job ID: 551
Working directory: /home/barattts/lavoltabuona/BA
---
Starting Python script...
Unable to determine the device handle for GPU0000:61:00.0: Unknown Error
Running: python run_optuna.py --target Iso_width --skip-optuna
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
2025-11-07 18:42:11,260 - INFO - Using device: cuda
2025-11-07 18:42:11,262 - INFO - Target labels for this run: ['Iso_width']
2025-11-07 18:42:11,262 - INFO - Skip Optuna: True
2025-11-07 18:42:11,262 - INFO - Skipping Optuna. Loading best parameters from study: nn_study_Iso_width...
2025-11-07 18:42:12,326 - INFO - Successfully loaded best parameters from trial 1616:
2025-11-07 18:42:12,352 - INFO -   Best value (RMSE): 0.001146
2025-11-07 18:42:19,532 - INFO -   Number of trials completed: 2743
2025-11-07 18:42:19,533 - INFO -   Optimized parameters:
2025-11-07 18:42:19,650 - INFO -     batch_size: 64
2025-11-07 18:42:19,650 - INFO -     learning_rate: 0.003384871040990215
2025-11-07 18:42:19,650 - INFO -     nr_hidden_layers: 1
2025-11-07 18:42:19,650 - INFO -     nr_neurons: 112
2025-11-07 18:42:19,650 - INFO -     dropout_rate: 0.00014697292771531992
2025-11-07 18:42:19,650 - INFO -     weight_decay: 4.3897138187438567e-05
2025-11-07 18:42:19,650 - INFO -     activation_name: GELU
2025-11-07 18:42:19,650 - INFO -     loss_criterion: SmoothL1
2025-11-07 18:42:19,650 - INFO -   Hardcoded parameters:
2025-11-07 18:42:19,650 - INFO -     batch_size: 64
2025-11-07 18:42:19,650 - INFO -     nr_hidden_layers: 1
2025-11-07 18:42:19,650 - INFO -     activation_name: GELU
2025-11-07 18:42:19,650 - INFO -     loss_criterion: SmoothL1
2025-11-07 18:42:19,650 - INFO - Training final model with parameters...
2025-11-07 18:42:19,650 - INFO - Starting main training for labels ['Iso_width']...
2025-11-07 18:42:20,736 - INFO - Final training: 47896 train samples, 11975 val samples, 25660 test samples.
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
2025-11-07 18:42:21,155 - INFO - Using SmoothL1Loss (Huber Loss)
2025-11-07 18:42:23,234 - INFO - Using CosineAnnealingLR with T_max=1000
2025-11-07 18:42:23,234 - INFO - Added warmup for 10 epochs
2025-11-07 18:42:23,292 - INFO - Starting final training loop for max 1000 epochs (Patience=100)...
2025-11-07 18:42:25,209 - INFO - Epoch [1/1000], Train Loss: 0.006617, Val Loss: 0.003218, LR: 0.000643
2025-11-07 18:42:25,211 - INFO - New best model found at epoch 1 with val_loss: 0.003218
2025-11-07 18:42:26,835 - INFO - New best model found at epoch 2 with val_loss: 0.002936
2025-11-07 18:42:28,429 - INFO - New best model found at epoch 3 with val_loss: 0.002057
2025-11-07 18:42:30,023 - INFO - New best model found at epoch 4 with val_loss: 0.001714
2025-11-07 18:42:32,027 - INFO - New best model found at epoch 5 with val_loss: 0.001227
2025-11-07 18:42:33,608 - INFO - New best model found at epoch 6 with val_loss: 0.000870
2025-11-07 18:42:35,196 - INFO - New best model found at epoch 7 with val_loss: 0.000617
2025-11-07 18:42:36,784 - INFO - New best model found at epoch 8 with val_loss: 0.000363
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
2025-11-07 18:42:41,479 - INFO - New best model found at epoch 11 with val_loss: 0.000193
2025-11-07 18:42:49,348 - INFO - New best model found at epoch 16 with val_loss: 0.000108
2025-11-07 18:42:52,515 - INFO - New best model found at epoch 18 with val_loss: 0.000062
2025-11-07 18:42:57,253 - INFO - New best model found at epoch 21 with val_loss: 0.000055
2025-11-07 18:43:00,383 - INFO - New best model found at epoch 23 with val_loss: 0.000038
2025-11-07 18:43:08,163 - INFO - New best model found at epoch 28 with val_loss: 0.000031
2025-11-07 18:43:15,945 - INFO - New best model found at epoch 33 with val_loss: 0.000022
2025-11-07 18:43:37,748 - INFO - New best model found at epoch 47 with val_loss: 0.000021
2025-11-07 18:43:42,414 - INFO - Epoch [50/1000], Train Loss: 0.000039, Val Loss: 0.000064, LR: 0.003372
2025-11-07 18:43:53,310 - INFO - New best model found at epoch 57 with val_loss: 0.000020
2025-11-07 18:44:05,783 - INFO - New best model found at epoch 65 with val_loss: 0.000015
2025-11-07 18:44:07,335 - INFO - New best model found at epoch 66 with val_loss: 0.000014
2025-11-07 18:44:26,008 - INFO - New best model found at epoch 78 with val_loss: 0.000013
2025-11-07 18:44:38,467 - INFO - New best model found at epoch 86 with val_loss: 0.000012
2025-11-07 18:44:46,611 - INFO - New best model found at epoch 90 with val_loss: 0.000010
2025-11-07 18:45:00,608 - INFO - New best model found at epoch 99 with val_loss: 0.000007
2025-11-07 18:45:02,169 - INFO - Epoch [100/1000], Train Loss: 0.000023, Val Loss: 0.000009, LR: 0.003318
2025-11-07 18:45:08,394 - INFO - New best model found at epoch 104 with val_loss: 0.000007
2025-11-07 18:45:39,543 - INFO - New best model found at epoch 124 with val_loss: 0.000006
2025-11-07 18:45:59,759 - INFO - New best model found at epoch 137 with val_loss: 0.000005
2025-11-07 18:46:02,870 - INFO - New best model found at epoch 139 with val_loss: 0.000005
2025-11-07 18:46:18,451 - INFO - New best model found at epoch 149 with val_loss: 0.000003
2025-11-07 18:46:20,020 - INFO - Epoch [150/1000], Train Loss: 0.000017, Val Loss: 0.000012, LR: 0.003224
slurmstepd-argon-gtx: error: *** JOB 551 ON argon-gtx CANCELLED AT 2025-11-07T18:47:25 ***

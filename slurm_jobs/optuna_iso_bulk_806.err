/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
2025-11-21 10:50:45.405784: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
2025-11-21 10:50:46.117214: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
2025-11-21 10:50:48.098166: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
2025-11-21 10:50:50.817370: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
2025-11-21 10:50:51,942 - INFO - Using device: cuda
2025-11-21 10:50:51,945 - INFO - Target labels for this run: ['Area', 'Iso_distance', 'Iso_width']
2025-11-21 10:50:51,947 - INFO - Optuna config -> study: nn_study_isotherm_bulk | storage: sqlite:///runs/optuna_isotherm_bulk.db | trials: 1429 | n_jobs: 4
2025-11-21 10:50:51,947 - INFO - Starting Optuna study: nn_study_isotherm_bulk...
2025-11-21 10:50:51,950 - INFO - Using device: cuda
2025-11-21 10:50:51,953 - INFO - Target labels for this run: ['Area', 'Iso_distance', 'Iso_width']
2025-11-21 10:50:51,954 - INFO - Optuna config -> study: nn_study_isotherm_bulk | storage: sqlite:///runs/optuna_isotherm_bulk.db | trials: 1429 | n_jobs: 4
2025-11-21 10:50:51,954 - INFO - Starting Optuna study: nn_study_isotherm_bulk...
2025-11-21 10:50:52.781621: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[I 2025-11-21 10:50:52,915] Using an existing study with name 'nn_study_isotherm_bulk' instead of creating a new one.
[I 2025-11-21 10:50:52,932] Using an existing study with name 'nn_study_isotherm_bulk' instead of creating a new one.
2025-11-21 10:50:52,957 - INFO - Using device: cuda
2025-11-21 10:50:52,958 - INFO - Target labels for this run: ['Area', 'Iso_distance', 'Iso_width']
2025-11-21 10:50:52,959 - INFO - Optuna config -> study: nn_study_isotherm_bulk | storage: sqlite:///runs/optuna_isotherm_bulk.db | trials: 1429 | n_jobs: 4
2025-11-21 10:50:52,959 - INFO - Starting Optuna study: nn_study_isotherm_bulk...
[I 2025-11-21 10:50:53,755] Using an existing study with name 'nn_study_isotherm_bulk' instead of creating a new one.
2025-11-21 10:50:54.557818: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-21 10:50:55,487 - INFO - Using device: cuda
2025-11-21 10:50:55,489 - INFO - Target labels for this run: ['Area', 'Iso_distance', 'Iso_width']
2025-11-21 10:50:55,489 - INFO - Optuna config -> study: nn_study_isotherm_bulk | storage: sqlite:///runs/optuna_isotherm_bulk.db | trials: 1429 | n_jobs: 4
2025-11-21 10:50:55,489 - INFO - Starting Optuna study: nn_study_isotherm_bulk...
[I 2025-11-21 10:50:56,317] Using an existing study with name 'nn_study_isotherm_bulk' instead of creating a new one.
2025-11-21 10:50:56.674509: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-21 10:50:57,255 - INFO - Using device: cuda
2025-11-21 10:50:57,256 - INFO - Target labels for this run: ['Area', 'Iso_distance', 'Iso_width']
2025-11-21 10:50:57,257 - INFO - Optuna config -> study: nn_study_isotherm_bulk | storage: sqlite:///runs/optuna_isotherm_bulk.db | trials: 1429 | n_jobs: 4
2025-11-21 10:50:57,257 - INFO - Starting Optuna study: nn_study_isotherm_bulk...
[I 2025-11-21 10:50:58,097] Using an existing study with name 'nn_study_isotherm_bulk' instead of creating a new one.
2025-11-21 10:50:59,007 - INFO - Using device: cuda
2025-11-21 10:50:59,008 - INFO - Target labels for this run: ['Area', 'Iso_distance', 'Iso_width']
2025-11-21 10:50:59,009 - INFO - Optuna config -> study: nn_study_isotherm_bulk | storage: sqlite:///runs/optuna_isotherm_bulk.db | trials: 1429 | n_jobs: 4
2025-11-21 10:50:59,009 - INFO - Starting Optuna study: nn_study_isotherm_bulk...
[I 2025-11-21 10:50:59,754] Using an existing study with name 'nn_study_isotherm_bulk' instead of creating a new one.
2025-11-21 10:51:01,073 - INFO - Using device: cuda
2025-11-21 10:51:01,075 - INFO - Target labels for this run: ['Area', 'Iso_distance', 'Iso_width']
2025-11-21 10:51:01,075 - INFO - Optuna config -> study: nn_study_isotherm_bulk | storage: sqlite:///runs/optuna_isotherm_bulk.db | trials: 1429 | n_jobs: 4
2025-11-21 10:51:01,075 - INFO - Starting Optuna study: nn_study_isotherm_bulk...
[I 2025-11-21 10:51:01,836] Using an existing study with name 'nn_study_isotherm_bulk' instead of creating a new one.
[I 2025-11-21 11:01:20,399] Trial 3530 pruned. 
[I 2025-11-21 11:01:25,384] Trial 3514 pruned. 
[I 2025-11-21 11:01:28,165] Trial 3536 pruned. 
[I 2025-11-21 11:01:50,754] Trial 3515 pruned. 
[I 2025-11-21 11:01:50,792] Trial 3519 pruned. 
[I 2025-11-21 11:02:22,829] Trial 3525 pruned. 
[I 2025-11-21 11:02:26,795] Trial 3538 pruned. 
[I 2025-11-21 11:02:53,754] Trial 3533 pruned. 
[I 2025-11-21 11:03:14,406] Trial 3521 pruned. 
[I 2025-11-21 11:03:25,132] Trial 3520 pruned. 
[I 2025-11-21 11:04:06,014] Trial 3524 pruned. 
[I 2025-11-21 11:04:46,003] Trial 3526 pruned. 
[I 2025-11-21 11:05:23,473] Trial 3540 pruned. 
[I 2025-11-21 11:06:30,340] Trial 3534 pruned. 
[I 2025-11-21 11:10:39,926] Trial 3542 pruned. 
[I 2025-11-21 11:12:00,994] Trial 3545 pruned. 
[I 2025-11-21 11:12:48,140] Trial 3546 pruned. 
[I 2025-11-21 11:16:28,364] Trial 3553 pruned. 
[I 2025-11-21 11:16:45,796] Trial 3548 pruned. 
[I 2025-11-21 11:16:58,513] Trial 3522 pruned. 
[I 2025-11-21 11:18:19,038] Trial 3552 pruned. 
[I 2025-11-21 11:18:22,474] Trial 3551 pruned. 
[I 2025-11-21 11:18:36,130] Trial 3550 pruned. 
[I 2025-11-21 11:19:20,438] Trial 3549 pruned. 
[I 2025-11-21 11:19:23,501] Trial 3554 pruned. 
srun: Job step aborted: Waiting up to 122 seconds for job step to finish.
srun: Job step aborted: Waiting up to 122 seconds for job step to finish.
srun: Job step aborted: Waiting up to 122 seconds for job step to finish.
srun: Job step aborted: Waiting up to 122 seconds for job step to finish.
srun: Job step aborted: Waiting up to 122 seconds for job step to finish.
srun: Job step aborted: Waiting up to 122 seconds for job step to finish.
srun: Job step aborted: Waiting up to 122 seconds for job step to finish.
slurmstepd-argon-gtx: error: *** STEP 806.4 ON argon-gtx CANCELLED AT 2025-11-21T11:20:12 ***
slurmstepd-argon-gtx: error: *** STEP 806.6 ON argon-gtx CANCELLED AT 2025-11-21T11:20:12 ***
slurmstepd-argon-gtx: error: *** STEP 806.1 ON argon-gtx CANCELLED AT 2025-11-21T11:20:12 ***
slurmstepd-argon-gtx: error: *** STEP 806.5 ON argon-gtx CANCELLED AT 2025-11-21T11:20:12 ***
slurmstepd-argon-gtx: error: *** STEP 806.0 ON argon-gtx CANCELLED AT 2025-11-21T11:20:12 ***
slurmstepd-argon-gtx: error: *** JOB 806 ON argon-gtx CANCELLED AT 2025-11-21T11:20:12 ***
slurmstepd-argon-gtx: error: *** STEP 806.3 ON argon-gtx CANCELLED AT 2025-11-21T11:20:12 ***
slurmstepd-argon-gtx: error: *** STEP 806.2 ON argon-gtx CANCELLED AT 2025-11-21T11:20:12 ***

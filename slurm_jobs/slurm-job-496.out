Job started on argon-gtx
Job ID: 496
Working directory: /home/barattts/lavoltabuona/BA
---
Starting Python script...
Running: python run_optuna.py --target Iso_distance
2025-11-04 14:41:16,503 - INFO - Using device: cuda
2025-11-04 14:41:16,505 - INFO - Target labels for this run: ['Iso_distance']
2025-11-04 14:41:16,506 - INFO - Loading data for Optuna study (Labels: ['Iso_distance'])...
2025-11-04 14:41:16,677 - INFO - Starting Optuna study: nn_study_['Iso_distance']...
[I 2025-11-04 14:41:17,446] Using an existing study with name 'nn_study_['Iso_distance']' instead of creating a new one.
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
[I 2025-11-04 14:41:43,687] Trial 1000 pruned. 
[I 2025-11-04 14:42:02,206] Trial 1001 pruned. 
[I 2025-11-04 14:42:20,427] Trial 1002 pruned. 
[I 2025-11-04 14:42:39,114] Trial 1003 pruned. 
[I 2025-11-04 14:42:57,742] Trial 1004 pruned. 
[I 2025-11-04 14:43:37,052] Trial 1005 pruned. 
[I 2025-11-04 14:43:55,810] Trial 1006 pruned. 
[I 2025-11-04 14:44:14,375] Trial 1007 pruned. 
[I 2025-11-04 14:44:21,259] Trial 1008 pruned. 
[I 2025-11-04 14:44:39,824] Trial 1009 pruned. 
2025-11-04 14:47:59,516 - INFO - Trial 1010: Early stopping at epoch 113.
[I 2025-11-04 14:47:59,633] Trial 1010 finished with value: 0.0034172292798757553 and parameters: {'batch_size': 64, 'learning_rate': 0.0008648071672126965, 'nr_hidden_layers': 2, 'nr_neurons': 208, 'dropout_rate': 0.0002956572218347919, 'weight_decay': 1.813198322144916e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 14:48:33,314] Trial 1011 pruned. 
[I 2025-11-04 14:48:55,363] Trial 1012 pruned. 
[I 2025-11-04 14:49:14,103] Trial 1013 pruned. 
[I 2025-11-04 14:49:25,660] Trial 1014 pruned. 
[I 2025-11-04 14:49:44,880] Trial 1015 pruned. 
[I 2025-11-04 14:50:03,622] Trial 1016 pruned. 
[I 2025-11-04 14:50:22,437] Trial 1017 pruned. 
[I 2025-11-04 14:50:41,140] Trial 1018 pruned. 
[I 2025-11-04 14:50:47,006] Trial 1019 pruned. 
[I 2025-11-04 14:50:55,401] Trial 1020 pruned. 
[I 2025-11-04 14:51:14,101] Trial 1021 pruned. 
[I 2025-11-04 14:51:33,207] Trial 1022 pruned. 
[I 2025-11-04 14:51:51,906] Trial 1023 pruned. 
[I 2025-11-04 14:51:59,095] Trial 1024 pruned. 
[I 2025-11-04 14:52:17,840] Trial 1025 pruned. 
[I 2025-11-04 14:52:41,888] Trial 1026 pruned. 
[I 2025-11-04 14:53:00,856] Trial 1027 pruned. 
[I 2025-11-04 14:53:19,895] Trial 1028 pruned. 
2025-11-04 14:58:29,222 - INFO - Trial 1029: Early stopping at epoch 179.
[I 2025-11-04 14:58:29,317] Trial 1029 finished with value: 0.002384205348789692 and parameters: {'batch_size': 64, 'learning_rate': 0.0009104096022773421, 'nr_hidden_layers': 2, 'nr_neurons': 165, 'dropout_rate': 5.2848770291778624e-05, 'weight_decay': 0.00015990237131902502, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 14:58:48,000] Trial 1030 pruned. 
[I 2025-11-04 14:59:06,778] Trial 1031 pruned. 
[I 2025-11-04 14:59:25,623] Trial 1032 pruned. 
[I 2025-11-04 15:00:04,671] Trial 1033 pruned. 
[I 2025-11-04 15:00:27,211] Trial 1034 pruned. 
[I 2025-11-04 15:00:46,798] Trial 1035 pruned. 
[I 2025-11-04 15:01:05,589] Trial 1036 pruned. 
[I 2025-11-04 15:01:12,428] Trial 1037 pruned. 
[I 2025-11-04 15:01:31,205] Trial 1038 pruned. 
[I 2025-11-04 15:01:49,950] Trial 1039 pruned. 
2025-11-04 15:04:35,018 - INFO - Trial 1040: Early stopping at epoch 98.
[I 2025-11-04 15:04:35,127] Trial 1040 finished with value: 0.0031892121769487858 and parameters: {'batch_size': 64, 'learning_rate': 0.001217928892959573, 'nr_hidden_layers': 2, 'nr_neurons': 153, 'dropout_rate': 1.9164616066630905e-05, 'weight_decay': 0.0012332632968666466, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 15:04:53,570] Trial 1041 pruned. 
[I 2025-11-04 15:05:06,468] Trial 1042 pruned. 
[I 2025-11-04 15:05:25,204] Trial 1043 pruned. 
[I 2025-11-04 15:05:43,809] Trial 1044 pruned. 
[I 2025-11-04 15:06:02,213] Trial 1045 pruned. 
[I 2025-11-04 15:06:08,148] Trial 1046 pruned. 
[I 2025-11-04 15:06:26,537] Trial 1047 pruned. 
[I 2025-11-04 15:06:34,854] Trial 1048 pruned. 
[I 2025-11-04 15:06:53,989] Trial 1049 pruned. 
[I 2025-11-04 15:07:12,669] Trial 1050 pruned. 
[I 2025-11-04 15:07:31,341] Trial 1051 pruned. 
[I 2025-11-04 15:07:38,640] Trial 1052 pruned. 
[I 2025-11-04 15:07:57,197] Trial 1053 pruned. 
[I 2025-11-04 15:08:15,935] Trial 1054 pruned. 
[I 2025-11-04 15:08:35,077] Trial 1055 pruned. 
[I 2025-11-04 15:08:53,622] Trial 1056 pruned. 
[I 2025-11-04 15:09:12,043] Trial 1057 pruned. 
[I 2025-11-04 15:09:30,710] Trial 1058 pruned. 
[I 2025-11-04 15:10:09,423] Trial 1059 pruned. 
2025-11-04 15:12:22,860 - INFO - Trial 1060: Early stopping at epoch 77.
[I 2025-11-04 15:12:22,955] Trial 1060 finished with value: 0.004000118467956781 and parameters: {'batch_size': 64, 'learning_rate': 0.0014704127879483495, 'nr_hidden_layers': 2, 'nr_neurons': 239, 'dropout_rate': 0.00020872213744775185, 'weight_decay': 1.0569722112730643e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 15:12:44,903] Trial 1061 pruned. 
[I 2025-11-04 15:13:03,749] Trial 1062 pruned. 
[I 2025-11-04 15:14:02,576] Trial 1063 pruned. 
[I 2025-11-04 15:14:21,145] Trial 1064 pruned. 
[I 2025-11-04 15:14:39,935] Trial 1065 pruned. 
[I 2025-11-04 15:14:46,714] Trial 1066 pruned. 
[I 2025-11-04 15:15:05,429] Trial 1067 pruned. 
[I 2025-11-04 15:15:24,033] Trial 1068 pruned. 
[I 2025-11-04 15:15:43,290] Trial 1069 pruned. 
[I 2025-11-04 15:16:02,372] Trial 1070 pruned. 
[I 2025-11-04 15:16:13,814] Trial 1071 pruned. 
2025-11-04 15:19:24,302 - INFO - Trial 1072: Early stopping at epoch 112.
[I 2025-11-04 15:19:24,400] Trial 1072 finished with value: 0.003397236578166485 and parameters: {'batch_size': 64, 'learning_rate': 0.0012229953470606306, 'nr_hidden_layers': 2, 'nr_neurons': 186, 'dropout_rate': 0.0002984000917437572, 'weight_decay': 0.0017566909630151973, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 15:19:43,025] Trial 1073 pruned. 
[I 2025-11-04 15:20:01,567] Trial 1074 pruned. 
[I 2025-11-04 15:20:10,180] Trial 1075 pruned. 
[I 2025-11-04 15:20:15,987] Trial 1076 pruned. 
[I 2025-11-04 15:20:34,638] Trial 1077 pruned. 
[I 2025-11-04 15:20:53,257] Trial 1078 pruned. 
[I 2025-11-04 15:21:11,976] Trial 1079 pruned. 
[I 2025-11-04 15:21:18,954] Trial 1080 pruned. 
[I 2025-11-04 15:21:41,017] Trial 1081 pruned. 
[I 2025-11-04 15:22:00,084] Trial 1082 pruned. 
[I 2025-11-04 15:22:18,673] Trial 1083 pruned. 
[I 2025-11-04 15:22:37,679] Trial 1084 pruned. 
[I 2025-11-04 15:22:56,441] Trial 1085 pruned. 
[I 2025-11-04 15:23:15,253] Trial 1086 pruned. 
[I 2025-11-04 15:23:38,976] Trial 1087 pruned. 
[I 2025-11-04 15:23:57,845] Trial 1088 pruned. 
[I 2025-11-04 15:24:37,570] Trial 1089 pruned. 
[I 2025-11-04 15:24:59,778] Trial 1090 pruned. 
[I 2025-11-04 15:25:06,609] Trial 1091 pruned. 
[I 2025-11-04 15:25:25,204] Trial 1092 pruned. 
[I 2025-11-04 15:25:43,884] Trial 1093 pruned. 
[I 2025-11-04 15:26:02,632] Trial 1094 pruned. 
[I 2025-11-04 15:26:21,353] Trial 1095 pruned. 
[I 2025-11-04 15:26:40,655] Trial 1096 pruned. 
[I 2025-11-04 15:26:52,091] Trial 1097 pruned. 
[I 2025-11-04 15:27:36,986] Trial 1098 pruned. 
[I 2025-11-04 15:27:55,456] Trial 1099 pruned. 
[I 2025-11-04 15:28:14,218] Trial 1100 pruned. 
[I 2025-11-04 15:28:20,161] Trial 1101 pruned. 
[I 2025-11-04 15:28:38,596] Trial 1102 pruned. 
2025-11-04 15:34:02,919 - INFO - Trial 1103: Early stopping at epoch 189.
[I 2025-11-04 15:34:03,018] Trial 1103 finished with value: 0.0026263948529958725 and parameters: {'batch_size': 64, 'learning_rate': 0.0009680355515977312, 'nr_hidden_layers': 2, 'nr_neurons': 207, 'dropout_rate': 0.00012090673264016048, 'weight_decay': 0.001999011490005796, 'activation_name': 'LeakyReLU', 'loss_criterion': 'L1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 15:34:21,880] Trial 1104 pruned. 
[I 2025-11-04 15:34:30,544] Trial 1105 pruned. 
[I 2025-11-04 15:34:54,623] Trial 1106 pruned. 
[I 2025-11-04 15:35:13,438] Trial 1107 pruned. 
[I 2025-11-04 15:35:32,273] Trial 1108 pruned. 
[I 2025-11-04 15:35:39,130] Trial 1109 pruned. 
[I 2025-11-04 15:35:57,834] Trial 1110 pruned. 
[I 2025-11-04 15:36:16,678] Trial 1111 pruned. 
[I 2025-11-04 15:36:35,524] Trial 1112 pruned. 
[I 2025-11-04 15:36:54,383] Trial 1113 pruned. 
[I 2025-11-04 15:37:13,378] Trial 1114 pruned. 
[I 2025-11-04 15:37:32,198] Trial 1115 pruned. 
[I 2025-11-04 15:37:52,866] Trial 1116 pruned. 
[I 2025-11-04 15:38:11,778] Trial 1117 pruned. 
[I 2025-11-04 15:38:30,662] Trial 1118 pruned. 
[I 2025-11-04 15:38:37,512] Trial 1119 pruned. 
[I 2025-11-04 15:38:56,215] Trial 1120 pruned. 
[I 2025-11-04 15:39:15,001] Trial 1121 pruned. 
[I 2025-11-04 15:39:33,957] Trial 1122 pruned. 
[I 2025-11-04 15:39:52,792] Trial 1123 pruned. 
[I 2025-11-04 15:40:16,662] Trial 1124 pruned. 
[I 2025-11-04 15:40:35,575] Trial 1125 pruned. 
[I 2025-11-04 15:40:54,421] Trial 1126 pruned. 
[I 2025-11-04 15:41:05,787] Trial 1127 pruned. 
[I 2025-11-04 15:41:24,821] Trial 1128 pruned. 
[I 2025-11-04 15:41:43,686] Trial 1129 pruned. 
[I 2025-11-04 15:41:49,772] Trial 1130 pruned. 
[I 2025-11-04 15:41:58,713] Trial 1131 pruned. 
[I 2025-11-04 15:42:17,791] Trial 1132 pruned. 
[I 2025-11-04 15:42:40,274] Trial 1133 pruned. 
[I 2025-11-04 15:42:58,859] Trial 1134 pruned. 
[I 2025-11-04 15:43:05,832] Trial 1135 pruned. 
[I 2025-11-04 15:43:24,418] Trial 1136 pruned. 
[I 2025-11-04 15:43:43,065] Trial 1137 pruned. 
[I 2025-11-04 15:44:02,164] Trial 1138 pruned. 
[I 2025-11-04 15:44:20,981] Trial 1139 pruned. 
[I 2025-11-04 15:44:41,541] Trial 1140 pruned. 
[I 2025-11-04 15:45:00,166] Trial 1141 pruned. 
2025-11-04 15:49:45,806 - INFO - Trial 1142: Early stopping at epoch 166.
[I 2025-11-04 15:49:45,905] Trial 1142 finished with value: 0.0028190347366034985 and parameters: {'batch_size': 64, 'learning_rate': 0.0007625335870492084, 'nr_hidden_layers': 2, 'nr_neurons': 256, 'dropout_rate': 0.0001430840950844576, 'weight_decay': 0.001802419302626324, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 15:50:05,084] Trial 1143 pruned. 
[I 2025-11-04 15:50:23,663] Trial 1144 pruned. 
[I 2025-11-04 15:50:42,163] Trial 1145 pruned. 
[I 2025-11-04 15:51:00,620] Trial 1146 pruned. 
[I 2025-11-04 15:51:07,349] Trial 1147 pruned. 
[I 2025-11-04 15:51:27,510] Trial 1148 pruned. 
[I 2025-11-04 15:51:50,035] Trial 1149 pruned. 
[I 2025-11-04 15:52:08,425] Trial 1150 pruned. 
[I 2025-11-04 15:52:36,967] Trial 1151 pruned. 
2025-11-04 15:58:08,179 - INFO - Trial 1152: Early stopping at epoch 196.
[I 2025-11-04 15:58:08,280] Trial 1152 finished with value: 0.0023813422303646803 and parameters: {'batch_size': 64, 'learning_rate': 0.000752254093351115, 'nr_hidden_layers': 2, 'nr_neurons': 201, 'dropout_rate': 0.0001039200234058769, 'weight_decay': 1.772401926128804e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 16:03:29,123 - INFO - Trial 1153: Early stopping at epoch 192.
[I 2025-11-04 16:03:29,223] Trial 1153 finished with value: 0.0026103926356881857 and parameters: {'batch_size': 64, 'learning_rate': 0.0007189086224709387, 'nr_hidden_layers': 2, 'nr_neurons': 202, 'dropout_rate': 0.00020138511381345307, 'weight_decay': 1.8340835976557615e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 16:03:40,857] Trial 1154 pruned. 
[I 2025-11-04 16:03:59,472] Trial 1155 pruned. 
[I 2025-11-04 16:04:18,171] Trial 1156 pruned. 
[I 2025-11-04 16:04:37,572] Trial 1157 pruned. 
[I 2025-11-04 16:04:56,285] Trial 1158 pruned. 
[I 2025-11-04 16:05:02,505] Trial 1159 pruned. 
[I 2025-11-04 16:05:11,459] Trial 1160 pruned. 
[I 2025-11-04 16:05:30,513] Trial 1161 pruned. 
[I 2025-11-04 16:05:49,557] Trial 1162 pruned. 
[I 2025-11-04 16:06:08,203] Trial 1163 pruned. 
[I 2025-11-04 16:06:28,678] Trial 1164 pruned. 
[I 2025-11-04 16:06:35,640] Trial 1165 pruned. 
[I 2025-11-04 16:06:54,488] Trial 1166 pruned. 
[I 2025-11-04 16:07:13,572] Trial 1167 pruned. 
[I 2025-11-04 16:07:32,278] Trial 1168 pruned. 
2025-11-04 16:13:25,424 - INFO - Trial 1169: Early stopping at epoch 207.
[I 2025-11-04 16:13:25,525] Trial 1169 finished with value: 0.0019870337564498186 and parameters: {'batch_size': 64, 'learning_rate': 0.0007961107176570951, 'nr_hidden_layers': 2, 'nr_neurons': 223, 'dropout_rate': 1.8129495034859027e-05, 'weight_decay': 3.653810425540817e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 16:13:44,376] Trial 1170 pruned. 
[I 2025-11-04 16:14:03,039] Trial 1171 pruned. 
[I 2025-11-04 16:14:22,095] Trial 1172 pruned. 
[I 2025-11-04 16:14:40,788] Trial 1173 pruned. 
[I 2025-11-04 16:14:59,678] Trial 1174 pruned. 
[I 2025-11-04 16:15:18,413] Trial 1175 pruned. 
[I 2025-11-04 16:15:36,929] Trial 1176 pruned. 
[I 2025-11-04 16:15:57,547] Trial 1177 pruned. 
[I 2025-11-04 16:16:04,434] Trial 1178 pruned. 
[I 2025-11-04 16:16:23,163] Trial 1179 pruned. 
[I 2025-11-04 16:16:43,862] Trial 1180 pruned. 
[I 2025-11-04 16:17:02,516] Trial 1181 pruned. 
[I 2025-11-04 16:17:14,176] Trial 1182 pruned. 
[I 2025-11-04 16:17:36,678] Trial 1183 pruned. 
[I 2025-11-04 16:17:55,726] Trial 1184 pruned. 
[I 2025-11-04 16:18:14,497] Trial 1185 pruned. 
[I 2025-11-04 16:18:33,352] Trial 1186 pruned. 
[I 2025-11-04 16:18:41,900] Trial 1187 pruned. 
[I 2025-11-04 16:18:47,913] Trial 1188 pruned. 
[I 2025-11-04 16:19:06,882] Trial 1189 pruned. 
[I 2025-11-04 16:19:25,436] Trial 1190 pruned. 
[I 2025-11-04 16:19:43,918] Trial 1191 pruned. 
[I 2025-11-04 16:19:51,053] Trial 1192 pruned. 
[I 2025-11-04 16:20:11,706] Trial 1193 pruned. 
[I 2025-11-04 16:20:30,696] Trial 1194 pruned. 
[I 2025-11-04 16:20:49,953] Trial 1195 pruned. 
[I 2025-11-04 16:21:08,640] Trial 1196 pruned. 
2025-11-04 16:24:29,966 - INFO - Trial 1197: Early stopping at epoch 117.
[I 2025-11-04 16:24:30,108] Trial 1197 finished with value: 0.003297341288998723 and parameters: {'batch_size': 64, 'learning_rate': 0.0008695216705681025, 'nr_hidden_layers': 2, 'nr_neurons': 235, 'dropout_rate': 0.00012043847086644092, 'weight_decay': 5.655932764988754e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 16:24:48,881] Trial 1198 pruned. 
[I 2025-11-04 16:25:07,641] Trial 1199 pruned. 
[I 2025-11-04 16:25:26,446] Trial 1200 pruned. 
[I 2025-11-04 16:25:47,290] Trial 1201 pruned. 
[I 2025-11-04 16:26:06,137] Trial 1202 pruned. 
[I 2025-11-04 16:26:13,043] Trial 1203 pruned. 
[I 2025-11-04 16:26:32,022] Trial 1204 pruned. 
[I 2025-11-04 16:26:50,588] Trial 1205 pruned. 
[I 2025-11-04 16:27:09,847] Trial 1206 pruned. 
[I 2025-11-04 16:27:28,570] Trial 1207 pruned. 
[I 2025-11-04 16:27:49,292] Trial 1208 pruned. 
[I 2025-11-04 16:28:07,996] Trial 1209 pruned. 
[I 2025-11-04 16:28:26,706] Trial 1210 pruned. 
[I 2025-11-04 16:28:45,762] Trial 1211 pruned. 
[I 2025-11-04 16:28:57,265] Trial 1212 pruned. 
[I 2025-11-04 16:29:16,095] Trial 1213 pruned. 
[I 2025-11-04 16:29:34,742] Trial 1214 pruned. 
[I 2025-11-04 16:29:43,307] Trial 1215 pruned. 
[I 2025-11-04 16:29:49,359] Trial 1216 pruned. 
[I 2025-11-04 16:30:13,710] Trial 1217 pruned. 
[I 2025-11-04 16:30:32,406] Trial 1218 pruned. 
[I 2025-11-04 16:30:51,067] Trial 1219 pruned. 
[I 2025-11-04 16:31:11,309] Trial 1220 pruned. 
[I 2025-11-04 16:31:33,193] Trial 1221 pruned. 
[I 2025-11-04 16:31:52,089] Trial 1222 pruned. 
[I 2025-11-04 16:31:59,015] Trial 1223 pruned. 
[I 2025-11-04 16:32:17,619] Trial 1224 pruned. 
[I 2025-11-04 16:32:36,437] Trial 1225 pruned. 
[I 2025-11-04 16:32:56,903] Trial 1226 pruned. 
[I 2025-11-04 16:33:15,659] Trial 1227 pruned. 
[I 2025-11-04 16:33:34,916] Trial 1228 pruned. 
[I 2025-11-04 16:33:53,713] Trial 1229 pruned. 
[I 2025-11-04 16:34:12,726] Trial 1230 pruned. 
[I 2025-11-04 16:34:19,560] Trial 1231 pruned. 
[I 2025-11-04 16:34:38,271] Trial 1232 pruned. 
[I 2025-11-04 16:34:57,370] Trial 1233 pruned. 
[I 2025-11-04 16:35:16,154] Trial 1234 pruned. 
[I 2025-11-04 16:35:34,804] Trial 1235 pruned. 
[I 2025-11-04 16:35:55,510] Trial 1236 pruned. 
[I 2025-11-04 16:36:07,006] Trial 1237 pruned. 
[I 2025-11-04 16:36:26,027] Trial 1238 pruned. 
[I 2025-11-04 16:36:44,571] Trial 1239 pruned. 
[I 2025-11-04 16:37:03,024] Trial 1240 pruned. 
[I 2025-11-04 16:37:08,868] Trial 1241 pruned. 
[I 2025-11-04 16:37:27,283] Trial 1242 pruned. 
[I 2025-11-04 16:37:45,827] Trial 1243 pruned. 
[I 2025-11-04 16:38:04,868] Trial 1244 pruned. 
[I 2025-11-04 16:38:23,572] Trial 1245 pruned. 
[I 2025-11-04 16:38:32,039] Trial 1246 pruned. 
[I 2025-11-04 16:38:54,357] Trial 1247 pruned. 
[I 2025-11-04 16:39:01,578] Trial 1248 pruned. 
[I 2025-11-04 16:39:20,670] Trial 1249 pruned. 
[I 2025-11-04 16:39:39,266] Trial 1250 pruned. 
[I 2025-11-04 16:39:57,944] Trial 1251 pruned. 
[I 2025-11-04 16:40:16,663] Trial 1252 pruned. 
[I 2025-11-04 16:40:35,502] Trial 1253 pruned. 
[I 2025-11-04 16:40:54,195] Trial 1254 pruned. 
[I 2025-11-04 16:41:13,382] Trial 1255 pruned. 
2025-11-04 16:48:24,559 - INFO - Trial 1256: Early stopping at epoch 229.
[I 2025-11-04 16:48:24,664] Trial 1256 finished with value: 0.002075522905215621 and parameters: {'batch_size': 64, 'learning_rate': 0.0008056335078414161, 'nr_hidden_layers': 3, 'nr_neurons': 237, 'dropout_rate': 3.92316572912826e-05, 'weight_decay': 5.456554025343097e-06, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 16:48:52,652] Trial 1257 pruned. 
2025-11-04 16:55:18,790 - INFO - Trial 1258: Early stopping at epoch 197.
[I 2025-11-04 16:55:18,902] Trial 1258 finished with value: 0.002496922854334116 and parameters: {'batch_size': 64, 'learning_rate': 0.0007177445637179842, 'nr_hidden_layers': 3, 'nr_neurons': 247, 'dropout_rate': 0.0004894869626715211, 'weight_decay': 5.36997343900459e-06, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 16:55:39,793] Trial 1259 pruned. 
[I 2025-11-04 16:55:46,947] Trial 1260 pruned. 
2025-11-04 16:58:58,303 - INFO - Trial 1261: Early stopping at epoch 101.
[I 2025-11-04 16:58:58,406] Trial 1261 finished with value: 0.003988214768469334 and parameters: {'batch_size': 64, 'learning_rate': 0.0006917260597964605, 'nr_hidden_layers': 3, 'nr_neurons': 244, 'dropout_rate': 0.00045015553913168606, 'weight_decay': 4.584865621303324e-06, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 16:59:19,677] Trial 1262 pruned. 
[I 2025-11-04 16:59:40,767] Trial 1263 pruned. 
[I 2025-11-04 17:00:01,883] Trial 1264 pruned. 
[I 2025-11-04 17:00:22,734] Trial 1265 pruned. 
[I 2025-11-04 17:00:35,528] Trial 1266 pruned. 
[I 2025-11-04 17:00:56,945] Trial 1267 pruned. 
[I 2025-11-04 17:01:17,760] Trial 1268 pruned. 
[I 2025-11-04 17:01:38,726] Trial 1269 pruned. 
[I 2025-11-04 17:01:45,106] Trial 1270 pruned. 
[I 2025-11-04 17:02:06,042] Trial 1271 pruned. 
[I 2025-11-04 17:02:15,056] Trial 1272 pruned. 
[I 2025-11-04 17:02:36,205] Trial 1273 pruned. 
[I 2025-11-04 17:02:57,026] Trial 1274 pruned. 
2025-11-04 17:07:34,498 - INFO - Trial 1275: Early stopping at epoch 146.
[I 2025-11-04 17:07:34,602] Trial 1275 finished with value: 0.0029200094286352396 and parameters: {'batch_size': 64, 'learning_rate': 0.0008028516169319831, 'nr_hidden_layers': 3, 'nr_neurons': 222, 'dropout_rate': 0.00016608425403688483, 'weight_decay': 3.588660351203491e-06, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 17:07:42,199] Trial 1276 pruned. 
[I 2025-11-04 17:08:03,241] Trial 1277 pruned. 
[I 2025-11-04 17:08:24,705] Trial 1278 pruned. 
[I 2025-11-04 17:08:45,898] Trial 1279 pruned. 
[I 2025-11-04 17:09:07,102] Trial 1280 pruned. 
[I 2025-11-04 17:09:27,924] Trial 1281 pruned. 
[I 2025-11-04 17:09:48,552] Trial 1282 pruned. 
[I 2025-11-04 17:10:10,100] Trial 1283 pruned. 
[I 2025-11-04 17:10:30,411] Trial 1284 pruned. 
[I 2025-11-04 17:10:51,456] Trial 1285 pruned. 
[I 2025-11-04 17:11:12,139] Trial 1286 pruned. 
[I 2025-11-04 17:11:34,220] Trial 1287 pruned. 
[I 2025-11-04 17:11:41,363] Trial 1288 pruned. 
[I 2025-11-04 17:12:04,767] Trial 1289 pruned. 
[I 2025-11-04 17:12:25,352] Trial 1290 pruned. 
[I 2025-11-04 17:12:46,228] Trial 1291 pruned. 
[I 2025-11-04 17:13:07,066] Trial 1292 pruned. 
[I 2025-11-04 17:13:27,684] Trial 1293 pruned. 
[I 2025-11-04 17:13:40,526] Trial 1294 pruned. 
[I 2025-11-04 17:14:05,546] Trial 1295 pruned. 
[I 2025-11-04 17:14:26,169] Trial 1296 pruned. 
[I 2025-11-04 17:14:47,159] Trial 1297 pruned. 
[I 2025-11-04 17:15:07,827] Trial 1298 pruned. 
[I 2025-11-04 17:15:14,192] Trial 1299 pruned. 
[I 2025-11-04 17:15:23,319] Trial 1300 pruned. 
2025-11-04 17:18:59,287 - INFO - Trial 1301: Early stopping at epoch 114.
[I 2025-11-04 17:18:59,392] Trial 1301 finished with value: 0.0028753422666341066 and parameters: {'batch_size': 64, 'learning_rate': 0.0009087673140033784, 'nr_hidden_layers': 3, 'nr_neurons': 218, 'dropout_rate': 2.081088798406826e-06, 'weight_decay': 4.829466747377107e-06, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 17:19:20,523] Trial 1302 pruned. 
[I 2025-11-04 17:19:41,319] Trial 1303 pruned. 
[I 2025-11-04 17:20:02,418] Trial 1304 pruned. 
[I 2025-11-04 17:20:09,661] Trial 1305 pruned. 
[I 2025-11-04 17:20:31,353] Trial 1306 pruned. 
[I 2025-11-04 17:20:52,380] Trial 1307 pruned. 
[I 2025-11-04 17:21:13,199] Trial 1308 pruned. 
[I 2025-11-04 17:21:33,602] Trial 1309 pruned. 
[I 2025-11-04 17:21:54,702] Trial 1310 pruned. 
2025-11-04 17:25:27,943 - INFO - Trial 1311: Early stopping at epoch 113.
[I 2025-11-04 17:25:28,063] Trial 1311 finished with value: 0.003174417419359088 and parameters: {'batch_size': 64, 'learning_rate': 0.0008420424138909879, 'nr_hidden_layers': 3, 'nr_neurons': 212, 'dropout_rate': 1.5312457093167317e-05, 'weight_decay': 0.00024147757834020806, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 17:25:49,276] Trial 1312 pruned. 
2025-11-04 17:30:19,441 - INFO - Trial 1313: Early stopping at epoch 141.
[I 2025-11-04 17:30:19,549] Trial 1313 finished with value: 0.003092534141615033 and parameters: {'batch_size': 64, 'learning_rate': 0.0007036748602092256, 'nr_hidden_layers': 3, 'nr_neurons': 200, 'dropout_rate': 0.0001490211880353053, 'weight_decay': 4.430562289842586e-05, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 17:30:40,731] Trial 1314 pruned. 
[I 2025-11-04 17:30:47,419] Trial 1315 pruned. 
[I 2025-11-04 17:31:09,080] Trial 1316 pruned. 
[I 2025-11-04 17:31:29,949] Trial 1317 pruned. 
[I 2025-11-04 17:31:46,836] Trial 1318 pruned. 
[I 2025-11-04 17:32:05,904] Trial 1319 pruned. 
[I 2025-11-04 17:32:26,967] Trial 1320 pruned. 
[I 2025-11-04 17:32:46,354] Trial 1321 pruned. 
[I 2025-11-04 17:32:58,227] Trial 1322 pruned. 
[I 2025-11-04 17:33:18,791] Trial 1323 pruned. 
[I 2025-11-04 17:33:38,031] Trial 1324 pruned. 
2025-11-04 17:38:07,029 - INFO - Trial 1325: Early stopping at epoch 142.
[I 2025-11-04 17:38:07,141] Trial 1325 finished with value: 0.0027651956770569086 and parameters: {'batch_size': 64, 'learning_rate': 0.000753240891856143, 'nr_hidden_layers': 3, 'nr_neurons': 234, 'dropout_rate': 7.69796625131925e-05, 'weight_decay': 0.00038410141107758725, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 17:38:25,801] Trial 1326 pruned. 
[I 2025-11-04 17:38:45,211] Trial 1327 pruned. 
[I 2025-11-04 17:38:51,798] Trial 1328 pruned. 
[I 2025-11-04 17:39:10,460] Trial 1329 pruned. 
[I 2025-11-04 17:39:19,105] Trial 1330 pruned. 
[I 2025-11-04 17:39:27,520] Trial 1331 pruned. 
[I 2025-11-04 17:39:48,841] Trial 1332 pruned. 
[I 2025-11-04 17:40:07,916] Trial 1333 pruned. 
[I 2025-11-04 17:40:28,520] Trial 1334 pruned. 
[I 2025-11-04 17:40:49,257] Trial 1335 pruned. 
[I 2025-11-04 17:41:07,937] Trial 1336 pruned. 
[I 2025-11-04 17:41:29,917] Trial 1337 pruned. 
[I 2025-11-04 17:41:49,076] Trial 1338 pruned. 
[I 2025-11-04 17:42:08,203] Trial 1339 pruned. 
[I 2025-11-04 17:42:32,508] Trial 1340 pruned. 
[I 2025-11-04 17:42:49,910] Trial 1341 pruned. 
[I 2025-11-04 17:43:08,958] Trial 1342 pruned. 
[I 2025-11-04 17:43:28,313] Trial 1343 pruned. 
[I 2025-11-04 17:43:35,529] Trial 1344 pruned. 
[I 2025-11-04 17:43:54,758] Trial 1345 pruned. 
[I 2025-11-04 17:44:15,719] Trial 1346 pruned. 
[I 2025-11-04 17:44:34,777] Trial 1347 pruned. 
[I 2025-11-04 17:44:53,819] Trial 1348 pruned. 
[I 2025-11-04 17:45:05,852] Trial 1349 pruned. 
[I 2025-11-04 17:45:27,088] Trial 1350 pruned. 
[I 2025-11-04 17:45:56,404] Trial 1351 pruned. 
[I 2025-11-04 17:46:15,487] Trial 1352 pruned. 
[I 2025-11-04 17:46:39,002] Trial 1353 pruned. 
[I 2025-11-04 17:46:45,555] Trial 1354 pruned. 
[I 2025-11-04 17:47:04,545] Trial 1355 pruned. 
2025-11-04 17:52:02,234 - INFO - Trial 1356: Early stopping at epoch 172.
[I 2025-11-04 17:52:02,348] Trial 1356 finished with value: 0.0021469690836966038 and parameters: {'batch_size': 64, 'learning_rate': 0.0009336471315758366, 'nr_hidden_layers': 2, 'nr_neurons': 240, 'dropout_rate': 2.1318041429668928e-05, 'weight_decay': 0.00020756611655140493, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 17:52:21,667] Trial 1357 pruned. 
[I 2025-11-04 17:52:30,416] Trial 1358 pruned. 
[I 2025-11-04 17:52:37,741] Trial 1359 pruned. 
[I 2025-11-04 17:52:57,102] Trial 1360 pruned. 
2025-11-04 17:57:18,725 - INFO - Trial 1361: Early stopping at epoch 130.
[I 2025-11-04 17:57:18,840] Trial 1361 finished with value: 0.002460391027852893 and parameters: {'batch_size': 64, 'learning_rate': 0.000848437770103041, 'nr_hidden_layers': 3, 'nr_neurons': 237, 'dropout_rate': 7.5943939453261035e-06, 'weight_decay': 0.0004010642704993846, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 17:57:40,066] Trial 1362 pruned. 
2025-11-04 18:03:43,442 - INFO - Trial 1363: Early stopping at epoch 191.
[I 2025-11-04 18:03:43,574] Trial 1363 finished with value: 0.002396757248789072 and parameters: {'batch_size': 64, 'learning_rate': 0.0007230986407269817, 'nr_hidden_layers': 3, 'nr_neurons': 240, 'dropout_rate': 7.980741484731201e-05, 'weight_decay': 0.0005724771859235787, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 18:09:19,920 - INFO - Trial 1364: Early stopping at epoch 176.
[I 2025-11-04 18:09:20,029] Trial 1364 finished with value: 0.0026665416080504656 and parameters: {'batch_size': 64, 'learning_rate': 0.0007857306237150595, 'nr_hidden_layers': 3, 'nr_neurons': 256, 'dropout_rate': 0.00022536547776686285, 'weight_decay': 0.0005335713589832746, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 18:09:41,144] Trial 1365 pruned. 
[I 2025-11-04 18:10:02,252] Trial 1366 pruned. 
[I 2025-11-04 18:10:40,486] Trial 1367 pruned. 
[I 2025-11-04 18:11:01,629] Trial 1368 pruned. 
[I 2025-11-04 18:11:22,902] Trial 1369 pruned. 
[I 2025-11-04 18:11:44,051] Trial 1370 pruned. 
[I 2025-11-04 18:11:51,300] Trial 1371 pruned. 
[I 2025-11-04 18:12:12,472] Trial 1372 pruned. 
[I 2025-11-04 18:12:33,527] Trial 1373 pruned. 
[I 2025-11-04 18:12:59,622] Trial 1374 pruned. 
[I 2025-11-04 18:13:20,777] Trial 1375 pruned. 
[I 2025-11-04 18:13:42,184] Trial 1376 pruned. 
[I 2025-11-04 18:13:54,983] Trial 1377 pruned. 
[I 2025-11-04 18:14:16,131] Trial 1378 pruned. 
[I 2025-11-04 18:14:37,268] Trial 1379 pruned. 
[I 2025-11-04 18:14:58,371] Trial 1380 pruned. 
[I 2025-11-04 18:15:19,515] Trial 1381 pruned. 
[I 2025-11-04 18:15:40,986] Trial 1382 pruned. 
[I 2025-11-04 18:16:02,197] Trial 1383 pruned. 
[I 2025-11-04 18:16:08,401] Trial 1384 pruned. 
[I 2025-11-04 18:16:29,365] Trial 1385 pruned. 
[I 2025-11-04 18:16:38,642] Trial 1386 pruned. 
[I 2025-11-04 18:16:59,542] Trial 1387 pruned. 
[I 2025-11-04 18:17:06,738] Trial 1388 pruned. 
[I 2025-11-04 18:17:27,707] Trial 1389 pruned. 
[I 2025-11-04 18:17:48,697] Trial 1390 pruned. 
[I 2025-11-04 18:18:09,891] Trial 1391 pruned. 
[I 2025-11-04 18:18:30,854] Trial 1392 pruned. 
[I 2025-11-04 18:18:52,180] Trial 1393 pruned. 
[I 2025-11-04 18:19:13,031] Trial 1394 pruned. 
[I 2025-11-04 18:19:33,981] Trial 1395 pruned. 
[I 2025-11-04 18:19:55,026] Trial 1396 pruned. 
[I 2025-11-04 18:20:16,191] Trial 1397 pruned. 
[I 2025-11-04 18:20:37,138] Trial 1398 pruned. 
[I 2025-11-04 18:20:44,322] Trial 1399 pruned. 
[I 2025-11-04 18:21:26,247] Trial 1400 pruned. 
[I 2025-11-04 18:21:47,125] Trial 1401 pruned. 
2025-11-04 18:27:15,219 - INFO - Trial 1402: Early stopping at epoch 172.
[I 2025-11-04 18:27:15,327] Trial 1402 finished with value: 0.0025686274748295546 and parameters: {'batch_size': 64, 'learning_rate': 0.0008146168128644887, 'nr_hidden_layers': 3, 'nr_neurons': 239, 'dropout_rate': 9.82851900485504e-05, 'weight_decay': 0.00019068773199117244, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 18:27:47,972] Trial 1403 pruned. 
[I 2025-11-04 18:28:09,138] Trial 1404 pruned. 
[I 2025-11-04 18:28:30,296] Trial 1405 pruned. 
[I 2025-11-04 18:28:43,924] Trial 1406 pruned. 
[I 2025-11-04 18:29:05,151] Trial 1407 pruned. 
2025-11-04 18:33:54,337 - INFO - Trial 1408: Early stopping at epoch 148.
[I 2025-11-04 18:33:54,452] Trial 1408 finished with value: 0.002845332259312272 and parameters: {'batch_size': 64, 'learning_rate': 0.0007305301213316763, 'nr_hidden_layers': 3, 'nr_neurons': 219, 'dropout_rate': 0.00010654173078211032, 'weight_decay': 0.00023625506768483874, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 18:34:15,688] Trial 1409 pruned. 
[I 2025-11-04 18:34:36,760] Trial 1410 pruned. 
[I 2025-11-04 18:34:43,099] Trial 1411 pruned. 
[I 2025-11-04 18:34:52,297] Trial 1412 pruned. 
[I 2025-11-04 18:35:13,542] Trial 1413 pruned. 
[I 2025-11-04 18:35:34,710] Trial 1414 pruned. 
[I 2025-11-04 18:35:55,930] Trial 1415 pruned. 
[I 2025-11-04 18:36:16,951] Trial 1416 pruned. 
[I 2025-11-04 18:36:24,214] Trial 1417 pruned. 
[I 2025-11-04 18:36:45,494] Trial 1418 pruned. 
[I 2025-11-04 18:37:10,374] Trial 1419 pruned. 
[I 2025-11-04 18:37:31,419] Trial 1420 pruned. 
[I 2025-11-04 18:37:52,504] Trial 1421 pruned. 
[I 2025-11-04 18:38:17,305] Trial 1422 pruned. 
[I 2025-11-04 18:38:38,464] Trial 1423 pruned. 
[I 2025-11-04 18:38:59,533] Trial 1424 pruned. 
[I 2025-11-04 18:39:20,207] Trial 1425 pruned. 
[I 2025-11-04 18:39:41,222] Trial 1426 pruned. 
[I 2025-11-04 18:40:01,828] Trial 1427 pruned. 
[I 2025-11-04 18:40:22,787] Trial 1428 pruned. 
[I 2025-11-04 18:40:29,968] Trial 1429 pruned. 
[I 2025-11-04 18:40:51,200] Trial 1430 pruned. 
[I 2025-11-04 18:41:12,213] Trial 1431 pruned. 
[I 2025-11-04 18:41:44,619] Trial 1432 pruned. 
[I 2025-11-04 18:41:57,453] Trial 1433 pruned. 
[I 2025-11-04 18:42:18,194] Trial 1434 pruned. 
[I 2025-11-04 18:42:39,034] Trial 1435 pruned. 
[I 2025-11-04 18:43:00,073] Trial 1436 pruned. 
[I 2025-11-04 18:43:20,999] Trial 1437 pruned. 
[I 2025-11-04 18:43:27,339] Trial 1438 pruned. 
[I 2025-11-04 18:43:48,145] Trial 1439 pruned. 
[I 2025-11-04 18:44:09,034] Trial 1440 pruned. 
2025-11-04 18:48:53,045 - INFO - Trial 1441: Early stopping at epoch 150.
[I 2025-11-04 18:48:53,164] Trial 1441 finished with value: 0.002974968869239092 and parameters: {'batch_size': 64, 'learning_rate': 0.0009361980196129066, 'nr_hidden_layers': 3, 'nr_neurons': 152, 'dropout_rate': 0.00023648909706188868, 'weight_decay': 0.00013429467660803357, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 18:49:02,344] Trial 1442 pruned. 
[I 2025-11-04 18:49:09,603] Trial 1443 pruned. 
2025-11-04 18:52:10,147 - INFO - Trial 1444: Early stopping at epoch 95.
[I 2025-11-04 18:52:10,271] Trial 1444 finished with value: 0.004100048914551735 and parameters: {'batch_size': 64, 'learning_rate': 0.0009929789111679656, 'nr_hidden_layers': 3, 'nr_neurons': 211, 'dropout_rate': 0.0002536241767299548, 'weight_decay': 0.00022186884095784076, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 18:52:31,330] Trial 1445 pruned. 
2025-11-04 18:59:54,878 - INFO - Trial 1446: Early stopping at epoch 234.
[I 2025-11-04 18:59:54,994] Trial 1446 finished with value: 0.0021578832529485226 and parameters: {'batch_size': 64, 'learning_rate': 0.0006256553815765561, 'nr_hidden_layers': 3, 'nr_neurons': 161, 'dropout_rate': 4.4102162312922386e-05, 'weight_decay': 0.00014252010204970808, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 19:00:15,910] Trial 1447 pruned. 
[I 2025-11-04 19:00:36,799] Trial 1448 pruned. 
[I 2025-11-04 19:00:57,603] Trial 1449 pruned. 
[I 2025-11-04 19:01:18,575] Trial 1450 pruned. 
[I 2025-11-04 19:01:39,530] Trial 1451 pruned. 
[I 2025-11-04 19:02:04,141] Trial 1452 pruned. 
[I 2025-11-04 19:02:24,983] Trial 1453 pruned. 
2025-11-04 19:12:00,377 - INFO - Trial 1454: Early stopping at epoch 303.
[I 2025-11-04 19:12:00,488] Trial 1454 finished with value: 0.0016945255920290947 and parameters: {'batch_size': 64, 'learning_rate': 0.0006399584154848915, 'nr_hidden_layers': 3, 'nr_neurons': 166, 'dropout_rate': 6.94345105947627e-06, 'weight_decay': 0.0001297016698940998, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 19:12:21,308] Trial 1455 pruned. 
[I 2025-11-04 19:12:42,201] Trial 1456 pruned. 
[I 2025-11-04 19:12:49,269] Trial 1457 pruned. 
[I 2025-11-04 19:13:10,274] Trial 1458 pruned. 
[I 2025-11-04 19:13:31,080] Trial 1459 pruned. 
2025-11-04 19:16:03,379 - INFO - Trial 1460: Early stopping at epoch 79.
[I 2025-11-04 19:16:03,527] Trial 1460 finished with value: 0.0039750877767801285 and parameters: {'batch_size': 64, 'learning_rate': 0.0006725933177373941, 'nr_hidden_layers': 3, 'nr_neurons': 150, 'dropout_rate': 3.2989683932663153e-06, 'weight_decay': 0.00014733083960069326, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 19:16:24,413] Trial 1461 pruned. 
[I 2025-11-04 19:16:37,120] Trial 1462 pruned. 
[I 2025-11-04 19:16:57,918] Trial 1463 pruned. 
[I 2025-11-04 19:17:18,776] Trial 1464 pruned. 
[I 2025-11-04 19:17:39,630] Trial 1465 pruned. 
[I 2025-11-04 19:17:45,941] Trial 1466 pruned. 
[I 2025-11-04 19:18:06,784] Trial 1467 pruned. 
[I 2025-11-04 19:18:15,934] Trial 1468 pruned. 
[I 2025-11-04 19:18:36,850] Trial 1469 pruned. 
[I 2025-11-04 19:18:57,529] Trial 1470 pruned. 
[I 2025-11-04 19:19:18,352] Trial 1471 pruned. 
[I 2025-11-04 19:19:39,152] Trial 1472 pruned. 
[I 2025-11-04 19:20:00,125] Trial 1473 pruned. 
[I 2025-11-04 19:20:21,156] Trial 1474 pruned. 
[I 2025-11-04 19:20:28,511] Trial 1475 pruned. 
[I 2025-11-04 19:20:49,343] Trial 1476 pruned. 
[I 2025-11-04 19:21:10,062] Trial 1477 pruned. 
[I 2025-11-04 19:21:30,888] Trial 1478 pruned. 
[I 2025-11-04 19:22:03,248] Trial 1479 pruned. 
2025-11-04 19:27:04,075 - INFO - Trial 1480: Early stopping at epoch 159.
[I 2025-11-04 19:27:04,188] Trial 1480 finished with value: 0.002512158825993538 and parameters: {'batch_size': 64, 'learning_rate': 0.0008254831593308096, 'nr_hidden_layers': 3, 'nr_neurons': 174, 'dropout_rate': 7.930009471194731e-05, 'weight_decay': 0.00011117599958675628, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 19:27:25,137] Trial 1481 pruned. 
[I 2025-11-04 19:27:46,077] Trial 1482 pruned. 
[I 2025-11-04 19:28:07,040] Trial 1483 pruned. 
[I 2025-11-04 19:28:56,164] Trial 1484 pruned. 
[I 2025-11-04 19:29:03,413] Trial 1485 pruned. 
[I 2025-11-04 19:29:24,336] Trial 1486 pruned. 
[I 2025-11-04 19:29:45,358] Trial 1487 pruned. 
[I 2025-11-04 19:30:06,344] Trial 1488 pruned. 
[I 2025-11-04 19:30:27,386] Trial 1489 pruned. 
[I 2025-11-04 19:30:48,261] Trial 1490 pruned. 
[I 2025-11-04 19:31:03,379] Trial 1491 pruned. 
[I 2025-11-04 19:31:26,202] Trial 1492 pruned. 
[I 2025-11-04 19:31:47,130] Trial 1493 pruned. 
[I 2025-11-04 19:31:53,449] Trial 1494 pruned. 
[I 2025-11-04 19:32:14,326] Trial 1495 pruned. 
[I 2025-11-04 19:32:35,174] Trial 1496 pruned. 
[I 2025-11-04 19:32:44,341] Trial 1497 pruned. 
[I 2025-11-04 19:33:05,257] Trial 1498 pruned. 
[I 2025-11-04 19:33:26,310] Trial 1499 pruned. 
[I 2025-11-04 19:33:33,763] Trial 1500 pruned. 
[I 2025-11-04 19:33:54,742] Trial 1501 pruned. 
2025-11-04 19:40:42,588 - INFO - Trial 1502: Early stopping at epoch 192.
[I 2025-11-04 19:40:42,701] Trial 1502 finished with value: 0.0021887857001274824 and parameters: {'batch_size': 64, 'learning_rate': 0.0007985234157652456, 'nr_hidden_layers': 4, 'nr_neurons': 170, 'dropout_rate': 3.7767432134852607e-05, 'weight_decay': 0.0005948418226787646, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 19:41:11,456] Trial 1503 pruned. 
[I 2025-11-04 19:41:34,239] Trial 1504 pruned. 
[I 2025-11-04 19:41:57,037] Trial 1505 pruned. 
[I 2025-11-04 19:42:21,472] Trial 1506 pruned. 
[I 2025-11-04 19:42:44,082] Trial 1507 pruned. 
[I 2025-11-04 19:43:06,833] Trial 1508 pruned. 
[I 2025-11-04 19:43:29,650] Trial 1509 pruned. 
[I 2025-11-04 19:43:56,875] Trial 1510 pruned. 
[I 2025-11-04 19:44:04,104] Trial 1511 pruned. 
[I 2025-11-04 19:44:26,773] Trial 1512 pruned. 
[I 2025-11-04 19:44:51,091] Trial 1513 pruned. 
[I 2025-11-04 19:45:15,473] Trial 1514 pruned. 
[I 2025-11-04 19:45:38,129] Trial 1515 pruned. 
[I 2025-11-04 19:46:02,531] Trial 1516 pruned. 
[I 2025-11-04 19:46:25,185] Trial 1517 pruned. 
[I 2025-11-04 19:46:38,757] Trial 1518 pruned. 
2025-11-04 19:50:46,077 - INFO - Trial 1519: Early stopping at epoch 131.
[I 2025-11-04 19:50:46,189] Trial 1519 finished with value: 0.003262870479375124 and parameters: {'batch_size': 64, 'learning_rate': 0.0009152251917419441, 'nr_hidden_layers': 3, 'nr_neurons': 171, 'dropout_rate': 0.00011941162160831164, 'weight_decay': 0.0004803977206055393, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 19:51:10,558] Trial 1520 pruned. 
[I 2025-11-04 19:51:34,715] Trial 1521 pruned. 
[I 2025-11-04 19:51:41,160] Trial 1522 pruned. 
[I 2025-11-04 19:52:03,775] Trial 1523 pruned. 
[I 2025-11-04 19:52:26,483] Trial 1524 pruned. 
[I 2025-11-04 19:52:47,495] Trial 1525 pruned. 
[I 2025-11-04 19:52:56,634] Trial 1526 pruned. 
[I 2025-11-04 19:53:17,576] Trial 1527 pruned. 
[I 2025-11-04 19:53:38,417] Trial 1528 pruned. 
[I 2025-11-04 19:54:01,226] Trial 1529 pruned. 
[I 2025-11-04 19:54:22,114] Trial 1530 pruned. 
[I 2025-11-04 19:54:29,347] Trial 1531 pruned. 
[I 2025-11-04 19:54:50,172] Trial 1532 pruned. 
[I 2025-11-04 19:55:10,999] Trial 1533 pruned. 
[I 2025-11-04 19:55:33,550] Trial 1534 pruned. 
[I 2025-11-04 19:55:58,326] Trial 1535 pruned. 
[I 2025-11-04 19:56:19,028] Trial 1536 pruned. 
[I 2025-11-04 19:56:36,070] Trial 1537 pruned. 
[I 2025-11-04 19:56:56,925] Trial 1538 pruned. 
[I 2025-11-04 19:57:04,109] Trial 1539 pruned. 
[I 2025-11-04 19:57:24,996] Trial 1540 pruned. 
[I 2025-11-04 19:57:45,858] Trial 1541 pruned. 
[I 2025-11-04 19:58:06,767] Trial 1542 pruned. 
[I 2025-11-04 19:58:27,630] Trial 1543 pruned. 
[I 2025-11-04 19:58:50,361] Trial 1544 pruned. 
[I 2025-11-04 19:59:03,069] Trial 1545 pruned. 
[I 2025-11-04 19:59:23,984] Trial 1546 pruned. 
[I 2025-11-04 19:59:44,852] Trial 1547 pruned. 
[I 2025-11-04 20:00:05,701] Trial 1548 pruned. 
[I 2025-11-04 20:00:11,846] Trial 1549 pruned. 
[I 2025-11-04 20:00:32,689] Trial 1550 pruned. 
[I 2025-11-04 20:00:41,902] Trial 1551 pruned. 
[I 2025-11-04 20:01:02,624] Trial 1552 pruned. 
[I 2025-11-04 20:01:27,313] Trial 1553 pruned. 
[I 2025-11-04 20:01:48,223] Trial 1554 pruned. 
[I 2025-11-04 20:02:09,040] Trial 1555 pruned. 
[I 2025-11-04 20:02:16,083] Trial 1556 pruned. 
[I 2025-11-04 20:02:36,865] Trial 1557 pruned. 
[I 2025-11-04 20:02:58,372] Trial 1558 pruned. 
[I 2025-11-04 20:03:19,295] Trial 1559 pruned. 
[I 2025-11-04 20:03:40,122] Trial 1560 pruned. 
[I 2025-11-04 20:04:00,815] Trial 1561 pruned. 
[I 2025-11-04 20:04:23,583] Trial 1562 pruned. 
[I 2025-11-04 20:04:44,487] Trial 1563 pruned. 
[I 2025-11-04 20:05:05,406] Trial 1564 pruned. 
[I 2025-11-04 20:05:26,124] Trial 1565 pruned. 
[I 2025-11-04 20:05:47,012] Trial 1566 pruned. 
[I 2025-11-04 20:05:54,226] Trial 1567 pruned. 
[I 2025-11-04 20:06:41,444] Trial 1568 pruned. 
[I 2025-11-04 20:06:58,428] Trial 1569 pruned. 
[I 2025-11-04 20:07:19,393] Trial 1570 pruned. 
[I 2025-11-04 20:07:48,294] Trial 1571 pruned. 
[I 2025-11-04 20:08:09,090] Trial 1572 pruned. 
[I 2025-11-04 20:08:21,748] Trial 1573 pruned. 
[I 2025-11-04 20:08:42,352] Trial 1574 pruned. 
[I 2025-11-04 20:09:03,216] Trial 1575 pruned. 
[I 2025-11-04 20:09:23,850] Trial 1576 pruned. 
[I 2025-11-04 20:09:44,712] Trial 1577 pruned. 
[I 2025-11-04 20:09:53,908] Trial 1578 pruned. 
[I 2025-11-04 20:10:00,134] Trial 1579 pruned. 
[I 2025-11-04 20:10:20,930] Trial 1580 pruned. 
[I 2025-11-04 20:10:41,833] Trial 1581 pruned. 
[I 2025-11-04 20:11:02,789] Trial 1582 pruned. 
[I 2025-11-04 20:11:10,161] Trial 1583 pruned. 
[I 2025-11-04 20:11:30,784] Trial 1584 pruned. 
[I 2025-11-04 20:11:51,663] Trial 1585 pruned. 
[I 2025-11-04 20:12:12,384] Trial 1586 pruned. 
[I 2025-11-04 20:12:34,676] Trial 1587 pruned. 
[I 2025-11-04 20:13:06,289] Trial 1588 pruned. 
[I 2025-11-04 20:13:26,977] Trial 1589 pruned. 
[I 2025-11-04 20:13:47,939] Trial 1590 pruned. 
[I 2025-11-04 20:14:08,572] Trial 1591 pruned. 
[I 2025-11-04 20:14:29,483] Trial 1592 pruned. 
[I 2025-11-04 20:14:50,341] Trial 1593 pruned. 
[I 2025-11-04 20:14:57,904] Trial 1594 pruned. 
[I 2025-11-04 20:15:18,836] Trial 1595 pruned. 
[I 2025-11-04 20:15:39,800] Trial 1596 pruned. 
[I 2025-11-04 20:16:00,751] Trial 1597 pruned. 
[I 2025-11-04 20:16:21,690] Trial 1598 pruned. 
2025-11-04 20:20:45,410 - INFO - Trial 1599: Early stopping at epoch 139.
[I 2025-11-04 20:20:45,528] Trial 1599 finished with value: 0.003228383371606469 and parameters: {'batch_size': 64, 'learning_rate': 0.0008278217982637824, 'nr_hidden_layers': 3, 'nr_neurons': 209, 'dropout_rate': 0.00040184451036472633, 'weight_decay': 0.00015933359271499595, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 20:20:59,971] Trial 1600 pruned. 
[I 2025-11-04 20:21:20,871] Trial 1601 pruned. 
[I 2025-11-04 20:21:43,611] Trial 1602 pruned. 
[I 2025-11-04 20:22:04,386] Trial 1603 pruned. 
[I 2025-11-04 20:22:10,475] Trial 1604 pruned. 
[I 2025-11-04 20:22:31,277] Trial 1605 pruned. 
[I 2025-11-04 20:22:40,375] Trial 1606 pruned. 
[I 2025-11-04 20:23:01,112] Trial 1607 pruned. 
[I 2025-11-04 20:23:21,900] Trial 1608 pruned. 
[I 2025-11-04 20:23:42,791] Trial 1609 pruned. 
[I 2025-11-04 20:23:50,196] Trial 1610 pruned. 
[I 2025-11-04 20:24:11,165] Trial 1611 pruned. 
[I 2025-11-04 20:24:32,322] Trial 1612 pruned. 
[I 2025-11-04 20:24:55,146] Trial 1613 pruned. 
[I 2025-11-04 20:25:12,291] Trial 1614 pruned. 
2025-11-04 20:28:59,554 - INFO - Trial 1615: Early stopping at epoch 120.
[I 2025-11-04 20:28:59,671] Trial 1615 finished with value: 0.003324550576508045 and parameters: {'batch_size': 64, 'learning_rate': 0.00093742339157285, 'nr_hidden_layers': 3, 'nr_neurons': 155, 'dropout_rate': 6.582962255289458e-05, 'weight_decay': 0.00015891299595308963, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 20:29:20,484] Trial 1616 pruned. 
[I 2025-11-04 20:29:41,757] Trial 1617 pruned. 
[I 2025-11-04 20:30:02,646] Trial 1618 pruned. 
2025-11-04 20:35:33,608 - INFO - Trial 1619: Early stopping at epoch 174.
[I 2025-11-04 20:35:33,724] Trial 1619 finished with value: 0.0024955528788268566 and parameters: {'batch_size': 64, 'learning_rate': 0.0010295926369428175, 'nr_hidden_layers': 3, 'nr_neurons': 218, 'dropout_rate': 0.00011137159090469418, 'weight_decay': 0.004040402204498747, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 20:35:58,145] Trial 1620 pruned. 
2025-11-04 20:38:54,535 - INFO - Trial 1621: Early stopping at epoch 85.
[I 2025-11-04 20:38:54,651] Trial 1621 finished with value: 0.0038129196036607027 and parameters: {'batch_size': 64, 'learning_rate': 0.0011300469687377673, 'nr_hidden_layers': 4, 'nr_neurons': 213, 'dropout_rate': 0.00013342728002103846, 'weight_decay': 0.00380029800360632, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 20:39:01,850] Trial 1622 pruned. 
[I 2025-11-04 20:39:22,764] Trial 1623 pruned. 
[I 2025-11-04 20:39:43,428] Trial 1624 pruned. 
[I 2025-11-04 20:40:04,256] Trial 1625 pruned. 
[I 2025-11-04 20:40:25,342] Trial 1626 pruned. 
[I 2025-11-04 20:40:46,383] Trial 1627 pruned. 
[I 2025-11-04 20:40:59,163] Trial 1628 pruned. 
[I 2025-11-04 20:41:20,288] Trial 1629 pruned. 
2025-11-04 20:46:27,938 - INFO - Trial 1630: Early stopping at epoch 163.
[I 2025-11-04 20:46:28,055] Trial 1630 finished with value: 0.002674940275028348 and parameters: {'batch_size': 64, 'learning_rate': 0.0012546634929261427, 'nr_hidden_layers': 3, 'nr_neurons': 201, 'dropout_rate': 0.0001523315085127961, 'weight_decay': 0.00018291229675250793, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 20:47:11,469] Trial 1631 pruned. 
[I 2025-11-04 20:47:17,703] Trial 1632 pruned. 
[I 2025-11-04 20:47:38,640] Trial 1633 pruned. 
[I 2025-11-04 20:47:47,398] Trial 1634 pruned. 
[I 2025-11-04 20:48:08,205] Trial 1635 pruned. 
[I 2025-11-04 20:48:27,073] Trial 1636 pruned. 
[I 2025-11-04 20:48:46,288] Trial 1637 pruned. 
[I 2025-11-04 20:49:07,421] Trial 1638 pruned. 
[I 2025-11-04 20:49:26,429] Trial 1639 pruned. 
[I 2025-11-04 20:49:33,637] Trial 1640 pruned. 
[I 2025-11-04 20:49:52,415] Trial 1641 pruned. 
[I 2025-11-04 20:50:12,951] Trial 1642 pruned. 
[I 2025-11-04 20:50:30,042] Trial 1643 pruned. 
2025-11-04 20:55:46,366 - INFO - Trial 1644: Early stopping at epoch 165.
[I 2025-11-04 20:55:46,485] Trial 1644 finished with value: 0.0026087898295372725 and parameters: {'batch_size': 64, 'learning_rate': 0.001007673089800215, 'nr_hidden_layers': 3, 'nr_neurons': 256, 'dropout_rate': 9.573401731257766e-05, 'weight_decay': 0.0003947416215485137, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 20:56:05,818] Trial 1645 pruned. 
[I 2025-11-04 20:56:28,586] Trial 1646 pruned. 
[I 2025-11-04 20:56:49,603] Trial 1647 pruned. 
[I 2025-11-04 20:57:08,596] Trial 1648 pruned. 
[I 2025-11-04 20:57:15,572] Trial 1649 pruned. 
[I 2025-11-04 20:57:41,924] Trial 1650 pruned. 
[I 2025-11-04 20:58:01,254] Trial 1651 pruned. 
[I 2025-11-04 20:58:20,175] Trial 1652 pruned. 
[I 2025-11-04 20:58:41,339] Trial 1653 pruned. 
[I 2025-11-04 20:59:00,525] Trial 1654 pruned. 
[I 2025-11-04 20:59:13,236] Trial 1655 pruned. 
2025-11-04 21:07:55,740 - INFO - Trial 1656: Early stopping at epoch 237.
[I 2025-11-04 21:07:55,857] Trial 1656 finished with value: 0.002339228056371212 and parameters: {'batch_size': 64, 'learning_rate': 0.001341571450731059, 'nr_hidden_layers': 5, 'nr_neurons': 206, 'dropout_rate': 0.0001606857896736294, 'weight_decay': 0.00022485365916158413, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 21:08:16,668] Trial 1657 pruned. 
[I 2025-11-04 21:08:41,129] Trial 1658 pruned. 
[I 2025-11-04 21:09:05,432] Trial 1659 pruned. 
[I 2025-11-04 21:09:29,832] Trial 1660 pruned. 
[I 2025-11-04 21:09:52,581] Trial 1661 pruned. 
[I 2025-11-04 21:09:58,955] Trial 1662 pruned. 
[I 2025-11-04 21:10:08,243] Trial 1663 pruned. 
2025-11-04 21:13:30,401 - INFO - Trial 1664: Early stopping at epoch 91.
[I 2025-11-04 21:13:30,517] Trial 1664 finished with value: 0.004429379478096962 and parameters: {'batch_size': 64, 'learning_rate': 0.0014507272326117447, 'nr_hidden_layers': 5, 'nr_neurons': 200, 'dropout_rate': 0.00030604515850770735, 'weight_decay': 0.00026969378860762993, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 21:13:53,270] Trial 1665 pruned. 
[I 2025-11-04 21:14:17,637] Trial 1666 pruned. 
[I 2025-11-04 21:14:25,180] Trial 1667 pruned. 
[I 2025-11-04 21:14:49,491] Trial 1668 pruned. 
[I 2025-11-04 21:15:13,856] Trial 1669 pruned. 
[I 2025-11-04 21:15:36,640] Trial 1670 pruned. 
[I 2025-11-04 21:16:01,153] Trial 1671 pruned. 
2025-11-04 21:23:41,903 - INFO - Trial 1672: Early stopping at epoch 208.
[I 2025-11-04 21:23:42,019] Trial 1672 finished with value: 0.00218207947909832 and parameters: {'batch_size': 64, 'learning_rate': 0.0014645921702673256, 'nr_hidden_layers': 5, 'nr_neurons': 221, 'dropout_rate': 0.00010072185715528409, 'weight_decay': 0.00025116882405621245, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 21:24:06,396] Trial 1673 pruned. 
[I 2025-11-04 21:24:39,770] Trial 1674 pruned. 
2025-11-04 21:27:13,162 - INFO - Trial 1675: Early stopping at epoch 69.
[I 2025-11-04 21:27:13,300] Trial 1675 finished with value: 0.005571107845753431 and parameters: {'batch_size': 64, 'learning_rate': 0.0018144613693033133, 'nr_hidden_layers': 5, 'nr_neurons': 235, 'dropout_rate': 0.00021637923528567386, 'weight_decay': 0.0003355796327954578, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 21:27:37,785] Trial 1676 pruned. 
[I 2025-11-04 21:28:11,261] Trial 1677 pruned. 
[I 2025-11-04 21:28:18,908] Trial 1678 pruned. 
[I 2025-11-04 21:28:56,642] Trial 1679 pruned. 
[I 2025-11-04 21:29:25,719] Trial 1680 pruned. 
2025-11-04 21:33:20,346 - INFO - Trial 1681: Early stopping at epoch 106.
[I 2025-11-04 21:33:20,463] Trial 1681 finished with value: 0.003584889229387045 and parameters: {'batch_size': 64, 'learning_rate': 0.0013139515465599295, 'nr_hidden_layers': 5, 'nr_neurons': 210, 'dropout_rate': 3.3930293457452276e-05, 'weight_decay': 0.00023663599679070617, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 21:33:43,297] Trial 1682 pruned. 
[I 2025-11-04 21:34:16,349] Trial 1683 pruned. 
[I 2025-11-04 21:34:30,761] Trial 1684 pruned. 
[I 2025-11-04 21:34:55,407] Trial 1685 pruned. 
[I 2025-11-04 21:35:24,601] Trial 1686 pruned. 
2025-11-04 21:40:49,832 - INFO - Trial 1687: Early stopping at epoch 146.
[I 2025-11-04 21:40:49,957] Trial 1687 finished with value: 0.0029411267023533583 and parameters: {'batch_size': 64, 'learning_rate': 0.001550330586498411, 'nr_hidden_layers': 5, 'nr_neurons': 216, 'dropout_rate': 0.00021214882781668245, 'weight_decay': 0.00022027754581976637, 'activation_name': 'ReLU', 'loss_criterion': 'MSE'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 21:41:19,524] Trial 1688 pruned. 
[I 2025-11-04 21:41:29,530] Trial 1689 pruned. 
[I 2025-11-04 21:41:36,035] Trial 1690 pruned. 
[I 2025-11-04 21:42:04,808] Trial 1691 pruned. 
[I 2025-11-04 21:42:29,253] Trial 1692 pruned. 
2025-11-04 21:45:15,361 - INFO - Trial 1693: Early stopping at epoch 74.
[I 2025-11-04 21:45:15,478] Trial 1693 finished with value: 0.0041150255128741264 and parameters: {'batch_size': 64, 'learning_rate': 0.0014788014242072894, 'nr_hidden_layers': 5, 'nr_neurons': 232, 'dropout_rate': 0.00014341973032049312, 'weight_decay': 2.7340901098598695e-06, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 21:45:39,946] Trial 1694 pruned. 
[I 2025-11-04 21:45:47,530] Trial 1695 pruned. 
[I 2025-11-04 21:46:38,057] Trial 1696 pruned. 
[I 2025-11-04 21:47:02,606] Trial 1697 pruned. 
[I 2025-11-04 21:47:21,613] Trial 1698 pruned. 
[I 2025-11-04 21:47:45,972] Trial 1699 pruned. 
2025-11-04 21:51:49,683 - INFO - Trial 1700: Early stopping at epoch 141.
[I 2025-11-04 21:51:49,818] Trial 1700 finished with value: 0.00299827684648335 and parameters: {'batch_size': 64, 'learning_rate': 0.0015227213531367827, 'nr_hidden_layers': 2, 'nr_neurons': 225, 'dropout_rate': 5.029904671638995e-05, 'weight_decay': 0.00018428418319997684, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 21:56:41,394 - INFO - Trial 1701: Early stopping at epoch 131.
[I 2025-11-04 21:56:41,523] Trial 1701 finished with value: 0.0030722860246896744 and parameters: {'batch_size': 64, 'learning_rate': 0.0012129387928047797, 'nr_hidden_layers': 5, 'nr_neurons': 242, 'dropout_rate': 9.198404157653351e-05, 'weight_decay': 0.00022876132525008862, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 21:57:05,876] Trial 1702 pruned. 
2025-11-04 22:02:17,979 - INFO - Trial 1703: Early stopping at epoch 142.
[I 2025-11-04 22:02:18,097] Trial 1703 finished with value: 0.002682619960978627 and parameters: {'batch_size': 64, 'learning_rate': 0.0014384529205417817, 'nr_hidden_layers': 5, 'nr_neurons': 215, 'dropout_rate': 2.7448361892239488e-05, 'weight_decay': 3.275355619043967e-06, 'activation_name': 'LeakyReLU', 'loss_criterion': 'MSE'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 22:02:42,632] Trial 1704 pruned. 
[I 2025-11-04 22:03:07,174] Trial 1705 pruned. 
[I 2025-11-04 22:03:14,603] Trial 1706 pruned. 
[I 2025-11-04 22:03:33,405] Trial 1707 pruned. 
[I 2025-11-04 22:03:57,780] Trial 1708 pruned. 
[I 2025-11-04 22:04:22,504] Trial 1709 pruned. 
2025-11-04 22:06:52,588 - INFO - Trial 1710: Early stopping at epoch 68.
[I 2025-11-04 22:06:52,708] Trial 1710 finished with value: 0.004222564399242401 and parameters: {'batch_size': 64, 'learning_rate': 0.0016546977462651186, 'nr_hidden_layers': 5, 'nr_neurons': 207, 'dropout_rate': 4.619095589857068e-05, 'weight_decay': 0.00018270950687117112, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 22:07:06,220] Trial 1711 pruned. 
[I 2025-11-04 22:07:30,866] Trial 1712 pruned. 
[I 2025-11-04 22:07:54,977] Trial 1713 pruned. 
[I 2025-11-04 22:08:19,320] Trial 1714 pruned. 
[I 2025-11-04 22:08:41,782] Trial 1715 pruned. 
[I 2025-11-04 22:08:48,086] Trial 1716 pruned. 
[I 2025-11-04 22:09:12,264] Trial 1717 pruned. 
[I 2025-11-04 22:09:36,366] Trial 1718 pruned. 
[I 2025-11-04 22:09:45,835] Trial 1719 pruned. 
2025-11-04 22:17:10,176 - INFO - Trial 1720: Early stopping at epoch 205.
[I 2025-11-04 22:17:10,295] Trial 1720 finished with value: 0.002599402330815792 and parameters: {'batch_size': 64, 'learning_rate': 0.0011383057395518636, 'nr_hidden_layers': 5, 'nr_neurons': 215, 'dropout_rate': 0.00012433257913845028, 'weight_decay': 1.7336301248588415e-06, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 22:17:34,461] Trial 1721 pruned. 
[I 2025-11-04 22:17:56,661] Trial 1722 pruned. 
[I 2025-11-04 22:18:03,980] Trial 1723 pruned. 
[I 2025-11-04 22:18:27,811] Trial 1724 pruned. 
[I 2025-11-04 22:18:50,089] Trial 1725 pruned. 
[I 2025-11-04 22:19:14,140] Trial 1726 pruned. 
[I 2025-11-04 22:19:38,657] Trial 1727 pruned. 
[I 2025-11-04 22:20:02,566] Trial 1728 pruned. 
[I 2025-11-04 22:20:25,097] Trial 1729 pruned. 
[I 2025-11-04 22:20:53,203] Trial 1730 pruned. 
[I 2025-11-04 22:21:09,854] Trial 1731 pruned. 
[I 2025-11-04 22:21:32,230] Trial 1732 pruned. 
[I 2025-11-04 22:21:39,072] Trial 1733 pruned. 
2025-11-04 22:23:50,129 - INFO - Trial 1734: Early stopping at epoch 77.
[I 2025-11-04 22:23:50,254] Trial 1734 finished with value: 0.004327154252678156 and parameters: {'batch_size': 64, 'learning_rate': 0.0011189745455771757, 'nr_hidden_layers': 2, 'nr_neurons': 209, 'dropout_rate': 0.000183976357231099, 'weight_decay': 0.0002410742521812891, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 22:24:08,946] Trial 1735 pruned. 
[I 2025-11-04 22:24:27,488] Trial 1736 pruned. 
[I 2025-11-04 22:24:51,732] Trial 1737 pruned. 
[I 2025-11-04 22:25:10,225] Trial 1738 pruned. 
[I 2025-11-04 22:25:28,852] Trial 1739 pruned. 
[I 2025-11-04 22:25:40,336] Trial 1740 pruned. 
[I 2025-11-04 22:26:02,553] Trial 1741 pruned. 
[I 2025-11-04 22:26:31,639] Trial 1742 pruned. 
[I 2025-11-04 22:26:37,719] Trial 1743 pruned. 
[I 2025-11-04 22:26:58,375] Trial 1744 pruned. 
[I 2025-11-04 22:27:06,873] Trial 1745 pruned. 
[I 2025-11-04 22:27:25,352] Trial 1746 pruned. 
[I 2025-11-04 22:27:43,896] Trial 1747 pruned. 
[I 2025-11-04 22:28:04,217] Trial 1748 pruned. 
[I 2025-11-04 22:28:11,259] Trial 1749 pruned. 
2025-11-04 22:32:51,717 - INFO - Trial 1750: Early stopping at epoch 129.
[I 2025-11-04 22:32:51,838] Trial 1750 finished with value: 0.0033160748425871134 and parameters: {'batch_size': 64, 'learning_rate': 0.0014677736891382967, 'nr_hidden_layers': 5, 'nr_neurons': 215, 'dropout_rate': 0.00010064241278949843, 'weight_decay': 0.00028383351716464536, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 22:33:12,763] Trial 1751 pruned. 
[I 2025-11-04 22:33:29,378] Trial 1752 pruned. 
[I 2025-11-04 22:33:47,882] Trial 1753 pruned. 
[I 2025-11-04 22:34:08,115] Trial 1754 pruned. 
[I 2025-11-04 22:34:28,484] Trial 1755 pruned. 
[I 2025-11-04 22:34:46,859] Trial 1756 pruned. 
[I 2025-11-04 22:35:05,497] Trial 1757 pruned. 
[I 2025-11-04 22:35:26,288] Trial 1758 pruned. 
[I 2025-11-04 22:35:44,779] Trial 1759 pruned. 
[I 2025-11-04 22:36:05,224] Trial 1760 pruned. 
[I 2025-11-04 22:36:12,470] Trial 1761 pruned. 
[I 2025-11-04 22:36:36,635] Trial 1762 pruned. 
[I 2025-11-04 22:36:55,110] Trial 1763 pruned. 
2025-11-04 22:43:58,799 - INFO - Trial 1764: Early stopping at epoch 251.
[I 2025-11-04 22:43:58,921] Trial 1764 finished with value: 0.0020498689264059067 and parameters: {'batch_size': 64, 'learning_rate': 0.0007661271079224311, 'nr_hidden_layers': 2, 'nr_neurons': 221, 'dropout_rate': 0.00017901263059271207, 'weight_decay': 0.0002457775751971751, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 22:44:17,666] Trial 1765 pruned. 
[I 2025-11-04 22:44:36,467] Trial 1766 pruned. 
[I 2025-11-04 22:44:48,063] Trial 1767 pruned. 
[I 2025-11-04 22:45:06,893] Trial 1768 pruned. 
[I 2025-11-04 22:45:25,649] Trial 1769 pruned. 
[I 2025-11-04 22:45:44,442] Trial 1770 pruned. 
[I 2025-11-04 22:46:03,083] Trial 1771 pruned. 
[I 2025-11-04 22:46:09,101] Trial 1772 pruned. 
[I 2025-11-04 22:46:28,067] Trial 1773 pruned. 
[I 2025-11-04 22:46:46,756] Trial 1774 pruned. 
[I 2025-11-04 22:46:55,169] Trial 1775 pruned. 
[I 2025-11-04 22:47:13,943] Trial 1776 pruned. 
[I 2025-11-04 22:47:32,528] Trial 1777 pruned. 
[I 2025-11-04 22:47:51,317] Trial 1778 pruned. 
2025-11-04 22:52:56,941 - INFO - Trial 1779: Early stopping at epoch 181.
[I 2025-11-04 22:52:57,062] Trial 1779 finished with value: 0.0025396712590008974 and parameters: {'batch_size': 64, 'learning_rate': 0.0008010540016401923, 'nr_hidden_layers': 2, 'nr_neurons': 204, 'dropout_rate': 0.00018349775609708804, 'weight_decay': 0.00048027711422094605, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 22:53:04,383] Trial 1780 pruned. 
[I 2025-11-04 22:53:23,100] Trial 1781 pruned. 
[I 2025-11-04 22:53:41,802] Trial 1782 pruned. 
[I 2025-11-04 22:54:00,739] Trial 1783 pruned. 
2025-11-04 22:57:55,369 - INFO - Trial 1784: Early stopping at epoch 139.
[I 2025-11-04 22:57:55,489] Trial 1784 finished with value: 0.0027710157446563244 and parameters: {'batch_size': 64, 'learning_rate': 0.0012024306681876929, 'nr_hidden_layers': 2, 'nr_neurons': 230, 'dropout_rate': 3.219844960547337e-05, 'weight_decay': 0.0005542364544892765, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 22:58:14,195] Trial 1785 pruned. 
[I 2025-11-04 22:58:32,774] Trial 1786 pruned. 
[I 2025-11-04 22:58:51,623] Trial 1787 pruned. 
[I 2025-11-04 22:59:11,860] Trial 1788 pruned. 
[I 2025-11-04 22:59:18,700] Trial 1789 pruned. 
[I 2025-11-04 22:59:37,387] Trial 1790 pruned. 
2025-11-04 23:03:07,832 - INFO - Trial 1791: Early stopping at epoch 123.
[I 2025-11-04 23:03:07,952] Trial 1791 finished with value: 0.002887429902330041 and parameters: {'batch_size': 64, 'learning_rate': 0.0011326496437739106, 'nr_hidden_layers': 2, 'nr_neurons': 245, 'dropout_rate': 0.0002229697256429348, 'weight_decay': 0.00026370615967631183, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 23:03:26,827] Trial 1792 pruned. 
[I 2025-11-04 23:03:45,794] Trial 1793 pruned. 
[I 2025-11-04 23:04:06,700] Trial 1794 pruned. 
[I 2025-11-04 23:04:18,239] Trial 1795 pruned. 
[I 2025-11-04 23:04:36,841] Trial 1796 pruned. 
[I 2025-11-04 23:04:55,558] Trial 1797 pruned. 
[I 2025-11-04 23:05:18,299] Trial 1798 pruned. 
[I 2025-11-04 23:05:37,321] Trial 1799 pruned. 
[I 2025-11-04 23:06:21,256] Trial 1800 pruned. 
[I 2025-11-04 23:06:27,382] Trial 1801 pruned. 
[I 2025-11-04 23:06:46,105] Trial 1802 pruned. 
[I 2025-11-04 23:07:04,973] Trial 1803 pruned. 
[I 2025-11-04 23:07:13,606] Trial 1804 pruned. 
[I 2025-11-04 23:07:20,683] Trial 1805 pruned. 
[I 2025-11-04 23:07:43,200] Trial 1806 pruned. 
[I 2025-11-04 23:08:01,783] Trial 1807 pruned. 
[I 2025-11-04 23:08:26,204] Trial 1808 pruned. 
[I 2025-11-04 23:08:43,137] Trial 1809 pruned. 
2025-11-04 23:13:03,338 - INFO - Trial 1810: Early stopping at epoch 155.
[I 2025-11-04 23:13:03,461] Trial 1810 finished with value: 0.0035731790121644735 and parameters: {'batch_size': 64, 'learning_rate': 0.0017634201924100234, 'nr_hidden_layers': 2, 'nr_neurons': 96, 'dropout_rate': 0.0003366487207500077, 'weight_decay': 0.00019943215420289856, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 23:13:25,556] Trial 1811 pruned. 
2025-11-04 23:19:09,908 - INFO - Trial 1812: Early stopping at epoch 202.
[I 2025-11-04 23:19:10,030] Trial 1812 finished with value: 0.0025653019547462463 and parameters: {'batch_size': 64, 'learning_rate': 0.0009251430242852512, 'nr_hidden_layers': 2, 'nr_neurons': 256, 'dropout_rate': 0.0003327086172713814, 'weight_decay': 0.0002275846468684716, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 23:19:28,634] Trial 1813 pruned. 
[I 2025-11-04 23:19:51,882] Trial 1814 pruned. 
[I 2025-11-04 23:20:15,780] Trial 1815 pruned. 
[I 2025-11-04 23:20:22,719] Trial 1816 pruned. 
[I 2025-11-04 23:20:41,238] Trial 1817 pruned. 
[I 2025-11-04 23:21:09,997] Trial 1818 pruned. 
[I 2025-11-04 23:21:28,880] Trial 1819 pruned. 
[I 2025-11-04 23:21:50,738] Trial 1820 pruned. 
[I 2025-11-04 23:22:09,699] Trial 1821 pruned. 
[I 2025-11-04 23:22:23,928] Trial 1822 pruned. 
[I 2025-11-04 23:22:42,640] Trial 1823 pruned. 
[I 2025-11-04 23:23:05,218] Trial 1824 pruned. 
[I 2025-11-04 23:24:10,925] Trial 1825 pruned. 
[I 2025-11-04 23:24:29,548] Trial 1826 pruned. 
[I 2025-11-04 23:24:35,478] Trial 1827 pruned. 
[I 2025-11-04 23:24:53,918] Trial 1828 pruned. 
[I 2025-11-04 23:25:02,402] Trial 1829 pruned. 
[I 2025-11-04 23:25:26,311] Trial 1830 pruned. 
[I 2025-11-04 23:25:46,595] Trial 1831 pruned. 
[I 2025-11-04 23:26:05,464] Trial 1832 pruned. 
[I 2025-11-04 23:26:12,454] Trial 1833 pruned. 
[I 2025-11-04 23:26:31,325] Trial 1834 pruned. 
[I 2025-11-04 23:26:49,978] Trial 1835 pruned. 
[I 2025-11-04 23:27:08,586] Trial 1836 pruned. 
[I 2025-11-04 23:27:30,836] Trial 1837 pruned. 
[I 2025-11-04 23:27:49,823] Trial 1838 pruned. 
[I 2025-11-04 23:28:08,367] Trial 1839 pruned. 
[I 2025-11-04 23:28:27,458] Trial 1840 pruned. 
[I 2025-11-04 23:28:55,830] Trial 1841 pruned. 
[I 2025-11-04 23:29:14,755] Trial 1842 pruned. 
2025-11-04 23:32:40,251 - INFO - Trial 1843: Early stopping at epoch 119.
[I 2025-11-04 23:32:40,487] Trial 1843 finished with value: 0.002823679242283106 and parameters: {'batch_size': 64, 'learning_rate': 0.0009834080316264383, 'nr_hidden_layers': 2, 'nr_neurons': 223, 'dropout_rate': 0.00010951600766892383, 'weight_decay': 0.0002244677733062076, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
2025-11-04 23:37:18,025 - INFO - Trial 1844: Early stopping at epoch 182.
[I 2025-11-04 23:37:18,164] Trial 1844 finished with value: 0.0025400405284017324 and parameters: {'batch_size': 64, 'learning_rate': 0.0006882579899265191, 'nr_hidden_layers': 1, 'nr_neurons': 234, 'dropout_rate': 9.992941010587279e-05, 'weight_decay': 0.00035970693187271794, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 23:37:36,567] Trial 1845 pruned. 
[I 2025-11-04 23:37:55,267] Trial 1846 pruned. 
[I 2025-11-04 23:38:14,229] Trial 1847 pruned. 
[I 2025-11-04 23:38:21,732] Trial 1848 pruned. 
[I 2025-11-04 23:38:40,501] Trial 1849 pruned. 
[I 2025-11-04 23:39:02,539] Trial 1850 pruned. 
[I 2025-11-04 23:39:14,039] Trial 1851 pruned. 
[I 2025-11-04 23:39:32,722] Trial 1852 pruned. 
2025-11-04 23:44:05,152 - INFO - Trial 1853: Early stopping at epoch 160.
[I 2025-11-04 23:44:05,275] Trial 1853 finished with value: 0.002435356844216585 and parameters: {'batch_size': 64, 'learning_rate': 0.001328464893684689, 'nr_hidden_layers': 2, 'nr_neurons': 240, 'dropout_rate': 3.58335009531032e-05, 'weight_decay': 1.173844806952728e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 23:44:40,438] Trial 1854 pruned. 
[I 2025-11-04 23:44:48,943] Trial 1855 pruned. 
[I 2025-11-04 23:45:07,388] Trial 1856 pruned. 
[I 2025-11-04 23:45:13,433] Trial 1857 pruned. 
[I 2025-11-04 23:45:32,047] Trial 1858 pruned. 
[I 2025-11-04 23:45:50,602] Trial 1859 pruned. 
[I 2025-11-04 23:46:27,942] Trial 1860 pruned. 
[I 2025-11-04 23:46:46,642] Trial 1861 pruned. 
[I 2025-11-04 23:46:53,811] Trial 1862 pruned. 
[I 2025-11-04 23:47:12,547] Trial 1863 pruned. 
[I 2025-11-04 23:47:31,118] Trial 1864 pruned. 
[I 2025-11-04 23:47:53,253] Trial 1865 pruned. 
[I 2025-11-04 23:48:12,118] Trial 1866 pruned. 
2025-11-04 23:52:07,947 - INFO - Trial 1867: Early stopping at epoch 139.
[I 2025-11-04 23:52:08,069] Trial 1867 finished with value: 0.0032867903355509043 and parameters: {'batch_size': 64, 'learning_rate': 0.0013006143643539876, 'nr_hidden_layers': 2, 'nr_neurons': 177, 'dropout_rate': 0.00024811912016918167, 'weight_decay': 1.6081766114551932e-05, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-04 23:53:30,507] Trial 1868 pruned. 
[I 2025-11-04 23:53:49,153] Trial 1869 pruned. 
[I 2025-11-04 23:54:07,692] Trial 1870 pruned. 
[I 2025-11-04 23:54:14,506] Trial 1871 pruned. 
[I 2025-11-04 23:54:33,392] Trial 1872 pruned. 
[I 2025-11-04 23:54:51,872] Trial 1873 pruned. 
[I 2025-11-04 23:55:10,628] Trial 1874 pruned. 
[I 2025-11-04 23:55:29,205] Trial 1875 pruned. 
[I 2025-11-04 23:55:48,038] Trial 1876 pruned. 
[I 2025-11-04 23:55:59,450] Trial 1877 pruned. 
[I 2025-11-04 23:56:21,713] Trial 1878 pruned. 
[I 2025-11-04 23:56:45,335] Trial 1879 pruned. 
[I 2025-11-04 23:57:03,854] Trial 1880 pruned. 
[I 2025-11-04 23:57:22,352] Trial 1881 pruned. 
[I 2025-11-04 23:57:28,413] Trial 1882 pruned. 
[I 2025-11-04 23:57:49,946] Trial 1883 pruned. 
[I 2025-11-04 23:58:08,476] Trial 1884 pruned. 
[I 2025-11-04 23:58:26,997] Trial 1885 pruned. 
[I 2025-11-04 23:58:35,451] Trial 1886 pruned. 
[I 2025-11-04 23:58:54,005] Trial 1887 pruned. 
[I 2025-11-04 23:59:01,032] Trial 1888 pruned. 
[I 2025-11-04 23:59:19,359] Trial 1889 pruned. 
2025-11-05 00:02:49,965 - INFO - Trial 1890: Early stopping at epoch 121.
[I 2025-11-05 00:02:50,089] Trial 1890 finished with value: 0.0035704050678759813 and parameters: {'batch_size': 64, 'learning_rate': 0.001146772811932128, 'nr_hidden_layers': 2, 'nr_neurons': 244, 'dropout_rate': 0.00033486941436676866, 'weight_decay': 0.00020968350902955424, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-05 00:03:08,511] Trial 1891 pruned. 
[I 2025-11-05 00:03:32,397] Trial 1892 pruned. 
[I 2025-11-05 00:03:50,681] Trial 1893 pruned. 
[I 2025-11-05 00:04:09,317] Trial 1894 pruned. 
[I 2025-11-05 00:04:27,871] Trial 1895 pruned. 
[I 2025-11-05 00:04:46,394] Trial 1896 pruned. 
[I 2025-11-05 00:05:04,828] Trial 1897 pruned. 
[I 2025-11-05 00:05:23,384] Trial 1898 pruned. 
[I 2025-11-05 00:05:30,134] Trial 1899 pruned. 
[I 2025-11-05 00:05:48,633] Trial 1900 pruned. 
[I 2025-11-05 00:06:12,608] Trial 1901 pruned. 
[I 2025-11-05 00:06:30,945] Trial 1902 pruned. 
2025-11-05 00:09:32,963 - INFO - Trial 1903: Early stopping at epoch 109.
[I 2025-11-05 00:09:33,112] Trial 1903 finished with value: 0.0032748994417488575 and parameters: {'batch_size': 64, 'learning_rate': 0.0014853268594364351, 'nr_hidden_layers': 2, 'nr_neurons': 214, 'dropout_rate': 0.00013618499779462592, 'weight_decay': 0.00040711763547852833, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-05 00:09:51,595] Trial 1904 pruned. 
[I 2025-11-05 00:10:10,268] Trial 1905 pruned. 
[I 2025-11-05 00:10:21,821] Trial 1906 pruned. 
[I 2025-11-05 00:10:44,297] Trial 1907 pruned. 
[I 2025-11-05 00:11:08,079] Trial 1908 pruned. 
[I 2025-11-05 00:11:14,050] Trial 1909 pruned. 
2025-11-05 00:16:35,868 - INFO - Trial 1910: Early stopping at epoch 159.
[I 2025-11-05 00:16:35,994] Trial 1910 finished with value: 0.0029949273448437452 and parameters: {'batch_size': 64, 'learning_rate': 0.0015565876372363517, 'nr_hidden_layers': 4, 'nr_neurons': 256, 'dropout_rate': 0.00010628011709426456, 'weight_decay': 0.00012253340567727934, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-05 00:16:54,681] Trial 1911 pruned. 
[I 2025-11-05 00:17:03,045] Trial 1912 pruned. 
[I 2025-11-05 00:17:26,330] Trial 1913 pruned. 
2025-11-05 00:20:07,615 - INFO - Trial 1914: Early stopping at epoch 96.
[I 2025-11-05 00:20:07,741] Trial 1914 finished with value: 0.0034587422851473093 and parameters: {'batch_size': 64, 'learning_rate': 0.0013913083546347503, 'nr_hidden_layers': 2, 'nr_neurons': 223, 'dropout_rate': 8.222966028009995e-05, 'weight_decay': 0.00022127828422564076, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-05 00:20:27,707] Trial 1915 pruned. 
[I 2025-11-05 00:20:34,698] Trial 1916 pruned. 
[I 2025-11-05 00:20:53,149] Trial 1917 pruned. 
[I 2025-11-05 00:21:31,427] Trial 1918 pruned. 
[I 2025-11-05 00:21:55,637] Trial 1919 pruned. 
[I 2025-11-05 00:22:14,235] Trial 1920 pruned. 
[I 2025-11-05 00:22:32,693] Trial 1921 pruned. 
[I 2025-11-05 00:22:49,356] Trial 1922 pruned. 
[I 2025-11-05 00:23:11,750] Trial 1923 pruned. 
[I 2025-11-05 00:23:30,404] Trial 1924 pruned. 
[I 2025-11-05 00:23:48,979] Trial 1925 pruned. 
[I 2025-11-05 00:24:07,478] Trial 1926 pruned. 
[I 2025-11-05 00:24:14,274] Trial 1927 pruned. 
[I 2025-11-05 00:24:38,293] Trial 1928 pruned. 
[I 2025-11-05 00:24:57,061] Trial 1929 pruned. 
[I 2025-11-05 00:25:15,898] Trial 1930 pruned. 
[I 2025-11-05 00:25:34,338] Trial 1931 pruned. 
[I 2025-11-05 00:25:45,753] Trial 1932 pruned. 
[I 2025-11-05 00:26:04,175] Trial 1933 pruned. 
2025-11-05 00:29:58,854 - INFO - Trial 1934: Early stopping at epoch 141.
[I 2025-11-05 00:29:58,977] Trial 1934 finished with value: 0.003198868129402399 and parameters: {'batch_size': 64, 'learning_rate': 0.0015747154318663235, 'nr_hidden_layers': 2, 'nr_neurons': 210, 'dropout_rate': 0.00019599555554387357, 'weight_decay': 0.00021383399942165052, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-05 00:30:20,975] Trial 1935 pruned. 
[I 2025-11-05 00:30:39,255] Trial 1936 pruned. 
[I 2025-11-05 00:30:45,251] Trial 1937 pruned. 
[I 2025-11-05 00:40:17,637] Trial 1938 pruned. 
[I 2025-11-05 00:40:36,118] Trial 1939 pruned. 
[I 2025-11-05 00:40:54,610] Trial 1940 pruned. 
[I 2025-11-05 00:41:03,052] Trial 1941 pruned. 
[I 2025-11-05 00:41:21,732] Trial 1942 pruned. 
[I 2025-11-05 00:41:40,340] Trial 1943 pruned. 
[I 2025-11-05 00:41:47,253] Trial 1944 pruned. 
[I 2025-11-05 00:42:03,802] Trial 1945 pruned. 
[I 2025-11-05 00:42:27,638] Trial 1946 pruned. 
[I 2025-11-05 00:42:46,257] Trial 1947 pruned. 
[I 2025-11-05 00:43:04,627] Trial 1948 pruned. 
[I 2025-11-05 00:43:23,072] Trial 1949 pruned. 
[I 2025-11-05 00:43:51,447] Trial 1950 pruned. 
[I 2025-11-05 00:44:10,240] Trial 1951 pruned. 
[I 2025-11-05 00:44:32,427] Trial 1952 pruned. 
[I 2025-11-05 00:44:50,907] Trial 1953 pruned. 
2025-11-05 00:50:00,128 - INFO - Trial 1954: Early stopping at epoch 143.
[I 2025-11-05 00:50:00,254] Trial 1954 finished with value: 0.002464319346472621 and parameters: {'batch_size': 64, 'learning_rate': 0.0009949720246647913, 'nr_hidden_layers': 5, 'nr_neurons': 206, 'dropout_rate': 2.7459495426436803e-05, 'weight_decay': 8.51113145028515e-06, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-05 00:50:07,655] Trial 1955 pruned. 
[I 2025-11-05 00:50:31,414] Trial 1956 pruned. 
[I 2025-11-05 00:50:55,216] Trial 1957 pruned. 
[I 2025-11-05 00:51:18,924] Trial 1958 pruned. 
[I 2025-11-05 00:51:42,719] Trial 1959 pruned. 
[I 2025-11-05 00:52:19,384] Trial 1960 pruned. 
[I 2025-11-05 00:52:43,418] Trial 1961 pruned. 
[I 2025-11-05 00:53:07,406] Trial 1962 pruned. 
[I 2025-11-05 00:53:21,428] Trial 1963 pruned. 
[I 2025-11-05 00:53:45,207] Trial 1964 pruned. 
[I 2025-11-05 00:53:51,488] Trial 1965 pruned. 
[I 2025-11-05 00:54:15,286] Trial 1966 pruned. 
[I 2025-11-05 00:54:24,936] Trial 1967 pruned. 
[I 2025-11-05 00:54:48,742] Trial 1968 pruned. 
[I 2025-11-05 00:55:12,543] Trial 1969 pruned. 
[I 2025-11-05 00:55:36,396] Trial 1970 pruned. 
[I 2025-11-05 00:55:43,437] Trial 1971 pruned. 
[I 2025-11-05 00:56:07,181] Trial 1972 pruned. 
[I 2025-11-05 00:56:30,643] Trial 1973 pruned. 
2025-11-05 01:03:05,345 - INFO - Trial 1974: Early stopping at epoch 183.
[I 2025-11-05 01:03:05,473] Trial 1974 finished with value: 0.0022709176409989595 and parameters: {'batch_size': 64, 'learning_rate': 0.0009263113445959622, 'nr_hidden_layers': 5, 'nr_neurons': 146, 'dropout_rate': 8.386451586857695e-06, 'weight_decay': 9.644642627775945e-06, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-05 01:04:01,507] Trial 1975 pruned. 
[I 2025-11-05 01:05:00,456] Trial 1976 pruned. 
[I 2025-11-05 01:05:24,442] Trial 1977 pruned. 
[I 2025-11-05 01:05:48,343] Trial 1978 pruned. 
[I 2025-11-05 01:06:12,585] Trial 1979 pruned. 
[I 2025-11-05 01:06:36,536] Trial 1980 pruned. 
[I 2025-11-05 01:07:00,532] Trial 1981 pruned. 
[I 2025-11-05 01:07:07,971] Trial 1982 pruned. 
[I 2025-11-05 01:07:31,544] Trial 1983 pruned. 
[I 2025-11-05 01:07:55,617] Trial 1984 pruned. 
[I 2025-11-05 01:08:19,515] Trial 1985 pruned. 
2025-11-05 01:12:26,126 - INFO - Trial 1986: Early stopping at epoch 113.
[I 2025-11-05 01:12:26,253] Trial 1986 finished with value: 0.003245624713599682 and parameters: {'batch_size': 64, 'learning_rate': 0.0009821583818028507, 'nr_hidden_layers': 5, 'nr_neurons': 227, 'dropout_rate': 0.0002312594611581734, 'weight_decay': 8.949509714208924e-06, 'activation_name': 'ReLU', 'loss_criterion': 'SmoothL1'}. Best is trial 124 with value: 0.0014025710088954345.
[I 2025-11-05 01:12:50,384] Trial 1987 pruned. 
[I 2025-11-05 01:13:14,159] Trial 1988 pruned. 
[I 2025-11-05 01:13:28,184] Trial 1989 pruned. 
[I 2025-11-05 01:13:52,013] Trial 1990 pruned. 
[I 2025-11-05 01:14:15,751] Trial 1991 pruned. 
[I 2025-11-05 01:14:39,584] Trial 1992 pruned. 
[I 2025-11-05 01:15:03,483] Trial 1993 pruned. 
[I 2025-11-05 01:15:09,811] Trial 1994 pruned. 
[I 2025-11-05 01:15:33,652] Trial 1995 pruned. 
[I 2025-11-05 01:15:43,531] Trial 1996 pruned. 
[I 2025-11-05 01:16:07,439] Trial 1997 pruned. 
[I 2025-11-05 01:16:31,180] Trial 1998 pruned. 
[I 2025-11-05 01:16:38,248] Trial 1999 pruned. 
2025-11-05 01:16:38,331 - INFO - Optuna study complete. Best trial: 124
2025-11-05 01:16:38,411 - INFO - Best Loss: 0.0014025710088954345
2025-11-05 01:16:38,434 - INFO - Best Params: {'batch_size': 64, 'learning_rate': 0.0004941338722825084, 'nr_hidden_layers': 2, 'nr_neurons': 211, 'dropout_rate': 0.000634511537600873, 'weight_decay': 0.001615577890788605, 'activation_name': 'LeakyReLU', 'loss_criterion': 'SmoothL1'}
2025-11-05 01:16:38,434 - INFO - Training final model with best parameters...
2025-11-05 01:16:38,457 - INFO - Starting main training for labels ['Iso_distance']...
2025-11-05 01:16:39,541 - INFO - Final training: 47896 train samples, 11975 val samples, 25660 test samples.
2025-11-05 01:16:39,544 - INFO - Using SmoothL1Loss (Huber Loss)
2025-11-05 01:16:39,544 - INFO - Using CosineAnnealingLR with T_max=1000
2025-11-05 01:16:39,551 - INFO - Starting final training loop for max 1000 epochs (Patience=25)...
2025-11-05 01:16:41,133 - INFO - Epoch [1/1000], Train Loss: 0.007528, Val Loss: 0.004025, LR: 0.000494
2025-11-05 01:16:41,135 - INFO - New best model found at epoch 1 with val_loss: 0.004025
2025-11-05 01:16:42,728 - INFO - New best model found at epoch 2 with val_loss: 0.001738
2025-11-05 01:16:45,906 - INFO - New best model found at epoch 4 with val_loss: 0.001050
2025-11-05 01:16:47,502 - INFO - New best model found at epoch 5 with val_loss: 0.000854
2025-11-05 01:16:49,096 - INFO - New best model found at epoch 6 with val_loss: 0.000707
2025-11-05 01:16:50,691 - INFO - New best model found at epoch 7 with val_loss: 0.000466
2025-11-05 01:16:52,278 - INFO - New best model found at epoch 8 with val_loss: 0.000333
2025-11-05 01:16:53,869 - INFO - New best model found at epoch 9 with val_loss: 0.000320
2025-11-05 01:16:55,457 - INFO - New best model found at epoch 10 with val_loss: 0.000195
2025-11-05 01:16:58,653 - INFO - New best model found at epoch 12 with val_loss: 0.000173
2025-11-05 01:17:00,246 - INFO - New best model found at epoch 13 with val_loss: 0.000147
2025-11-05 01:17:09,696 - INFO - New best model found at epoch 18 with val_loss: 0.000070
2025-11-05 01:17:20,830 - INFO - New best model found at epoch 25 with val_loss: 0.000063
2025-11-05 01:17:28,783 - INFO - New best model found at epoch 30 with val_loss: 0.000044
2025-11-05 01:17:30,382 - INFO - New best model found at epoch 31 with val_loss: 0.000033
2025-11-05 01:17:43,116 - INFO - New best model found at epoch 39 with val_loss: 0.000031
2025-11-05 01:17:44,708 - INFO - New best model found at epoch 40 with val_loss: 0.000026
2025-11-05 01:17:54,234 - INFO - New best model found at epoch 46 with val_loss: 0.000021
2025-11-05 01:18:00,586 - INFO - Epoch [50/1000], Train Loss: 0.000048, Val Loss: 0.000027, LR: 0.000491
2025-11-05 01:18:11,731 - INFO - New best model found at epoch 57 with val_loss: 0.000017
2025-11-05 01:18:14,915 - INFO - New best model found at epoch 59 with val_loss: 0.000016
2025-11-05 01:18:27,660 - INFO - New best model found at epoch 67 with val_loss: 0.000015
2025-11-05 01:18:46,726 - INFO - New best model found at epoch 79 with val_loss: 0.000011
2025-11-05 01:18:54,682 - INFO - New best model found at epoch 84 with val_loss: 0.000011
2025-11-05 01:18:57,869 - INFO - New best model found at epoch 86 with val_loss: 0.000010
2025-11-05 01:19:15,346 - INFO - New best model found at epoch 97 with val_loss: 0.000009
2025-11-05 01:19:20,122 - INFO - Epoch [100/1000], Train Loss: 0.000023, Val Loss: 0.000016, LR: 0.000482
2025-11-05 01:19:21,713 - INFO - New best model found at epoch 101 with val_loss: 0.000009
2025-11-05 01:19:31,269 - INFO - New best model found at epoch 107 with val_loss: 0.000008
2025-11-05 01:19:56,634 - INFO - New best model found at epoch 121 with val_loss: 0.000007
2025-11-05 01:20:20,511 - INFO - New best model found at epoch 136 with val_loss: 0.000006
2025-11-05 01:20:42,820 - INFO - Epoch [150/1000], Train Loss: 0.000015, Val Loss: 0.000006, LR: 0.000467
2025-11-05 01:20:42,822 - INFO - New best model found at epoch 150 with val_loss: 0.000006
2025-11-05 01:21:01,948 - INFO - New best model found at epoch 162 with val_loss: 0.000005
2025-11-05 01:21:38,652 - INFO - New best model found at epoch 185 with val_loss: 0.000004
2025-11-05 01:22:02,479 - INFO - Epoch [200/1000], Train Loss: 0.000014, Val Loss: 0.000004, LR: 0.000447
2025-11-05 01:22:02,480 - INFO - New best model found at epoch 200 with val_loss: 0.000004
2025-11-05 01:22:18,402 - INFO - New best model found at epoch 210 with val_loss: 0.000004
2025-11-05 01:22:42,421 - INFO - New best model found at epoch 225 with val_loss: 0.000004
2025-11-05 01:22:59,950 - INFO - New best model found at epoch 236 with val_loss: 0.000004
2025-11-05 01:23:07,895 - INFO - New best model found at epoch 241 with val_loss: 0.000003
2025-11-05 01:23:22,201 - INFO - Epoch [250/1000], Train Loss: 0.000009, Val Loss: 0.000005, LR: 0.000422
2025-11-05 01:23:25,383 - INFO - New best model found at epoch 252 with val_loss: 0.000003
2025-11-05 01:23:49,220 - INFO - New best model found at epoch 267 with val_loss: 0.000003
2025-11-05 01:23:50,814 - INFO - New best model found at epoch 268 with val_loss: 0.000003
2025-11-05 01:24:09,959 - INFO - New best model found at epoch 280 with val_loss: 0.000003
2025-11-05 01:24:41,775 - INFO - Epoch [300/1000], Train Loss: 0.000006, Val Loss: 0.000003, LR: 0.000392
2025-11-05 01:24:43,356 - INFO - New best model found at epoch 301 with val_loss: 0.000003
2025-11-05 01:25:19,875 - INFO - New best model found at epoch 324 with val_loss: 0.000003
2025-11-05 01:25:26,214 - INFO - New best model found at epoch 328 with val_loss: 0.000002
2025-11-05 01:26:01,132 - INFO - Epoch [350/1000], Train Loss: 0.000007, Val Loss: 0.000003, LR: 0.000359
2025-11-05 01:26:05,889 - INFO - Early stopping at epoch 353.
2025-11-05 01:26:05,889 - INFO - Training complete. Evaluating on test set...
2025-11-05 01:26:06,203 - INFO - Final Test Loss (SmoothL1): 0.000002
2025-11-05 01:26:06,203 - INFO - Inverting transforms and generating plots...
2025-11-05 01:26:06,205 - INFO - Calculating final metrics...
2025-11-05 01:26:06,210 - INFO - Final Test MAE: 3.634718
2025-11-05 01:26:06,210 - INFO - Final Test RMSE: 7.985631
2025-11-05 01:26:06,210 - INFO - Final Test R2: 0.999722
2025-11-05 01:26:06,211 - INFO - Final Test MEDAE: 1.133514
2025-11-05 01:26:06,211 - INFO - Final Test MAPE: 0.012746
2025-11-05 01:26:06,211 - INFO - Final Test REL_ERR_STD: 0.018267
2025-11-05 01:26:06,211 - INFO - Final Test REL_ERR_MEAN_ABS: 0.012746
2025-11-05 01:26:06,914 - INFO - Logging plots to tensorboard...
2025-11-05 01:26:07,071 - INFO - Main training function finished.
2025-11-05 01:26:07,077 - INFO - Final model saved to runs/run_20251104-144116_['Iso_distance']/final_model/best_model.pt
2025-11-05 01:26:07,077 - INFO - --- Run complete ---
2025-11-05 01:26:07,077 - INFO - To view Optuna results: optuna-dashboard sqlite:///runs/optuna_study.db
2025-11-05 01:26:07,077 - INFO - To view TensorBoard logs: tensorboard --logdir runs/run_20251104-144116_['Iso_distance']/
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [64, 1]                   --
ModuleList: 1-7                        --                        (recursive)
    Linear: 2-1                       [64, 211]                 2,110
    LeakyReLU: 2-2                    [64, 211]                 --
Dropout: 1-2                           [64, 211]                 --
ModuleList: 1-7                        --                        (recursive)
    Linear: 2-3                       [64, 211]                 44,732
    LeakyReLU: 2-4                    [64, 211]                 --
Dropout: 1-4                           [64, 211]                 --
ModuleList: 1-7                        --                        (recursive)
    Linear: 2-5                       [64, 211]                 44,732
    LeakyReLU: 2-6                    [64, 211]                 --
Dropout: 1-6                           [64, 211]                 --
ModuleList: 1-7                        --                        (recursive)
    Linear: 2-7                       [64, 1]                   212
==========================================================================================
Total params: 91,786
Trainable params: 91,786
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 5.87
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.32
Params size (MB): 0.37
Estimated Total Size (MB): 0.69
==========================================================================================
Job finished.

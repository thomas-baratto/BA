Job started on argon-gtx
Job ID: 524
Working directory: /home/barattts/lavoltabuona/BA
---
Starting Python script...
Running: python run_optuna.py --target Area --skip-optuna
2025-11-06 16:52:58,222 - INFO - Using device: cuda
2025-11-06 16:52:58,223 - INFO - Target labels for this run: ['Area']
2025-11-06 16:52:58,223 - INFO - Skip Optuna: True
2025-11-06 16:52:58,223 - INFO - Skipping Optuna. Loading best parameters from study: nn_study_['Area']...
2025-11-06 16:52:59,248 - INFO - Loaded best parameters from trial 333:
2025-11-06 16:52:59,274 - INFO - Best value (RMSE): 0.0009757127058634517
2025-11-06 16:52:59,274 - INFO - Parameters: {'batch_size': 64, 'learning_rate': 0.001372335074817238, 'nr_hidden_layers': 2, 'nr_neurons': 230, 'dropout_rate': 8.943741579532514e-05, 'weight_decay': 0.00021732207759797098, 'activation_name': 'GELU', 'loss_criterion': 'MSE'}
2025-11-06 16:52:59,274 - INFO - Training final model with parameters...
2025-11-06 16:52:59,274 - INFO - Starting main training for labels ['Area']...
2025-11-06 16:53:00,348 - INFO - Final training: 47896 train samples, 11975 val samples, 25660 test samples.
/home/barattts/lavoltabuona/BA/.venv/daicheelavoltabuona/lib/python3.12/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
2025-11-06 16:53:00,711 - INFO - Using MSELoss
2025-11-06 16:53:03,049 - INFO - Using CosineAnnealingLR with T_max=1000
2025-11-06 16:53:03,139 - INFO - Starting final training loop for max 1000 epochs (Patience=25)...
2025-11-06 16:53:04,946 - INFO - Epoch [1/1000], Train Loss: 0.011154, Val Loss: 0.007909, LR: 0.001372
2025-11-06 16:53:04,947 - INFO - New best model found at epoch 1 with val_loss: 0.007909
2025-11-06 16:53:06,599 - INFO - New best model found at epoch 2 with val_loss: 0.004087
2025-11-06 16:53:08,189 - INFO - New best model found at epoch 3 with val_loss: 0.002156
2025-11-06 16:53:09,741 - INFO - New best model found at epoch 4 with val_loss: 0.001907
2025-11-06 16:53:11,322 - INFO - New best model found at epoch 5 with val_loss: 0.001673
2025-11-06 16:53:12,934 - INFO - New best model found at epoch 6 with val_loss: 0.001133
2025-11-06 16:53:14,551 - INFO - New best model found at epoch 7 with val_loss: 0.000487
2025-11-06 16:53:17,647 - INFO - New best model found at epoch 9 with val_loss: 0.000273
2025-11-06 16:53:20,705 - INFO - New best model found at epoch 11 with val_loss: 0.000149
2025-11-06 16:53:23,750 - INFO - New best model found at epoch 13 with val_loss: 0.000128
2025-11-06 16:53:28,462 - INFO - New best model found at epoch 16 with val_loss: 0.000082
2025-11-06 16:53:33,214 - INFO - New best model found at epoch 19 with val_loss: 0.000073
2025-11-06 16:53:34,798 - INFO - New best model found at epoch 20 with val_loss: 0.000063
2025-11-06 16:53:56,490 - INFO - New best model found at epoch 34 with val_loss: 0.000044
2025-11-06 16:54:02,867 - INFO - New best model found at epoch 38 with val_loss: 0.000032
2025-11-06 16:54:17,292 - INFO - New best model found at epoch 47 with val_loss: 0.000023
2025-11-06 16:54:22,101 - INFO - Epoch [50/1000], Train Loss: 0.000065, Val Loss: 0.000252, LR: 0.001364
2025-11-06 16:54:41,322 - INFO - New best model found at epoch 62 with val_loss: 0.000022
2025-11-06 16:54:58,939 - INFO - New best model found at epoch 73 with val_loss: 0.000019
2025-11-06 16:55:14,742 - INFO - New best model found at epoch 82 with val_loss: 0.000008
2025-11-06 16:55:22,700 - INFO - New best model found at epoch 87 with val_loss: 0.000006
2025-11-06 16:55:45,127 - INFO - Epoch [100/1000], Train Loss: 0.000025, Val Loss: 0.000028, LR: 0.001339
2025-11-06 16:56:05,057 - INFO - Early stopping at epoch 112.
2025-11-06 16:56:05,057 - INFO - Training complete. Evaluating on test set...
2025-11-06 16:56:05,372 - INFO - Final Test Loss (MSE): 0.000007
2025-11-06 16:56:05,373 - INFO - Inverting transforms and generating plots...
2025-11-06 16:56:05,374 - INFO - Calculating final metrics...
2025-11-06 16:56:05,380 - INFO - Final Test MAE (unscaled): 547.088257
2025-11-06 16:56:05,380 - INFO - Final Test RMSE (unscaled): 1628.712769
2025-11-06 16:56:05,381 - INFO - Final Test R2 (unscaled): 0.998522
2025-11-06 16:56:05,381 - INFO - Final Test MEDAE (unscaled): 42.602051
2025-11-06 16:56:05,381 - INFO - Final Test MAPE (unscaled): 0.025873
2025-11-06 16:56:05,381 - INFO - Final Test REL_ERR_STD (unscaled): 0.058645
2025-11-06 16:56:05,381 - INFO - Final Test REL_ERR_MEAN_ABS (unscaled): 0.025873
2025-11-06 16:56:06,249 - INFO - Logging scatter plots to tensorboard...
2025-11-06 16:56:06,399 - INFO - Main training function finished.
2025-11-06 16:56:06,404 - INFO - Final model saved to runs/run_20251106-165258_['Area']/final_model/best_model.pt
2025-11-06 16:56:06,404 - INFO - --- Run complete ---
2025-11-06 16:56:06,405 - INFO - To view Optuna results: optuna-dashboard sqlite:///runs/optuna_study.db
2025-11-06 16:56:06,405 - INFO - To view TensorBoard logs: tensorboard --logdir runs/run_20251106-165258_['Area']/
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [64, 1]                   --
├─ModuleList: 1-7                        --                        (recursive)
│    └─Linear: 2-1                       [64, 230]                 2,300
│    └─GELU: 2-2                         [64, 230]                 --
├─Dropout: 1-2                           [64, 230]                 --
├─ModuleList: 1-7                        --                        (recursive)
│    └─Linear: 2-3                       [64, 230]                 53,130
│    └─GELU: 2-4                         [64, 230]                 --
├─Dropout: 1-4                           [64, 230]                 --
├─ModuleList: 1-7                        --                        (recursive)
│    └─Linear: 2-5                       [64, 230]                 53,130
│    └─GELU: 2-6                         [64, 230]                 --
├─Dropout: 1-6                           [64, 230]                 --
├─ModuleList: 1-7                        --                        (recursive)
│    └─Linear: 2-7                       [64, 1]                   231
==========================================================================================
Total params: 108,791
Trainable params: 108,791
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 6.96
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.35
Params size (MB): 0.44
Estimated Total Size (MB): 0.79
==========================================================================================
Job finished.
